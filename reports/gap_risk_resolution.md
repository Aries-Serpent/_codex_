# Gap → Risk → Resolution Register — 2025-10-05 Alignment

This register translates the open items from the 2025-10-05 status update into
actionable containment plans and records which mitigations have already landed
in the repository.

| Capability | Gap | Risk | Containment / Resolution | Source | Status | Notes |
| --- | --- | --- | --- | --- | --- | --- |
| Tokenization | SentencePiece adapters and padding/truncation guidance were missing from the original tokenizer surface. | Advanced models could diverge because tokens were encoded inconsistently across runs. | Ship a `SentencePieceTokenizer` adapter and expose encode/decode helpers that support padding and truncation through the CLI. | `reports/_codex_status_update-2025-10-05.md` §2.2【F:reports/_codex_status_update-2025-10-05.md†L52-L52】 | closed | Implemented via `SentencePieceTokenizer` and CLI utilities, providing deterministic loading and padding controls.【F:src/codex_ml/tokenization/adapter.py†L137-L210】【F:src/codex_ml/tokenization/cli.py†L51-L104】 |
| Logging & Monitoring | System metrics were not captured by default, leaving CPU/GPU visibility absent. | Operators lacked telemetry to debug resource saturation. | Add a `log_system_metrics` toggle in `TrainingRunConfig` and a collector that wraps `psutil`/`pynvml` with graceful degradation. | `reports/_codex_status_update-2025-10-05.md` §2.2【F:reports/_codex_status_update-2025-10-05.md†L57-L57】 | closed | Training now records optional metrics through the config flags and `codex_ml.utils.system_metrics.collect_metrics`.【F:src/codex_ml/training/__init__.py†L90-L156】【F:src/codex_ml/utils/system_metrics.py†L1-L65】 |
| Checkpointing & Resume | No retention policy or compressed saves were enforced for checkpoints. | Long runs risked exhausting disk space and restoring stale states. | Introduce keep-last pruning, RNG restoration, and zipped Torch checkpoint emission alongside checksum manifests. | `reports/_codex_status_update-2025-10-05.md` §2.2【F:reports/_codex_status_update-2025-10-05.md†L58-L58】 | closed | `TrainingRunConfig.keep_last_n` and the checkpoint manager now prune old epochs and persist metadata/seeds with `_use_new_zipfile_serialization`.【F:src/codex_ml/training/__init__.py†L112-L138】【F:src/codex_ml/utils/checkpointing.py†L200-L258】【F:src/codex_ml/utils/checkpointing.py†L747-L893】 |
| Configuration Management | Central YAML defaults were absent, forcing environment-variable driven overrides. | Misconfiguration could erode reproducibility for auditors. | Establish Hydra-readable defaults that encode baseline training, logging, and retention behaviour. | `reports/_codex_status_update-2025-10-05.md` §2.2【F:reports/_codex_status_update-2025-10-05.md†L55-L55】 | closed | Default Hydra manifests now live under `configs/`, covering seeds, schedulers, and logging toggles for repeatable runs.【F:configs/default.yaml†L1-L22】【F:configs/base.yaml†L1-L27】 |
| ChatGPT Codex Modeling | Heavy-model loading and LoRA validation remain minimal beyond the `minilm` example. | Larger models may silently downgrade to minimal shims with unverified LoRA hooks. | Implement guarded Hugging Face `AutoModel` loading and add LoRA selection tests before enabling advanced presets. | `reports/_codex_status_update-2025-10-05.md` §2.2【F:reports/_codex_status_update-2025-10-05.md†L53-L53】 | open | Still pending; track integration work alongside targeted regression tests for LoRA parameter routing. |
| Security & Safety | No offline SBOM generation or moderation fallback was supplied beyond heuristic filters. | Supply-chain drift or harmful completions could escape detection. | Add an offline SBOM pipeline and introduce a moderation adapter with an offline stub to enforce policy checks. | `reports/_codex_status_update-2025-10-05.md` §2.2【F:reports/_codex_status_update-2025-10-05.md†L60-L60】 | open | Capture requirements for SBOM tooling and moderation adapters in the upcoming security-focused run. |
| Deployment | Container build artefacts and packaging scripts were not part of the repo. | "Works on my machine" scenarios make repeatable deployment difficult. | Produce an offline-friendly Dockerfile/Makefile pair that reuses the pinned lockfiles for reproducible builds. | `reports/_codex_status_update-2025-10-05.md` §2.2【F:reports/_codex_status_update-2025-10-05.md†L62-L62】 | open | Align container work with the deployment plan once dependency graph stabilises. |
