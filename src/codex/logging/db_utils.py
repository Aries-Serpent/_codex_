"""Helpers for discovering SQLite schemas used by logging.

Auto-generated by ``.codex/run_db_utils_workflow.py``. Functions in this module
open SQLite databases, inspect available tables and columns, and infer likely
names used for common logging fields. The code is intentionally lightweight and
avoids triggering any GitHub Actions or network access.
"""

# Constraint: DO NOT ACTIVATE ANY GitHub Actions files.
# ruff: noqa: E501,E701,E702

from __future__ import annotations

import os
import sqlite3
try:
    from codex.db.sqlite_patch import auto_enable_from_env as _codex_sqlite_auto
    _codex_sqlite_auto()
except Exception:
    pass
from typing import Dict, List, Optional

# Common column name variants seen in repo/README and typical SQLite logs.
LIKELY_MAP = {
    "session_id": ["session_id", "sid", "session"],
    "timestamp": ["timestamp", "ts", "event_ts", "created_at"],
    "message": ["message", "content", "text", "body"],
    "level": ["level", "severity", "log_level"],
    "role": ["role", "speaker", "source"],
}


def open_db(
    path: Optional[str] = None, env_keys=("CODEX_DB_PATH", "CODEX_LOG_DB_PATH")
) -> sqlite3.Connection:
    """
    Open a SQLite DB at `path` or from known env vars; if none exist, attempt common paths.
    """
    if path and path.strip():
        return sqlite3.connect(path)
    for k in env_keys:
        v = os.getenv(k)
        if v and v.strip():
            return sqlite3.connect(v)
    # Probe a few common locations used within this repository
    for guess in (
        "data/codex.db",
        "data/logs.sqlite",
        ".codex/session_logs.db",
        "logs.db",
    ):
        if os.path.exists(guess):
            return sqlite3.connect(guess)
    # Fallback to an in-memory database so callers can still operate
    return sqlite3.connect(":memory:")


def list_tables(con: sqlite3.Connection) -> List[str]:
    cur = con.execute("SELECT name FROM sqlite_master WHERE type='table'")
    return [r[0] for r in cur.fetchall()]


def get_columns(con: sqlite3.Connection, table: str) -> List[str]:
    cur = con.execute(f"PRAGMA table_info({table})")
    return [r[1] for r in cur.fetchall()]


def _first_match(columns: List[str], candidates: List[str]) -> Optional[str]:
    cols_lower = [c.lower() for c in columns]
    for cand in candidates:
        if cand.lower() in cols_lower:
            return columns[cols_lower.index(cand.lower())]
    return None


def infer_probable_table(
    con: sqlite3.Connection, candidates=("session_events", "logs", "events", "messages")
) -> Optional[str]:
    tables = list_tables(con)
    if not tables:
        return None
    # Prefer an exact candidate match when possible
    for c in candidates:
        if c in tables:
            return c
    # Otherwise score tables by how many known columns they contain
    best = None
    best_score = -1
    for t in tables:
        cols = get_columns(con, t)
        score = 0
        for k, cand in LIKELY_MAP.items():
            score += 1 if _first_match(cols, cand) else 0
        if score > best_score:
            best, best_score = t, score
    return best


def infer_columns(con: sqlite3.Connection, table: str) -> Dict[str, Optional[str]]:
    cols = get_columns(con, table) if table else []
    mapping = {}
    for logical, cands in LIKELY_MAP.items():
        mapping[logical] = _first_match(cols, cands)
    return mapping
