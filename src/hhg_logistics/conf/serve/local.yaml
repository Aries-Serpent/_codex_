serve:
  enabled: false
  host: "127.0.0.1"
  port: 8000
  route_prefix: "/"
  num_replicas: 1
  timeout_s: 30
  batching:
    enabled: true
    max_batch_size: 8
    timeout_ms: 20
  model:
    source: "adapters"
    adapters_dir: ${data.models_dir}/baseline
    pretrained: ${model.pretrained}
  generate:
    max_new_tokens: 32
    do_sample: false
    temperature: 0.7
    top_p: 0.95
    top_k: null
  logging:
    enable_request_log: true
    metrics_dir: .codex/metrics
    filename_prefix: "serve"
