# BEGIN: HYDRA_ROOT_CONFIG
# Root Hydra configuration for codex_ml
defaults:
  - env: ubuntu
  - model: base
  - data: base
  - logging: base
  - training: base
  - tokenization: base
  - tracking: base
  - pipeline_inputs: smoke

env:
  name: ubuntu

logging:
  level: INFO

output_dir: ${oc.env:CODEX_OUTPUT_DIR, "runs/default"}

eval:
  datasets: []
  metrics: []

train:
  epochs: 3
  lr: 3e-4
  batch_size: 8

tokenizer:
  name: gpt2
  use_fast: true

pipeline:
  steps: ["pipeline"]
  inputs: ${pipeline_inputs}
  summary_path: ${pipeline_inputs.summary_path}
  log_summary: ${pipeline_inputs.log_summary}
  seed: ${pipeline_inputs.seed}

symbolic_pipeline:
  enabled: false

trainer:
  lora_r: 0
  lora_alpha: 16
  lora_dropout: 0.0
  precision: fp32
  checkpoint_dir: null
  save_steps: 100

dry_run: false

wandb:
  enable: false

mlflow:
  enable: false
  tracking_uri: ./mlruns
  experiment: codex

tensorboard:
  logdir: ./runs
