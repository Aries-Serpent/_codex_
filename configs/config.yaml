# BEGIN: HYDRA_ROOT_CONFIG
# Root Hydra configuration for codex_ml
defaults:
  - env: ubuntu

env:
  name: ubuntu

logging:
  level: INFO

output_dir: ${oc.env:CODEX_OUTPUT_DIR, "runs/default"}

eval:
  datasets: []
  metrics: []

train:
  epochs: 3
  lr: 3e-4
  batch_size: 8

tokenizer:
  name: gpt2
  use_fast: true

output_dir: ${oc.env:CODEX_OUTPUT_DIR, "runs/default"}

eval:
  datasets: []
  metrics: []

pipeline:
  steps: ["load_data", "tokenize", "train", "evaluate"]

output_dir: ./outputs

eval:
  datasets: []
  metrics: []

symbolic_pipeline:
  enabled: false

trainer:
  lora_r: null
  lora_alpha: 16
  precision: fp32
  checkpoint_dir: null
  save_steps: 100

dry_run: false

wandb:
  enable: false

mlflow:
  enable: false
  tracking_uri: ./mlruns
  experiment: codex

tensorboard:
  logdir: ./runs
