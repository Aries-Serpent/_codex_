defaults:
  - model: base
  - training: base
  - data: tiny
  - _self_

# High-level aliases for backwards compatibility and CLI overrides
model_name: ${model.name}
tokenizer_name: ${model.tokenizer_name}
dataset_path: ${data.dataset_path}
epochs: ${training.epochs}
batch_size: ${training.batch_size}
learning_rate: ${training.learning_rate}
gradient_accumulation_steps: ${training.gradient_accumulation_steps}
mixed_precision: ${training.mixed_precision}
seed: ${training.seed}
deterministic: true
use_lora: ${model.lora.enabled}
lora_rank: ${model.lora.r}
lora_alpha: ${model.lora.alpha}
device: ${model.device}
dtype: ${model.dtype}
checkpoint_dir: ${training.checkpoint.directory}
keep_best_k: ${training.checkpoint.best_k}

logging:
  enable_tensorboard: ${training.logging.enable_tensorboard}
  enable_mlflow: ${training.logging.enable_mlflow}
  enable_wandb: false
