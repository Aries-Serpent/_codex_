# Tokenizer defaults aligned with TokenizationConfig
# Path globs and hyperparameters are intentionally lightweight so the
# configuration can be overridden per experiment using Hydra dotlists.
tokenization:
  corpus_glob: data/tokenizer/*.txt
  model_type: unigram
  vocab_size: 32000
  character_coverage: 0.9995
  normalization_rule: null
  seed: 42
  workers: 4
  out_dir: artifacts/tokenizers/default
  name: default
  stream_chunk_size: null
  padding: max_length
  truncation: true
  max_length: null
  dry_run: false
  stream_chunk_size: null
