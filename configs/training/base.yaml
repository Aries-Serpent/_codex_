seed: 42
learning_rate: 0.0003
batch_size: 32
max_epochs: 5
scheduler: linear
warmup_steps: 0
gradient_accumulation: 1
tensorboard: true
mlflow_enable: false
model: minilm
output_dir: runs/default
training:
  seed: 42
  lr: 0.0003
  batch_size: 32
  epochs: 5
  grad_accum: 1
  warmup_steps: 0
  save_every: 50
  log_every: 10
  checkpoint_dir: runs/default/checkpoints
  texts: []
  val_texts: []
logging:
  enable_tensorboard: true
  mlflow_enable: false
hf_trainer:
  output_dir: runs/default
  num_train_epochs: 5
  per_device_train_batch_size: 32
  per_device_eval_batch_size: 32
  learning_rate: 0.0003
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  logging_steps: 10
  save_steps: 50
  evaluation_strategy: steps
  eval_steps: 50
  fp16: false
  lora:
    enable: false
    r: 4
    alpha: 16
    dropout: 0.1
  privacy:
    enabled: false
    noise_multiplier: 1.0
    max_grad_norm: 1.0
    target_delta: 1.0e-05
    accountant: rdp
