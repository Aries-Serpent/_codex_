# Codex Automation Change Log

## Phase 1: Preparation
- Identified repository root at `/workspace/_codex_`.
- Verified `.github/workflows/` remains untouched.
- Reviewed `README.md` (1327 lines) to understand capabilities and noted references to missing configs such as `configs/training/base.yaml`.


### Phase 2: Search & Mapping

#### Module capability map
- **tokenization** (11 files)
  - src/codex_ml/tokenization/__init__.py
  - src/codex_ml/tokenization/adapter.py
  - src/codex_ml/tokenization/cli.py
  - src/codex_ml/tokenization/hf_tokenizer.py
  - src/codex_ml/tokenization/sentencepiece_adapter.py
  - src/codex_ml/tokenization/train_tokenizer.py
  - src/tokenization/.gitkeep
  - src/tokenization/__init__.py
  - src/tokenization/cli.py
  - src/tokenization/sentencepiece_adapter.py
- **training** (6 files)
  - src/codex/training.py
  - src/codex/training.py01
  - src/codex_ml/training/__init__.py
  - src/codex_ml/training/callbacks.py
  - src/codex_ml/training/functional_training.py
  - src/utils/training_callbacks.py
- **safety** (6 files)
  - src/codex_ml/safety/__init__.py
  - src/codex_ml/safety/filters.py
  - src/codex_ml/safety/risk_score.py
  - src/codex_ml/safety/sandbox.py
  - src/codex_ml/safety/sanitizers.py
  - src/safety/.gitkeep
- **monitoring** (20 files)
  - src/codex/logging/__init__.py
  - src/codex/logging/config.py
  - src/codex/logging/conversation_logger.py
  - src/codex/logging/db_utils.py
  - src/codex/logging/export.py
  - src/codex/logging/fetch_messages.py
  - src/codex/logging/import_ndjson.py
  - src/codex/logging/query_logs.py
  - src/codex/logging/session_hooks.py
  - src/codex/logging/session_logger.py
- **data** (12 files)
  - src/codex_ml/data/__init__.py
  - src/codex_ml/data/cache.py
  - src/codex_ml/data/cli.py
  - src/codex_ml/data/hf_datasets.py
  - src/codex_ml/data/loader.py
  - src/codex_ml/data/loaders.py
  - src/codex_ml/data/registry.py
  - src/codex_ml/data/sharding.py
  - src/codex_ml/data/splits.py
  - src/codex_ml/data_utils.py
- **cli** (11 files)
  - src/codex/cli.py
  - src/codex_ml/cli/__init__.py
  - src/codex_ml/cli/__main__.py
  - src/codex_ml/cli/audit_pipeline.py
  - src/codex_ml/cli/codex_cli.py
  - src/codex_ml/cli/generate.py
  - src/codex_ml/cli/infer.py
  - src/codex_ml/cli/main.py
  - src/codex_ml/cli/plugins_cli.py
  - src/codex_ml/cli/validate.py
- **evaluation** (5 files)
  - src/codex_ml/eval/__init__.py
  - src/codex_ml/eval/eval_runner.py
  - src/codex_ml/eval/evaluator.py
  - src/codex_ml/eval/metrics.py
  - src/codex_ml/eval/run_eval.py
- **models** (9 files)
  - src/codex_ml/models/__init__.py
  - src/codex_ml/models/activations.py
  - src/codex_ml/models/decoder_only.py
  - src/codex_ml/models/generate.py
  - src/codex_ml/models/minilm.py
  - src/codex_ml/models/registry.py
  - src/codex_ml/reward_models/__init__.py
  - src/codex_ml/reward_models/rlhf.py
  - src/codex_ml/reward_models/simple.py
- **other** (77 files)
  - src/__init__.py
  - src/codex/__init__.py
  - src/codex/chat.py
  - src/codex/db/sqlite_patch.py
  - src/codex/monkeypatch/log_adapters.py
  - src/codex/search/__init__.py
  - src/codex/search/providers.py
  - src/codex/utils/__init__.py
  - src/codex/utils/subprocess.py
  - src/codex_ml/__init__.py

#### Stub references
- codex_setup.py:238: # If user passes raw text, wrap into a JSON record with message
- AUDIT_PROMPT.md:24: - Identify stubs (TODO, NotImplementedError, pass, placeholders) and unimplemented areas.
- CHANGELOG_CODEX.md:264: - Pin `peft` dependency to ensure `nox -s tests` passes.
- CHANGELOG_CODEX.md:267: - Conformed to local gates (pre-commit/Black/isort/tests), Codex-only (no GitHub Actions). - Ensure test dependencies (i
- CHANGELOG_CODEX.md:285: - Generated gaps report for TODOs and stubs.
- CHANGELOG_CODEX.md:293: - Pin `peft` dependency to ensure `nox -s tests` passes.
- CHANGELOG_CODEX.md:296: - Conformed to local gates (pre-commit/Black/isort/tests), Codex-only (no GitHub Actions). - Ensure test dependencies (i
- CHANGELOG_CODEX.md:314: - Generated gaps report for TODOs and stubs.
- codex_script.py:519: bad = ["password","api_key","ssn","rm -rf /","kill","drop database"]
- codex_script.py:585: {"cell_type":"markdown","metadata":{},"source":["# GPU Training Example (Stub)\n","TODO: Fill with end-to-end training d
- codex_ast_upgrade.py:119: pass
- codex_ast_upgrade.py:125: pass
- codex_ast_upgrade.py:131: pass
- codex_ast_upgrade.py:201: pass
- codex_ast_upgrade.py:248: raise NotImplementedError
- codex_ast_upgrade.py:263: pass
- codex_ast_upgrade.py:267: def __init__(self): pass
- codex_ast_upgrade.py:382: pass
- CODEBASE_AUDIT_2025-08-26_203612.md:26: - Keywords: TODO, FIXME, TBD, NotImplementedError, pass (empty bodies), raise NotImplementedError
- CODEBASE_AUDIT_2025-08-26_203612.md:196: +                pass
- CODEBASE_AUDIT_2025-08-26_203612.md:342: +            pass
- CODEBASE_AUDIT_2025-08-26_203612.md:370: +passenv =
- CODEBASE_AUDIT_2025-08-26_203612.md:385: - 5 passed, 0 skipped in 0.42s, coverage 85% (codex_utils)
- codex_digest/tokenizer.py:20: raise NotImplementedError
- codex_digest/tokenizer.py:67: pass
- codex_digest/tokenizer.py:69: pass
- docs/gaps_report.md:3: - codex_script.py:534: TODO
- docs/gaps_report.md:4: - codex_ast_upgrade.py:248: NotImplementedError
- docs/gaps_report.md:5: - .codex/codex_repo_scout.py:238: TODO
- docs/gaps_report.md:6: - .codex/codex_repo_scout.py:266: TODO
- docs/gaps_report.md:7: - .codex/codex_repo_scout.py:335: TODO
- docs/gaps_report.md:8: - .codex/codex_repo_scout.py:268: NotImplementedError
- docs/gaps_report.md:9: - .codex/codex_repo_scout.py:315: NotImplementedError
- docs/gaps_report.md:10: - .codex/run_repo_scout.py:236: TODO
- docs/gaps_report.md:11: - .codex/run_repo_scout.py:253: TODO
- docs/gaps_report.md:12: - .codex/run_repo_scout.py:258: TODO
- docs/gaps_report.md:13: - .codex/run_repo_scout.py:263: TODO
- docs/gaps_report.md:14: - .codex/run_repo_scout.py:263: TODO
- docs/gaps_report.md:15: - .codex/run_repo_scout.py:264: TODO
- docs/gaps_report.md:16: - .codex/run_repo_scout.py:248: NotImplementedError
- docs/gaps_report.md:17: - codex_digest/tokenizer.py:20: NotImplementedError
- docs/gaps_report.md:18: - scripts/run_codex_tasks.py:9: TODO
- docs/gaps_report.md:19: - scripts/run_codex_tasks.py:61: TODO
- docs/gaps_report.md:20: - scripts/run_codex_tasks.py:62: TODO
- docs/gaps_report.md:21: - scripts/run_codex_tasks.py:62: TODO
- docs/gaps_report.md:22: - scripts/run_codex_tasks.py:101: TODO
- docs/gaps_report.md:23: - scripts/run_codex_tasks.py:61: NotImplementedError
- docs/gaps_report.md:24: - scripts/run_codex_tasks.py:62: NotImplementedError
- docs/gaps_report.md:25: - scripts/run_codex_tasks.py:62: pass  # TODO
- docs/gaps_report.md:26: - tests/test_offline_repo_auditor.py:9: TODO
- docs/gaps_report.md:27: - tests/test_offline_repo_auditor.py:31: TODO
- docs/gaps_report.md:28: - tests/test_offline_repo_auditor.py:16: NotImplementedError
- docs/gaps_report.md:29: - tests/test_session_logging.py:106: NotImplementedError
- docs/gaps_report.md:30: - tests/test_interfaces_compat.py:28: TODO
- docs/gaps_report.md:31: - tests/test_interfaces_compat.py:42: TODO
- docs/gaps_report.md:32: - tests/test_interfaces_compat.py:52: TODO
- docs/gaps_report.md:33: - tests/test_interfaces_compat.py:106: TODO
- docs/gaps_report.md:34: - tests/test_interfaces_compat.py:107: TODO
- docs/gaps_report.md:35: - tools/apply_ci_precommit.py:14: TODO
- docs/gaps_report.md:36: - tools/offline_repo_auditor.py:8: TODO
- docs/gaps_report.md:37: - tools/offline_repo_auditor.py:71: TODO
- docs/gaps_report.md:38: - tools/offline_repo_auditor.py:8: NotImplementedError
- docs/gaps_report.md:39: - tools/offline_repo_auditor.py:74: NotImplementedError
- docs/gaps_report.md:40: - tools/offline_repo_auditor.py:75: NotImplementedError
- docs/gaps_report.md:41: - tools/apply_hydra_scaffold.py:155: TODO
- docs/gaps_report.md:42: - tools/codex_exec.py:90: TODO
- docs/gaps_report.md:43: - tools/codex_exec.py:90: TODO
- docs/gaps_report.md:44: - tools/codex_exec.py:92: TODO
- docs/gaps_report.md:45: - tools/codex_exec.py:90: NotImplementedError
- docs/gaps_report.md:46: - tools/apply_interfaces.py:214: TODO
- docs/gaps_report.md:47: - tools/apply_interfaces.py:227: TODO
- docs/gaps_report.md:48: - tools/apply_interfaces.py:236: TODO
- docs/gaps_report.md:49: - tools/apply_interfaces.py:287: TODO
- docs/gaps_report.md:50: - tools/apply_interfaces.py:288: TODO
- docs/gaps_report.md:51: - tools/apply_interfaces.py:296: TODO
- docs/gaps_report.md:52: - tools/apply_interfaces.py:95: NotImplementedError
- docs/gaps_report.md:53: - tools/apply_interfaces.py:104: NotImplementedError
- docs/gaps_report.md:54: - tools/apply_interfaces.py:109: NotImplementedError
- docs/gaps_report.md:55: - tools/apply_interfaces.py:114: NotImplementedError
- docs/gaps_report.md:56: - tools/apply_interfaces.py:119: NotImplementedError
- docs/gaps_report.md:57: - tools/apply_interfaces.py:135: NotImplementedError
- docs/gaps_report.md:58: - tools/apply_interfaces.py:148: NotImplementedError
- docs/gaps_report.md:59: - tools/apply_interfaces.py:164: NotImplementedError
- docs/gaps_report.md:60: - tools/apply_interfaces.py:169: NotImplementedError
- docs/gaps_report.md:61: - tools/apply_interfaces.py:174: NotImplementedError
- docs/gaps_report.md:62: - tools/apply_interfaces.py:179: NotImplementedError
- docs/gaps_report.md:63: - tools/apply_stack_polish.py:553: TODO
- docs/gaps_report.md:64: - tools/codex_patch_session_logging.py:182: NotImplementedError
- docs/gaps_report.md:65: - tools/codex_patch_session_logging.py:281: NotImplementedError
- docs/gaps_report.md:66: - tools/codex_workflow_executor.py:52: TODO
- docs/gaps_report.md:67: - tools/codex_workflow_executor.py:54: TODO
- docs/gaps_report.md:68: - tools/codex_workflow_executor.py:54: TODO
- docs/gaps_report.md:69: - tools/codex_workflow_executor.py:65: TODO
- docs/gaps_report.md:70: - tools/codex_workflow_executor.py:70: TODO
- docs/gaps_report.md:71: - src/codex_ml/pipeline.py:33: NotImplementedError
- docs/gaps_report.md:72: - src/codex_ml/pipeline.py:39: NotImplementedError
- docs/gaps_report.md:73: - src/codex_ml/analysis/providers.py:17: NotImplementedError
- docs/gaps_report.md:74: - src/codex_ml/interfaces/tokenizer.py:51: NotImplementedError
- docs/gaps_report.md:75: - src/codex_ml/interfaces/tokenizer.py:70: NotImplementedError
- docs/gaps_report.md:76: - src/codex_ml/interfaces/tokenizer.py:80: NotImplementedError
- docs/gaps_report.md:77: - src/codex_ml/interfaces/reward_model.py:20: NotImplementedError
- docs/gaps_report.md:78: - src/codex_ml/interfaces/reward_model.py:38: NotImplementedError
- docs/gaps_report.md:79: - src/codex_ml/interfaces/rl.py:14: NotImplementedError
- docs/gaps_report.md:80: - src/codex_ml/interfaces/rl.py:19: NotImplementedError
- docs/gaps_report.md:81: - src/codex_ml/interfaces/rl.py:24: NotImplementedError
- docs/gaps_report.md:82: - src/codex_ml/interfaces/rl.py:29: NotImplementedError
- docs/gaps_report.md:83: - src/codex_ml/tracking/writers.py:12: NotImplementedError
- docs/ephemeral-runners.md:48: - `CODEX_RUNNER_TOKEN` – optional **registration token** to pass directly to `config.sh`.
- docs/deep_research_prompts.md:1: # Deep Research Prompts for Repository TODOs
- docs/deep_research_prompts.md:3: This document enumerates all current TODO comments in the repository and provides suggested prompts for ChatGPT-5 Deep R
- docs/deep_research_prompts.md:8: - **TODO:** Implement real step handlers; currently the pipeline simply reports success.
- docs/deep_research_prompts.md:14: - **TODO:** Fill the GPU training example with an end-to-end demo.
- docs/deep_research_prompts.md:20: - **TODO:** Supply constructor kwargs where needed when instantiating Tokenizer, RewardModel, and RLAgent implementation
- docs/deep_research_prompts.md:21: - **Research Prompt:** "For each interface (TokenizerAdapter, RewardModel, RLAgent), determine the minimal constructor p
- docs/deep_research_prompts.md:26: - **TODOs:**
- docs/deep_research_prompts.md:27: - Update tests to pass minimal viable config if implementations require constructor arguments.
- docs/deep_research_prompts.md:34: - **TODO:** Replace placeholder `yourpkg.tokenizers.hf:HFTokenizer` with actual module and class names.
- docs/deep_research_prompts.md:40: - **TODO:** README badges still reference a TODO repository slug.
- docs/deep_research_prompts.md:46: - **TODO:** Wire `peft.get_peft_model(model, LoraConfig(**cfg))` into `apply_lora`.
- docs/status_update_prompt.md:104: - [ ] Tests passing (`nox -s tests`): {{tests_status}}
- docs/dynamical-system.md:53: Define projectors (pass = 1, fail = 0):
- docs/dynamical-system.md:154: G(θ) |R_T⟩ = |R_T⟩       (all gates pass at final time),
- docs/dynamical-system.md:202: Interpretation: no pending edits, no error channels active, all gates passing.
- docs/ops/RUNBOOK.md:21: ruff check src tests && ruff format --check .     # pass=Π_lint ✓   [oai_citation:0‡Astral Docs](https://docs.astral.sh/
- docs/ops/RUNBOOK.md:24: pytest -q --cov --cov-fail-under=70               # pass=Π_tests ⋂ Π_cov ✓   [oai_citation:1‡pytest-cov](https://pytest-
- docs/ops/RUNBOOK.md:27: pyright                                            # pass=Π_types ✓
- docs/ops/RUNBOOK.md:52: * **Quality gate projector** $\mathcal P_G$: filter onto passing subspace.
- docs/ops/RUNBOOK.md:59: | Gate (projector)                  | Definition (what must pass) | Minimal local command                               
- docs/ops/RUNBOOK.md:61: | $\Pi_{\text{lint}}$               | Code style & lint pass      | `ruff check src tests && ruff format --check .` (Ruf
- docs/ops/RUNBOOK.md:64: | $\Pi_{\text{types}}$ *(optional)* | Type checks pass            | `pyright` (if configured in the repo).              
- docs/ops/RUNBOOK.md:66: **Strict vs soft gating.** For release builds, use strict pass/fail (treat the projector as Lüders post-selection). For 
- docs/ops/RUNBOOK.md:75: 4. **Patch:** commit when all active gates pass.
- docs/ops/training_args.md:15: To resume from a saved run, pass `resume_from=/path/to/checkpoint`.
- docs/ops/training_args.md:42: Each validation pass appends a line to `metrics.json`:
- codex_utils/ndjson.py:22: pass
- codex_utils/repro.py:50: pass
- codex_utils/repro.py:79: pass
- tools/codex_task_runner.py:156: pass
- tools/codex_task_runner.py:163: pass
- tools/codex_task_runner.py:211: pass
- tools/codex_task_runner.py:213: pass
- tools/codex_task_runner.py:259: pass_filenames: false
- tools/monitoring_integrate.py:173: pass
- tools/monitoring_integrate.py:293: pass
- tools/monitoring_integrate.py:352: pass
- tools/monitoring_integrate.py:358: pass
- tools/monitoring_integrate.py:363: pass
- tools/apply_hydra_scaffold.py:153: # TODO: Implement real step handlers; here we simulate success
- tools/apply_hydra_scaffold.py:188: # You can pass overrides, e.g. train.epochs=2 tokenizer.name=gpt2
- tools/git_patch_parser_complete.py:327: pass
- tools/answer_codex_questions.py:15: return """Root cause: strict mode treats warnings as errors; nav had missing/dup paths. Fix: set `strict: false` for thi
- tools/answer_codex_questions.py:19: return """Root cause: coverage deps not present or too strict thresholds. Fix: install coverage/pytest-cov; if still fai
- tools/apply_mlflow_tracking.py:289: pass
- tools/install_codex_hooks.py:57: pass
- tools/codex_import_normalizer.py:103: pass
- tools/codex_import_normalizer.py:206: # attempt another fix pass
- tools/codex_exec.py:86: pass
- tools/codex_exec.py:90: out = sh(["bash", "-lc", 'rg -n "TODO|NotImplementedError" || true'], "Phase 2: scan TODOs")
- tools/codex_exec.py:92: append_changelog("- scan: TODO/NotImplemented present; see ripgrep output in local logs")
- tools/apply_patch_safely.py:69: pass
- tools/codex_execute_audit.py:196: pass
- tools/codex_src_consolidation.py:436: # pass proves duplication.
- tools/apply_ml_metrics.py:215: Returns a summary dict: {{passed, failed, errors}}.
- tools/apply_ml_metrics.py:224: passed = len(re.findall(r"\\b(\\d+) passed\\b", out)) and int(re.findall(r"\\b(\\d+) passed\\b", out)[-1]) or 0
- tools/apply_ml_metrics.py:227: return {{"passed": passed, "failed": failed, "errors": errors}}
- tools/codex_logging_workflow.py:176: pass
- tools/codex_run_tasks.py:96: pass
- tools/codex_run_tasks.py:272: Variable arguments passed to run_task
- tools/codex_run_tasks.py:327: # If the caller passed unexpected args, bubble up a non-zero code
- tools/apply_interfaces.py:95: raise NotImplementedError
- tools/apply_interfaces.py:104: raise NotImplementedError
- tools/apply_interfaces.py:109: raise NotImplementedError
- tools/apply_interfaces.py:114: raise NotImplementedError
- tools/apply_interfaces.py:119: raise NotImplementedError
- tools/apply_interfaces.py:135: raise NotImplementedError
- tools/apply_interfaces.py:148: raise NotImplementedError
- tools/apply_interfaces.py:164: raise NotImplementedError
- tools/apply_interfaces.py:169: raise NotImplementedError
- tools/apply_interfaces.py:174: raise NotImplementedError
- tools/apply_interfaces.py:179: raise NotImplementedError
- tools/apply_interfaces.py:329: path: yourpkg.tokenizers.hf:HFTokenizer   # TODO: replace with actual module:class
- tools/codex_seq_runner.py:135: pattern = r"except Exception:\n\s*pass"
- tools/codex_seq_runner.py:233: record_changelog("- pre-commit: passed.")
- tools/codex_seq_runner.py:241: record_changelog("- pytest: passed.")
- tools/codex_workflow_executor.py:52: # --- README normalization: remove placeholder badges and inline TODOs
- tools/codex_workflow_executor.py:54: TODO_LINE = re.compile(r"^.*\bTODO\b.*$", re.I)
- tools/codex_workflow_executor.py:65: if TODO_LINE.search(ln):
- tools/codex_workflow_executor.py:70: log_change("README: removed placeholder badges / TODO lines")
- tools/codex_workflow_executor.py:111: log_change("Local gates passed (pre-commit, pytest)")
- tools/apply_ci_precommit.py:14: - README.md (badges with TODO repo slug)
- tools/codex_apply_modeling_monitoring_api.py:174: pass
- tools/codex_apply_modeling_monitoring_api.py:182: pass
- tools/codex_apply_modeling_monitoring_api.py:189: pass
- tools/codex_apply_modeling_monitoring_api.py:231: pass
- tools/codex_apply_modeling_monitoring_api.py:241: pass
- tools/codex_apply_modeling_monitoring_api.py:296: pass
- tools/codex_apply_modeling_monitoring_api.py:301: pass
- tools/codex_apply_modeling_monitoring_api.py:309: pass
- tools/codex_apply_modeling_monitoring_api.py:339: pass
- tools/codex_apply_modeling_monitoring_api.py:346: pass
- tools/codex_apply_modeling_monitoring_api.py:354: pass
- tools/codex_apply_modeling_monitoring_api.py:372: pass
- tools/codex_apply_modeling_monitoring_api.py:379: pass
- tools/codex_apply_modeling_monitoring_api.py:388: pass
- tools/codex_apply_modeling_monitoring_api.py:395: pass
- tools/codex_apply_modeling_monitoring_api.py:415: pass
- tools/codex_coverage_booster.py:225: def __init__(self): pass
- tools/codex_coverage_booster.py:230: pass
- tools/codex_coverage_booster.py:313: pass
- tools/run_supplied_task.py:226: # Runtime guard (defense-in-depth) in case argparse wiring is bypassed:
- tools/codex_run.py:69: return OK, "pre-commit passed"
- tools/codex_run.py:81: return OK, "tests with coverage passed"
- tools/codex_run.py:85: return WARN, "tests passed without coverage"
- tools/codex_patch_exec.py:80: # Optional: pass eval_dataset if available
- tools/codex_patch_exec.py:225: log_change("edit", run, "pass --gpus all when available", RUN_GPU)
- tools/runner_doctor.py:4: All operations default to --dry-run; pass --apply to perform cleanup.
- tools/apply_stack_polish.py:471: bad = ["password","api_key","ssn","rm -rf /","kill","drop database"]
- tools/apply_stack_polish.py:553: {"cell_type":"markdown","metadata":{},"source":["# GPU Training Example (Stub)\n","TODO: Fill with end-to-end training d
- tools/codex_patch_session_logging.py:5: `except Exception: pass` near lines 60–68 with observable handling that
- tools/codex_patch_session_logging.py:176: r"(^[ \t]*)except\s+Exception(?:\s+as\s+\w+)?\s*:\s*\n" r"([ \t]*)pass\b",
- tools/codex_patch_session_logging.py:182: {indent2}if isinstance(e, (ImportError, AttributeError, NotImplementedError)):
- tools/codex_patch_session_logging.py:187: def patch_except_pass(
- tools/codex_patch_session_logging.py:192: return src, False, "No `except Exception: pass` pattern found."
- tools/codex_patch_session_logging.py:221: return new_src, True, "Patched `except Exception: pass` with logging + skip/fail."
- tools/codex_patch_session_logging.py:271: patched, did_patch, msg = patch_except_pass(after, prefer_range=(60, 68))
- tools/codex_patch_session_logging.py:273: patched, did_patch, msg = patch_except_pass(after, prefer_range=None)
- tools/codex_patch_session_logging.py:281: "(ImportError/AttributeError/NotImplementedError) and otherwise fail."
- tools/codex_patch_session_logging.py:283: add_change(TARGET_REL, "Patch except-pass", rationale, before, patched)
- tools/codex_patch_session_logging.py:293: log_error("3.2", "Patch except-pass", msg, TARGET)
- tools/codex_patch_session_logging.py:318: f"- Patched `{TARGET_REL}` to replace `except Exception: pass` with logging + skip/fail."
- tools/offline_repo_auditor.py:8: - Detects stubs (TODO/FIXME/TBD, NotImplementedError, pass placeholders)
- tools/offline_repo_auditor.py:71: r"\bTODO\b",
- tools/offline_repo_auditor.py:74: r"NotImplementedError",
- tools/offline_repo_auditor.py:75: r"\braise\s+NotImplementedError\b",
- tools/offline_repo_auditor.py:76: r"^\s*pass\s*(#.*)?$",
- tools/offline_repo_auditor.py:171: pass
- tools/unify_logging_canonical.py:279: lines.append("- None removed in this pass (wrappers retained for back-compat).")
- tools/codex_sqlite_align.py:30: pass
- tools/export_to_parquet.py:53: pass
- tests/test_tokenizer.py:10: pass
- tests/test_export.py:41: @pytest.mark.parametrize("session_id", ["..", "a b", "abc!", "../../etc/passwd"])
- tests/test_engine_hf_trainer.py:148: def test_run_hf_trainer_passes_resume_from(monkeypatch, tmp_path):
- tests/test_engine_hf_trainer.py:191: pass
- tests/test_offline_repo_auditor.py:9: # TODO: implement training loop
- tests/test_offline_repo_auditor.py:13: pass
- tests/test_offline_repo_auditor.py:16: raise NotImplementedError("later")
- tests/test_offline_repo_auditor.py:31: assert any("TODO" in f.line for f in summary.stubs)
- tests/test_chat_session_exit.py:20: pass
- tests/test_chat_session.py:86: pass
- tests/test_interface_loader_env.py:12: pass
- tests/test_model_loader.py:12: - Proper parameter passing to underlying transformers calls
- tests/test_model_loader.py:43: # Verify kwargs are passed through appropriately
- tests/test_model_loader.py:147: Verify that custom kwargs are properly passed through to the underlying
- tests/test_model_loader.py:169: # Verify custom kwargs were passed through
- tests/test_model_loader.py:217: def test_device_map_passes_through(monkeypatch):
- tests/test_mlflow_utils.py:95: pass
- tests/test_train_loop.py:126: pass
- tests/test_sentencepiece_adapter.py:86: # Capture what was passed for later inspection
- tests/test_sentencepiece_adapter.py:91: # If adapter passed a single string like "--model_prefix=prefix --vocab_size=8"
- tests/test_sentencepiece_adapter.py:350: pass for the reported size and fail for larger requirements.
- tests/test_session_hooks.py:117: "    pass\n"
- tests/test_hf_trainer_lora_config.py:7: def test_run_hf_trainer_passes_lora_params(monkeypatch, tmp_path):
- tests/test_checkpoint_checksum.py:113: # Verify integrity check passes
- tests/test_checkpoint_checksum.py:135: # Verify integrity check passes when no checksum file exists
- tests/test_checkpoint_checksum.py:153: # Verify integrity check passes (wrong file name is ignored)
- tests/test_query_logs_build_query.py:82: pass
- tests/test_query_logs_build_query.py:93: pass
- tests/test_query_logs_build_query.py:246: pass
- tests/test_query_logs_build_query.py:282: pass
- tests/test_query_logs_build_query.py:302: pass
- tests/test_query_logs_build_query.py:314: pass
- tests/test_safety.py:10: text = "please share your password and run rm -rf / after using API_KEY=XYZ"
- tests/test_safety.py:14: assert "{REDACTED}" in red or "password" not in red.lower()
- tests/test_codex_run_tasks.py:93: pass
- tests/test_mlflow_utils_root.py:78: pass
- tests/_codex_introspect.py:123: pass
- tests/test_logging_bootstrap.py:23: pass
- tests/test_registry.py:10: pass
- tests/test_registry.py:18: pass
- tests/test_registry.py:25: pass
- tests/test_session_logging.py:106: if isinstance(e, (ImportError, AttributeError, NotImplementedError)):
- tests/test_session_logging.py:157: pass
- tests/test_session_logging.py:207: pass
- tests/test_model_forward.py:1: """MiniLM forward pass shape test."""
- tests/connectors/test_registry.py:15: pass
- tests/utils/test_modeling.py:36: pass
- tests/utils/test_checkpointing.py:22: pass
- tests/plugins/test_registry_basic.py:9: pass
- tests/plugins/test_registry_basic.py:22: pass
- tests/plugins/test_registry_basic.py:26: pass
- tests/plugins/test_entry_point_collision.py:27: pass
- tests/eval/test_run_unit_tests.py:17: assert summary == {"passed": 0, "failed": 0, "errors": 2}
- tests/gates/test_quality_gates.py:68: pass
- tests/tokenization/test_tokenizer_cli.py:43: pass
- tests/monitoring/test_mlflow_monitoring_utils.py:52: """Test explicit enabled flag bypasses environment check."""
- tests/monitoring/test_sampler_multi_gpu.py:10: pass
- tests/monitoring/test_sampler_multi_gpu.py:13: pass
- tests/monitoring/test_monitoring_mlflow_utils.py:52: """Test explicit enabled flag bypasses environment check."""
- tests/monitoring/test_codex_logging_offline.py:15: pass
- tests/monitoring/test_logging_bootstrap_initialization.py:15: pass
- tests/monitoring/test_codex_logging_cfg.py:15: pass
- tests/monitoring/test_engine_bootstrap.py:64: pass
- tests/cli/test_infer_cli_lora.py:10: def test_infer_passes_lora_args(monkeypatch, tmp_path: Path) -> None:
- tests/interfaces/test_tokenizer_hf.py:245: pass
- tests/interfaces/test_get_component_env_var.py:6: module_path.write_text("class Dummy:\n    pass\n")
- tests/safety/test_risk_score.py:9: assert risk_score("leak password please") > 0.5
- tests/safety/test_license_checker.py:12: def test_license_checker_pass(monkeypatch):
- tests/tracking/test_composite_writer_degrades.py:13: pass
- tests/telemetry/test_instrumentation.py:6: pass
- tests/telemetry/test_metrics_server.py:14: pass
- tests/training/test_functional_training_main.py:62: pass
- tests/training/test_functional_training_main.py:108: def test_main_passes_lora_config(monkeypatch, tmp_path: Path):
- tests/training/test_strict_determinism.py:39: def test_passes_when_deterministic(monkeypatch, tmp_path):
- tests/training/test_strict_determinism.py:95: def test_hf_trainer_passes_when_deterministic(monkeypatch, tmp_path):
- src/utils/trackers.py:28: pass
- src/codex/cli.py:77: pass
- src/codex/cli.py:109: pass
- src/codex/cli.py:115: pass
- src/codex/cli.py:270: pass
- src/codex/cli.py:309: pass
- src/codex/training.py:119: pass
- src/codex/training.py:131: pass
- src/codex/training.py:285: # Back-compat: also pass a derived legacy use_scheduler flag
- src/codex/training.py:815: pass
- src/codex/training.py:825: pass
- src/codex/training.py:832: pass
- src/codex/training.py:927: pass
- src/codex/training.py:935: pass
- src/codex/db/sqlite_patch.py:61: pass
- src/codex/db/sqlite_patch.py:135: pass
- src/codex/logging/session_hooks.py:79: pass
- src/codex/logging/session_logger.py:108: pass
- src/codex/logging/session_logger.py:156: pass
- src/codex/logging/session_logger.py:163: pass
- src/codex/logging/session_logger.py:167: pass
- src/codex/logging/session_logger.py:171: pass
- src/codex/logging/session_logger.py:175: pass
- src/codex/logging/session_logger.py:338: pass
- src/codex/logging/import_ndjson.py:53: pass
- src/codex/logging/import_ndjson.py:127: pass
- src/codex/logging/fetch_messages.py:45: pass
- src/codex/logging/db_utils.py:24: pass
- src/codex/logging/db_utils.py:49: pass
- src/codex/logging/db_utils.py:58: pass
- src/codex/logging/db_utils.py:72: pass
- src/codex/logging/db_utils.py:79: pass
- src/codex/logging/export.py:35: pass
- src/codex/logging/conversation_logger.py:27: pass
- src/codex/logging/conversation_logger.py:36: pass
- src/codex/logging/query_logs.py:41: pass
- src/codex_ml/data_utils.py:80: pass
- src/codex_ml/data_utils.py:93: pass
- src/codex_ml/data_utils.py:112: pass
- src/codex_ml/pipeline.py:33: ``NotImplementedError`` is raised to signal missing real
- src/codex_ml/pipeline.py:39: raise NotImplementedError("Real training pipeline not implemented")
- src/codex_ml/config_schema.py:50: # Existing callers import `validate_config` and may pass either a mapping or a path.
- src/codex_ml/connectors/base.py:8: raise NotImplementedError
- src/codex_ml/connectors/base.py:11: raise NotImplementedError
- src/codex_ml/connectors/base.py:14: raise NotImplementedError
- src/codex_ml/utils/determinism.py:83: pass
- src/codex_ml/utils/determinism.py:88: pass
- src/codex_ml/utils/checkpointing.py:135: pass
- src/codex_ml/utils/checkpointing.py:178: pass
- src/codex_ml/utils/checkpointing.py:216: pass
- src/codex_ml/utils/checkpointing.py:227: pass
- src/codex_ml/utils/provenance.py:61: pass
- src/codex_ml/utils/provenance.py:67: pass
- src/codex_ml/utils/error_log.py:9: pass
- src/codex_ml/utils/error_log.py:36: pass
- src/codex_ml/utils/error_log.py:50: pass
- src/codex_ml/utils/repro.py:49: pass
- src/codex_ml/utils/repro.py:55: pass
- src/codex_ml/models/registry.py:40: The function operates in **offline** mode by passing
- src/codex_ml/models/registry.py:107: pass
- src/codex_ml/models/registry.py:113: pass
- src/codex_ml/plugins/registry.py:122: pass
- src/codex_ml/eval/metrics.py:137: Returns a summary dict: {passed, failed, errors}.
- src/codex_ml/eval/metrics.py:153: "passed": _count(r"\b(\d+)\s+passed\b"),
- src/codex_ml/analysis/registry.py:35: pass
- src/codex_ml/analysis/extractors.py:108: pass
- src/codex_ml/analysis/parsers.py:36: pass
- src/codex_ml/analysis/parsers.py:42: pass
- src/codex_ml/analysis/parsers.py:48: pass
- src/codex_ml/analysis/providers.py:17: raise NotImplementedError
- src/codex_ml/analysis/providers.py:37: pass
- src/codex_ml/analysis/providers.py:43: pass
- src/codex_ml/tokenization/adapter.py:47: raise NotImplementedError("SentencePieceTokenizer is not implemented yet")
- src/codex_ml/tokenization/adapter.py:104: raise NotImplementedError("SentencePieceTokenizer is not implemented yet")
- src/codex_ml/tokenization/adapter.py:107: raise NotImplementedError
- src/codex_ml/tokenization/adapter.py:110: raise NotImplementedError
- src/codex_ml/tokenization/adapter.py:113: raise NotImplementedError
- src/codex_ml/tokenization/adapter.py:116: raise NotImplementedError
- src/codex_ml/monitoring/codex_logging.py:17: pass
- src/codex_ml/monitoring/codex_logging.py:166: pass
- src/codex_ml/monitoring/codex_logging.py:271: pass
- src/codex_ml/monitoring/codex_logging.py:341: pass
- src/codex_ml/monitoring/codex_logging.py:370: pass
- src/codex_ml/monitoring/codex_logging.py:376: pass
- src/codex_ml/monitoring/codex_logging.py:382: pass
- src/codex_ml/cli/main.py:59: pass
- src/codex_ml/cli/plugins_cli.py:70: pass
- src/codex_ml/cli/audit_pipeline.py:107: pass
- src/codex_ml/interfaces/registry.py:39: pass
- src/codex_ml/interfaces/tokenizer.py:51: raise NotImplementedError
- src/codex_ml/interfaces/tokenizer.py:70: raise NotImplementedError
- src/codex_ml/interfaces/tokenizer.py:80: raise NotImplementedError
- src/codex_ml/interfaces/tokenizer.py:141: Model or tokenizer identifier to pass to AutoTokenizer.from_pretrained.
- src/codex_ml/interfaces/rl.py:14: raise NotImplementedError
- src/codex_ml/interfaces/rl.py:19: raise NotImplementedError
- src/codex_ml/interfaces/rl.py:24: raise NotImplementedError
- src/codex_ml/interfaces/rl.py:29: raise NotImplementedError
- src/codex_ml/interfaces/reward_model.py:20: raise NotImplementedError
- src/codex_ml/interfaces/reward_model.py:38: raise NotImplementedError
- src/codex_ml/peft/peft_adapter.py:10: - Unified defaults with the ability to pass a configuration mapping and/or
- src/codex_ml/peft/peft_adapter.py:114: pass
- src/codex_ml/peft/peft_adapter.py:128: pass
- src/codex_ml/peft/peft_adapter.py:136: pass
- src/codex_ml/safety/risk_score.py:24: "password": 1.0,
- src/codex_ml/safety/sandbox.py:70: for tag in ["password", "api_key", "secret", "AKIA"]:
- src/codex_ml/safety/filters.py:42: re.compile(r"(?i)password\s*[:=]"),
- src/codex_ml/safety/filters.py:48: re.compile(r"(?i)test(_|-)?password"),
- src/codex_ml/safety/filters.py:106: pass
- src/codex_ml/tracking/writers.py:12: raise NotImplementedError
- src/codex_ml/tracking/writers.py:15: pass
- src/codex_ml/tracking/writers.py:61: pass
- src/codex_ml/tracking/writers.py:92: pass
- src/codex_ml/tracking/writers.py:124: pass
- src/codex_ml/tracking/mlflow_utils.py:250: pass
- src/codex_ml/tracking/mlflow_utils.py:290: By default this only writes the file locally; pass ``enabled=True`` to also
- src/codex_ml/metrics/registry.py:207: pass
- src/codex_ml/data/loaders.py:68: pass
- src/ingestion/encoding_detect.py:97: pass
- src/ingestion/io_text.py:51: pass
- src/ingestion/io_text.py:101: - errors: error handling strategy passed to bytes.decode() (default "strict").
- src/ingestion/io_text.py:151: pass
- src/ingestion/__init__.py:93: pass
- src/ingestion/__init__.py:98: pass
- src/ingestion/__init__.py:115: pass
- src/ingestion/__init__.py:203: pass
- src/ingestion/__init__.py:230: pass
- src/ingestion/utils.py:89: pass
- src/ingestion/utils.py:130: pass
- src/ingestion/utils.py:187: pass
- src/ingestion/utils.py:257: pass
- src/ingestion/utils.py:309: pass
- src/ingestion/utils.py:319: Some older callers used the name `read_text_file` and passed encoding; keep
- scripts/deep_research_task_process.py:526: echo "$CR_PAT" | docker login ghcr.io -u $GITHUB_ACTOR --password-stdin
- scripts/deep_research_task_process.py:784: "                pass\n"
- scripts/deep_research_task_process.py:788: "                pass\n"
- scripts/apply_session_logging_workflow.py:23: pass
- scripts/apply_session_logging_workflow.py:375: pass
- scripts/run_codex_tasks.py:9: 2. Scanning the repository for TODOs, stubs, and missing implementations.
- scripts/run_codex_tasks.py:60: """Scan repository files for TODOs, NotImplementedError, and pass statements."""
- scripts/run_codex_tasks.py:61: patterns = [r"TODO", r"NotImplementedError", r"pass  # TODO"]
- scripts/run_codex_tasks.py:100: "- Generated gaps report for TODOs and stubs.\n"
- .venv/lib/python3.12/site-packages/isympy.py:153: Additionally you can pass command line options directly to the IPython
- .venv/lib/python3.12/site-packages/typing_extensions.py:321: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:337: class Disjoint1: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:340: class Disjoint2: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:342: class Disjoint3(Disjoint1, Disjoint2): pass  # Type checker error
- .venv/lib/python3.12/site-packages/typing_extensions.py:402: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:481: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:619: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:623: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:672: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:888: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:897: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:906: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:915: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:923: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:934: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:945: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:1227: raise NotImplementedError(format)
- .venv/lib/python3.12/site-packages/typing_extensions.py:1267: "Failing to pass a value for the 'fields' parameter"
- .venv/lib/python3.12/site-packages/typing_extensions.py:1276: "using the functional syntax, pass an empty dictionary, e.g. "
- .venv/lib/python3.12/site-packages/typing_extensions.py:1488: - If no dict arguments are passed, an attempt is made to use the
- .venv/lib/python3.12/site-packages/typing_extensions.py:1493: - If one dict argument is passed, it is used for both globals and
- .venv/lib/python3.12/site-packages/typing_extensions.py:1496: - If two dict arguments are passed, they specify globals and
- .venv/lib/python3.12/site-packages/typing_extensions.py:1684: # PEP 695 implemented (3.12+), can pass infer_variance to typing.TypeVar
- .venv/lib/python3.12/site-packages/typing_extensions.py:1792: # PEP 695 implemented, can pass infer_variance to typing.TypeVar
- .venv/lib/python3.12/site-packages/typing_extensions.py:1928: # Hack to get typing._type_check to pass.
- .venv/lib/python3.12/site-packages/typing_extensions.py:1930: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:1971: # Hack to get typing._type_check to pass in Generic.
- .venv/lib/python3.12/site-packages/typing_extensions.py:1973: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:2355: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:2847: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:2872: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:2893: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:2897: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:2916: The deprecation message passed to the decorator is saved in the
- .venv/lib/python3.12/site-packages/typing_extensions.py:3249: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:3319: # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
- .venv/lib/python3.12/site-packages/typing_extensions.py:3354: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:3413: deprecated_thing = "Failing to pass a value for the 'fields' parameter"
- .venv/lib/python3.12/site-packages/typing_extensions.py:3419: "pass an empty list, e.g. "
- .venv/lib/python3.12/site-packages/typing_extensions.py:3424: "Cannot pass `None` as the 'fields' parameter "
- .venv/lib/python3.12/site-packages/typing_extensions.py:3434: "pass an empty list, e.g. "
- .venv/lib/python3.12/site-packages/typing_extensions.py:3678: # Unpack Backport passes isinstance(type_param, TypeVar)
- .venv/lib/python3.12/site-packages/typing_extensions.py:3857: The string value passed is available in the attribute ``documentation``.
- .venv/lib/python3.12/site-packages/typing_extensions.py:3885: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:4052: pass
- .venv/lib/python3.12/site-packages/typing_extensions.py:4081: # If we pass None to eval() below, the globals of this module are used.
- .venv/lib/python3.12/site-packages/nodeenv.py:83: pass
- .venv/lib/python3.12/site-packages/_virtualenv.py:81: pass  # C-Extension loaders are r/o such as zipimporter with <3.7
- .venv/lib/python3.12/site-packages/cfgv.py:49: pass
- .venv/lib/python3.12/site-packages/cfgv.py:320: pass
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:9: names being passed into the API.
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:73: # capture these to bypass sandboxing
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:118: _ResourceStream: TypeAlias = Any  # TODO / Incomplete: A readable file-like object
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:211: pass
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:404: and `provider_factory` is a function that, passed a *module* object,
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:458: pass
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:889: if not req_extras.markers_pass(req, extras):
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:1123: def markers_pass(self, req: Requirement, extras: tuple[str, ...] | None = None):
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:1451: _bypass_ensure_directory(target_path)
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:1473: #  bypass the warning.
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:1752: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:1757: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:1762: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:1855: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:1944: pass
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:2039: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:2268: handler), and `distribution_finder` is a callable that, passed a path
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:2383: pass
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:2774: # We could pass `env` and `installer` directly,
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:2799: # then resolve them. We have to pass `extras` along when resolving so
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:3334: # TODO: remove this except clause when python/cpython#103632 is fixed.
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:3440: pass
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:3543: def _bypass_ensure_directory(path) -> None:
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:3544: """Sandbox-bypassing version of ensure_directory()"""
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:3549: _bypass_ensure_directory(dirname)
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:3553: pass
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:3585: # temporarily bypass sandboxing
- .venv/lib/python3.12/site-packages/pkg_resources/__init__.py:3635: # TODO: Add a deadline?
- .venv/lib/python3.12/site-packages/pkg_resources/tests/test_pkg_resources.py:273: # Also check the args passed to the ValueError.
- .venv/lib/python3.12/site-packages/pkg_resources/tests/test_pkg_resources.py:346: pass
- .venv/lib/python3.12/site-packages/pkg_resources/tests/test_resources.py:240: markers should pass for bar without extras.
- .venv/lib/python3.12/site-packages/pkg_resources/tests/test_resources.py:245: assert req_extras.markers_pass(req)
- .venv/lib/python3.12/site-packages/pkg_resources/tests/test_resources.py:250: assert req_extras.markers_pass(req)
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:62: pass
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:66: pass
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:70: pass
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:263: pass
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:304: pass
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:314: pass
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:711: pass
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:1343: pass
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:1902: pass
- .venv/lib/python3.12/site-packages/regex/_regex_core.py:4450: pass
- .venv/lib/python3.12/site-packages/regex/test_regex.py:851: class my_unicode(str): pass
- .venv/lib/python3.12/site-packages/regex/regex.py:275: backslash escapes in it are processed; if a callable, it's passed the match
- .venv/lib/python3.12/site-packages/regex/regex.py:285: it's treated as a format string; if a callable, it's passed the match object
- .venv/lib/python3.12/site-packages/regex/regex.py:297: are processed; if a callable, it's passed the match object and must return a
- .venv/lib/python3.12/site-packages/regex/regex.py:309: string; if a callable, it's passed the match object and must return a
- .venv/lib/python3.12/site-packages/regex/regex.py:456: pass
- .venv/lib/python3.12/site-packages/regex/regex.py:506: pass
- .venv/lib/python3.12/site-packages/regex/regex.py:639: pass
- .venv/lib/python3.12/site-packages/distlib/index.py:49: self.password_handler = None
- .venv/lib/python3.12/site-packages/distlib/index.py:55: # prompting for passwords
- .venv/lib/python3.12/site-packages/distlib/index.py:64: pass
- .venv/lib/python3.12/site-packages/distlib/index.py:77: ``username``, ``password``, ``realm`` and ``url`` attributes from the
- .venv/lib/python3.12/site-packages/distlib/index.py:83: self.password = cfg.get('password')
- .venv/lib/python3.12/site-packages/distlib/index.py:90: ``password`` attributes before calling this method.
- .venv/lib/python3.12/site-packages/distlib/index.py:98: Check that ``username`` and ``password`` have been set, and raise an
- .venv/lib/python3.12/site-packages/distlib/index.py:101: if self.username is None or self.password is None:
- .venv/lib/python3.12/site-packages/distlib/index.py:102: raise DistlibException('username and password must be set')
- .venv/lib/python3.12/site-packages/distlib/index.py:105: pm.add_password(self.realm, netloc, self.username, self.password)
- .venv/lib/python3.12/site-packages/distlib/index.py:106: self.password_handler = HTTPBasicAuthHandler(pm)
- .venv/lib/python3.12/site-packages/distlib/index.py:146: def get_sign_command(self, filename, signer, sign_password, keystore=None):  # pragma: no cover
- .venv/lib/python3.12/site-packages/distlib/index.py:152: :param sign_password: The passphrase for the signer's
- .venv/lib/python3.12/site-packages/distlib/index.py:158: passed to :class:`subprocess.Popen`.
- .venv/lib/python3.12/site-packages/distlib/index.py:165: if sign_password is not None:
- .venv/lib/python3.12/site-packages/distlib/index.py:166: cmd.extend(['--batch', '--passphrase-fd', '0'])
- .venv/lib/python3.12/site-packages/distlib/index.py:176: Run a command in a child process , passing it any input data specified.
- .venv/lib/python3.12/site-packages/distlib/index.py:209: def sign_file(self, filename, signer, sign_password, keystore=None):  # pragma: no cover
- .venv/lib/python3.12/site-packages/distlib/index.py:215: :param sign_password: The passphrase for the signer's
- .venv/lib/python3.12/site-packages/distlib/index.py:223: cmd, sig_file = self.get_sign_command(filename, signer, sign_password,
- .venv/lib/python3.12/site-packages/distlib/index.py:226: sign_password.encode('utf-8'))
- .venv/lib/python3.12/site-packages/distlib/index.py:232: def upload_file(self, metadata, filename, signer=None, sign_password=None,
- .venv/lib/python3.12/site-packages/distlib/index.py:241: :param sign_password: The passphrase for the signer's
- .venv/lib/python3.12/site-packages/distlib/index.py:265: sig_file = self.sign_file(filename, signer, sign_password,
- .venv/lib/python3.12/site-packages/distlib/index.py:330: passed to :class:`subprocess.Popen`.
- .venv/lib/python3.12/site-packages/distlib/index.py:451: if self.password_handler:
- .venv/lib/python3.12/site-packages/distlib/index.py:452: handlers.append(self.password_handler)
- .venv/lib/python3.12/site-packages/distlib/version.py:27: pass
- .venv/lib/python3.12/site-packages/distlib/version.py:38: raise NotImplementedError('please implement in a subclass')
- .venv/lib/python3.12/site-packages/distlib/version.py:76: raise NotImplementedError('Please implement in subclasses.')
- .venv/lib/python3.12/site-packages/distlib/version.py:145: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/distlib/version.py:267: TODO: fill this out
- .venv/lib/python3.12/site-packages/distlib/version.py:482: pass
- .venv/lib/python3.12/site-packages/distlib/version.py:516: # TODO: unintended side-effect on, e.g., "2003.05.09"
- .venv/lib/python3.12/site-packages/distlib/wheel.py:278: pass
- .venv/lib/python3.12/site-packages/distlib/wheel.py:721: paths = dict(paths)  # don't change passed in dict
- .venv/lib/python3.12/site-packages/distlib/wheel.py:778: pass
- .venv/lib/python3.12/site-packages/distlib/wheel.py:844: # TODO version verification
- .venv/lib/python3.12/site-packages/distlib/wheel.py:891: the modifier, and then use the passed (and possibly updated)
- .venv/lib/python3.12/site-packages/distlib/markers.py:80: raise NotImplementedError('op not implemented: %s' % op)
- .venv/lib/python3.12/site-packages/distlib/database.py:412: # from what's passed to the matcher
- .venv/lib/python3.12/site-packages/distlib/database.py:434: pass
- .venv/lib/python3.12/site-packages/distlib/database.py:527: instantiated., or uses a passed in Metadata instance (useful for when
- .venv/lib/python3.12/site-packages/distlib/database.py:667: Writes the ``RECORD`` file, using the ``paths`` iterable passed in. Any
- .venv/lib/python3.12/site-packages/distlib/database.py:920: pass
- .venv/lib/python3.12/site-packages/distlib/locators.py:116: # is set from the requirement passed to locate(). See issue #18 for
- .venv/lib/python3.12/site-packages/distlib/locators.py:163: raise NotImplementedError('Please implement in the subclass')
- .venv/lib/python3.12/site-packages/distlib/locators.py:169: raise NotImplementedError('Please implement in the subclass')
- .venv/lib/python3.12/site-packages/distlib/locators.py:376: pass  # logger.debug('%s did not match %r', matcher, k)
- .venv/lib/python3.12/site-packages/distlib/locators.py:382: pass  # slist.append(k)
- .venv/lib/python3.12/site-packages/distlib/locators.py:467: raise NotImplementedError('Not available from this locator')
- .venv/lib/python3.12/site-packages/distlib/locators.py:746: pass
- .venv/lib/python3.12/site-packages/distlib/locators.py:760: XXX TODO Note: this cache is never actually cleared. It's assumed that
- .venv/lib/python3.12/site-packages/distlib/locators.py:904: raise NotImplementedError('Not available from this locator')
- .venv/lib/python3.12/site-packages/distlib/locators.py:922: # TODO SHA256 digest
- .venv/lib/python3.12/site-packages/distlib/locators.py:1050: except NotImplementedError:
- .venv/lib/python3.12/site-packages/distlib/locators.py:1051: pass
- .venv/lib/python3.12/site-packages/distlib/locators.py:1207: from the ``requirement`` passed to ``find()``, and they have the
- .venv/lib/python3.12/site-packages/distlib/locators.py:1229: logger.debug('passed %s as requirement', odist)
- .venv/lib/python3.12/site-packages/distlib/scripts.py:302: pass  # still in use - ignore error
- .venv/lib/python3.12/site-packages/distlib/__init__.py:13: pass
- .venv/lib/python3.12/site-packages/distlib/__init__.py:23: pass
- .venv/lib/python3.12/site-packages/distlib/__init__.py:26: pass
- .venv/lib/python3.12/site-packages/distlib/resources.py:303: pass
- .venv/lib/python3.12/site-packages/distlib/compat.py:53: # """splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'."""
- .venv/lib/python3.12/site-packages/distlib/compat.py:94: pass
- .venv/lib/python3.12/site-packages/distlib/compat.py:218: # directories pass the os.access check.
- .venv/lib/python3.12/site-packages/distlib/compat.py:253: # what file suffixes are executable, so just pass on cmd as-is.
- .venv/lib/python3.12/site-packages/distlib/compat.py:553: pass
- .venv/lib/python3.12/site-packages/distlib/compat.py:657: pass
- .venv/lib/python3.12/site-packages/distlib/compat.py:733: pass
- .venv/lib/python3.12/site-packages/distlib/util.py:146: Parse a requirement passed in as a string. Return a Container
- .venv/lib/python3.12/site-packages/distlib/util.py:401: # TODO check k, v for valid values
- .venv/lib/python3.12/site-packages/distlib/util.py:816: username = password = None
- .venv/lib/python3.12/site-packages/distlib/util.py:822: username, password = prefix.split(':', 1)
- .venv/lib/python3.12/site-packages/distlib/util.py:825: if password:
- .venv/lib/python3.12/site-packages/distlib/util.py:826: password = unquote(password)
- .venv/lib/python3.12/site-packages/distlib/util.py:827: return username, password, netloc
- .venv/lib/python3.12/site-packages/distlib/util.py:1060: :param args: The positional arguments to pass to the event's
- .venv/lib/python3.12/site-packages/distlib/util.py:1062: :param kwargs: The keyword arguments to pass to the event's
- .venv/lib/python3.12/site-packages/distlib/util.py:1501: pass a connection class to do_open, but it doesn't actually check for
- .venv/lib/python3.12/site-packages/distlib/util.py:1504: we *must* pass a class, we'll create an UnsafeHTTPSConnection class
- .venv/lib/python3.12/site-packages/distlib/util.py:1506: choose which one to pass to do_open.
- .venv/lib/python3.12/site-packages/distlib/util.py:1742: Read lines from a subprocess' output stream and either pass to a progress
- .venv/lib/python3.12/site-packages/distlib/util.py:1829: ('password', None)):
- .venv/lib/python3.12/site-packages/distlib/util.py:1851: 'password': config.get(server, 'password'),
- .venv/lib/python3.12/site-packages/distlib/util.py:1858: def update(self, username, password):
- .venv/lib/python3.12/site-packages/distlib/util.py:1866: config.set('pypi', 'password', password)
- .venv/lib/python3.12/site-packages/distlib/util.py:1879: PyPIRCFile().update(index.username, index.password)
- .venv/lib/python3.12/site-packages/distlib/metadata.py:239: # TODO document the mapping API and UNKNOWN default key
- .venv/lib/python3.12/site-packages/distlib/metadata.py:407: pass
- .venv/lib/python3.12/site-packages/distlib/metadata.py:560: # TODO could add iter* variants
- .venv/lib/python3.12/site-packages/distlib/metadata.py:754: raise NotImplementedError
- .venv/lib/python3.12/site-packages/distlib/metadata.py:856: raise NotImplementedError
- .venv/lib/python3.12/site-packages/distlib/metadata.py:863: raise NotImplementedError
- .venv/lib/python3.12/site-packages/distlib/metadata.py:984: # TODO: any other fields wanted
- .venv/lib/python3.12/site-packages/omegaconf/_utils.py:761: return _get_value(boxed)  # pass through value of boxed node
- .venv/lib/python3.12/site-packages/omegaconf/basecontainer.py:72: """Like _get_node, passing through to the nearest concrete Node."""
- .venv/lib/python3.12/site-packages/omegaconf/base.py:807: "pass-through" node. User apps and downstream libraries should not need to
- .venv/lib/python3.12/site-packages/omegaconf/grammar_visitor.py:71: raise NotImplementedError
- .venv/lib/python3.12/site-packages/omegaconf/grammar_visitor.py:75: raise NotImplementedError
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:117: raise NotImplementedError("Use one of the static construction functions")
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:355: pass
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:410: def _should_pass(special: str) -> bool:
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:418: pass_parent = _should_pass("_parent_")
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:419: pass_node = _should_pass("_node_")
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:420: pass_root = _should_pass("_root_")
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:434: pass
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:438: if pass_parent:
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:440: if pass_node:
- .venv/lib/python3.12/site-packages/omegaconf/omegaconf.py:442: if pass_root:
- .venv/lib/python3.12/site-packages/omegaconf/nodes.py:541: raise NotImplementedError
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:13: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:17: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:22: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:26: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:31: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:35: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:40: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:44: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:49: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:53: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:58: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:62: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:67: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:71: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:76: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:80: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:85: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:89: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:94: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:98: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:103: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:107: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:112: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:116: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:121: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:125: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:130: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:134: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:139: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:143: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:148: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParserListener.py:152: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:366: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:370: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:374: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:378: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:382: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:386: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:460: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:465: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:470: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:475: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:769: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:792: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:852: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:858: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:953: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:961: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:977: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:985: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1129: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1134: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1139: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1211: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1215: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1231: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1235: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1430: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1434: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1438: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1442: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1446: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1450: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1454: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1458: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1462: pass
- .venv/lib/python3.12/site-packages/omegaconf/grammar/gen/OmegaConfGrammarParser.py:1466: pass
- .venv/lib/python3.12/site-packages/tqdm/cli.py:24: pass
- .venv/lib/python3.12/site-packages/tqdm/cli.py:117: # TODO: add custom support for some of the following?
- .venv/lib/python3.12/site-packages/tqdm/cli.py:125: TODO: find out why this is needed.
- .venv/lib/python3.12/site-packages/tqdm/cli.py:136: If true, passes `stdin` to both `stderr` and `stdout`.
- .venv/lib/python3.12/site-packages/tqdm/cli.py:139: i.e. numbers to pass to `update()`. Note that this is slow
- .venv/lib/python3.12/site-packages/tqdm/cli.py:255: pass
- .venv/lib/python3.12/site-packages/tqdm/_monitor.py:12: pass
- .venv/lib/python3.12/site-packages/tqdm/_monitor.py:80: # force bypassing miniters on next iteration
- .venv/lib/python3.12/site-packages/tqdm/tk.py:31: # TODO: @classmethod: write()?
- .venv/lib/python3.12/site-packages/tqdm/tk.py:128: pass
- .venv/lib/python3.12/site-packages/tqdm/rich.py:74: # TODO: @classmethod: write()?
- .venv/lib/python3.12/site-packages/tqdm/rich.py:124: pass
- .venv/lib/python3.12/site-packages/tqdm/gui.py:26: # TODO: @classmethod: write() on GUI?
- .venv/lib/python3.12/site-packages/tqdm/gui.py:108: pass
- .venv/lib/python3.12/site-packages/tqdm/std.py:33: pass
- .venv/lib/python3.12/site-packages/tqdm/std.py:37: pass
- .venv/lib/python3.12/site-packages/tqdm/std.py:54: pass
- .venv/lib/python3.12/site-packages/tqdm/std.py:59: pass
- .venv/lib/python3.12/site-packages/tqdm/std.py:64: pass
- .venv/lib/python3.12/site-packages/tqdm/std.py:73: pass
- .venv/lib/python3.12/site-packages/tqdm/std.py:479: Number of seconds passed since start.
- .venv/lib/python3.12/site-packages/tqdm/std.py:571: pass
- .venv/lib/python3.12/site-packages/tqdm/std.py:702: pass  # py2: maybe magically removed already
- .venv/lib/python3.12/site-packages/tqdm/std.py:903: pass
- .venv/lib/python3.12/site-packages/tqdm/std.py:1442: # TODO: private method
- .venv/lib/python3.12/site-packages/tqdm/__init__.py:3: from .cli import main  # TODO: remove in v5.0.0
- .venv/lib/python3.12/site-packages/tqdm/__init__.py:4: from .gui import tqdm as tqdm_gui  # TODO: remove in v5.0.0
- .venv/lib/python3.12/site-packages/tqdm/__init__.py:5: from .gui import trange as tgrange  # TODO: remove in v5.0.0
- .venv/lib/python3.12/site-packages/tqdm/notebook.py:34: pass
- .venv/lib/python3.12/site-packages/tqdm/notebook.py:60: pass
- .venv/lib/python3.12/site-packages/tqdm/notebook.py:131: pass
- .venv/lib/python3.12/site-packages/tqdm/notebook.py:287: pass
- .venv/lib/python3.12/site-packages/tqdm/utils.py:9: # TODO consider using wcswidth third-party package for 0-width characters
- .venv/lib/python3.12/site-packages/tqdm/utils.py:88: pass
- .venv/lib/python3.12/site-packages/tqdm/utils.py:97: pass
- .venv/lib/python3.12/site-packages/tqdm/utils.py:165: Change only `.write()` of the wrapped object by encoding the passed
- .venv/lib/python3.12/site-packages/tqdm/utils.py:166: value and passing the result to the wrapped object's `.write()` method.
- .venv/lib/python3.12/site-packages/tqdm/utils.py:175: Encode `s` and pass to the wrapped object's `.write()` method.
- .venv/lib/python3.12/site-packages/tqdm/utils.py:203: pass
- .venv/lib/python3.12/site-packages/tqdm/utils.py:210: pass
- .venv/lib/python3.12/site-packages/tqdm/utils.py:317: pass
- .venv/lib/python3.12/site-packages/tqdm/utils.py:329: pass
- .venv/lib/python3.12/site-packages/tqdm/auto.py:28: pass
- .venv/lib/python3.12/site-packages/tqdm/contrib/__init__.py:40: pass
- .venv/lib/python3.12/site-packages/tqdm/contrib/__init__.py:61: pass
- .venv/lib/python3.12/site-packages/tqdm/contrib/logging.py:11: pass
- .venv/lib/python3.12/site-packages/tqdm/contrib/logging.py:119: **tqdm_kwargs  : passed to `tqdm_class`.
- .venv/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:64: Maximum number of workers to spawn; passed to
- .venv/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:82: Maximum number of workers to spawn; passed to
- .venv/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:86: Size of chunks sent to worker processes; passed to
- .venv/lib/python3.12/site-packages/functorch/dim/__init__.py:14: pass
- .venv/lib/python3.12/site-packages/functorch/dim/__init__.py:18: pass
- .venv/lib/python3.12/site-packages/functorch/einops/_parsing.py:116: pass  # no need to think about 1s inside parenthesis
- .venv/lib/python3.12/site-packages/pre_commit/hook.py:30: pass_filenames: bool
- .venv/lib/python3.12/site-packages/pre_commit/hook.py:50: # TODO: have cfgv do this (?)
- .venv/lib/python3.12/site-packages/pre_commit/store.py:234: # TODO: eventually remove this and only create in _create
- .venv/lib/python3.12/site-packages/pre_commit/errors.py:5: pass
- .venv/lib/python3.12/site-packages/pre_commit/main.py:432: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pre_commit/xargs.py:33: pass
- .venv/lib/python3.12/site-packages/pre_commit/xargs.py:37: except NotImplementedError:
- .venv/lib/python3.12/site-packages/pre_commit/xargs.py:73: pass
- .venv/lib/python3.12/site-packages/pre_commit/repository.py:97: # TODO: remove v1 state writing, no longer needed after pre-commit 3.0
- .venv/lib/python3.12/site-packages/pre_commit/clientlib.py:131: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pre_commit/clientlib.py:160: pass
- .venv/lib/python3.12/site-packages/pre_commit/clientlib.py:163: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pre_commit/clientlib.py:186: pass
- .venv/lib/python3.12/site-packages/pre_commit/clientlib.py:189: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pre_commit/clientlib.py:220: cfgv.Optional('pass_filenames', cfgv.check_bool, True),
- .venv/lib/python3.12/site-packages/pre_commit/clientlib.py:232: pass
- .venv/lib/python3.12/site-packages/pre_commit/clientlib.py:304: """the hook `entry` is passed through `shlex.split()` by the command
- .venv/lib/python3.12/site-packages/pre_commit/clientlib.py:492: pass
- .venv/lib/python3.12/site-packages/pre_commit/commands/run.py:188: if not hook.pass_filenames:
- .venv/lib/python3.12/site-packages/pre_commit/commands/autoupdate.py:74: pass  # this will be caught by manifest validating code
- .venv/lib/python3.12/site-packages/pre_commit/commands/autoupdate.py:86: pass
- .venv/lib/python3.12/site-packages/pre_commit/commands/try_repo.py:22: # if `ref` is explicitly passed, use it
- .venv/lib/python3.12/site-packages/pre_commit/languages/golang.py:93: # TODO: 3.9+ .removeprefix('go')
- .venv/lib/python3.12/site-packages/pre_commit/languages/julia.py:71: # TODO: Support language_version with juliaup similar to rust via
- .venv/lib/python3.12/site-packages/pre_commit/languages/python.py:74: pass
- .venv/lib/python3.12/site-packages/hydra/types.py:31: instantiate will work correctly if you pass in a DictConfig object or any dataclass that has the
- .venv/lib/python3.12/site-packages/hydra/main.py:81: def decorated_main(cfg_passthrough: Optional[DictConfig] = None) -> Any:
- .venv/lib/python3.12/site-packages/hydra/main.py:82: if cfg_passthrough is not None:
- .venv/lib/python3.12/site-packages/hydra/main.py:83: return task_function(cfg_passthrough)
- .venv/lib/python3.12/site-packages/hydra/plugins/launcher.py:29: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/plugins/launcher.py:39: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/plugins/completion_plugin.py:3: # TODO: Test with /miniconda3/envs/hydra36/bin/python , seems to be running python for some reason.
- .venv/lib/python3.12/site-packages/hydra/plugins/completion_plugin.py:4: # TODO: Add tests for completion with +prefix (should suggest config groups that are not listed)
- .venv/lib/python3.12/site-packages/hydra/plugins/completion_plugin.py:5: # TODO: Test completion when defaults has a missing mandatory item
- .venv/lib/python3.12/site-packages/hydra/plugins/completion_plugin.py:256: pass
- .venv/lib/python3.12/site-packages/hydra/plugins/completion_plugin.py:290: raise NotImplementedError
- .venv/lib/python3.12/site-packages/hydra/plugins/completion_plugin.py:293: raise NotImplementedError
- .venv/lib/python3.12/site-packages/hydra/plugins/completion_plugin.py:297: raise NotImplementedError
- .venv/lib/python3.12/site-packages/hydra/plugins/completion_plugin.py:300: raise NotImplementedError
- .venv/lib/python3.12/site-packages/hydra/plugins/completion_plugin.py:304: raise NotImplementedError
- .venv/lib/python3.12/site-packages/hydra/plugins/config_source.py:28: pass
- .venv/lib/python3.12/site-packages/hydra/plugins/sweeper.py:35: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/_internal/hydra.py:590: :param from_shell: True if the parameters are passed from the shell. used for more helpful error messages
- .venv/lib/python3.12/site-packages/hydra/_internal/config_loader_impl.py:424: pass
- .venv/lib/python3.12/site-packages/hydra/_internal/utils.py:84: pass
- .venv/lib/python3.12/site-packages/hydra/_internal/grammar/utils.py:28: # so we do one pass per special character.
- .venv/lib/python3.12/site-packages/hydra/_internal/grammar/utils.py:35: pass  # no '\' in the string
- .venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:154: _args_: List-like of positional arguments to pass to the target
- .venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:171: :param args: Optional positional parameters pass-through
- .venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:174: in the config objects are being passed as is to the target.
- .venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:176: and cannot be used as passthrough
- .venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:197: # TODO: print full key
- .venv/lib/python3.12/site-packages/hydra/conf/__init__.py:173: # TODO: good use case for Union support in OmegaConf
- .venv/lib/python3.12/site-packages/hydra/core/plugins.py:66: pass
- .venv/lib/python3.12/site-packages/hydra/core/utils.py:321: pass
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:53: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:70: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:73: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:76: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:86: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:89: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:92: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:95: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:98: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:220: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:227: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:230: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:265: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:268: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:271: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:283: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:286: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:292: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:295: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:298: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:304: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:307: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/core/default_element.py:313: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:225: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:247: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:271: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:408: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:428: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:486: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:490: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:494: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:498: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:558: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:564: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:631: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:637: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:643: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:649: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:1233: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParser.py:1253: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:13: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:17: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:22: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:26: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:31: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:35: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:40: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:44: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:49: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:53: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:58: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:62: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:67: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:71: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:76: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:80: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:85: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:89: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:94: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:98: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:103: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:107: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:112: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:116: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:121: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:125: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:130: pass
- .venv/lib/python3.12/site-packages/hydra/grammar/gen/OverrideParserListener.py:134: pass
- .venv/lib/python3.12/site-packages/hydra/test_utils/test_utils.py:258: code = "pass"
- .venv/lib/python3.12/site-packages/hydra/test_utils/a_module.py:9: pass
- .venv/lib/python3.12/site-packages/hydra/test_utils/launcher_common_tests.py:86: pass
- .venv/lib/python3.12/site-packages/hydra/test_utils/launcher_common_tests.py:192: {"db": {"driver": "mysql", "password": "secret", "user": "someone"}},
- .venv/lib/python3.12/site-packages/hydra/test_utils/launcher_common_tests.py:197: "password": "drowssap",
- .venv/lib/python3.12/site-packages/antlr4/IntervalSet.py:116: k -= 1  # need another pass
- .venv/lib/python3.12/site-packages/antlr4/InputStream.py:66: pass
- .venv/lib/python3.12/site-packages/antlr4/TokenStreamRewriter.py:238: pass
- .venv/lib/python3.12/site-packages/antlr4/CommonTokenFactory.py:15: pass
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:39: pass
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:54: # bypass alternatives.
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:56: # @see ATNDeserializationOptions#isGenerateRuleBypassTransitions()
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:58: bypassAltsAtnCache = dict()
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:184: # <li>Alterations to the command line options passed to ANTLR 4 when
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:253: # The ATN with bypass alternatives is expensive to create so we create it
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:259: def getATNWithBypassAlts(self):
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:262: raise UnsupportedOperationException("The current parser does not support an ATN with bypass alternatives.")
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:263: result = self.bypassAltsAtnCache.get(serializedAtn, None)
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:266: deserializationOptions.generateRuleBypassTransitions = True
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:268: self.bypassAltsAtnCache[serializedAtn] = result
- .venv/lib/python3.12/site-packages/antlr4/Parser.py:466: # TODO: useful in parser?
- .venv/lib/python3.12/site-packages/antlr4/Lexer.py:27: pass
- .venv/lib/python3.12/site-packages/antlr4/Lexer.py:328: # TODO: Do we lose character or line position information?
- .venv/lib/python3.12/site-packages/antlr4/LL1Analyzer.py:97: # from causing a stack overflow. Outside code should pass
- .venv/lib/python3.12/site-packages/antlr4/LL1Analyzer.py:100: # ATN from causing a stack overflow. Outside code should pass
- .venv/lib/python3.12/site-packages/antlr4/ParserRuleContext.py:19: #  could add a ctor to this so that we can pass in and store the input
- .venv/lib/python3.12/site-packages/antlr4/ParserRuleContext.py:82: pass
- .venv/lib/python3.12/site-packages/antlr4/ParserRuleContext.py:85: pass
- .venv/lib/python3.12/site-packages/antlr4/PredictionContext.py:114: # someone can pass in the bits of an array ctx that mean $
- .venv/lib/python3.12/site-packages/antlr4/PredictionContext.py:515: # TODO: track whether this is possible above during merge sort for speed
- .venv/lib/python3.12/site-packages/antlr4/PredictionContext.py:532: # Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}
- .venv/lib/python3.12/site-packages/antlr4/Recognizer.py:137: #  consistent with the ATN state passed in.  This way we always know
- .venv/lib/python3.12/site-packages/antlr4/BufferedTokenStream.py:26: pass
- .venv/lib/python3.12/site-packages/antlr4/BufferedTokenStream.py:70: pass
- .venv/lib/python3.12/site-packages/antlr4/BufferedTokenStream.py:302: pass
- .venv/lib/python3.12/site-packages/antlr4/RuleContext.py:106: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorListener.py:16: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorListener.py:19: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorListener.py:22: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorListener.py:25: pass
- .venv/lib/python3.12/site-packages/antlr4/error/Errors.py:93: # TODO symbol = Utils.escapeWhitespace(symbol, false);
- .venv/lib/python3.12/site-packages/antlr4/error/Errors.py:163: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorStrategy.py:20: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorStrategy.py:23: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorStrategy.py:26: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorStrategy.py:29: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorStrategy.py:32: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorStrategy.py:35: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorStrategy.py:241: pass
- .venv/lib/python3.12/site-packages/antlr4/error/ErrorStrategy.py:707: pass
- .venv/lib/python3.12/site-packages/antlr4/atn/Transition.py:69: # TODO: make all transitions sets? no, should remove set edges
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNConfig.py:58: # accurate depth since I don't ever decrement. TODO: make it a boolean then
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNConfig.py:117: __slots__ = ('lexerActionExecutor', 'passedThroughNonGreedyDecision')
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNConfig.py:127: self.passedThroughNonGreedyDecision = False if config is None else self.checkNonGreedyDecision(config, state)
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNConfig.py:131: self.semanticContext, self.passedThroughNonGreedyDecision,
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNConfig.py:139: if self.passedThroughNonGreedyDecision != other.passedThroughNonGreedyDecision:
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNConfig.py:158: return source.passedThroughNonGreedyDecision \
- .venv/lib/python3.12/site-packages/antlr4/atn/PredictionMode.py:247: # You can compute the alternative subsets in one pass as follows:</p>
- .venv/lib/python3.12/site-packages/antlr4/atn/LexerAction.py:231: # @param channel The channel value to pass to {@link Lexer#setChannel}.
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:80: if self.deserializationOptions.generateRuleBypassTransitions \
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:82: self.generateRuleBypassTransitions(atn)
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:270: def generateRuleBypassTransitions(self, atn:ATN):
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:278: self.generateRuleBypassTransition(atn, i)
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:280: def generateRuleBypassTransition(self, atn:ATN, idx:int):
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:282: bypassStart = BasicBlockStartState()
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:283: bypassStart.ruleIndex = idx
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:284: atn.addState(bypassStart)
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:286: bypassStop = BlockEndState()
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:287: bypassStop.ruleIndex = idx
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:288: atn.addState(bypassStop)
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:290: bypassStart.endState = bypassStop
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:291: atn.defineDecisionState(bypassStart)
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:293: bypassStop.startState = bypassStart
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:319: transition.target = bypassStop
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:325: bypassStart.addTransition(ruleToStartState.transitions[count-1])
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:329: atn.ruleToStartState[idx].addTransition(EpsilonTransition(bypassStart))
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:330: bypassStop.addTransition(EpsilonTransition(endState))
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:334: matchState.addTransition(AtomTransition(bypassStop, atn.ruleToTokenType[idx]))
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializer.py:335: bypassStart.addTransition(EpsilonTransition(matchState))
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNState.py:141: # TODO System.err.format(Locale.getDefault(), "ATN state %d has both epsilon and non-epsilon transitions.\n", stateNumbe
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializationOptions.py:9: __slots__ = ('readonly', 'verifyATN', 'generateRuleBypassTransitions')
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNDeserializationOptions.py:16: self.generateRuleBypassTransitions = False if copyFrom is None else copyFrom.generateRuleBypassTransitions
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNConfigSet.py:53: # TODO: these fields make me pretty uncomfortable but nice to pack up info together, saves recomputation
- .venv/lib/python3.12/site-packages/antlr4/atn/ATNConfigSet.py:54: # TODO: can we track conflicts as they are added to save scanning configs later?
- .venv/lib/python3.12/site-packages/antlr4/atn/ATN.py:40: # For parser ATNs, this maps the rule index to the generated bypass token
- .venv/lib/python3.12/site-packages/antlr4/atn/ATN.py:42: # {@link ATNDeserializationOptions#isGenerateRuleBypassTransitions}
- .venv/lib/python3.12/site-packages/antlr4/atn/ParserATNSimulator.py:231: # both SLL and LL parsing. Erroneous input will therefore require 2 passes over
- .venv/lib/python3.12/site-packages/antlr4/atn/ParserATNSimulator.py:292: pass
- .venv/lib/python3.12/site-packages/antlr4/atn/ParserATNSimulator.py:834: # <li>The closure block cannot contain any epsilon transitions which bypass
- .venv/lib/python3.12/site-packages/antlr4/atn/ParserATNSimulator.py:1084: # TODO: If we are doing predicates, there is no point in pursuing
- .venv/lib/python3.12/site-packages/antlr4/atn/ParserATNSimulator.py:1172: configs.dipsIntoOuterContext = True # TODO: can remove? only care when we add to set per middle of this method
- .venv/lib/python3.12/site-packages/antlr4/atn/ParserATNSimulator.py:1253: # we choose the more efficient path, which is to take the bypass
- .venv/lib/python3.12/site-packages/antlr4/atn/SemanticContext.py:33: # <p>For context dependent predicates, we must pass in a local context so that
- .venv/lib/python3.12/site-packages/antlr4/atn/SemanticContext.py:36: # prediction, so we passed in the outer context here in case of context
- .venv/lib/python3.12/site-packages/antlr4/atn/SemanticContext.py:40: pass
- .venv/lib/python3.12/site-packages/antlr4/atn/LexerActionExecutor.py:109: # @param startIndex The token start index. This value may be passed to
- .venv/lib/python3.12/site-packages/antlr4/atn/LexerATNSimulator.py:265: if currentAltReachedAcceptState and cfg.passedThroughNonGreedyDecision:
- .venv/lib/python3.12/site-packages/antlr4/atn/LexerATNSimulator.py:353: if not currentAltReachedAcceptState or not config.passedThroughNonGreedyDecision:
- .venv/lib/python3.12/site-packages/antlr4/atn/LexerATNSimulator.py:403: # TODO: if the entry rule is invoked recursively, some
- .venv/lib/python3.12/site-packages/antlr4/xpath/XPath.py:248: # path. The root {@code /} is relative to the node passed to
- .venv/lib/python3.12/site-packages/antlr4/tree/RuleTagToken.py:19: # name, bypass token type, and label.
- .venv/lib/python3.12/site-packages/antlr4/tree/RuleTagToken.py:22: # @param bypassTokenType The bypass token type assigned to the parser rule.
- .venv/lib/python3.12/site-packages/antlr4/tree/RuleTagToken.py:29: def __init__(self, ruleName:str, bypassTokenType:int, label:str=None):
- .venv/lib/python3.12/site-packages/antlr4/tree/RuleTagToken.py:33: self.type = bypassTokenType # token type of the token
- .venv/lib/python3.12/site-packages/antlr4/tree/ParseTreePatternMatcher.py:44: # <p>The lexer and parser that you pass into the {@link ParseTreePatternMatcher}
- .venv/lib/python3.12/site-packages/antlr4/tree/ParseTreePatternMatcher.py:54: # {@code expr} but, from the parser passed in, we create a special version of
- .venv/lib/python3.12/site-packages/antlr4/tree/ParseTreePatternMatcher.py:57: # these <em>bypass alternatives</em>.</p>
- .venv/lib/python3.12/site-packages/antlr4/tree/ParseTreePatternMatcher.py:88: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/ParseTreePatternMatcher.py:167: self.parser.ruleNames, self.parser.getATNWithBypassAlts(),tokens)
- .venv/lib/python3.12/site-packages/antlr4/tree/ParseTreePatternMatcher.py:214: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/ParseTreePatternMatcher.py:293: ruleImaginaryTokenType = self.parser.getATNWithBypassAlts().ruleToTokenType[ruleIndex]
- .venv/lib/python3.12/site-packages/antlr4/tree/Chunk.py:8: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:15: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:18: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:21: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:24: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:27: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:30: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:69: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:72: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:75: pass
- .venv/lib/python3.12/site-packages/antlr4/tree/Tree.py:78: pass
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:525: source code form), and must require no special password or key for
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:3694: software.  If the software is modified by someone else and passed on, we
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:3979: `Gnomovision' (which makes passes at compilers) written by James Hacker.
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:4028: gratis or for a fee, you must pass on to the recipients the same
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:4333: source code form), and must require no special password or key for
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:4746: modified by someone else and passed on, the recipients should know
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:4869: the facility, other than as an argument passed when the facility
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:5252: that uses the facility (other than as an argument passed when the
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:5641: 3a. If the Current Maintainer is reachable and agrees to pass
- .venv/lib/python3.12/site-packages/identify/vendor/licenses.py:5646: Holder agrees that maintenance of the Work be passed to you,
- .venv/lib/python3.12/site-packages/filelock/_unix.py:21: raise NotImplementedError
- .venv/lib/python3.12/site-packages/filelock/_unix.py:24: raise NotImplementedError
- .venv/lib/python3.12/site-packages/filelock/_unix.py:32: pass
- .venv/lib/python3.12/site-packages/filelock/_unix.py:53: raise NotImplementedError(msg) from exception
- .venv/lib/python3.12/site-packages/filelock/_windows.py:57: raise NotImplementedError
- .venv/lib/python3.12/site-packages/filelock/_windows.py:60: raise NotImplementedError
- .venv/lib/python3.12/site-packages/filelock/_api.py:104: name: (passed_param, set_param)
- .venv/lib/python3.12/site-packages/filelock/_api.py:105: for name, (passed_param, set_param) in params_to_check.items()
- .venv/lib/python3.12/site-packages/filelock/_api.py:106: if passed_param != set_param
- .venv/lib/python3.12/site-packages/filelock/_api.py:114: for param_name, (passed_param, set_param) in non_matching_params.items():
- .venv/lib/python3.12/site-packages/filelock/_api.py:115: msg += f"\n\t{param_name} (existing lock has {set_param} but {passed_param} was passed)"
- .venv/lib/python3.12/site-packages/filelock/_api.py:175: to pass the same object around.
- .venv/lib/python3.12/site-packages/filelock/_api.py:247: raise NotImplementedError
- .venv/lib/python3.12/site-packages/filelock/_api.py:252: raise NotImplementedError
- .venv/lib/python3.12/site-packages/filelock/_api.py:295: pass
- .venv/lib/python3.12/site-packages/filelock/_api.py:300: pass
- .venv/lib/python3.12/site-packages/filelock/asyncio.py:131: to pass the same object around.
- .venv/lib/python3.12/site-packages/filelock/asyncio.py:204: pass
- .venv/lib/python3.12/site-packages/filelock/asyncio.py:209: pass
- .venv/lib/python3.12/site-packages/filelock/asyncio.py:287: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/jinja2/exceptions.py:125: pass
- .venv/lib/python3.12/site-packages/jinja2/lexer.py:283: # passed an iterable of not interned strings.
- .venv/lib/python3.12/site-packages/jinja2/async_utils.py:7: from .utils import pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/async_utils.py:17: pass_arg = _PassArg.from_obj(normal_func)
- .venv/lib/python3.12/site-packages/jinja2/async_utils.py:18: need_eval_context = pass_arg is None
- .venv/lib/python3.12/site-packages/jinja2/async_utils.py:20: if pass_arg is _PassArg.environment:
- .venv/lib/python3.12/site-packages/jinja2/async_utils.py:51: wrapper = pass_eval_context(wrapper)
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:25: from .utils import pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:111: # we don't want to modify the dict passed
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:147: values passed to the template and also the names the template exports.
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:155: :func:`pass_context` get the active context passed as first argument
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:271: argument if the callable has :func:`pass_context` or
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:272: :func:`pass_environment`.
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:284: pass_arg = _PassArg.from_obj(__obj)
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:286: if pass_arg is _PassArg.context:
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:294: elif pass_arg is _PassArg.eval_context:
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:296: elif pass_arg is _PassArg.environment:
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:695: @pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:705: # there are historic callers that do not pass an eval context (and
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:706: # will continue to not pass one), we need to perform an instance
- .venv/lib/python3.12/site-packages/jinja2/runtime.py:711: # that if no eval context is passed we fall back to the compile
- .venv/lib/python3.12/site-packages/jinja2/environment.py:75: :param args: Positional arguments passed to environment.
- .venv/lib/python3.12/site-packages/jinja2/environment.py:226: be a callable that is passed the template name and has to
- .venv/lib/python3.12/site-packages/jinja2/environment.py:321: #   passed by keyword rather than position.  However it's important to
- .venv/lib/python3.12/site-packages/jinja2/environment.py:477: pass
- .venv/lib/python3.12/site-packages/jinja2/environment.py:482: pass
- .venv/lib/python3.12/site-packages/jinja2/environment.py:492: pass
- .venv/lib/python3.12/site-packages/jinja2/environment.py:530: pass_arg = _PassArg.from_obj(func)
- .venv/lib/python3.12/site-packages/jinja2/environment.py:532: if pass_arg is _PassArg.context:
- .venv/lib/python3.12/site-packages/jinja2/environment.py:539: elif pass_arg is _PassArg.eval_context:
- .venv/lib/python3.12/site-packages/jinja2/environment.py:547: elif pass_arg is _PassArg.environment:
- .venv/lib/python3.12/site-packages/jinja2/environment.py:589: Tests support ``@pass_context``, etc. decorators. Added
- .venv/lib/python3.12/site-packages/jinja2/environment.py:833: `extensions` and `filter_func` are passed to :meth:`list_templates`.
- .venv/lib/python3.12/site-packages/jinja2/environment.py:849: pass
- .venv/lib/python3.12/site-packages/jinja2/environment.py:912: is passed a template name and should return `True` if it should end up
- .venv/lib/python3.12/site-packages/jinja2/environment.py:925: "either extensions or filter_func can be passed, but not both"
- .venv/lib/python3.12/site-packages/jinja2/environment.py:1069: pass
- .venv/lib/python3.12/site-packages/jinja2/environment.py:1382: provided will be passed to the template.  Per default the globals
- .venv/lib/python3.12/site-packages/jinja2/environment.py:1384: is passed as is to the context without adding the globals.
- .venv/lib/python3.12/site-packages/jinja2/environment.py:1427: """If a context is passed in, this means that the template was
- .venv/lib/python3.12/site-packages/jinja2/environment.py:1532: "Async mode requires a body stream to be passed to"
- .venv/lib/python3.12/site-packages/jinja2/parser.py:49: """This is the central parsing class Jinja uses.  It's passed to
- .venv/lib/python3.12/site-packages/jinja2/parser.py:82: """Convenience method that raises `exc` with the message, passed
- .venv/lib/python3.12/site-packages/jinja2/tests.py:9: from .utils import pass_environment
- .venv/lib/python3.12/site-packages/jinja2/tests.py:52: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/tests.py:70: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/ext.py:18: from .utils import pass_context
- .venv/lib/python3.12/site-packages/jinja2/ext.py:31: pass
- .venv/lib/python3.12/site-packages/jinja2/ext.py:111: """It's passed a :class:`~jinja2.lexer.TokenStream` that can be used
- .venv/lib/python3.12/site-packages/jinja2/ext.py:124: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/jinja2/ext.py:130: to pass constants on extensions to generated template code.
- .venv/lib/python3.12/site-packages/jinja2/ext.py:164: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/ext.py:172: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/ext.py:186: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/ext.py:205: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/ext.py:224: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/ext.py:251: # TODO: the i18n extension is currently reevaluating values in a few
- .venv/lib/python3.12/site-packages/jinja2/optimizer.py:46: pass
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:145: """Check if the names passed are accessed undeclared.  The return value
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:153: pass
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:447: self.writeline("pass")
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:451: pass
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:588: pass
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:596: raise NotImplementedError("unknown load instruction")
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:1064: self.writeline("pass")
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:1423: pass_arg = {
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:1432: if pass_arg is None:
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:1438: src = f"{src}{pass_arg}, "
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:1440: if pass_arg == "environment":
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:1765: # slices bypass the environment getitem method.
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:1815: pass_arg = {
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:1823: if pass_arg is not None:
- .venv/lib/python3.12/site-packages/jinja2/compiler.py:1824: self.write(f"{pass_arg}, ")
- .venv/lib/python3.12/site-packages/jinja2/sandbox.py:109: pass
- .venv/lib/python3.12/site-packages/jinja2/sandbox.py:299: pass
- .venv/lib/python3.12/site-packages/jinja2/sandbox.py:304: pass
- .venv/lib/python3.12/site-packages/jinja2/sandbox.py:316: attribute.  The attribute passed *must* be a bytestring.
- .venv/lib/python3.12/site-packages/jinja2/sandbox.py:324: pass
- .venv/lib/python3.12/site-packages/jinja2/sandbox.py:436: pass
- .venv/lib/python3.12/site-packages/jinja2/bccache.py:48: and initialized by the bytecode cache and passed to the loading functions.
- .venv/lib/python3.12/site-packages/jinja2/bccache.py:85: """Dump the bytecode into the file or file like object passed."""
- .venv/lib/python3.12/site-packages/jinja2/bccache.py:106: these methods are passed a :class:`~jinja2.bccache.Bucket`.
- .venv/lib/python3.12/site-packages/jinja2/bccache.py:137: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/jinja2/bccache.py:144: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/jinja2/bccache.py:298: pass
- .venv/lib/python3.12/site-packages/jinja2/bccache.py:328: pass
- .venv/lib/python3.12/site-packages/jinja2/bccache.py:343: does not support storing binary data, only text. You can however pass
- .venv/lib/python3.12/site-packages/jinja2/bccache.py:347: The minimal interface for the client passed to the constructor is this:
- .venv/lib/python3.12/site-packages/jinja2/filters.py:24: from .utils import pass_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:25: from .utils import pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:26: from .utils import pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:41: pass
- .venv/lib/python3.12/site-packages/jinja2/filters.py:65: passed object with the rules of the environment.  Dots are allowed
- .venv/lib/python3.12/site-packages/jinja2/filters.py:92: attributes from a passed object with the rules of the environment.
- .venv/lib/python3.12/site-packages/jinja2/filters.py:178: @pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:259: @pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:385: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:420: attributes, pass a comma separate list of attributes.
- .venv/lib/python3.12/site-packages/jinja2/filters.py:441: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:456: the iterable passed to the filter.
- .venv/lib/python3.12/site-packages/jinja2/filters.py:506: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:526: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:551: """If the value is undefined it will return the passed default value,
- .venv/lib/python3.12/site-packages/jinja2/filters.py:579: @pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:652: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:673: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:695: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:745: @pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:873: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:921: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1078: If you pass it a second argument it's used to fill missing
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1201: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1252: will have two values. This can be disabled by passing
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1312: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1411: @pass_environment
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1456: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1478: Alternatively you can let it invoke a filter by passing the name of the
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1540: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1581: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1617: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1657: @pass_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1695: @pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/filters.py:1708: :param indent: The ``indent`` parameter passed to ``dumps``, for
- .venv/lib/python3.12/site-packages/jinja2/__init__.py:33: from .utils import pass_context as pass_context
- .venv/lib/python3.12/site-packages/jinja2/__init__.py:34: from .utils import pass_environment as pass_environment
- .venv/lib/python3.12/site-packages/jinja2/__init__.py:35: from .utils import pass_eval_context as pass_eval_context
- .venv/lib/python3.12/site-packages/jinja2/utils.py:38: def pass_context(f: F) -> F:
- .venv/lib/python3.12/site-packages/jinja2/utils.py:45: :func:`pass_eval_context`. If only ``Context.environment`` is
- .venv/lib/python3.12/site-packages/jinja2/utils.py:46: needed, use :func:`pass_environment`.
- .venv/lib/python3.12/site-packages/jinja2/utils.py:51: f.jinja_pass_arg = _PassArg.context  # type: ignore
- .venv/lib/python3.12/site-packages/jinja2/utils.py:55: def pass_eval_context(f: F) -> F:
- .venv/lib/python3.12/site-packages/jinja2/utils.py:63: :func:`pass_environment`.
- .venv/lib/python3.12/site-packages/jinja2/utils.py:68: f.jinja_pass_arg = _PassArg.eval_context  # type: ignore
- .venv/lib/python3.12/site-packages/jinja2/utils.py:72: def pass_environment(f: F) -> F:
- .venv/lib/python3.12/site-packages/jinja2/utils.py:81: f.jinja_pass_arg = _PassArg.environment  # type: ignore
- .venv/lib/python3.12/site-packages/jinja2/utils.py:92: if hasattr(obj, "jinja_pass_arg"):
- .venv/lib/python3.12/site-packages/jinja2/utils.py:93: return obj.jinja_pass_arg  # type: ignore
- .venv/lib/python3.12/site-packages/jinja2/utils.py:105: """Check if the object passed is undefined.  This does nothing more than
- .venv/lib/python3.12/site-packages/jinja2/utils.py:124: pass
- .venv/lib/python3.12/site-packages/jinja2/utils.py:524: pass
- .venv/lib/python3.12/site-packages/jinja2/utils.py:553: pass
- .venv/lib/python3.12/site-packages/jinja2/utils.py:657: :param kwargs: Extra arguments to pass to ``dumps``. Merged onto
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:98: "if no eval context is passed, the node must have an"
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:115: or arbitrary values.  Fields are passed to the constructor as regular
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:167: pass
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:296: is passed to the compiler.
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:427: pass unsafe names to the name attribute.  The compiler translates the
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:762: pass_arg = _PassArg.from_obj(func)  # type: ignore
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:764: if func is None or pass_arg is _PassArg.context:
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:776: if pass_arg is _PassArg.eval_context:
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:778: elif pass_arg is _PassArg.environment:
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:810: check for volatile, async, and ``@pass_context`` etc.
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:1128: :func:`~jinja2.pass_context` decorator when using the high-level
- .venv/lib/python3.12/site-packages/jinja2/nodes.py:1129: API, which causes a reference to the context to be passed as the
- .venv/lib/python3.12/site-packages/jinja2/loaders.py:79: It's passed the environment and template name and has to return a
- .venv/lib/python3.12/site-packages/jinja2/loaders.py:91: changed.  No arguments are passed so the function must store the
- .venv/lib/python3.12/site-packages/jinja2/loaders.py:461: """A loader that is passed a function which does the loading.  The
- .venv/lib/python3.12/site-packages/jinja2/loaders.py:506: """A loader that is passed a dict of loaders where each loader is bound
- .venv/lib/python3.12/site-packages/jinja2/loaders.py:592: pass
- .venv/lib/python3.12/site-packages/jinja2/loaders.py:606: pass
- .venv/lib/python3.12/site-packages/jinja2/idtracking.py:229: raise NotImplementedError(f"Cannot find symbols for {type(node).__name__!r}")
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:103: Store the string that was passed to [`PreTrainedModel.from_pretrained`] or
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:252: f"You passed `num_labels={num_labels}` which is incompatible to "
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:338: "`Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`."
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:349: # TODO: remove later, deprecated arguments for TF models
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:451: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:460: # TODO (joao): this should be an exception if the user has modified the loaded config. See #33886
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:574: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:791: # Those arguments may be passed along for our internal telemetry.
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:819: f"You passed along `num_labels={num_labels}` with an incompatible id to label map: "
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:827: # To authorize passing a custom subconfig as kwarg in models that have nested configs.
- .venv/lib/python3.12/site-packages/transformers/configuration_utils.py:1054: Checks whether the passed dictionary and its nested dicts have a *dtype* key and if it's not None,
- .venv/lib/python3.12/site-packages/transformers/modeling_layers.py:45: must be passed as positional arguments (`*args`) rather than keyword arguments to properly propagate gradients.
- .venv/lib/python3.12/site-packages/transformers/modeling_layers.py:50: >>> # Correct - hidden_states passed as positional arg
- .venv/lib/python3.12/site-packages/transformers/modeling_layers.py:53: >>> # Incorrect - hidden_states passed as keyword arg
- .venv/lib/python3.12/site-packages/transformers/modeling_layers.py:72: # TODO cyril: this one without `S` can be removed after deprection cycle
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:33: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:38: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:59: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:83: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:88: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:112: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:135: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:141: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:146: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:168: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:173: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:179: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:206: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:211: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:217: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:223: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:250: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:256: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:261: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:267: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:293: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:298: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:303: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:313: router_logits (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_logits=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:338: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:343: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:349: router_probs (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_probs=True` and `config.add_router_pr
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:370: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:376: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:381: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:387: router_logits (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_probs=True` and `config.add_router_p
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:416: router_logits (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_probs=True` and `config.add_router_p
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:422: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:427: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:432: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:461: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:467: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:472: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:478: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:484: router_probs (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_probs=True` and `config.add_router_pr
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:511: past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=T
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:516: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:521: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:527: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:535: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:540: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:570: past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=T
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:575: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:580: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:586: decoder_router_logits (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_logits=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:590: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:598: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:603: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:609: encoder_router_logits (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_logits=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:638: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:643: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:667: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:672: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:677: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:702: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:707: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:713: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:719: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:744: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:749: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:754: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:779: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:784: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:808: past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=T
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:813: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:818: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:824: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:832: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:837: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:866: past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=T
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:871: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:876: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:882: decoder_router_logits (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_logits=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:886: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:894: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:899: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:905: encoder_router_logits (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_logits=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:940: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:945: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:969: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:974: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:998: past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=T
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1003: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1008: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1014: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1022: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1027: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1058: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1063: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1087: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1092: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1118: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1123: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1150: past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=T
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1155: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1160: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1166: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1174: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1179: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1212: The logits returned do not necessarily have the same size as the `pixel_values` passed as inputs. This is
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1218: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1223: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1247: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1251: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1275: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1297: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1302: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1326: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1330: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1354: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1359: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1385: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1390: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1413: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1419: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1445: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1450: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1456: projection_state (`tuple(torch.FloatTensor)`, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1479: past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=T
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1484: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1489: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1495: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1503: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1508: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1539: past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=T
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1544: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1549: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1555: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1563: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1568: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1608: past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=T
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1613: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1618: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1624: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1632: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1637: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1691: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or
- .venv/lib/python3.12/site-packages/transformers/modeling_outputs.py:1696: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/audio_utils.py:47: # TODO: @eustlb, we actually don't need librosa but soxr is installed with librosa
- .venv/lib/python3.12/site-packages/transformers/audio_utils.py:165: # TODO: @eustlb, we actually don't need librosa but soxr is installed with librosa
- .venv/lib/python3.12/site-packages/transformers/audio_utils.py:414: # add on fixed offset of 10*num_chroma to ensure all values passed to
- .venv/lib/python3.12/site-packages/transformers/audio_utils.py:610: # TODO This method does not support batching yet as we are mainly focused on inference.
- .venv/lib/python3.12/site-packages/transformers/audio_utils.py:699: Coefficient for a low-pass filter that applies pre-emphasis before the DFT.
- .venv/lib/python3.12/site-packages/transformers/trainer.py:268: # TODO: @AjayP13, @younesbelkada replace this check with version check at the next `accelerate` release
- .venv/lib/python3.12/site-packages/transformers/trainer.py:325: The model to train, evaluate or use for predictions. If not provided, a `model_init` must be passed.
- .venv/lib/python3.12/site-packages/transformers/trainer.py:372: a dictionary string to metric values. *Note* When passing TrainingArgs with `batch_eval_metrics` set to
- .venv/lib/python3.12/site-packages/transformers/trainer.py:401: original model. This is the model that should be used for the forward pass. For example, under `DeepSpeed`,
- .venv/lib/python3.12/site-packages/transformers/trainer.py:438: logger.info(f"No `TrainingArguments` passed, using `output_dir={output_dir}`.")
- .venv/lib/python3.12/site-packages/transformers/trainer.py:449: f"You have set `args.eval_strategy` to {args.eval_strategy} but you didn't pass an `eval_dataset` to `Trainer`. Either s
- .venv/lib/python3.12/site-packages/transformers/trainer.py:561: "You cannot fine-tune quantized model with `torch.compile()` make sure to pass a non-compiled model when fine-tuning a q
- .venv/lib/python3.12/site-packages/transformers/trainer.py:675: " created an optimizer around your model **before** putting on the device and passing it to the"
- .venv/lib/python3.12/site-packages/transformers/trainer.py:1257: We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the
- .venv/lib/python3.12/site-packages/transformers/trainer.py:1285: We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the
- .venv/lib/python3.12/site-packages/transformers/trainer.py:1425: raise NotImplementedError(f"Layer-wise {optimizer_name} does not support DDP at this time")
- .venv/lib/python3.12/site-packages/transformers/trainer.py:1438: raise ValueError(f"You need to pass a model to initialize {optimizer_name} optimizer.")
- .venv/lib/python3.12/site-packages/transformers/trainer.py:1569: # Above we pass all `adam_kwargs` to the optimizer, here
- .venv/lib/python3.12/site-packages/transformers/trainer.py:1570: # we only pass `optim_args` which can be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/trainer.py:1622: # TODO Change dtypes back to M=FP32, Var = BF16, Kahan = False once they can be cast together in torchdistx.
- .venv/lib/python3.12/site-packages/transformers/trainer.py:1716: raise ValueError("You need to pass a `model` in order to correctly initialize a LOMO optimizer.")
- .venv/lib/python3.12/site-packages/transformers/trainer.py:1849: passed as an argument.
- .venv/lib/python3.12/site-packages/transformers/trainer.py:2067: return smp.DistributedModel(model, backward_passes_per_step=self.args.gradient_accumulation_steps)
- .venv/lib/python3.12/site-packages/transformers/trainer.py:2368: # Check for DeepSpeed *after* the initial pass and modify the config
- .venv/lib/python3.12/site-packages/transformers/trainer.py:2485: # to handle cases wherein we pass "DummyScheduler" such as when it is specified in DeepSpeed config.
- .venv/lib/python3.12/site-packages/transformers/trainer.py:2857: # After training we make sure to retrieve back the original forward pass method
- .venv/lib/python3.12/site-packages/transformers/trainer.py:3001: # TODO: in the future support only specific min PEFT versions
- .venv/lib/python3.12/site-packages/transformers/trainer.py:3091: # TODO: in the future support only specific min PEFT versions
- .venv/lib/python3.12/site-packages/transformers/trainer.py:3647: """If callback states exist and were passed in, restore their states if enabled"""
- .venv/lib/python3.12/site-packages/transformers/trainer.py:3675: logger.info("Continuing training from checkpoint, restoring any callbacks that were passed in")
- .venv/lib/python3.12/site-packages/transformers/trainer.py:3757: "To use hyperparameter search, you need to pass your model through a model_init function."
- .venv/lib/python3.12/site-packages/transformers/trainer.py:3919: # TODO: check this only once or always, with speed being the cost
- .venv/lib/python3.12/site-packages/transformers/trainer.py:3961: # TODO Matt: This syntax is deprecated and the preferred version is
- .venv/lib/python3.12/site-packages/transformers/trainer.py:4082: The number of items in the batch. If num_items_in_batch is not passed,
- .venv/lib/python3.12/site-packages/transformers/trainer.py:4101: # TODO: this needs to be fixed and made cleaner later.
- .venv/lib/python3.12/site-packages/transformers/trainer.py:4411: (pass it to the init `compute_metrics` argument).
- .venv/lib/python3.12/site-packages/transformers/trainer.py:4424: If you pass a dictionary with names of datasets as keys and datasets as values, evaluate will run
- .venv/lib/python3.12/site-packages/transformers/trainer.py:4428: of the datasets. If you, for example, pass in `{"data1": data1, "data2": data2}` for two datasets
- .venv/lib/python3.12/site-packages/transformers/trainer.py:4896: # TODO: this needs to be fixed and made cleaner later.
- .venv/lib/python3.12/site-packages/transformers/trainer.py:4912: operations for every backward + forward pass. If using another model, either implement such a method in the
- .venv/lib/python3.12/site-packages/transformers/trainer.py:5115: Additional keyword arguments passed along to [`~Trainer.create_model_card`].
- .venv/lib/python3.12/site-packages/transformers/trainer.py:5141: # Add additional tags in the case the model has already some tags and users pass
- .venv/lib/python3.12/site-packages/transformers/trainer.py:5257: # The actual number of eval_sample can be greater than num_examples in distributed settings (when we pass
- .venv/lib/python3.12/site-packages/transformers/trainer.py:5425: # check if num_steps is attempted to be passed in gradient_accumulation_kwargs
- .venv/lib/python3.12/site-packages/transformers/trainer.py:5430: "The `AcceleratorConfig`'s `num_steps` is set but `gradient_accumulation_steps` is greater than 1 in the passed `Trainin
- .venv/lib/python3.12/site-packages/transformers/trainer.py:5431: "If using the passed `AcceleratorConfig` is desired, do not set the `TrainingArguments` `gradient_accumulation_steps`."
- .venv/lib/python3.12/site-packages/transformers/trainer.py:5589: # num_items_in_batch is passed to model forward
- .venv/lib/python3.12/site-packages/transformers/trainer.py:5592: # num_items_in_batch is passed to compute_loss_func
- .venv/lib/python3.12/site-packages/transformers/trainer.py:5605: pass
- .venv/lib/python3.12/site-packages/transformers/time_series_utils.py:153: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:121: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:148: (pass it to the init `compute_metrics` argument).
- .venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:178: # Use legacy argument setting if a) the option is not explicitly passed; and b) the argument is set in the
- .venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:242: # Use legacy argument setting if a) the option is not explicitly passed; and b) the argument is set in the
- .venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:330: # TODO: remove this hack when the legacy code that initializes generation_config from a model config is
- .venv/lib/python3.12/site-packages/transformers/hf_argparser.py:85: Single string or list of strings of aliases to pass on to argparse, e.g. `aliases=["--example", "-e"]`.
- .venv/lib/python3.12/site-packages/transformers/hf_argparser.py:87: help (str, optional): Help string to pass on to argparse that can be displayed with --help. Defaults to None.
- .venv/lib/python3.12/site-packages/transformers/hf_argparser.py:95: metadata (dict, optional): Further metadata to pass on to `dataclasses.field`. Defaults to None.
- .venv/lib/python3.12/site-packages/transformers/hf_argparser.py:316: - the dataclass instances in the same order as they were passed to the initializer.abspath
- .venv/lib/python3.12/site-packages/transformers/hf_argparser.py:385: - the dataclass instances in the same order as they were passed to the initializer.
- .venv/lib/python3.12/site-packages/transformers/hf_argparser.py:416: - the dataclass instances in the same order as they were passed to the initializer.
- .venv/lib/python3.12/site-packages/transformers/hf_argparser.py:440: - the dataclass instances in the same order as they were passed to the initializer.
- .venv/lib/python3.12/site-packages/transformers/optimization_tf.py:137: List of the parameter names (or re patterns) to apply weight decay to. If none is passed, weight decay is
- .venv/lib/python3.12/site-packages/transformers/optimization_tf.py:204: List of the parameter names (or re patterns) to apply weight decay to. If none is passed, weight decay is
- .venv/lib/python3.12/site-packages/transformers/optimization_tf.py:208: `include_in_weight_decay` is passed, the names in it will supersede this list.
- .venv/lib/python3.12/site-packages/transformers/optimization_tf.py:313: then call `.gradients`, scale the gradients if required, and pass the result to `apply_gradients`.
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:338: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:339: raise unittest.SkipTest(f"Test skipped due to NotImplementedError: {e}")
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:1371: # TODO: Remove once eetq releases a fix and this release is used in CI
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:1708: # TODO (if possible): Avoid exceptional cases
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:1806: doing. If this is a not wanted behavior and the captured data shouldn't be replayed, pass `replay=False` to
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2098: will get nuked. i.e. please always pass paths that start with `./`
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2222: tmp_dir(`string`): either the same value as passed via *tmp_dir* or the path to the auto-selected tmp dir
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2270: Runs the passed python one liner (just the code) and returns how much max cpu memory was used to run the
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2275: a python one liner code that gets passed to `python -c`
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2395: - tr: `terminalreporter` passed from `conftest.py`
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2424: "passes",
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2494: tr.reportchars = "wPpsxXEf"  # emulate -rA (used in summary_passes() and short_test_summary())
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2496: # Skip the `passes` report, as it starts to take more than 5 minutes, and sometimes it timeouts on CircleCI if it
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2499: # with open(report_files["passes"], "w") as f:
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2501: #     tr.summary_passes()
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2678: pass
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2862: The inputs that will be passed to `target_func` through an (input) queue.
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2864: The timeout (in seconds) that will be passed to the input and output queues. If not specified, the env.
- .venv/lib/python3.12/site-packages/transformers/testing_utils.py:2914: # full information can be passed to the parent pytest process.
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:69: f"Make sure that when passing `sliding_window` that its value is a strictly positive integer, not `{self.sliding_window}
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:125: "This attention mask converter is causal. Make sure to pass `key_value_length` to correctly create a causal mask."
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:137: raise NotImplementedError("Sliding window is currently only implemented for causal masking")
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:264: passed).
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:275: # TODO: When tracing with TorchDynamo with fullgraph=True, the model is recompiled depending on the input
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:278: # `torch.export` or `torch.onnx.dynamo_export`, we must pass an example input, and `is_causal` behavior is
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:303: # TODO: maybe revisit this with https://github.com/pytorch/pytorch/pull/114823 in PyTorch 2.3.
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:329: If the model uses windowed attention, a sliding window should be passed.
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:335: # 4d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:373: allowing to dispatch to the flash attention kernel (that can otherwise not be used if a custom `attn_mask` is passed).
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:381: # TODO: For dynamo, rather use a check on fullgraph=True once this is possible (https://github.com/pytorch/pytorch/pull/
- .venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:478: If the model uses windowed attention, a sliding window should be passed.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:88: "This may result in unexpected behaviour or errors if Keras 3 objects are passed to Transformers models."
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:156: 2. Wrapping `__init__` to accept that `transformers_config` dict (passed by Keras at deserialization time) and
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:188: raise TypeError("Must pass either `config` (PretrainedConfig) or `config` (dict)")
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:405: Decorator that processes the inputs to a Keras layer, passing them to the layer as keyword arguments. This enables
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:439: # Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:636: optimization made to make each sub-checkpoint as close as possible to the maximum size passed. For example, if the
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1170: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1187: pass  # This is just here to make sure we don't call the superclass build()
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1329: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1337: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1342: raise NotImplementedError("Audio models need a manually defined input_signature")
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1366: pass  # Layers may not have the same dimensions
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1395: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1423: designed to create a "ready-to-use" dataset that can be passed directly to Keras methods like `fit()` without
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1438: `collate_fn` is passed instead.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1442: passed.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1444: A dict of arguments to pass to the `collate_fn` alongside the list of samples.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1454: `Dataset`: A `tf.data.Dataset` which is ready to pass to the Keras API.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1480: # TODO Matt: This is a workaround for older versions of datasets that are missing the `cols_to_retain`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1496: # were a single element list, the returned element spec would be a single element. Now, passing [feature]
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1497: # will return a dict structure {"feature": feature}, and passing a single string will return a single element.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1530: if loss in ("auto_with_warning", "passthrough"):  # "passthrough" for workflow backward compatibility
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1534: "To disable this behaviour please pass a loss argument, or explicitly pass "
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1603: that they are available to the model during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1651: # Run forward pass.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1692: # Run backwards pass.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1711: that they are available to the model during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1759: # Run forward pass.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1881: raise NotImplementedError("The model does not implements the base_model_prefix attribute.")
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2007: # TODO (joao): flagged for replacement (by `_v2_resized_token_embeddings`) due to embeddings refactor
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2047: # TODO (joao): flagged for detection due to embeddings refactor
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2078: # TODO (joao): flagged for replacement (by `_v2_resize_token_embeddings`) due to embeddings refactor
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2115: # TODO (joao): this one probably needs a v2 version with other models
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2138: # TODO (joao): flagged for replacement (by `_v2_get_resized_lm_head_bias`) due to embeddings refactor
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2265: # TODO (joao): flagged for replacement (by `_v2_get_resized_embeddings`) due to embeddings refactor
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2338: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2371: Model's signature used for serving. This will be passed to the `signatures` argument of model.save().
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2391: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2558: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2608: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2631: - If a configuration is provided with `config`, `**kwargs` will be directly passed to the
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2634: - If a configuration is not provided, `kwargs` will be first passed to the configuration class
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2638: will be passed to the underlying model's `__init__` function.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2907: f"The safetensors archive passed at {resolved_archive_file} does not contain the valid metadata."
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2916: f"The safetensors archive passed at {resolved_archive_file} does not contain the valid metadata."
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2932: # TODO Matt: This is a temporary workaround to allow weight renaming, but requires a method
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3102: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3261: Additional keyword arguments passed along to the `__init__` of `keras.layers.Layer`.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3306: Additional keyword arguments passed along to the `__init__` of `keras.layers.Layer`.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3309: # TODO (joao): flagged for detection due to embeddings refactor
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3421: Additional keyword arguments passed along to the `__init__` of `keras.layers.Layer`.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3432: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3494: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:724: f"You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\n"
- .venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:736: f"Please pass the argument `trust_remote_code=True` to allow custom code to be run."
- .venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:749: f"Please pass the argument `trust_remote_code=True` to allow custom code to be run."
- .venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:766: Additional arguments to pass to `cached_file`.
- .venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:803: pass
- .venv/lib/python3.12/site-packages/transformers/video_utils.py:179: If the input is a batch of videos, it is converted to a list of 4D video arrays. Videos passed as list `PIL.Image`
- .venv/lib/python3.12/site-packages/transformers/video_utils.py:193: pass
- .venv/lib/python3.12/site-packages/transformers/video_utils.py:197: # only one frame passed, thus we unsqueeze time dim
- .venv/lib/python3.12/site-packages/transformers/video_utils.py:631: Number of frames to sample uniformly. If not passed, the whole video is loaded.
- .venv/lib/python3.12/site-packages/transformers/video_utils.py:633: Number of frames to sample per second. Should be passed only when `num_frames=None`.
- .venv/lib/python3.12/site-packages/transformers/video_utils.py:641: The function expects at input the all args along with all kwargs passed to `load_video` and should output valid
- .venv/lib/python3.12/site-packages/transformers/video_utils.py:660: # If user didn't pass a sampling function, create one on the fly with default logic
- .venv/lib/python3.12/site-packages/transformers/video_utils.py:814: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:238: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:335: # Fixes issue where the model code passes a value that is out of range for XLA_USE_BF16=1
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:513: f"The safetensors archive passed at {checkpoint_file} does not contain the valid metadata. Make sure "
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:690: # We convert floating dtypes to the `dtype` passed except for float8_e4m3fn type. We also want to keep the buffers/param
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:728: unexpected_keys: Optional[list[str]] = None,  # passing `unexpected` for cleanup from quantization items
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:853: # TODO naming is stupid it loads it as well
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1018: is_remote_code: bool,  # Because we can't determine this inside this function, we need it to be passed in
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1415: """Compute the final `device_map` to use if we passed a value in ['auto', 'balanced', 'balanced_low_0', 'sequential'].
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1465: # respect the `max_memory` passed by the user
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1636: Add a memory hook before and after each sub-module forward pass to record increase in memory consumption.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1890: Get number of (optionally, non-embeddings) floating-point operations for the forward and backward passes of a
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1898: The batch size for the forward pass.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1952: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1964: 4. otherwise raise `NotImplementedError` so subclasses still can (and
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1980: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1991: except NotImplementedError:
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2080: # by passing `tp_plan` to the init, it should be {"model.language_model.layers.fc1":"colwise"}
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2099: # In practice, it means that they support attention (mask) interface functions, fully pass the kwargs
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2150: `dict[str, torch.Tensor]`: Dummy inputs to do a forward pass in the network.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2405: # a warning is raised that dtype should be fp16. Since we never pass dtype from within
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2421: # If passing `attn_implementation` as kwargs, respect it (it will be applied recursively on subconfigs)
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2459: `torch.int64` is passed. So if a non-float `dtype` is passed this functions will throw an exception.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2529: # check `supports_flash_attn_2` for BC with custom code. TODO: remove after a few releases
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2603: "This is not supported yet. Please make sure to have access to a GPU and either initialise the model on a GPU by passing
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2681: "This is not supported yet. Please make sure to have access to a GPU and either initialise the model on a GPU by passing
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2824: # check `supports_flash_attn_2` for BC with custom code. TODO: remove after a few releases
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3438: f"Asking to pad the embedding matrix to a multiple of `{pad_to_multiple_of}`, which is not and integer. Please make sure
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3528: # This ensures correct functionality when a Custom Embedding class is passed as input.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3747: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3753: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3799: We pass the `__call__` method of the modules instead of `forward` because `__call__` attaches all the hooks of
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3804: Additional keyword arguments passed along to the `torch.utils.checkpoint.checkpoint` function.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3823: "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_che
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3871: "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_che
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3950: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4137: # TODO: fix safe_serialization for tied weights
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4440: " desired `dtype` by passing the correct `dtype` argument."
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4457: " `dtype` by passing the correct `dtype` argument."
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4545: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4603: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4654: same device. If we only pass the device (*e.g.*, `"cpu"`, `"cuda:1"`, `"mps"`, or a GPU ordinal rank
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4708: - If a configuration is provided with `config`, `**kwargs` will be directly passed to the
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4711: - If a configuration is not provided, `kwargs` will be first passed to the configuration class
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4715: will be passed to the underlying model's `__init__` function.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4799: "`state_dict` cannot be passed together with a model name or a `gguf_file`. Use one of the two loading strategies."
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4802: raise ValueError("tp_plan has to be set when tp_size is passed.")
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4804: # TODO: we can relax this check when we support taking tp_plan from a json file, for example.
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4902: # TODO Cyril: raise an error instead of the warning in v4.53 (and change the test to check for raise instead of success)
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4910: # change device_map into a map if we passed an int, a str or a torch.device
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4918: "When passing device_map as a string, the value needs to be a device name (e.g. cpu, cuda:0) or "
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4924: "You can't pass device_map as a negative int. If you want to put the model on the cpu, pass device_map = 'cpu' "
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4931: raise ValueError("DeepSpeed Zero-3 is not compatible with passing a `device_map`.")
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4942: "You can't pass `load_in_4bit`or `load_in_8bit` as a kwarg when passing "
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4954: "Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead."
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5014: "You cannot combine Quantization and loading a model from a GGUF file, try again by making sure you did not passed a `qu
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5062: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5064: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5073: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5086: # passed directly as a kwarg from now on
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5238: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5247: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5424: # TODO: we should only be calling hf_quantizer.skip_placement or something like that
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5899: "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See "
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5975: if "llama4" in self.config.model_type:  # TODO try to enable for FULL COMPILE HYBRID CACHE SUPPORT
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:6076: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:6080: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:6286: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_utils.py:6291: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:33: hidden_states (`tuple(tf.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:38: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:59: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:85: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:90: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:114: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:141: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:147: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:152: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:158: cross_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:185: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:191: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:196: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:218: hidden_states (`tuple(tf.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:223: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:229: cross_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:254: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:260: hidden_states (`tuple(tf.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:265: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:271: cross_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:298: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:304: decoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:309: decoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:315: cross_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:323: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:328: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:356: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:361: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:385: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:391: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:396: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:421: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:426: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:432: cross_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:438: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:464: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:469: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:493: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:499: decoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:504: decoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:510: cross_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:518: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:523: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:553: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:558: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:582: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:587: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:611: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:617: decoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:622: decoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:628: cross_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:633: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:638: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:670: The logits returned do not necessarily have the same size as the `pixel_values` passed as inputs. This is
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:676: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:681: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:707: The logits returned do not necessarily have the same size as the `pixel_values` passed as inputs. This is
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:713: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:735: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:739: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:764: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:769: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:793: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:798: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:824: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:829: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:856: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:862: decoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:867: decoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:875: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:880: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:909: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:915: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:920: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:945: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:966: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/modeling_tf_outputs.py:971: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/image_processing_base.py:46: # TODO: Move BatchFeature to be imported by both image_processing_utils and image_processing_utils_fast
- .venv/lib/python3.12/site-packages/transformers/image_processing_base.py:63: # TODO: (Amy) - factor out the common parts of this and the feature extractor
- .venv/lib/python3.12/site-packages/transformers/image_processing_base.py:139: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/image_processing_base.py:218: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/image_processing_base.py:404: # dict within the image processor and isn't overwritten if `size` is passed in as a kwarg.
- .venv/lib/python3.12/site-packages/transformers/image_processing_base.py:519: If a single url is passed, the return value will be a single object. If a list is passed a list of objects is
- .venv/lib/python3.12/site-packages/transformers/modeling_gguf_pytorch_utils.py:309: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:337: Base class for kwargs passing to processors.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:396: support function calling, this argument will have no effect. Each tool should be passed as a JSON Schema,
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:405: for examples of passing documents with chat templates.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:409: Note that this argument will be passed to the chat template, and so it must be supported in the
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:434: Number of frames to sample uniformly. If not passed, the whole video is loaded.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:436: Whether to use the audio track of input video. If `True` the audio track will be loaded and passed to the
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:552: Checks the passed argument's class against the expected transformers class. In case of an unexpected
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:679: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:907: pass  # No template dir means no template files
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1036: # In any case we need to pass `chat_template` if it is available
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1151: 1) kwargs passed as before have highest priority to preserve BC.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1156: 2) kwargs passed as modality-specific kwargs have second priority. This is the recommended API.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1160: 3) kwargs passed during instantiation of a modality processor have fourth priority.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1164: processor(tokenizer, image_processor) # will pass max_length unless overridden by kwargs at call
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1178: Typed dictionary of kwargs specifically required by the model passed.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1184: Dictionary of per-modality kwargs to be passed to each modality-specific processor.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1221: # pass defaults to output dictionary
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1224: # update modality kwargs with passed kwargs
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1231: # check if this key was passed as a flat kwarg.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1234: f"Keyword argument {modality_key} was passed two times:\n"
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1307: Additional keyword arguments passed along to both
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1373: # TODO: @yoni, change logic in v4.52 (when use_fast set to True by default)
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1502: " which one to use by passing the `chat_template` argument. Available templates are: "
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1517: pass
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1624: # and pass it to the processor. Users thus never worried about special tokens relying on processor handling
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1632: # Always sample frames by default unless explicitly set to `False` by users. If users do not pass `num_frames`/`video_fp
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1683: Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/processing_utils.py:1685: Additional arguments to be passed to the tokenizer's `batch_decode method`.
- .venv/lib/python3.12/site-packages/transformers/image_utils.py:552: # Here, size_divisor might be passed as the value of size
- .venv/lib/python3.12/site-packages/transformers/image_utils.py:953: # TODO raise a warning here instead of simply logging?
- .venv/lib/python3.12/site-packages/transformers/image_processing_utils.py:54: raise NotImplementedError("Each image processor must implement its own preprocess method")
- .venv/lib/python3.12/site-packages/transformers/masking_utils.py:232: passed).
- .venv/lib/python3.12/site-packages/transformers/masking_utils.py:240: # When using `torch.export` or `torch.onnx.dynamo_export`, we must pass an example input, and `is_causal` behavior is
- .venv/lib/python3.12/site-packages/transformers/masking_utils.py:798: # TODO: cyril -> probably revisit and remove this, but a lot of tests rely on it
- .venv/lib/python3.12/site-packages/transformers/masking_utils.py:895: # TODO: cyril -> probably revisit and remove this, but a lot of tests rely on it
- .venv/lib/python3.12/site-packages/transformers/masking_utils.py:1015: # TODO: cyril -> probably revisit and remove this, but a lot of tests rely on it
- .venv/lib/python3.12/site-packages/transformers/masking_utils.py:1219: pass
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:121: Python's tokenizer, this method will raise `NotImplementedError`.
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:126: **kwargs: passed to the `self.tokenize()` method
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:222: - **model_input_names** (`List[str]`) -- A list of inputs expected in the forward pass of the model.
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:232: The mode to use for the tokenizer. This will be passed to the `MistralTokenizer` constructor.
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:245: The list of inputs accepted by the forward pass of the model (like `"token_type_ids"` or
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:709: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:1155: If the `encoded_inputs` passed are dictionary of numpy arrays, PyTorch tensors, the
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:1208: # The model's main input name, usually `input_ids`, has been passed for padding
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:1390: support function calling, this argument will have no effect. Each tool should be passed as a JSON Schema,
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:1429: tokens. This output is ready to pass to the model, either directly or via methods like `generate()`.
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:1549: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:1550: "When passing audio content in apply_chat_template, `return_tensors` must be None since we cannot batch the audio inputs
- .venv/lib/python3.12/site-packages/transformers/tokenization_mistral_common.py:1748: The list of inputs accepted by the forward pass of the model (like `"token_type_ids"` or
- .venv/lib/python3.12/site-packages/transformers/optimization.py:62: Extra parameters to be passed to the scheduler. See `torch.optim.lr_scheduler.ReduceLROnPlateau`
- .venv/lib/python3.12/site-packages/transformers/optimization.py:622: # If a `LayerWiseDummyOptimizer` is passed we extract the optimizer dict and
- .venv/lib/python3.12/site-packages/transformers/training_args.py:68: trainer_log_levels = dict(**log_levels, passive=-1)
- .venv/lib/python3.12/site-packages/transformers/training_args.py:195: def _convert_str_dict(passed_value: dict):
- .venv/lib/python3.12/site-packages/transformers/training_args.py:196: "Safely checks that a passed value is a dictionary and converts any string values to their appropriate types."
- .venv/lib/python3.12/site-packages/transformers/training_args.py:197: for key, value in passed_value.items():
- .venv/lib/python3.12/site-packages/transformers/training_args.py:199: passed_value[key] = _convert_str_dict(value)
- .venv/lib/python3.12/site-packages/transformers/training_args.py:203: passed_value[key] = value.lower() == "true"
- .venv/lib/python3.12/site-packages/transformers/training_args.py:206: passed_value[key] = int(value)
- .venv/lib/python3.12/site-packages/transformers/training_args.py:208: passed_value[key] = float(value)
- .venv/lib/python3.12/site-packages/transformers/training_args.py:210: return passed_value
- .venv/lib/python3.12/site-packages/transformers/training_args.py:213: # TODO: `TrainingArguments` users rely on it being fully mutable. In the future see if we can narrow this to a few keys:
- .venv/lib/python3.12/site-packages/transformers/training_args.py:258: Number of updates steps to accumulate the gradients for, before performing a backward/update pass.
- .venv/lib/python3.12/site-packages/transformers/training_args.py:262: When using gradient accumulation, one step is counted as one step with backward pass. Therefore, logging,
- .venv/lib/python3.12/site-packages/transformers/training_args.py:311: log_level (`str`, *optional*, defaults to `passive`):
- .venv/lib/python3.12/site-packages/transformers/training_args.py:313: 'info', 'warning', 'error' and 'critical', plus a 'passive' level which doesn't set anything and keeps the
- .venv/lib/python3.12/site-packages/transformers/training_args.py:360: If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in
- .venv/lib/python3.12/site-packages/transformers/training_args.py:382: callbacks passed to the `Trainer` if they exist in the checkpoint."
- .venv/lib/python3.12/site-packages/transformers/training_args.py:427: When training on TPU, the number of TPU cores (automatically passed by launcher script).
- .venv/lib/python3.12/site-packages/transformers/training_args.py:512: passed).
- .venv/lib/python3.12/site-packages/transformers/training_args.py:515: `T5Block` .... (useful only when `fsdp` flag is passed).
- .venv/lib/python3.12/site-packages/transformers/training_args.py:518: `fsdp` field is passed).
- .venv/lib/python3.12/site-packages/transformers/training_args.py:529: FSDP's forward prefetch mode (useful only when `fsdp` field is passed).
- .venv/lib/python3.12/site-packages/transformers/training_args.py:531: forward pass.
- .venv/lib/python3.12/site-packages/transformers/training_args.py:533: FSDP's limit_all_gathers (useful only when `fsdp` field is passed).
- .venv/lib/python3.12/site-packages/transformers/training_args.py:551: certain layers and recomputing them during a backward pass. Effectively, this trades extra
- .venv/lib/python3.12/site-packages/transformers/training_args.py:638: When using distributed training, the value of the flag `find_unused_parameters` passed to
- .venv/lib/python3.12/site-packages/transformers/training_args.py:641: When using distributed training, the value of the flag `bucket_cap_mb` passed to `DistributedDataParallel`.
- .venv/lib/python3.12/site-packages/transformers/training_args.py:643: When using distributed training, the value of the flag `broadcast_buffers` passed to
- .venv/lib/python3.12/site-packages/transformers/training_args.py:685: - `"end"`: push the model, its configuration, the processing class e.g. tokenizer (if passed along to the [`Trainer`]) a
- .venv/lib/python3.12/site-packages/transformers/training_args.py:687: - `"every_save"`: push the model, its configuration, the processing class e.g. tokenizer (if passed along to the [`Train
- .venv/lib/python3.12/site-packages/transformers/training_args.py:707: If True, use gradient checkpointing to save memory at the expense of slower backward pass.
- .venv/lib/python3.12/site-packages/transformers/training_args.py:709: Key word arguments to be passed to the `gradient_checkpointing_enable` method.
- .venv/lib/python3.12/site-packages/transformers/training_args.py:715: - `"inputs"`: Input data passed to the model, intended for calculating input dependent metrics.
- .venv/lib/python3.12/site-packages/transformers/training_args.py:785: You need to make sure to pass a valid GaLore or APOLLO optimizer, e.g., one of: "apollo_adamw", "galore_adamw", "galore_
- .venv/lib/python3.12/site-packages/transformers/training_args.py:789: rather than saving all eval logits in memory. When set to `True`, you must pass a compute_metrics function
- .venv/lib/python3.12/site-packages/transformers/training_args.py:790: that takes a boolean argument `compute_result`, which when passed `True`, will trigger the final global
- .venv/lib/python3.12/site-packages/transformers/training_args.py:805: Configuration to be used for Liger Kernel. When use_liger_kernel=True, this dict is passed as keyword arguments to the
- .venv/lib/python3.12/site-packages/transformers/training_args.py:815: # Sometimes users will pass in a `str` repr of a dict in the CLI
- .venv/lib/python3.12/site-packages/transformers/training_args.py:884: metadata={"help": "Number of updates steps to accumulate before performing a backward/update pass."},
- .venv/lib/python3.12/site-packages/transformers/training_args.py:940: default="passive",
- .venv/lib/python3.12/site-packages/transformers/training_args.py:944: " 'info', 'warning', 'error' and 'critical', plus a 'passive' level which doesn't set anything and"
- .venv/lib/python3.12/site-packages/transformers/training_args.py:945: " lets the application set the level. Defaults to 'passive'."
- .venv/lib/python3.12/site-packages/transformers/training_args.py:999: "If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in"
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1038: "help": "Whether to restore the callback states from the checkpoint. If `True`, will override callbacks passed to the `T
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1132: default=None, metadata={"help": "TPU: Number of TPU cores (automatically passed by launcher script)"}
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1248: " only when `fsdp` field is passed)."
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1266: " `BertLayer`, `GPTJBlock`, `T5Block` .... (useful only when `fsdp` flag is passed)."
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1287: "Enable deepspeed and pass the path to deepspeed json config file (e.g. `ds_config.json`) or an already"
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1323: "When using distributed training, the value of the flag `find_unused_parameters` passed to "
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1332: "When using distributed training, the value of the flag `bucket_cap_mb` passed to "
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1341: "When using distributed training, the value of the flag `broadcast_buffers` passed to "
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1395: "help": "If True, use gradient checkpointing to save memory at the expense of slower backward pass."
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1401: "help": "Gradient checkpointing key word arguments such as `use_reentrant`. Will be passed to `torch.utils.checkpoint.ch
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1495: "help": "Which backend to use with `torch.compile`, passing one will trigger a model compilation.",
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1501: "help": "Which mode to use with `torch.compile`, passing one will trigger a model compilation.",
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1553: "this dict is passed as keyword arguments to the `_apply_liger_kernel_to_instance` function, "
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1588: passed_value = getattr(self, field)
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1591: if isinstance(passed_value, str) and passed_value.startswith("{"):
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1592: loaded_dict = json.loads(passed_value)
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1786: # Check that a user didn't pass in the class instantiator
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1789: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1790: "Tried passing in a callable to `accelerator_config`, but this is not supported. "
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1791: "Please pass in a fully constructed `AcceleratorConfig` object instead."
- .venv/lib/python3.12/site-packages/transformers/training_args.py:1928: " operation in backward pass. Reference: https://github.com/huggingface/transformers/issues/30404"
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2107: "version 5 of 🤗 Transformers. Use `--hub_model_id` instead and pass the full repo name to this "
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2114: "`--hub_model_id` instead and pass the full repo name to this argument (in this case "
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2122: "`--hub_model_id` instead and pass the full repo name to this argument (in this case "
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2135: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2150: # those deprecated arguments are removed from TrainingArguments. (TODO: v5)
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2223: "but also passed in a `deepspeed` configuration to the `TrainingArguments`. Please set "
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2275: pass
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2539: Checks whether the passed dictionary and its nested dicts have a *dtype* key and if it's not None,
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2564: # Handle the accelerator_config if passed
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2567: # Handle the quantization_config if passed
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2635: Number of updates steps to accumulate the gradients for, before performing a backward/update pass.
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2639: When using gradient accumulation, one step is counted as one step with backward pass. Therefore,
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2650: If True, use gradient checkpointing to save memory at the expense of slower backward pass.
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2796: If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2829: level: str = "passive",
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2833: replica_level: str = "passive",
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2848: level (`str`, *optional*, defaults to `"passive"`):
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2850: `"info"`, `"warning"`, `"error"` and `"critical"`, plus a `"passive"` level which doesn't set anything
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2873: replica_level (`str`, *optional*, defaults to `"passive"`):
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2928: - `"end"`: push the model, its configuration, the processing_class e.g. tokenizer (if passed along to the [`Trainer`]) a
- .venv/lib/python3.12/site-packages/transformers/training_args.py:2930: - `"every_save"`: push the model, its configuration, the processing_class e.g. tokenizer (if passed along to the [`Train
- .venv/lib/python3.12/site-packages/transformers/feature_extraction_utils.py:210: Will be passed to the `to(...)` function of the tensors.
- .venv/lib/python3.12/site-packages/transformers/feature_extraction_utils.py:212: Will be passed to the `to(...)` function of the tensors.
- .venv/lib/python3.12/site-packages/transformers/feature_extraction_utils.py:229: pass
- .venv/lib/python3.12/site-packages/transformers/feature_extraction_utils.py:324: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/feature_extraction_utils.py:400: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:320: # Some old models give None for `cache_position` or even omit passing `cache_kwargs` when used as cross-attention,
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:331: except NotImplementedError:
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:427: except NotImplementedError:
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:503: except NotImplementedError:
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:964: If a config is passed, it will additionally check for sliding or hybrid cache structure, greatly reducing the
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:976: The config of the model for which this Cache will be used. If passed, it will be used to check for sliding
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:995: >>> # Prepare a cache class and pass it to model's forward
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1010: # If a config is passed, use it to infer the layer types and initialize accordingly
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1030: # In this case, use the passed data to already fill in the Cache
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1034: # If the config was not passed above, initialize a DynamicLayer for each entry of the ddp_data
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1040: # If neither of config nor ddp_data was passed, then simply lazy init a full cache of DynamicLayer
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1105: >>> # Prepare a cache class and pass it to model's forward
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1230: >>> # Prepare cache classes for encoder and decoder and pass it to model's forward
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1241: # For dp and ddp support, if only one argument is passed, it should be an iterable of tuples of tensors
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1338: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1362: # TODO(gante, sanchit-gandhi): move following functionality into `.generate`
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1511: # TODO (joao, manuel): Remove this class in v4.59.0
- .venv/lib/python3.12/site-packages/transformers/cache_utils.py:1513: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:131: Implements the NEFTune forward pass for the model using forward hooks. Note this works only for torch.nn.Embedding
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:162: inputs (`np.ndarray`, *optional*): Input data passed to the model.
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:455: When a stage completes, it can pass metrics dict to update with the memory metrics gathered during this stage.
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:616: """stop tracking for the passed stage"""
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:642: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:771: Recursively calls `.item()` on the element of the dictionary passed
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:786: Return the number of arguments of the passed function, even if it's a partial function.
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:800: CUDNN, the batch size is multiplied by 0.9 and passed to `function`. `function` must take in a `batch_size` parameter as
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:836: """Wrap the data collator to remove unused columns before they are passed to the collator."""
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:875: """A helper method to check if the passed module's key name matches any of the target modules in the optim_target_module
- .venv/lib/python3.12/site-packages/transformers/trainer_utils.py:883: If set to `True`, the method will return whether the passed `optim_target_modules`
- .venv/lib/python3.12/site-packages/transformers/modelcard.py:395: pass
- .venv/lib/python3.12/site-packages/transformers/modelcard.py:713: passed to the `PushToHubCallback`. Returns lines and logs compatible with those returned by `parse_log_history`.
- .venv/lib/python3.12/site-packages/transformers/feature_extraction_sequence_utils.py:77: If the `processed_features` passed are dictionary of numpy arrays, PyTorch tensors or TensorFlow tensors, the
- .venv/lib/python3.12/site-packages/transformers/feature_extraction_sequence_utils.py:130: # The model's main input name, usually `input_values`, has be passed for padding
- .venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:274: All other keyword arguments passed to `DistributedSampler`.
- .venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:348: have to be synced (i.e. will not hang for synchronization even if varied number of forward passes), we still add
- .venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:370: # Add extra samples to make num_samples a multiple of batch_size if passed
- .venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:469: If passed, the class assumes the datasets passed to each process are made to be a multiple of this argument
- .venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:491: Add `arrays` to the internal storage, Will initialize the storage to the full size at the first arrays passed
- .venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:509: f"Arrays passed should all have a first dimension multiple of {self.world_size}, found {arrays.shape[0]}."
- .venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:533: logger.warning("Not all data has been set. Are you sure you passed all values?")
- .venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:1358: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:1361: pass
- .venv/lib/python3.12/site-packages/transformers/keras_callbacks.py:25: `eval_dataset` before being passed to the `metric_fn` in `np.ndarray` format. The `metric_fn` should compute
- .venv/lib/python3.12/site-packages/transformers/keras_callbacks.py:73: Keyword arguments to pass to `model.generate()` when generating. Has no effect if `predict_with_generate`
- .venv/lib/python3.12/site-packages/transformers/keras_callbacks.py:95: "When passing data to KerasMetricCallback that is not a pre-batched tf.data.Dataset "
- .venv/lib/python3.12/site-packages/transformers/keras_callbacks.py:105: # that is passed to the metric_fn
- .venv/lib/python3.12/site-packages/transformers/keras_callbacks.py:232: # Keras REALLY doesn't like it when we pass around a BatchEncoding or other derived class
- .venv/lib/python3.12/site-packages/transformers/keras_callbacks.py:261: # This is the critical bit - Keras passes a dict containing the loss and standard metric values for this epoch
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:89: there is no optimization made to make each sub-checkpoint as close as possible to the maximum size passed. For
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:229: raise NotImplementedError(f"init method has to be implemented for {self}")
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:232: raise NotImplementedError(f"gradient checkpointing method has to be implemented for {self}")
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:262: "pass it explicitly where needed."
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:341: >>> # then pass the mask as follows
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:407: >>> # then pass the mask as follows
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:552: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:600: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:612: - If a configuration is provided with `config`, `**kwargs` will be directly passed to the
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:615: - If a configuration is not provided, `kwargs` will be first passed to the configuration class
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:619: will be passed to the underlying model's `__init__` function.
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:743: raise NotImplementedError("Support for sharded checkpoints using safetensors is coming soon!")
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:823: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:889: f"The safetensors archive passed at {resolved_archive_file} does not contain the valid metadata."
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:1072: pass
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_utils.py:1117: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/tf_utils.py:70: # TODO: When the issue linked above gets sorted, add a check on TF version here and use the original function if
- .venv/lib/python3.12/site-packages/transformers/tf_utils.py:81: raise NotImplementedError("Only 1D weight and bias tensors are supported for now, with only a single axis.")
- .venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:132: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:984: pass
- .venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:1020: pass
- .venv/lib/python3.12/site-packages/transformers/image_transforms.py:579: # Function is used during model forward pass, so we use the input framework if possible, without
- .venv/lib/python3.12/site-packages/transformers/image_transforms.py:751: pass
- .venv/lib/python3.12/site-packages/transformers/image_transforms.py:780: # TODO (Amy): Accept 1/3/4 channel numpy array as input and return np.array as default
- .venv/lib/python3.12/site-packages/transformers/hyperparameter_search.py:45: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/hyperparameter_search.py:48: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/hyperparameter_search.py:51: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:220: pass
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:768: If you want to rename some of the special tokens this tokenizer uses, pass along a mapping old special
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:771: Additional keyword arguments passed along to the trainer from the 🤗 Tokenizers library.
- .venv/lib/python3.12/site-packages/transformers/video_processing_utils.py:248: If `fps` is passed along with metadata, `fps` frames per second are sampled uniformty. Arguments `num_frames`
- .venv/lib/python3.12/site-packages/transformers/video_processing_utils.py:277: "Please pass in `VideoMetadata` object or use a fixed `num_frames` per input video"
- .venv/lib/python3.12/site-packages/transformers/video_processing_utils.py:305: # Only sample frames if an array video is passed, otherwise first decode -> then sample
- .venv/lib/python3.12/site-packages/transformers/video_processing_utils.py:318: # Videos sometimes are passed as a list of image URLs, especially through templates
- .venv/lib/python3.12/site-packages/transformers/video_processing_utils.py:496: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/video_processing_utils.py:575: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/video_processing_utils.py:756: # dict within the video processor and isn't overwritten if `size` is passed in as a kwarg.
- .venv/lib/python3.12/site-packages/transformers/video_processing_utils.py:877: If a single url is passed, the return value will be a single object. If a list is passed a list of objects is
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:39: and passed to the [`TrainerCallback`].
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:44: step may require several forward and backward passes: if you use `gradient_accumulation_steps=n`, then one update
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:124: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:131: f"All callbacks passed to be saved must inherit `ExportableState`, but received {type(callback)}"
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:175: # use self._trial because the SigOpt/Optuna hpo only call `_hp_search_setup(trial)` instead of passing trial
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:225: raise NotImplementedError("You must implement a `state` function to utilize this class.")
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:354: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:360: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:366: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:372: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:378: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:385: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:391: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:397: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:403: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:410: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:416: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:422: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:428: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:434: pass
- .venv/lib/python3.12/site-packages/transformers/trainer_callback.py:440: pass
- .venv/lib/python3.12/site-packages/transformers/model_debugging_utils.py:246: # summary-only version for readability - traversing the tree again #TODO optimize?
- .venv/lib/python3.12/site-packages/transformers/model_debugging_utils.py:279: This records structured inputs and outputs during the forward pass into a call tree.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:125: pass
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:806: # Otherwise it passes the casts down and casts the LongTensor containing the token idxs
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:865: # TODO clean this up at some point (probably by switching to fast tokenizers)
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1044: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1270: Python's tokenizer, this method will raise `NotImplementedError`.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1275: **kwargs: passed to the `self.tokenize()` method
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1314: - **model_input_names** (`list[str]`) -- A list of inputs expected in the forward pass of the model.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1336: The list of inputs accepted by the forward pass of the model (like `"token_type_ids"` or
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1491: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1504: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1516: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1546: support function calling, this argument will have no effect. Each tool should be passed as a JSON Schema,
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1555: for examples of passing documents with chat templates.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1557: A Jinja template to use for this conversion. It is usually not necessary to pass anything to this
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1562: Note that this argument will be passed to the chat template, and so it must be supported in the
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1595: tokenizer_kwargs (`dict[str: Any]`, *optional*): Additional kwargs to pass to the tokenizer.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1600: **kwargs: Additional kwargs to pass to the template renderer. Will be accessible by the chat template.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1604: output is ready to pass to the model, either directly or via methods like `generate()`. If `return_dict` is
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1717: tokenizing messages one by one, you should pass the previous messages in the conversation here.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1719: Additional kwargs to pass to the `apply_chat_template` method.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1762: It is usually not necessary to pass anything to this argument,
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1766: support function calling, this argument will have no effect. Each tool should be passed as a JSON Schema,
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1778: # The user can pass the name of a template to the chat template argument instead of an entire template
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1787: "This model has multiple chat templates with no default specified! Please either pass a chat "
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1800: "argument was passed! For information about writing templates and setting the "
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1860: Will be passed along to the Tokenizer `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1866: Will be passed to the Tokenizer `__init__` method. Can be used to set special tokens like `bos_token`,
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2105: # If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2463: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2645: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2659: Will be passed to the underlying model specific encode method. See details in
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2665: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2721: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3142: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3251: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3282: If the `encoded_inputs` passed are dictionary of numpy arrays, PyTorch tensors or TensorFlow tensors, the
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3345: # The model's main input name, usually `input_ids`, has been passed for padding
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3436: Create the token type IDs corresponding to the sequences passed. [What are token type
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3831: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3852: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3889: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3911: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3993: pass
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3999: pass
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4098: Additional keyword arguments passed along to `self.__call__`.
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4107: The full set of keys `[input_ids, attention_mask, labels]`, will only be returned if tgt_texts is passed.
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:30: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:35: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:56: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:76: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:95: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:117: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:122: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:148: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:153: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:180: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:185: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:191: cross_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` and `config.add_cross_attenti
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:197: past_key_values (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True` is passed or when `config.use_c
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:227: past_key_values (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True` is passed or when `config.use_c
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:236: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:241: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:247: cross_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` and `config.add_cross_attenti
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:274: past_key_values (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True` is passed or when `config.use_c
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:281: decoder_hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:286: decoder_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.o
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:292: cross_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:300: encoder_hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:305: encoder_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.o
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:331: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:336: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:342: cross_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:348: past_key_values (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True` is passed or when `config.use_c
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:372: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:377: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:401: past_key_values (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True` is passed or when `config.use_c
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:408: decoder_hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:413: decoder_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.o
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:419: cross_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:427: encoder_hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:432: encoder_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.o
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:459: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:464: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:485: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:490: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:511: past_key_values (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True` is passed or when `config.use_c
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:518: decoder_hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:523: decoder_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.o
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:529: cross_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:537: encoder_hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:542: encoder_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.o
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:570: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:575: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:596: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:601: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:624: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:629: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:653: past_key_values (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True` is passed or when `config.use_c
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:660: decoder_hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:665: decoder_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.o
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:671: cross_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:679: encoder_hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/modeling_flax_outputs.py:684: encoder_attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.o
- .venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:32: Decorator function to update the RoPE parameters in the forward pass, if the model is using a dynamic RoPE
- .venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:33: (i.e. a RoPE implementation that may recompute its frequencies in the forward pass).
- .venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:37: The forward pass of the RoPE implementation.
- .venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:40: The decorated forward pass.
- .venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:71: self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
- .venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:170: # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
- .venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:301: # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
- .venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:445: # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
- .venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:525: # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
- .venv/lib/python3.12/site-packages/transformers/training_args_tf.py:72: Number of updates steps to accumulate the gradients for, before performing a backward/update pass.
- .venv/lib/python3.12/site-packages/transformers/training_args_tf.py:76: When using gradient accumulation, one step is counted as one step with backward pass. Therefore, logging,
- .venv/lib/python3.12/site-packages/transformers/training_args_tf.py:127: If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in
- .venv/lib/python3.12/site-packages/transformers/training_args_tf.py:141: When training on TPU, the number of TPU cores (automatically passed by launcher script).
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:34: # TODO Deprecate when all models have the attention interface
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:46: # TODO Deprecate when all models have the attention interface
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:351: # `torch._dynamo.config.capture_scalar_outputs = True` before doing the forward pass.
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:353: # requires `max_length_q`, `max_length_k` to be passed as `int` and not `torch.Tensor`.
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:468: Returns a set of kwargs that are passed down to the according flash attention function based on
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:559: Input query states to be passed to Flash Attention API
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:561: Input key states to be passed to Flash Attention API
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:563: Input value states to be passed to Flash Attention API
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:595: # Case 2. Some models pass directly pre-computed `cu_seqlens` so we don't need to infer it from position ids. It is safe
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:611: # TODO for now this is required to work with
- .venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:642: # TODO for now this is required to work with
- .venv/lib/python3.12/site-packages/transformers/image_processing_utils_fast.py:291: # TODO: remove this once the bug is fixed (detected with torch==2.7.0+git1fee196, torchvision==0.22.0+9eb57cd)
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:54: Trie in Python. Creates a Trie out of a list of words. The trie is used to split on `added_tokens` in one pass
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:429: # 3. if a `added_tokens_decoder` is passed, we are loading from a saved tokenizer, we overwrite
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:454: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:545: # TODO this is fairly slow to improve!
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:708: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:741: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:792: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:872: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:1077: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:1105: # TODO @ArthurZ in version 5, special tokens should be handled in convert_tokens_to_string, while _convert_tokens_to_str
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:94: - *assisted decoding* if `assistant_model` or `prompt_lookup_num_tokens` is passed to `.generate()`
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:127: the current pass after allocated time has been passed.
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:158: Arguments used in the key-value cache class can be passed in `cache_config`.
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:258: details. If passed as `Dict`, it will be converted to a `WatermarkingConfig` internally.
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:316: (defined by `num_assistant_tokens`) is not yet reached. The assistant's confidence threshold is adjusted throughout the 
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:339: If using a compilable cache, this controls how `generate` will `compile` the forward pass for faster
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:342: Whether to disable the automatic compilation of the forward pass. Automatic compilation happens when
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:440: # Deprecated (moved to the Hub). TODO joao, manuel: remove in v4.62.0
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:491: # TODO joao: find out a way of not depending on external fields (e.g. `assistant_model`), then make this a
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:532: # TODO joao, manuel: remove this in v4.62.0
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:700: # passed to `generate` directly to hot-fix cache issues, let's raise a warning instead of an error
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:721: # 3. Check common issue: passing `generate` arguments inside the generation config
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:736: f"Argument `{arg}` is not a valid argument of `GenerationConfig`. It should be passed to "
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:785: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:884: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:921: >>> # If you'd like to try a minor variation to an existing configuration, you can also pass generation
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:1042: # Those arguments may be passed along for our internal telemetry.
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:1063: Checks whether the passed dictionary and its nested dicts have a *dtype* key and if it's not None,
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:1333: Class that holds arguments for watermark generation and should be passed into `GenerationConfig` during `generate`.
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:1411: Class that holds arguments for watermark generation and should be passed into `GenerationConfig` during `generate`.
- .venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:1516: A dictionary of options to pass to the backend.
- .venv/lib/python3.12/site-packages/transformers/generation/beam_search.py:107: raise NotImplementedError("This is an abstract method.")
- .venv/lib/python3.12/site-packages/transformers/generation/beam_search.py:120: raise NotImplementedError("This is an abstract method.")
- .venv/lib/python3.12/site-packages/transformers/generation/beam_search.py:944: "When `do_early_stopping` is set to a string, `max_length` must be defined. Ensure it is passed to the"
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:148: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:256: # `kwargs`/`model_kwargs` is often used to handle optional forward pass inputs like `attention_mask`. If
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:288: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:297: Optionally the model parameters can be passed. Can be useful for parallelized generation.
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:300: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:347: "unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results."
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:481: raise NotImplementedError("`Beam sampling is currently not implemented.")
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:566: f"A custom {object_type} of type {type(custom)} with values {custom} has been passed to"
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:568: " created by passing the corresponding arguments to generate or by the model's config default"
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:569: f" values. If you just want to change the default values of {object_type} consider passing"
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:605: # and pass it the `encoder_outputs`, which are part of the `model_kwargs`.
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:694: # and pass it the `encoder_outputs`, which are part of the `model_kwargs`.
- .venv/lib/python3.12/site-packages/transformers/generation/flax_utils.py:840: # and pass it the `encoder_outputs`, which are part of the `model_kwargs`.
- .venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:58: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:69: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:89: f"{processor.__class__} are passed to the logits processor."
- .venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:370: # TODO (Joao): this function might trigger XLA retracing as `cur_len` increases. Fix it if it becomes
- .venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:427: # TODO (joao): enable XLA on this logits processor. See discussion and attempts in
- .venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:430: raise NotImplementedError("TFNoRepeatNGramLogitsProcessor is only implemented for eager execution.")
- .venv/lib/python3.12/site-packages/transformers/generation/flax_logits_process.py:57: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/flax_logits_process.py:68: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/flax_logits_process.py:88: f"{processor.__class__} are passed to the logits processor."
- .venv/lib/python3.12/site-packages/transformers/generation/__init__.py:36: pass
- .venv/lib/python3.12/site-packages/transformers/generation/__init__.py:132: pass
- .venv/lib/python3.12/site-packages/transformers/generation/__init__.py:169: pass
- .venv/lib/python3.12/site-packages/transformers/generation/__init__.py:209: pass
- .venv/lib/python3.12/site-packages/transformers/generation/__init__.py:293: pass
- .venv/lib/python3.12/site-packages/transformers/generation/__init__.py:330: pass
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:205: past_key_values (`tuple(tuple(torch.FloatTensor)))`, *optional*, returned when `use_cache=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:322: # TODO (joao): remove the equivalent classes and typing shortcuts below in v5
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:376: - *assisted decoding* if `assistant_model` or `prompt_lookup_num_tokens` is passed to `.generate()`
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:460: - Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:463: - Exception 4: If input_embeds are passed then slice it through `cache_position`, to keep only the unprocessed tokens an
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:558: See the forward pass in the model documentation for expected arguments (different models might have different
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:575: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step for every prompt.
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:618: # pass)
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:680: # 8. Remove unexpected `generate` inputs (TODO @joao: fix trainer and examples)
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:706: # 2. check whether model_input_name is passed as kwarg
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:711: f"`inputs`: {inputs}` were passed alongside {input_name} which is not allowed. "
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:712: f"Make sure to either pass {inputs} or {input_name}=..."
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:718: # - decoder-only models should complain if the user attempts to pass `inputs_embeds`, but the model
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:721: # - encoder-decoder models should complain if the user attempts to pass `inputs_embeds` and `input_ids`, and
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:732: f"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} "
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:744: raise ValueError("You passed `inputs_embeds` and `input_ids` to `.generate()`. Please pick one.")
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:870: # we also allow the user to pass it under `input_ids`, if the encoder does not use it as the main input.
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:902: pass
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:904: pass
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:964: # TODO (joao): remove output/input mismatch when these old models (xlnet, reformer) are deprecated
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1138: "Passing `encoder_repetition_penalty` requires some form of `input_ids` to be passed to "
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1159: "Passing `encoder_no_repeat_ngram_size` requires some form of `input_ids` to be passed to "
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1248: # TODO (joao): find a strategy to specify the order of the processors
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1335: "stop strings, you must pass the model's tokenizer to the `tokenizer` argument of `generate`."
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1372: f"A custom {object_type} of type {type(custom)} has been passed to `.generate()`, but it "
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1549: # `kwargs`/`model_kwargs` is often used to handle optional forward pass inputs like `attention_mask`. If
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1562: # TODO: A better way to handle this.
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1654: # if both `inputs_embeds` and `input_ids` are passed, we do not correct the length
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1698: # TODO (joao): per-model generation config classes.
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1783: # Finally, apply any passed kwargs
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1904: # b) convert to the new cache format (if the user passes a legacy cache and model supports it)
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1938: # TODO(joao): support static caches in assisted generation. assisted generation needs to roll back caches,
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:1948: # To handle this, we skip passing the model config to DynamicCache (forcing a full-layer cache).
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2062: "unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results."
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2079: "eos token. As a consequence, you may observe unexpected behavior. Please pass your input's "
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2101: Determines whether to trigger auto-compilation of the model's forward pass at generation time.
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2163: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2164: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2180: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2187: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2191: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2193: sure you pass `return_dict_in_generate=True, output_scores=True` to `generate`. This feature is
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2212: Streamer object that will be used to stream the generated sequences. Generated tokens are passed
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2331: # TODO (joao): generalize this check with other types of inputs
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2333: raise ValueError("`attention_mask` passed to `generate` must be 2D.")
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2381: # logit matrix. This can save a lot of memory during the first forward pass. Note that assisted decoding
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2495: # TODO joao, manuel: remove this in v4.62.0
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2515: # TODO joao, manuel: remove this in v4.62.0
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2693: " When generating with token healing, you must pass the model's tokenizer to the `tokenizer` "
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2794: Streamer object that will be used to stream the generated sequences. Generated tokens are passed
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2843: # only raise warning if the user passed an explicit compile-config
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:2911: # TODO (joao): this OP throws "skipping cudagraphs due to ['incompatible ops']", find solution
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:3088: # TODO (joao): This function should take an optional beam scorer function, to manipulate the scores after
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:3256: # TODO (joao): standardize special cases
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:4100: Streamer object that will be used to stream the generated sequences. Generated tokens are passed
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:4156: # we use this forward pass to also pick the subsequent logits in the original model.
- .venv/lib/python3.12/site-packages/transformers/generation/utils.py:4177: # 2.2. Run a forward pass on the candidate sequence
- .venv/lib/python3.12/site-packages/transformers/generation/streamers.py:34: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/generation/streamers.py:38: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/generation/streamers.py:57: Additional keyword arguments to pass to the tokenizer's `decode` method.
- .venv/lib/python3.12/site-packages/transformers/generation/streamers.py:183: Additional keyword arguments to pass to the tokenizer's `decode` method.
- .venv/lib/python3.12/site-packages/transformers/generation/streamers.py:254: Additional keyword arguments to pass to the tokenizer's `decode` method.
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:67: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:71: attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.output_at
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:74: hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:97: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:101: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or `config.output_a
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:104: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:107: decoder_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.o
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:110: cross_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.out
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:113: decoder_hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:137: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:141: attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.output_at
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:144: hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:167: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:171: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or `config.output_a
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:174: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:177: decoder_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.o
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:180: cross_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.out
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:183: decoder_hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:206: sequences_scores (`tf.Tensor` of shape `(batch_size*num_return_sequences)`, *optional*, returned when `output_scores=Tru
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:208: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:213: beam_indices (`tf.Tensor`, *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:216: attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.output_at
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:219: hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:243: sequences_scores (`tf.Tensor` of shape `(batch_size*num_return_sequences)`, *optional*, returned when `output_scores=Tru
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:245: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:250: beam_indices (`tf.Tensor`, *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:253: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or `config.output_a
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:256: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:259: decoder_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.o
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:263: cross_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.out
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:266: decoder_hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:291: sequences_scores (`tf.Tensor` of shape `(batch_size * num_return_sequence)`, *optional*, returned when `output_scores=Tr
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:293: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:298: beam_indices (`tf.Tensor`, *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:301: attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.output_at
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:304: hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:328: sequences_scores (`tf.Tensor` of shape `(batch_size * num_return_sequence)`, *optional*, returned when `output_scores=Tr
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:330: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:335: beam_indices (`tf.Tensor`, *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:338: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or `config.output_a
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:341: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:344: decoder_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.o
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:347: cross_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.out
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:350: decoder_hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:375: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:379: attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.output_at
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:382: hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:404: scores (`tuple(tf.Tensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`)
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:408: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or `config.output_a
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:411: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:414: decoder_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.o
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:417: cross_attentions (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_attentions=True` is passed or `config.out
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:420: decoder_hidden_states (`tuple(tuple(tf.Tensor))`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:473: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:631: # `kwargs`/`model_kwargs` is often used to handle optional forward pass inputs like `attention_mask`. If
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:658: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:659: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:675: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:682: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:744: pass
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:746: pass
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:756: pass
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:760: pass
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:771: "unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results."
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1068: if model_input_name != self.main_input_name:  # in Keras, the first input must always be passed
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1085: # we also allow the user to pass it under `input_ids`, if the encoder does not use it as the main input.
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1196: # 2. check whether model_input_name is passed as kwarg
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1201: f"`inputs`: {inputs}` were passed alongside {input_name} which is not allowed. "
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1202: f"Make sure to either pass {inputs} or {input_name}=..."
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1208: # - decoder-only models should complain if the user attempts to pass `inputs_embeds`, but the model
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1211: # - encoder-decoder models should complain if the user attempts to pass `inputs_embeds` and `input_ids`, and
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1220: f"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} "
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1231: raise ValueError("You passed `inputs_embeds` and `input_ids` to `.generate()`. Please pick one.")
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1518: f"A custom {object_type} of type {type(custom)} with values {custom} has been passed to"
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1520: " created by passing the corresponding arguments to generate or by the model's config default"
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1521: f" values. If you just want to change the default values of {object_type} consider passing"
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1629: # TODO (Joao): fix cache format or find programmatic way to detect cache index
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1664: # forward pass to get next token logits
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1913: # TODO (Joao): fix cache format or find programmatic way to detect cache index
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1944: # forward pass to get next token logits
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2256: # TODO (Joao): fix cache format or find programmatic way to detect cache index
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2791: # TODO (Joao): fix cache format or find programmatic way to detect cache index
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2868: # Expands model inputs top_k times, for batched forward passes (akin to beam search).
- .venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:3014: # passes one step ahead -- hence the `cur_len=cur_len + 1`; 2) the attention mask here is expanded from
- .venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py:57: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py:74: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py:97: The keyword arguments that will be passed to the main model, and are used as base inputs for the assistant
- .venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py:184: "Please pass in `min_length` into `.generate()` instead"
- .venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py:249: # The assistant's confidence threshold is adjusted throughout the speculative iterations to reduce the number of unneces
- .venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py:359: The keyword arguments that will be passed to the main model, and are used as base inputs for the assistant
- .venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py:740: This method is required for the first forward pass of `_MapInputEmbedding` where input ids are already in the assistant 
- .venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py:1130: The keyword arguments that will be passed to the main model, and are used as base inputs for the assistant
- .venv/lib/python3.12/site-packages/transformers/generation/stopping_criteria.py:35: make sure you pass `return_dict_in_generate=True, output_scores=True` to `generate`.
- .venv/lib/python3.12/site-packages/transformers/generation/stopping_criteria.py:50: If your stopping criteria depends on the `scores` input, make sure you pass `return_dict_in_generate=True,
- .venv/lib/python3.12/site-packages/transformers/generation/stopping_criteria.py:56: raise NotImplementedError("StoppingCriteria needs to be subclassed")
- .venv/lib/python3.12/site-packages/transformers/generation/stopping_criteria.py:91: time will start being counted when you initialize this function. You can override this by passing an
- .venv/lib/python3.12/site-packages/transformers/generation/stopping_criteria.py:213: A list of strings that should end generation. If a string is passed, it will be treated like a
- .venv/lib/python3.12/site-packages/transformers/generation/stopping_criteria.py:233: >>> # Note that generating with stop strings requires you to pass the tokenizer too
- .venv/lib/python3.12/site-packages/transformers/generation/beam_constraints.py:59: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/beam_constraints.py:68: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/beam_constraints.py:93: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/beam_constraints.py:103: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/beam_constraints.py:112: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/beam_constraints.py:127: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/watermarking.py:152: def _score_ngrams_in_passage(self, input_ids: torch.LongTensor):
- .venv/lib/python3.12/site-packages/transformers/generation/watermarking.py:225: num_tokens_scored, green_token_count = self._score_ngrams_in_passage(input_ids)
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:29: # TODO (joao): We shouldn't need this, but there would be a circular import
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:55: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:89: f"{processor.__class__} are passed to the logits processor."
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:336: >>> # with a `prompt_ignore_length` and passing it as a custom logit processor
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:2016: # TODO(Patrick): Make sure that official models have max_initial_timestamp_index set to 50
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:2266: Whether to cache key/values during the negative prompt forward pass.
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:2310: "first_pass": True,
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:2314: if self.unconditional_context["first_pass"]:
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:2323: self.unconditional_context["first_pass"] = False
- .venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:2896: It is not possible to pass random keys in a vectorized way in torch. Instead
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/scheduler.py:39: pass
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/scheduler.py:43: pass
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/scheduler.py:53: pass
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/continuous_api.py:70: slice_inputs: bool = True,  # TODO: remove this once parity is ensured
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/continuous_api.py:231: """Prepare tensors and metadata for the next model forward pass."""
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/continuous_api.py:546: self.input_queue.put(state, block=True, timeout=10)  # XXX: pass timeout as fn arg?
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/continuous_api.py:588: # Warmup the model with a dummy forward pass
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/continuous_api.py:604: batch_processor.output_probs.copy_(logits)  # TODO
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/continuous_api.py:614: # Pass continuous batching context to logits processor if it supports it. TODO we should find a way to make this a littl
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/continuous_api.py:694: logger.error(f"Model forward pass failed: {e}", exc_info=True)
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/continuous_api.py:722: pass
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/cache.py:68: # self.num_key_value_heads //= tp_size # TODO: why is this commented out?
- .venv/lib/python3.12/site-packages/transformers/generation/continuous_batching/classes.py:158: # TODO: this logic seems one token off, check it out
- .venv/lib/python3.12/site-packages/transformers/loss/loss_for_object_detection.py:94: the maximum id for a class in your dataset. For example, COCO has a `max_obj_id` of 90, so we pass `num_classes` to
- .venv/lib/python3.12/site-packages/transformers/loss/loss_for_object_detection.py:95: be 91. As another example, for a dataset that has a single class with `id` 1, you should pass `num_classes` to be 2
- .venv/lib/python3.12/site-packages/transformers/loss/loss_for_object_detection.py:197: # TODO use valid to mask invalid areas due to padding in loss
- .venv/lib/python3.12/site-packages/transformers/loss/loss_utils.py:38: # just in case users pass an int for num_items_in_batch, which could be the case for custom trainer
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_higgs.py:49: raise NotImplementedError("HIGGS quantization is only supported on GPU. Please use a different quantizer.")
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:68: f" You explicitly passed `pre_quantized=False` meaning your model weights are not quantized. Make sure to "
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:69: f"pass `pre_quantized=True` while knowing what you are doing."
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:78: The input dtype that is passed in `from_pretrained`
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:93: The input dtype that is passed in `from_pretrained`
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:99: Override this method if you want to pass a override the existing device map with a new
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:101: passed, the device_map is set to `"auto"``
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:105: The device_map that is passed through the `from_pretrained` method.
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:113: to `torch.int8` and for 4-bit we pass a custom enum `accelerate.CustomDtype.int4`.
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:167: one passes a str as a device_map. The method will use the `modules_to_not_convert` that is modified
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:174: The dtype passed in `from_pretrained` method.
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:213: passed in `from_pretrained`. You need to define it for all future quantizers that are integrated with transformers.
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:232: The keyword arguments that are passed along `_process_model_before_weight_loading`.
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:249: The keyword arguments that are passed along `_process_model_after_weight_loading`.
- .venv/lib/python3.12/site-packages/transformers/quantizers/base.py:295: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_finegrained_fp8.py:64: "pass device_map = 'cuda' or 'xpu'. "
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_fp_quant.py:49: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_mxfp4.py:124: "your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. "
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_mxfp4.py:144: "Pass your own dtype to specify the dtype of the remaining non-linear layers or pass"
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_mxfp4.py:310: # if we are using kernels, we can't use the quantized model, since the forward pass is different and needs special handl
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_mxfp4.py:409: "MXFP4 quantization don't support training, please consider dequantizing the model first by passing quantization_config=
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_hqq.py:202: # TODO: This is a compatibility hack. HQQ-quantized linear layers do not have a `weight` attribute,
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_hqq.py:203: # but some models attempt to access `weight.dtype` during the forward pass. To prevent runtime errors,
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_hqq.py:298: # Remove accelerate hook and uses a simpler forward pass. Otherwise, this breaks with multi-gpu
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:47: before loading: converts transformer layers into Linear8bitLt during loading: load 16bit weight and pass to the
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:52: need to locate SCB component and pass to the Linear8bitLt object
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:112: pass
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:117: "in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to "
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:140: "Pass your own dtype to specify the dtype of the remaining non-linear layers or pass"
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:248: # messages. The correct format is correctly retrieved during the first forward pass.
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:287: # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_fbgemm_fp8.py:78: "your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. "
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_fbgemm_fp8.py:98: "Pass your own dtype to specify the dtype of the remaining non-linear layers or pass"
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_fbgemm_fp8.py:104: "You cannot use FP8 with dtype=torch.float16.We recommend you passing dtype=torch.bfloat16"
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_eetq.py:36: before loading: converts transformer layers into W8A16Linear during loading: load 16bit weight and pass to the
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_eetq.py:62: # TODO: Update message once eetq releases a fix
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_eetq.py:101: "Pass your own dtype to specify the dtype of the remaining non-linear layers or pass"
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_awq.py:136: model._awq_is_fused = True  # TODO: consider storing this flag in model.config instead
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:50: before loading: converts transformer layers into Linear4bit during loading: load 16bit weight and pass to the
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:55: need to locate `quant_state` components and pass to Param4bit constructor
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:115: pass
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:120: "in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to "
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:138: "calculation. You may encounter unexpected behavior, or pass your own device map"
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:267: "Pass your own dtype to specify the dtype of the remaining non-linear layers or pass"
- .venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:324: # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
- .venv/lib/python3.12/site-packages/transformers/quantizers/auto.py:151: # Update with potential kwargs that are passed through from_pretrained.
- .venv/lib/python3.12/site-packages/transformers/quantizers/auto.py:203: "You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading"
- .venv/lib/python3.12/site-packages/transformers/quantizers/auto.py:221: f"The model is quantized with {quantization_config.__class__.__name__} but you are passing a {quantization_config_from_a
- .venv/lib/python3.12/site-packages/transformers/quantizers/auto.py:222: "Please make sure to pass the same quantization config class to `from_pretrained` with different loading attributes."
- .venv/lib/python3.12/site-packages/transformers/quantizers/auto.py:236: warning_msg += f"However, loading attributes (e.g. {list(loading_attr_dict.keys())}) will be overwritten with the one yo
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:282: pass
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:763: `extra` list, are passed to the function. Any additional keyword arguments are filtered out and a warning is issued.
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:786: extra_params_to_pass = set(extra)
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:791: valid_kwargs_to_pass = function_named_args.union(extra_params_to_pass)
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:806: if k in valid_kwargs_to_pass:
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:839: Keyword arguments to be passed to the loss function
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:843: Number of items in the batch. It is recommended to pass it when
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:846: Most of the models support outputting all hidden states computed during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:927: Decorator to wrap model method, to call output.to_tuple() if return_dict=False passed as a kwarg or
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:937: return_dict_passed = kwargs.pop("return_dict", return_dict)
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:938: if return_dict_passed is not None:
- .venv/lib/python3.12/site-packages/transformers/utils/generic.py:939: return_dict = return_dict_passed
- .venv/lib/python3.12/site-packages/transformers/utils/doc.py:52: Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]
- .venv/lib/python3.12/site-packages/transformers/utils/doc.py:92: `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`) comprising various
- .venv/lib/python3.12/site-packages/transformers/utils/doc.py:101: `return_dict=False` is passed or when `config.return_dict=False`) comprising various elements depending on the
- .venv/lib/python3.12/site-packages/transformers/utils/doc.py:289: >>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
- .venv/lib/python3.12/site-packages/transformers/utils/doc.py:315: >>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
- .venv/lib/python3.12/site-packages/transformers/utils/doc.py:1090: >>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
- .venv/lib/python3.12/site-packages/transformers/utils/attention_visualizer.py:199: if "token_type_ids" in inputs:  # TODO inspect signature of update causal mask
- .venv/lib/python3.12/site-packages/transformers/utils/chat_template_utils.py:78: pass
- .venv/lib/python3.12/site-packages/transformers/utils/chat_template_utils.py:84: pass
- .venv/lib/python3.12/site-packages/transformers/utils/chat_template_utils.py:161: "pass the element directly."
- .venv/lib/python3.12/site-packages/transformers/utils/chat_template_utils.py:239: mostly used for passing lists of tools to a chat template. The JSON schema contains the name and description of
- .venv/lib/python3.12/site-packages/transformers/utils/chat_template_utils.py:308: >>> # The formatted chat can now be passed to model.generate()
- .venv/lib/python3.12/site-packages/transformers/utils/chat_template_utils.py:323: >>>    pass
- .venv/lib/python3.12/site-packages/transformers/utils/chat_template_utils.py:414: @jinja2.pass_eval_context
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:201: # TODO: add support for them as it should be quite easy to do so (small blocking issues).
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:393: # TODO: infer shape without performing the computation, this might be quite hard.
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:586: # TODO: infer shape without performing the computation.
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:713: pass
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:898: # rightfully pass certain controlflows (Example: https://github.com/huggingface/transformers/blob/5c8d941d66734811d2ef6f
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:959: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:1042: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:1230: the `root` passed in here. For example, when a free function is passed to `trace()`, we will create a
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:1236: [`~transformers.PreTrainedModel`], then `dummy_inputs` must be passed, otherwise tracing will fail.
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:1249: A FX `torch.fx.Graph` representing the semantics of the passed-in `root`.
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:1322: # Removing default values for inputs as the forward pass will fail with them.
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:1340: # TODO: solves GraphModule creation.
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:1381: a submodule named `foo`, which has a submodule named `bar`, passing `bar` into this function will return the
- .venv/lib/python3.12/site-packages/transformers/utils/fx.py:1433: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/utils/peft_utils.py:70: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>".
- .venv/lib/python3.12/site-packages/transformers/utils/backbone_utils.py:251: raise NotImplementedError("This method should be implemented by the derived class.")
- .venv/lib/python3.12/site-packages/transformers/utils/backbone_utils.py:333: # If any of the following are set, then the config passed in is from a model which contains a backbone.
- .venv/lib/python3.12/site-packages/transformers/utils/backbone_utils.py:341: # Because of how timm backbones were originally added to models, we need to pass in use_pretrained_backbone
- .venv/lib/python3.12/site-packages/transformers/utils/backbone_utils.py:370: Verify that the config arguments to be passed to load_backbone are valid
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:261: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:266: raise NotImplementedError("Failed to convert gptq format to auto_round format. Only supports `gptqv1`")
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:269: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:355: pass
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:441: have to be converted back and forth for the backward pass.
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:650: The tokenizer used to process the dataset. You can pass either:
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:670: quantization using inputs that have passed through the previously quantized layers.
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:978: "You cannot enable fused modules without specifying a `fuse_max_seq_len`, make sure to pass a valid `fuse_max_seq_len` f
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:1561: The dtype to use for the forward pass.
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:1563: The scaling to use for the forward pass. Can be `"abs_max"` or `"quest"`. `"abs_max"` is better for PTQ, `"quest"` is be
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:1565: The dtype to use for the backward pass.
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:1867: during each forward pass (e.g., based on the current weight values). This can
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:1907: pass
- .venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:2039: # TODO: Remove this check once configuration version is handled natively by Quark.
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:36: AUTODOC_FILES = [
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:78: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:86: passing in videos with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:358: If no `past_key_values` are passed, [`~cache_utils.DynamicCache`] will be initialized by default.
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:371: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:392: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:599: "additional_info": "returned when `use_cache=True` is passed or when `config.use_cache=True`",
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:610: "additional_info": "returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`",
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:622: "additional_info": "returned when `output_attentions=True` is passed or when `config.output_attentions=True`",
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:641: "additional_info": "returned when `output_attentions=True` is passed or when `config.output_attentions=True`",
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:652: "additional_info": "returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`",
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:664: "additional_info": "returned when `output_attentions=True` is passed or when `config.output_attentions=True`",
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:682: "additional_info": "returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`",
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:694: "additional_info": "returned when `output_attentions=True` is passed or when `config.output_attentions=True`",
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:704: "additional_info": "returned when `output_router_logits=True` is passed or when `config.add_router_probs=True`",
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:715: "additional_info": "returned when `output_router_probs=True` and `config.add_router_probs=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:945: Whether the model supports gradient checkpointing or not. Gradient checkpointing is a memory-saving technique that trade
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:1118: for file_type in AUTODOC_FILES:
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:1175: pass
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:1218: Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:1407: # elif param_type == "" and False:  # TODO: Enforce typing for all parameters
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:1880: # TODO (Yoni): Add support for Attributes section in docs
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:1935: custom_intro="Performs forward pass with enhanced attention computation."
- .venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:2033: or passed via the `custom_args` parameter.
- .venv/lib/python3.12/site-packages/transformers/utils/notebook.py:69: `update_every` seconds. The progress bar uses the average time passed up until now to guess the next value
- .venv/lib/python3.12/site-packages/transformers/utils/notebook.py:82: their display. If set, the object passed must have a `display()` method.
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:44: # TODO: This doesn't work for all packages (`bs4`, `faiss`, etc.) Talk to Sylvain to see how to do with it better.
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:51: # TODO: Once python 3.9 support is dropped, `importlib.metadata.packages_distributions()`
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:74: # TODO: remove once `importlib.metadata.packages_distributions()` is supported.
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:291: pass
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:464: # TODO check if some bugs cause push backs on the exact version
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:685: # TODO: more precise exception matching, if possible.
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:709: # TODO: more precise exception matching, if possible.
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1186: # TODO: Bump the requirement to 2.1.0 once released in https://github.com/ROCmSoftwarePlatform/flash-attention
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1207: # TODO: Check for a minimum version when FA3 is stable
- .venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:2286: pass
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:99: # TODO: clean this for v5?
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:180: pass  # offline mode, internet down, etc. => try local files
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:390: passed when we are chaining several calls to various files (e.g. when loading a tokenizer or
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:512: "listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token "
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:513: "having permission to this repo either by logging in with `hf auth login` or by passing "
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:703: f"https://huggingface.co/{path_or_repo} and pass a token having permission to this repo either by "
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:704: "logging in with `hf auth login` or by passing `token=<your_token>`."
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:752: "organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`)."
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:832: pass
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:914: )  # TODO: This is only used for testing and should be removed once save_jinja_files becomes the default
- .venv/lib/python3.12/site-packages/transformers/utils/hub.py:948: # Repo_id is passed correctly: infer working_dir from it
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/configuration_falcon_h1.py:36: `inputs_ids` passed when calling [`FalconH1Model`]
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/modeling_falcon_h1.py:181: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/modeling_falcon_h1.py:500: - Users can pass custom intermediate_size through `config.mamba_d_ssm`
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/modeling_falcon_h1.py:1567: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/modeling_falcon_h1.py:1596: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/modular_falcon_h1.py:200: pass
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/modular_falcon_h1.py:305: - Users can pass custom intermediate_size through `config.mamba_d_ssm`
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/modular_falcon_h1.py:826: pass
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/modular_falcon_h1.py:1332: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/falcon_h1/modular_falcon_h1.py:1361: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/configuration_rt_detr.py:61: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:106: pass
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:302: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:341: raise NotImplementedError("No need to override this method for RT-DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:344: raise NotImplementedError("Post-processing is not implemented for RT-DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:347: raise NotImplementedError("Segmentation post-processing is not implemented for RT-DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:350: raise NotImplementedError("Instance post-processing is not implemented for RT-DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:353: raise NotImplementedError("Panoptic post-processing is not implemented for RT-DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:356: raise NotImplementedError("Segmentation post-processing is not implemented for RT-DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:359: raise NotImplementedError("Semantic segmentation post-processing is not implemented for RT-DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modular_rt_detr.py:362: raise NotImplementedError("Panoptic segmentation post-processing is not implemented for RT-DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:46: # TODO: Replace all occurrences of the checkpoint with the final one
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:126: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1181: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1316: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1599: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1600: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1602: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1654: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1868: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1869: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1871: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:1896: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/image_processing_rt_detr.py:812: from 0 to 255. If passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/image_processing_rt_detr.py:1064: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr/image_processing_rt_detr_fast.py:551: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/llava_next/image_processing_llava_next.py:340: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/llava_next/image_processing_llava_next.py:575: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/llava_next/modeling_llava_next.py:156: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava_next/modeling_llava_next.py:182: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava_next/modeling_llava_next.py:733: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/configuration_mpnet.py:38: `inputs_ids` passed when calling [`MPNetModel`] or [`TFMPNetModel`].
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/tokenization_mpnet_fast.py:185: Creates a mask from the two sequences passed to be used in a sequence-pair classification task. MPNet does not
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_tf_mpnet.py:288: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_tf_mpnet.py:556: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_tf_mpnet.py:613: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_tf_mpnet.py:675: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_tf_mpnet.py:677: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_tf_mpnet.py:690: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_tf_mpnet.py:728: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py:732: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/tokenization_mpnet.py:277: Creates a mask from the two sequences passed to be used in a sequence-pair classification task. MPNet does not
- .venv/lib/python3.12/site-packages/transformers/models/mpnet/tokenization_mpnet.py:497: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2/modular_qwen2.py:139: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2/modular_qwen2.py:222: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2/modular_qwen2.py:226: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2/modular_qwen2.py:230: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2/modular_qwen2.py:234: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2/configuration_qwen2.py:39: `inputs_ids` passed when calling [`Qwen2Model`]
- .venv/lib/python3.12/site-packages/transformers/models/qwen2/tokenization_qwen2_fast.py:94: # We need to at least pass vocab_file and merges_file to base class
- .venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:479: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:483: pass
- .venv/lib/python3.12/site-packages/transformers/models/siglip/image_processing_siglip.py:133: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:562: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:1029: >>> # important: we pass `padding=max_length` since the model was trained with this
- .venv/lib/python3.12/site-packages/transformers/models/siglip/tokenization_siglip.py:67: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/siglip/tokenization_siglip.py:209: Create a mask from the two sequences passed to be used in a sequence-pair classification task. T5 does not make
- .venv/lib/python3.12/site-packages/transformers/models/siglip/configuration_siglip.py:37: the `inputs_ids` passed when calling [`SiglipModel`].
- .venv/lib/python3.12/site-packages/transformers/models/align/modeling_align.py:551: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/align/configuration_align.py:38: the `inputs_ids` passed when calling [`AlignTextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/align/configuration_align.py:58: The vocabulary size of the `token_type_ids` passed when calling [`AlignTextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/align/processing_align.py:42: The preferred way of passing kwargs is as a dictionary per modality, see usage example below.
- .venv/lib/python3.12/site-packages/transformers/models/align/processing_align.py:119: # then, we can pass correct kwargs to each processor
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:167: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:171: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:175: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:179: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:183: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:187: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:191: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:705: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:709: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:713: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modular_evolla.py:717: pass
- .venv/lib/python3.12/site-packages/transformers/models/evolla/configuration_evolla.py:35: by the `inputs_ids` passed when calling [`EvollaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/evolla/configuration_evolla.py:116: `inputs_ids` passed when calling [`EvollaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/evolla/modeling_evolla.py:489: f"If `encoder_hidden_states` are passed, {self} has to be instantiated"
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/modeling_owlvit.py:1228: raise ValueError("feature_map has been deprecated as an input. Please pass in num_patches instead")
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/configuration_owlvit.py:48: by the `inputs_ids` passed when calling [`OwlViTTextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/processing_owlvit.py:263: raise ValueError("Make sure that you pass in as many lists of text labels as images")
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit.py:328: ranging from 0 to 255. If passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit.py:464: # TODO: (amy) add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit.py:474: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit.py:523: raise ValueError("Make sure that you pass in as many target sizes as images")
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit.py:572: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit_fast.py:71: # TODO: (amy) add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit_fast.py:81: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit_fast.py:131: raise ValueError("Make sure that you pass in as many target sizes as images")
- .venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit_fast.py:181: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:45: pass
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:53: # TODO: Could have better fused kernels depending on scaling, dropout and head mask.
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:159: raise NotImplementedError("Multi-Query Attention not supported for cross_attention")
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:289: raise NotImplementedError("Cross-attention not implemented for MQA")
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:333: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with "
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:460: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:495: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:644: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:711: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:748: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:880: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/configuration_gpt_bigcode.py:38: `inputs_ids` passed when calling [`GPTBigCodeModel`].
- .venv/lib/python3.12/site-packages/transformers/models/superglue/image_processing_superglue.py:76: Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
- .venv/lib/python3.12/site-packages/transformers/models/superglue/image_processing_superglue.py:244: pixel values ranging from 0 to 255. If passing in images with pixel values between 0 and 1, set
- .venv/lib/python3.12/site-packages/transformers/models/superglue/image_processing_superglue.py:365: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the mask")
- .venv/lib/python3.12/site-packages/transformers/models/superglue/modeling_superglue.py:173: num_keypoints)`, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/superglue/modeling_superglue.py:177: num_keypoints)`, returned when `output_attentions=True` is passed or when `config.output_attentions=True`)
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modular_lightglue.py:201: num_keypoints)` returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modular_lightglue.py:205: num_keypoints)` returned when `output_attentions=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modular_lightglue.py:716: # if we should stop the forward pass through the transformer layers for each pair of images.
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modular_lightglue.py:723: # If the current layer is the last layer, we stop the forward pass through the transformer layers for
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modular_lightglue.py:885: # Early stop consists of stopping the forward pass through the transformer layers when the confidence of the
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modular_lightglue.py:936: # keypoints and stop the forward pass through the transformer layers for this pair of images.
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modular_lightglue.py:949: # Remove image pairs that have been early stopped from the forward pass
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modular_lightglue.py:965: # If all pairs of images are early stopped, we stop the forward pass through the transformer
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modeling_lightglue.py:66: num_keypoints)` returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modeling_lightglue.py:70: num_keypoints)` returned when `output_attentions=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modeling_lightglue.py:558: # if we should stop the forward pass through the transformer layers for each pair of images.
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modeling_lightglue.py:565: # If the current layer is the last layer, we stop the forward pass through the transformer layers for
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modeling_lightglue.py:727: # Early stop consists of stopping the forward pass through the transformer layers when the confidence of the
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modeling_lightglue.py:778: # keypoints and stop the forward pass through the transformer layers for this pair of images.
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modeling_lightglue.py:791: # Remove image pairs that have been early stopped from the forward pass
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/modeling_lightglue.py:807: # If all pairs of images are early stopped, we stop the forward pass through the transformer
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/image_processing_lightglue.py:76: Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/image_processing_lightglue.py:243: pixel values ranging from 0 to 255. If passing in images with pixel values between 0 and 1, set
- .venv/lib/python3.12/site-packages/transformers/models/lightglue/image_processing_lightglue.py:364: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the mask")
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modular_t5gemma.py:65: pass
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modular_t5gemma.py:99: Will be passed to the PretrainedConfig base class.
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modular_t5gemma.py:216: pass
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modular_t5gemma.py:483: # TODO: support intialization for encoders and decoders separately(?)
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modular_t5gemma.py:576: # As we want to pass `past_key_values=None` explicitly everywhere, we need to pop them from kwargs if present
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modular_t5gemma.py:1042: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modular_t5gemma.py:1051: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modular_t5gemma.py:1185: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modular_t5gemma.py:1193: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modeling_t5gemma.py:602: # TODO: support intialization for encoders and decoders separately(?)
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modeling_t5gemma.py:719: # As we want to pass `past_key_values=None` explicitly everywhere, we need to pop them from kwargs if present
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modeling_t5gemma.py:1185: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modeling_t5gemma.py:1194: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modeling_t5gemma.py:1328: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/modeling_t5gemma.py:1336: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/configuration_t5gemma.py:38: `inputs_ids` passed when calling [`T5GemmaModuleModel`]
- .venv/lib/python3.12/site-packages/transformers/models/t5gemma/configuration_t5gemma.py:215: Will be passed to the PretrainedConfig base class.
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/modeling_roc_bert.py:191: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/modeling_roc_bert.py:536: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/modeling_roc_bert.py:604: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/modeling_roc_bert.py:761: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/modeling_roc_bert.py:1465: # Some generation methods already pass only the last input ID
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/modeling_roc_bert.py:1669: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/configuration_roc_bert.py:38: `inputs_ids` passed when calling [`RoCBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/configuration_roc_bert.py:58: The vocabulary size of the `token_type_ids` passed when calling [`RoCBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/configuration_roc_bert.py:84: represented by the `input_pronunciation_ids` passed when calling [`RoCBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/configuration_roc_bert.py:89: by the `input_shape_ids` passed when calling [`RoCBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/tokenization_roc_bert.py:260: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/tokenization_roc_bert.py:600: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/roc_bert/tokenization_roc_bert.py:1052: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/funnel/tokenization_funnel.py:275: Create a mask from the two sequences passed to be used in a sequence-pair classification task. A Funnel
- .venv/lib/python3.12/site-packages/transformers/models/funnel/tokenization_funnel.py:502: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_tf_funnel.py:323: raise NotImplementedError("The supported modes are 'mean', 'max' and 'min'.")
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_tf_funnel.py:808: raise NotImplementedError  # Not implemented yet in the library fr TF 2.0 models
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_tf_funnel.py:891: raise NotImplementedError  # Not implemented yet in the library fr TF 2.0 models
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_tf_funnel.py:1093: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_tf_funnel.py:1098: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_tf_funnel.py:1131: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_tf_funnel.py:1133: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_tf_funnel.py:1146: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_tf_funnel.py:1181: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/funnel/configuration_funnel.py:37: by the `inputs_ids` passed when calling [`FunnelModel`] or [`TFFunnelModel`].
- .venv/lib/python3.12/site-packages/transformers/models/funnel/configuration_funnel.py:41: If passed along, each layer of each block is repeated the number of times indicated.
- .venv/lib/python3.12/site-packages/transformers/models/funnel/configuration_funnel.py:153: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/funnel/configuration_funnel.py:163: raise NotImplementedError("This model does not support the setting of `num_blocks`. Please set `block_sizes`.")
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:369: raise NotImplementedError("The supported modes are 'mean', 'max' and 'min'.")
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:884: # TODO: deal with head_mask
- .venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:951: # TODO: deal with head_mask
- .venv/lib/python3.12/site-packages/transformers/models/funnel/tokenization_funnel_fast.py:172: Create a mask from the two sequences passed to be used in a sequence-pair classification task. A Funnel
- .venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:69: # TODO(joao): add me back asap :)
- .venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:128: self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: this may break with compilation
- .venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:255: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:287: # TODO(joao): add me back asap :)
- .venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:1164: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/chameleon/configuration_chameleon.py:114: `inputs_ids` passed when calling [`ChameleonModel`]; this includes text and image tokens.
- .venv/lib/python3.12/site-packages/transformers/models/chameleon/image_processing_chameleon.py:192: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:366: def _tokenize(self, text, lang="en", bypass_tokenizer=False):
- .venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:395: externally, and set `bypass_tokenizer=True` to bypass the tokenizer.
- .venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:400: - bypass_tokenizer: Allow users to preprocess and tokenize the sentences externally (default = False)
- .venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:411: if bypass_tokenizer:
- .venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:415: # TODO: make sure we are using `FacebookAI/xlm-mlm-enro-1024`, since XLM-100 doesn't have this step
- .venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:452: if self.do_lowercase_and_remove_accent and not bypass_tokenizer:
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_xlm.py:431: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_xlm.py:486: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_xlm.py:702: raise NotImplementedError("Currently XLM can only be used as an encoder")
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_xlm.py:1561: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/xlm/configuration_xlm.py:41: `inputs_ids` passed when calling [`XLMModel`] or [`TFXLMModel`].
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:123: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:261: raise NotImplementedError("Currently XLM can only be used as an encoder")
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:293: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:384: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:468: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:588: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:593: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:623: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:625: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:638: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:693: The dictionary object will be modified in-place during the forward pass to add newly computed
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:702: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/xlm/modeling_tf_xlm.py:796: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/modeling_speecht5.py:1545: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/modeling_speecht5.py:1557: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/modeling_speecht5.py:1590: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/modeling_speecht5.py:1974: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/modeling_speecht5.py:2042: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/modeling_speecht5.py:2052: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/number_normalizer.py:112: Converts an individual number passed in string form to spelt-out form
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/feature_extraction_speecht5.py:241: to pass `sampling_rate` at the forward call to prevent silent errors.
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/feature_extraction_speecht5.py:255: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/tokenization_speecht5.py:58: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/speecht5/configuration_speecht5.py:40: the `inputs_ids` passed to the forward method of [`SpeechT5Model`].
- .venv/lib/python3.12/site-packages/transformers/models/dac/feature_extraction_dac.py:99: The sampling rate at which the `audio` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/dac/feature_extraction_dac.py:111: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/dac/modeling_dac.py:148: # noop in forward pass, straight-through gradient estimator in backward pass
- .venv/lib/python3.12/site-packages/transformers/models/dac/modeling_dac.py:189: Forward pass through the residual unit.
- .venv/lib/python3.12/site-packages/transformers/models/dac/modeling_dac.py:197: Input tensor after passing through the residual unit.
- .venv/lib/python3.12/site-packages/transformers/models/dac/modeling_dac.py:666: >>> # or the equivalent with a forward pass
- .venv/lib/python3.12/site-packages/transformers/models/vitpose/image_processing_vitpose.py:444: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/vitpose/image_processing_vitpose.py:632: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/vitpose/modeling_vitpose.py:50: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/vitpose/modeling_vitpose.py:254: raise NotImplementedError("Training is not yet supported")
- .venv/lib/python3.12/site-packages/transformers/models/vitpose/configuration_vitpose.py:51: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/led/configuration_led.py:40: `inputs_ids` passed when calling [`LEDModel`] or [`TFLEDModel`].
- .venv/lib/python3.12/site-packages/transformers/models/led/tokenization_led.py:96: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/led/tokenization_led.py:383: Create a mask from the two sequences passed to be used in a sequence-pair classification task. LED does not
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:466: # TODO: This code is most likely not very efficient and should be improved
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:729: """compute global attn indices required throughout forward pass"""
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1443: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1448: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1463: global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1490: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1496: decoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1501: decoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1507: cross_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1515: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1520: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1526: encoder_global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1556: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1562: decoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1567: decoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1573: cross_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1581: encoder_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1586: encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1592: encoder_global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1629: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1631: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1644: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:1806: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:2080: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:2280: # If the user passed a tuple for encoder_outputs, we wrap it in a TFLEDEncoderBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:2287: # If the user passed a TFLEDEncoderBaseModelOutput for encoder_outputs, we wrap it in a tuple when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:2470: # TODO (Joao): investigate why LED has numerical issues in XLA generate
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:265: # TODO: remove the redundant computation
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:380: # TODO replace this with
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:527: """compute global attn indices required throughout forward pass"""
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1148: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1163: global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1192: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1198: encoder_global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1230: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1236: encoder_global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1269: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1275: encoder_global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1306: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1312: encoder_global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1482: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1711: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1723: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1768: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:1971: # If the user passed a tuple for encoder_outputs, we wrap it in a LEDEncoderBaseModelOutput when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:2315: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/led/tokenization_led_fast.py:53: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/led/tokenization_led_fast.py:257: Create a mask from the two sequences passed to be used in a sequence-pair classification task. LED does not
- .venv/lib/python3.12/site-packages/transformers/models/mobilenet_v1/image_processing_mobilenet_v1.py:193: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/mobilenet_v1/modeling_mobilenet_v1.py:307: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/instructblip/modeling_instructblip.py:1146: _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
- .venv/lib/python3.12/site-packages/transformers/models/instructblip/modeling_instructblip.py:1190: " Please pass a `device_map` that contains `language_model` to remove this warning."
- .venv/lib/python3.12/site-packages/transformers/models/instructblip/modeling_instructblip.py:1342: One can optionally pass `input_ids` to the model, which serve as a text prompt, to make the language model continue
- .venv/lib/python3.12/site-packages/transformers/models/instructblip/modeling_instructblip.py:1351: _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
- .venv/lib/python3.12/site-packages/transformers/models/instructblip/modeling_instructblip.py:1416: " Please pass a `device_map` that contains `language_model` to remove this warning."
- .venv/lib/python3.12/site-packages/transformers/models/instructblip/configuration_instructblip.py:124: the `inputs_ids` passed when calling the model.
- .venv/lib/python3.12/site-packages/transformers/models/instructblip/configuration_instructblip.py:233: The number of query tokens passed through the Transformer.
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/configuration_encoder_decoder.py:82: f"both `encoder` and `decoder` sub-configurations were not passed, only {kwargs}"
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:57: " labels, no need to pass them yourself anymore."
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:133: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:137: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:274: "The selected decoder is not prepared for the encoder hidden states to be passed. Please see the "
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:340: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:432: "passed to `.from_encoder_decoder_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:531: # Handle the case where the inputs are passed as a single dict which contains `labels`.
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:532: # The `labels` shouldn't be passed to `self.encoder` below, because it is a based model without this
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:621: "input_ids": None,  # needs to be passed to make Keras.layer.__call__ happy
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:625: # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:636: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py:191: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py:560: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py:573: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py:574: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py:787: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py:883: "passed to `.from_encoder_decoder_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:45: " labels, no need to pass them yourself anymore."
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:163: "The selected decoder is not prepared for the encoder hidden states to be passed. Please see the "
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:339: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:435: "passed to `.from_encoder_decoder_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:481: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:601: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/omdet_turbo/modeling_omdet_turbo.py:732: Flattened feature map (output of the backbone + projection layers) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/omdet_turbo/modeling_omdet_turbo.py:1571: raise NotImplementedError("Training is not implemented yet")
- .venv/lib/python3.12/site-packages/transformers/models/omdet_turbo/processing_omdet_turbo.py:362: raise ValueError("Make sure that you pass in as many target sizes as output sequences")
- .venv/lib/python3.12/site-packages/transformers/models/omdet_turbo/processing_omdet_turbo.py:369: raise ValueError("Make sure that you pass in as many classes group as output sequences")
- .venv/lib/python3.12/site-packages/transformers/models/bitnet/configuration_bitnet.py:37: `inputs_ids` passed when calling [`BitNetModel`]
- .venv/lib/python3.12/site-packages/transformers/models/bitnet/modular_bitnet.py:44: pass
- .venv/lib/python3.12/site-packages/transformers/models/bitnet/modular_bitnet.py:110: pass
- .venv/lib/python3.12/site-packages/transformers/models/bitnet/modular_bitnet.py:114: pass
- .venv/lib/python3.12/site-packages/transformers/models/ernie4_5/configuration_ernie4_5.py:34: `inputs_ids` passed when calling [`Ernie4_5Model`]
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/modeling_pop2piano.py:58: pass
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/modeling_pop2piano.py:61: pass
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/modeling_pop2piano.py:187: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/modeling_pop2piano.py:754: # do not pass cache object down the line for encoder stack
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/modeling_pop2piano.py:1164: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/modeling_pop2piano.py:1250: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/modeling_pop2piano.py:1251: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/modeling_pop2piano.py:1266: This value is passed to `Pop2PianoConcatEmbeddingToMel` to generate different embeddings for each
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/modeling_pop2piano.py:1272: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/feature_extraction_pop2piano.py:59: This class extracts rhythm and preprocesses the audio before it is passed to the model. First the audio is passed
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/feature_extraction_pop2piano.py:151: raw audio waveform which is passed to the Rhythm Extractor.
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/feature_extraction_pop2piano.py:168: beat_times is passed into `scipy.interpolate.interp1d` for processing.
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/feature_extraction_pop2piano.py:362: The sampling rate at which the `audio` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/feature_extraction_pop2piano.py:385: "Please give sampling_rate of each audio separately when you are passing multiple raw_audios at the same time. "
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/tokenization_pop2piano.py:204: pass
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/tokenization_pop2piano.py:557: # batches and the inner list contains all Notes for a single batch. Otherwise if np.ndarray is passed it will be
- .venv/lib/python3.12/site-packages/transformers/models/pop2piano/configuration_pop2piano.py:37: that can be represented by the `inputs_ids` passed when calling [`Pop2PianoForConditionalGeneration`].
- .venv/lib/python3.12/site-packages/transformers/models/granitemoe/configuration_granitemoe.py:43: `inputs_ids` passed when calling [`GraniteMoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:252: Forward pass of the GraniteMoeParallelExperts module.
- .venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:346: Forward pass of the mixture of experts layer.
- .venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:400: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:676: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/mt5/tokenization_mt5.py:21: pass
- .venv/lib/python3.12/site-packages/transformers/models/mt5/configuration_mt5.py:40: `inputs_ids` passed when calling [`T5Model`] or [`TFT5Model`].
- .venv/lib/python3.12/site-packages/transformers/models/mt5/tokenization_mt5_fast.py:21: pass
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:243: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1006: # do not pass cache object down the line for encoder stack
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1468: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1481: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1746: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1823: # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflo
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:2076: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:2086: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:2352: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:2366: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/configuration_granitemoehybrid.py:38: can be represented by the `inputs_ids` passed when calling [`GraniteMoeHybridModel`]
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/modular_granitemoehybrid.py:347: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/modular_granitemoehybrid.py:371: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py:149: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py:312: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py:859: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py:985: Forward pass of the GraniteMoeHybridParallelExperts module.
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py:1082: Forward pass of the mixture of experts layer.
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py:1795: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py:1819: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/image_processing_deepseek_vl_hybrid_fast.py:149: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modeling_deepseek_vl_hybrid.py:54: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modeling_deepseek_vl_hybrid.py:89: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modeling_deepseek_vl_hybrid.py:119: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modeling_deepseek_vl_hybrid.py:498: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/image_processing_deepseek_vl_hybrid.py:263: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/image_processing_deepseek_vl_hybrid.py:430: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modular_deepseek_vl_hybrid.py:158: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modular_deepseek_vl_hybrid.py:162: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modular_deepseek_vl_hybrid.py:166: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modular_deepseek_vl_hybrid.py:436: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modular_deepseek_vl_hybrid.py:569: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl_hybrid/modular_deepseek_vl_hybrid.py:916: pass
- .venv/lib/python3.12/site-packages/transformers/models/persimmon/configuration_persimmon.py:39: the `inputs_ids` passed when calling [`PersimmonModel`]
- .venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:179: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:260: query_rot, query_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:264: key_rot, key_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:272: query_states = torch.cat((query_rot, query_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:273: key_states = torch.cat((key_rot, key_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:475: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_bert/modeling_wav2vec2_bert.py:199: # Ensure that we do not leak padded positions in depthwise convolution if attention mask is passed.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_bert/configuration_wav2vec2_bert.py:39: represented by the `inputs_ids` passed when calling [`Wav2Vec2BertModel`]. Vocabulary size of the
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_bert/configuration_wav2vec2_bert.py:40: model. Defines the different tokens that can be represented by the *inputs_ids* passed to the forward
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_bert/modular_wav2vec2_bert.py:81: pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_bert/modular_wav2vec2_bert.py:155: # Ensure that we do not leak padded positions in depthwise convolution if attention mask is passed.
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py:850: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py:855: # would have been to pass on max_len=config.max_2d_position_embeddings - 1.
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py:1139: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py:1141: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py:1154: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py:1227: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/image_processing_layoutlmv3.py:252: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/configuration_layoutlmv3.py:50: the `inputs_ids` passed when calling [`LayoutLMv3Model`].
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/configuration_layoutlmv3.py:70: The vocabulary size of the `token_type_ids` passed when calling [`LayoutLMv3Model`].
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py:831: Create a mask from the two sequences passed to be used in a sequence-pair classification task. RoBERTa does not:
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/tokenization_layoutlmv3.py:501: Create a mask from the two sequences passed to be used in a sequence-pair classification task. RoBERTa does not
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/tokenization_layoutlmv3.py:776: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/tokenization_layoutlmv3.py:1025: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/processing_layoutlmv3.py:94: [`LayoutLMv3ImageProcessor`] was initialized with `apply_ocr` set to `True`, it passes the obtained words and
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/processing_layoutlmv3.py:97: `apply_ocr` set to `False`, it passes the words (`text`/``text_pair`) and `boxes` specified by the user along
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/modeling_layoutlmv3.py:732: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/bert_generation/modeling_bert_generation.py:322: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/bert_generation/modeling_bert_generation.py:388: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/bert_generation/modeling_bert_generation.py:606: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/bert_generation/configuration_bert_generation.py:34: `inputs_ids` passed when calling [`BertGeneration`].
- .venv/lib/python3.12/site-packages/transformers/models/bert_generation/tokenization_bert_generation.py:59: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/xglm/modeling_tf_xglm.py:687: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/xglm/modeling_tf_xglm.py:689: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/xglm/modeling_tf_xglm.py:702: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/xglm/modeling_tf_xglm.py:762: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/xglm/configuration_xglm.py:38: `inputs_ids` passed when calling [`XGLMModel`] or [`FlaxXGLMModel`].
- .venv/lib/python3.12/site-packages/transformers/models/xglm/tokenization_xglm.py:80: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/xglm/tokenization_xglm.py:232: Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLM-RoBERTa does
- .venv/lib/python3.12/site-packages/transformers/models/xglm/modeling_flax_xglm.py:648: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/xglm/tokenization_xglm_fast.py:152: Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLM-RoBERTa does
- .venv/lib/python3.12/site-packages/transformers/models/xglm/modeling_xglm.py:506: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/vitpose_backbone/modeling_vitpose_backbone.py:308: "to the forward pass."
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/configuration_roberta_prelayernorm.py:44: `inputs_ids` passed when calling [`RobertaPreLayerNormModel`] or [`TFRobertaPreLayerNormModel`].
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/configuration_roberta_prelayernorm.py:64: The vocabulary size of the `token_type_ids` passed when calling [`RobertaPreLayerNormModel`] or [`TFRobertaPreLayerNormM
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py:373: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py:531: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py:696: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py:818: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py:901: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py:903: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py:916: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py:962: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py:100: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py:415: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py:485: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py:590: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py:1169: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py:845: # init input tensors if not passed
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py:866: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py:950: # make sure `token_type_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py:954: # make sure `position_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/ibert/quant_modules.py:148: raise NotImplementedError("per-channel mode is not currently supported for activation.")
- .venv/lib/python3.12/site-packages/transformers/models/ibert/modeling_ibert.py:648: raise NotImplementedError("`resize_token_embeddings` is not supported for I-BERT.")
- .venv/lib/python3.12/site-packages/transformers/models/ibert/modeling_ibert.py:1014: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/ibert/configuration_ibert.py:43: `inputs_ids` passed when calling [`IBertModel`]
- .venv/lib/python3.12/site-packages/transformers/models/ibert/configuration_ibert.py:63: The vocabulary size of the `token_type_ids` passed when calling [`IBertModel`]
- .venv/lib/python3.12/site-packages/transformers/models/convnextv2/modeling_tf_convnextv2.py:496: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/convnextv2/modeling_tf_convnextv2.py:498: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/convnextv2/modeling_tf_convnextv2.py:511: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/convnextv2/modeling_convnextv2.py:103: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/xcodec/modeling_xcodec.py:376: pass
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_flax_mbart.py:206: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_flax_mbart.py:962: # make sure initialization pass will work for FlaxMBartForSequenceClassificationModule
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_flax_mbart.py:1155: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_flax_mbart.py:1168: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_flax_mbart.py:1169: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_flax_mbart.py:1420: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_flax_mbart.py:1433: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_flax_mbart.py:1434: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_tf_mbart.py:550: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_tf_mbart.py:552: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_tf_mbart.py:565: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_tf_mbart.py:639: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_tf_mbart.py:777: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_tf_mbart.py:987: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_tf_mbart.py:1201: # If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_tf_mbart.py:1208: # If the user passed a TFBaseModelOutput for encoder_outputs, we wrap it in a tuple when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:45: `inputs_ids` passed when calling [`MBartModel`] or [`TFMBartModel`].
- .venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:189: # TODO: figure this case out.
- .venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:288: # TODO: test this.
- .venv/lib/python3.12/site-packages/transformers/models/mbart/tokenization_mbart_fast.py:168: Create a mask from the two sequences passed to be used in a sequence-pair classification task. mBART does not
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:189: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:209: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:797: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:983: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:995: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:1050: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:1258: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:1564: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/mbart/tokenization_mbart.py:233: Create a mask from the two sequences passed to be used in a sequence-pair classification task. mBART does not
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:167: Forward pass of the JetMoeParallelExperts module.
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:262: Forward pass of the mixture of experts layer.
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:366: raise NotImplementedError("This module doesn't support call and forward.")
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:484: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:566: `JetMoeAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:583: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:656: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:676: Forward pass of the JetMoeAttention module.
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:712: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:924: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/jetmoe/configuration_jetmoe.py:39: `inputs_ids` passed when calling [`JetMoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/fnet/configuration_fnet.py:38: `inputs_ids` passed when calling [`FNetModel`] or [`TFFNetModel`].
- .venv/lib/python3.12/site-packages/transformers/models/fnet/configuration_fnet.py:54: The vocabulary size of the `token_type_ids` passed when calling [`FNetModel`] or [`TFFNetModel`].
- .venv/lib/python3.12/site-packages/transformers/models/fnet/modeling_fnet.py:123: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/fnet/modeling_fnet.py:498: "The `tpu_short_seq_length` in FNetConfig should be set equal to the sequence length being passed to"
- .venv/lib/python3.12/site-packages/transformers/models/fnet/modeling_fnet.py:909: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/fnet/tokenization_fnet.py:70: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_blip.py:71: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed):
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_blip.py:898: BLIP Model for image captioning. The model consists of a vision encoder and a text decoder. One can optionally pass
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_blip.py:1156: "Either `decoder_input_ids` or `labels` should be passed when calling `forward` with"
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_blip.py:1157: " `BlipForQuestionAnswering`. if you are training the model make sure that `labels` is passed, if you"
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_blip.py:1158: " are using the model for inference make sure that `decoder_input_ids` is passed or call `generate`"
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_blip.py:1240: Additional arguments passed to the *generate* function of the decoder
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_blip_text.py:436: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_blip_text.py:601: `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/blip/image_processing_blip.py:182: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:88: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed):
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:126: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:131: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:162: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:169: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:1086: BLIP Model for image captioning. The model consists of a vision encoder and a text decoder. One can optionally pass
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:1377: "Either `decoder_input_ids` or `labels` should be passed when calling"
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:1378: " `TFBlipForQuestionAnswering`. if you are training the model make sure that `labels` is passed, if you"
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:1379: " are using the model for inference make sure that `decoder_input_ids` is passed or call `generate`"
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:1456: Additional arguments passed to the `generate` function of the decoder
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip.py:1632: # which output to pass to the final output. The unnecessary nodes will be pruned from the final graph, but
- .venv/lib/python3.12/site-packages/transformers/models/blip/modeling_tf_blip_text.py:734: `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/blip/configuration_blip.py:38: the `inputs_ids` passed when calling [`BlipModel`].
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/configuration_d_fine.py:30: # TODO: Attribute map assignment logic should be fixed in modular
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/configuration_d_fine.py:64: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modeling_d_fine.py:551: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modeling_d_fine.py:677: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modeling_d_fine.py:1245: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modeling_d_fine.py:1246: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modeling_d_fine.py:1248: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modeling_d_fine.py:1300: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modeling_d_fine.py:1608: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modeling_d_fine.py:2086: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modular_d_fine.py:49: # TODO: Attribute map assignment logic should be fixed in modular
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modular_d_fine.py:83: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modular_d_fine.py:707: pass
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modular_d_fine.py:945: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modular_d_fine.py:1001: pass
- .venv/lib/python3.12/site-packages/transformers/models/d_fine/modular_d_fine.py:1178: pass
- .venv/lib/python3.12/site-packages/transformers/models/code_llama/tokenization_code_llama.py:91: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/code_llama/tokenization_code_llama.py:413: Creates a mask from the two sequences passed to be used in a sequence-pair classification task. An ALBERT
- .venv/lib/python3.12/site-packages/transformers/models/idefics/processing_idefics.py:186: """Checks if the passed string contains a valid url and nothing else. e.g. if space is included it's immediately
- .venv/lib/python3.12/site-packages/transformers/models/idefics/processing_idefics.py:261: either a single image or a batched list of images - can be passed in when text contains only text prompts,
- .venv/lib/python3.12/site-packages/transformers/models/idefics/processing_idefics.py:272: directly passed to `model.generate`
- .venv/lib/python3.12/site-packages/transformers/models/idefics/processing_idefics.py:276: Each entry in `text` is either a text to be passed as is or an image that will be processed.
- .venv/lib/python3.12/site-packages/transformers/models/idefics/processing_idefics.py:317: This example also exemplifies that images can be passed as objects or as text urls. It can be seen that the
- .venv/lib/python3.12/site-packages/transformers/models/idefics/processing_idefics.py:318: first image is passed as object and the second one as a url.
- .venv/lib/python3.12/site-packages/transformers/models/idefics/configuration_idefics.py:171: `inputs_ids` passed when calling [`~IdeficsModel`]
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:68: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:103: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:429: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:515: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:797: raise NotImplementedError(f"Alpha initialization scheme {config.alpha_initializer} not yet implemented!")
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:844: raise NotImplementedError("Past key value states are not implemented for Idefics cross attention module.")
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:1051: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:1105: raise ValueError("If `perceiver_embeddings` are passed, use_resampler should be True")
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:1154: # TODO(ls): Add cross attention values to respective lists
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:66: past_key_values (`tuple(tuple(tf.Tensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:75: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:80: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:110: past_key_values (`tuple(tuple(tf.Tensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:116: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:121: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:964: raise NotImplementedError(f"Alpha initialization scheme {self.alpha_initializer} not yet implemented!")
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1015: raise NotImplementedError("Past key value states are not implemented for Idefics cross attention module.")
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1117: past_key_values (`tuple(tuple(tf.Tensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1129: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1312: # initial forward pass with dummy input and code below is here to handle that
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1343: raise ValueError("If `perceiver_embeddings` are passed, use_resampler should be True")
- .venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1416: # TODO(ls): Add cross attention values to respective lists
- .venv/lib/python3.12/site-packages/transformers/models/idefics/vision.py:50: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/idefics/vision.py:55: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/idefics/vision.py:368: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/idefics/vision_tf.py:44: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/idefics/vision_tf.py:49: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/idefics/vision_tf.py:414: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/idefics/image_processing_idefics.py:129: A custom transform function that accepts a single image can be passed for training. For example,
- .venv/lib/python3.12/site-packages/transformers/models/idefics/image_processing_idefics.py:163: # For training a user needs to pass their own set of transforms as a Callable.
- .venv/lib/python3.12/site-packages/transformers/models/idefics/image_processing_idefics.py:173: raise ImportError("To pass in `transform` torch must be installed")
- .venv/lib/python3.12/site-packages/transformers/models/nystromformer/modeling_nystromformer.py:84: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/nystromformer/modeling_nystromformer.py:804: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/nystromformer/configuration_nystromformer.py:37: by the `inputs_ids` passed when calling [`NystromformerModel`].
- .venv/lib/python3.12/site-packages/transformers/models/nystromformer/configuration_nystromformer.py:57: The vocabulary size of the `token_type_ids` passed when calling [`NystromformerModel`].
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py:49: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py:65: `inputs_ids` passed when calling [`Glm4vMoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py:295: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py:337: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py:338: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py:345: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py:346: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py:428: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py:449: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/configuration_glm4v_moe.py:135: `inputs_ids` passed when calling [`Glm4vMoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modeling_glm4v_moe.py:155: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modeling_glm4v_moe.py:156: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modeling_glm4v_moe.py:163: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modeling_glm4v_moe.py:164: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modeling_glm4v_moe.py:539: Forward pass with integrated position encoding adaptation using 2D interpolation.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modeling_glm4v_moe.py:792: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modeling_glm4v_moe.py:1429: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/glm4v_moe/modeling_glm4v_moe.py:1631: These parameters are not passed through the processor to avoid unpredictable impacts from interface modifications.
- .venv/lib/python3.12/site-packages/transformers/models/granite/modular_granite.py:123: pass
- .venv/lib/python3.12/site-packages/transformers/models/granite/configuration_granite.py:43: `inputs_ids` passed when calling [`GraniteModel`]
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl/modular_deepseek_vl.py:111: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl/modular_deepseek_vl.py:115: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl/image_processing_deepseek_vl.py:228: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl/image_processing_deepseek_vl.py:357: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl/modeling_deepseek_vl.py:57: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl/modeling_deepseek_vl.py:92: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl/modeling_deepseek_vl.py:354: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_vl/image_processing_deepseek_vl_fast.py:115: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/seggpt/modeling_seggpt.py:55: Additionally, each feature passes through a LayerNorm.
- .venv/lib/python3.12/site-packages/transformers/models/seggpt/modeling_seggpt.py:521: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/seggpt/image_processing_seggpt.py:266: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/seggpt/image_processing_seggpt.py:310: channel to a 3 channel RGB. Not specifying this will result in the prompt mask either being passed
- .venv/lib/python3.12/site-packages/transformers/models/seggpt/image_processing_seggpt.py:325: # If segmentation map is passed we expect 2D images
- .venv/lib/python3.12/site-packages/transformers/models/seggpt/image_processing_seggpt.py:414: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/seggpt/image_processing_seggpt.py:417: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/seggpt/image_processing_seggpt.py:450: with no channels to a 3 channel RGB. Not specifying this will result in the prompt mask either being passed
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/configuration_exaone4.py:38: `inputs_ids` passed when calling [`Exaone4Model`].
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modular_exaone4.py:73: `inputs_ids` passed when calling [`Exaone4Model`].
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modular_exaone4.py:259: pass
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modular_exaone4.py:263: pass
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modular_exaone4.py:345: pass
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modular_exaone4.py:349: pass
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modular_exaone4.py:502: pass
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modular_exaone4.py:506: pass
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modular_exaone4.py:510: pass
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modeling_exaone4.py:520: pass
- .venv/lib/python3.12/site-packages/transformers/models/exaone4/modeling_exaone4.py:524: pass
- .venv/lib/python3.12/site-packages/transformers/models/jamba/configuration_jamba.py:41: `inputs_ids` passed when calling [`JambaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:266: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:287: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:370: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:377: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:471: `JambaAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:488: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:676: # This is a hack to apply dt_proj while still using the forward pass of `torch.nn.Linear`, which is needed
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:678: # linear layers, and requires to call the forward pass directly.
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:740: # In training mode, we don't want to perform in-place operations on ssm_state so we can compute the backwards pass
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:1410: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:1434: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/configuration_kosmos2_5.py:37: `inputs_ids` passed when calling [`Kosmos2_5Model`].
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:160: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:222: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:250: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:255: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:275: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:312: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:317: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:337: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:392: # TODO: check with krip
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:937: # TODO (ydshieh): Remove this (to match Llama's code)
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:1007: # TODO (ydshieh): Remove this (to match Llama's code)
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py:1831: # Otherwise we need `flattened_patches` to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/processing_kosmos2_5.py:100: raise ValueError("Kosmos2_5Processor requires images to be passed.")
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/image_processing_kosmos2_5_fast.py:99: # TODO: revert once the issue is fixed: https://huggingface.slack.com/archives/C02TXKQQLE5/p1743411133979019
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/image_processing_kosmos2_5_fast.py:150: # TODO: correct this return type, and the docstring
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/image_processing_kosmos2_5_fast.py:250: # TODO: if it's possible to do in batch mode
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2_5/image_processing_kosmos2_5_fast.py:254: # TODO: we need this to be in batch from
- .venv/lib/python3.12/site-packages/transformers/models/splinter/tokenization_splinter_fast.py:163: Create the token type IDs corresponding to the sequences passed. [What are token type
- .venv/lib/python3.12/site-packages/transformers/models/splinter/modeling_splinter.py:756: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/splinter/tokenization_splinter.py:255: Create the token type IDs corresponding to the sequences passed. [What are token type
- .venv/lib/python3.12/site-packages/transformers/models/splinter/tokenization_splinter.py:467: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/splinter/configuration_splinter.py:38: the `inputs_ids` passed when calling [`SplinterModel`].
- .venv/lib/python3.12/site-packages/transformers/models/splinter/configuration_splinter.py:58: The vocabulary size of the `token_type_ids` passed when calling [`SplinterModel`].
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_openai.py:294: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_openai.py:349: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_openai.py:730: it cannot guess the padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take
- .venv/lib/python3.12/site-packages/transformers/models/openai/configuration_openai.py:38: `inputs_ids` passed when calling [`OpenAIGPTModel`] or [`TFOpenAIGPTModel`].
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:80: pass
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:284: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:339: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:418: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:423: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:454: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:456: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:469: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:515: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/openai/modeling_tf_openai.py:822: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:91: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:329: raise NotImplementedError(f"link_tower_type {config.link_tower_type} is not implemented")
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:339: raise NotImplementedError(f"link_tower_type {self.link_tower_type} is not implemented")
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:708: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:776: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:878: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:994: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:1239: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:1283: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:1284: "BridgeTowerModel does not use `inputs_embeds`.  Make sure to pass in `input_ids` instead."
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:1547: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:1571: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:1649: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:1669: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/modeling_bridgetower.py:1763: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/configuration_bridgetower.py:110: represented by the `inputs_ids` passed when calling [`BridgeTowerModel`].
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/configuration_bridgetower.py:279: # TODO: remove this once the Hub files are updated.
- .venv/lib/python3.12/site-packages/transformers/models/bridgetower/image_processing_bridgetower.py:400: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/mamba/configuration_mamba.py:40: `inputs_ids` passed when calling [`MambaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/mamba/modeling_mamba.py:83: >>> # Prepare a cache class and pass it to model's forward
- .venv/lib/python3.12/site-packages/transformers/models/mamba/modeling_mamba.py:93: # TODO (joao): add layer_device_map arg and update code in `generate` accordingly
- .venv/lib/python3.12/site-packages/transformers/models/mamba/modeling_mamba.py:134: # This `if` blocks is only reached in multigpu and if `layer_device_map` is not passed. It is used
- .venv/lib/python3.12/site-packages/transformers/models/mamba/modeling_mamba.py:135: # when the cache is initialized in the forward pass (e.g. Mamba)
- .venv/lib/python3.12/site-packages/transformers/models/mamba/modeling_mamba.py:635: If passed along, the model uses the previous state in all the blocks (which will give the output for the
- .venv/lib/python3.12/site-packages/transformers/models/mamba/modeling_mamba.py:666: "You have to specify the `cache_position` manually when `use_cache=True` and `cache_params` is passed, "
- .venv/lib/python3.12/site-packages/transformers/models/mamba/modeling_mamba.py:667: "you don't have to pass a `cache_params` if you are in prefilling stage because in that case it will "
- .venv/lib/python3.12/site-packages/transformers/models/mamba/modeling_mamba.py:800: If passed along, the model uses the previous state in all the blocks (which will give the output for the
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:281: TODO let's just use the original freqcis computation to not have the view
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:292: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:394: q_pass, q_rot = torch.split(q_states, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:397: k_pass, k_rot = torch.split(compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:399: k_pass = self.kv_b_proj(self.kv_a_layernorm(k_pass)).view(key_shape).transpose(1, 2)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:400: k_pass, value_states = torch.split(k_pass, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:409: k_rot = k_rot.expand(*k_pass.shape[:-1], -1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:411: query_states = torch.cat((q_pass, q_rot), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:412: key_states = torch.cat((k_pass, k_rot), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py:676: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:35: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:39: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:44: TODO let's just use the original freqcis computation to not have the view
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:55: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:276: q_pass, q_rot = torch.split(q_states, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:279: k_pass, k_rot = torch.split(compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:281: k_pass = self.kv_b_proj(self.kv_a_layernorm(k_pass)).view(key_shape).transpose(1, 2)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:282: k_pass, value_states = torch.split(k_pass, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:291: k_rot = k_rot.expand(*k_pass.shape[:-1], -1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:293: query_states = torch.cat((q_pass, q_rot), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:294: key_states = torch.cat((k_pass, k_rot), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:357: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py:361: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/configuration_deepseek_v3.py:39: `inputs_ids` passed when calling [`DeepseekV3Model`]
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v3/configuration_deepseek_v3.py:135: base_model_tp_plan = {  # TODO: only replicate attention layers when > first_k_dense_replace
- .venv/lib/python3.12/site-packages/transformers/models/vit/modeling_tf_vit.py:349: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/vit/modeling_tf_vit.py:578: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/vit/modeling_tf_vit.py:606: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/vit/modeling_tf_vit.py:679: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/vit/modeling_tf_vit.py:681: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/vit/modeling_tf_vit.py:694: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/vit/image_processing_vit.py:176: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/vit/modeling_vit.py:477: # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
- .venv/lib/python3.12/site-packages/transformers/models/perception_lm/modular_perception_lm.py:100: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/perception_lm/modular_perception_lm.py:123: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/perception_lm/modular_perception_lm.py:314: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/perception_lm/modeling_perception_lm.py:111: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/perception_lm/modeling_perception_lm.py:142: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/perception_lm/modeling_perception_lm.py:461: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/image_processing_grounding_dino.py:1331: from 0 to 255. If passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/image_processing_grounding_dino.py:1596: raise ValueError("Make sure that you pass in as many target sizes as images")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modular_grounding_dino.py:81: raise ValueError("Make sure that you pass in as many target sizes as images")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modular_grounding_dino.py:106: raise NotImplementedError("Post-processing is not implemented for Grounding-Dino yet.")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modular_grounding_dino.py:109: raise NotImplementedError("Segmentation post-processing is not implemented for Grounding-Dino yet.")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modular_grounding_dino.py:112: raise NotImplementedError("Instance post-processing is not implemented for Grounding-Dino yet.")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modular_grounding_dino.py:115: raise NotImplementedError("Panoptic post-processing is not implemented for Grounding-Dino yet.")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modular_grounding_dino.py:118: raise NotImplementedError("Segmentation post-processing is not implemented for Grounding-Dino yet.")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modular_grounding_dino.py:121: raise NotImplementedError("Semantic segmentation post-processing is not implemented for Grounding-Dino yet.")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modular_grounding_dino.py:124: raise NotImplementedError("Panoptic segmentation post-processing is not implemented for Grounding-Dino yet.")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/configuration_grounding_dino.py:49: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:142: vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:146: text_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when 
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:179: encoder_vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passe
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:183: encoder_text_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed 
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:187: encoder_attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:259: encoder_vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passe
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:263: encoder_text_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed 
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:1494: # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:1524: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:1541: Flattened text features that are passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:1632: - `position_embeddings`, `reference_points`, `spatial_shapes` and `valid_ratios` are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:1678: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:2212: # If the user passed a tuple for encoder_outputs, we wrap it in a GroundingDinoEncoderOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/image_processing_grounding_dino_fast.py:783: raise ValueError("Make sure that you pass in as many target sizes as images")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/processing_grounding_dino.py:259: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/grounding_dino/processing_grounding_dino.py:294: # TODO: @pavel, set labels to None since v4.51.0 or find a way to extract ids
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:50: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:53: The `past_key_values` are returned when `use_cache=True` is passed or when `config.use_cache=True`.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:135: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:883: # Overwritten -- we should not pass input_features when we are in cached decoding stage
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:891: # input_features should only be passed when we are not in cached decoding stage
- .venv/lib/python3.12/site-packages/transformers/models/tvp/configuration_tvp.py:52: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/tvp/configuration_tvp.py:72: the `inputs_ids` passed when calling [`TvpModel`].
- .venv/lib/python3.12/site-packages/transformers/models/tvp/modeling_tvp.py:47: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_flax_gpt_neo.py:94: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_flax_gpt_neo.py:425: raise ValueError("Make sure to provide `position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_flax_gpt_neo.py:439: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed down to ens
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:267: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:274: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:384: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:480: _can_compile_fullgraph = False  # TODO: needs a hybrid cache
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:546: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:574: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:815: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:889: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:925: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:1048: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:1130: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/configuration_gpt_neo.py:44: `inputs_ids` passed when calling [`GPTNeoModel`]. Vocabulary size of the model. Defines the different
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neo/configuration_gpt_neo.py:45: tokens that can be represented by the *inputs_ids* passed to the forward method of [`GPTNeoModel`].
- .venv/lib/python3.12/site-packages/transformers/models/umt5/configuration_umt5.py:40: `inputs_ids` passed when calling [`UMT5Model`] or [`TFUMT5Model`].
- .venv/lib/python3.12/site-packages/transformers/models/umt5/modeling_umt5.py:178: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/umt5/modeling_umt5.py:706: # do not pass cache object down the line for encoder stack
- .venv/lib/python3.12/site-packages/transformers/models/umt5/modeling_umt5.py:1086: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/umt5/modeling_umt5.py:1093: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/umt5/modeling_umt5.py:1301: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/umt5/modeling_umt5.py:1577: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/umt5/modeling_umt5.py:1587: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/umt5/modeling_umt5.py:1855: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/umt5/modeling_umt5.py:1863: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/cpm/tokenization_cpm.py:300: Create a mask from the two sequences passed to be used in a sequence-pair classification task. An XLNet
- .venv/lib/python3.12/site-packages/transformers/models/cpm/tokenization_cpm_fast.py:178: Create a mask from the two sequences passed to be used in a sequence-pair classification task. An XLNet
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/configuration_dab_detr.py:50: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:53: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:861: - object_queries are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:891: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:971: - object_queries and query_position_embeddings are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:1021: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:1231: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:1232: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:1234: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:1253: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:1308: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:1486: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:1487: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/dab_detr/modeling_dab_detr.py:1489: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/depth_anything/modeling_depth_anything.py:391: raise NotImplementedError("Training is not implemented yet")
- .venv/lib/python3.12/site-packages/transformers/models/depth_anything/configuration_depth_anything.py:52: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/image_processing_oneformer_fast.py:777: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:586: uncertainty is calculated for each point using the passed `uncertainty function` that takes points logit
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:780: sequence_length)`. Attentions weights from pixel decoder. Returned when `output_attentions=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:822: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:826: pixel_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:830: transformer_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is 
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:848: attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:871: This output can be directly passed to [`~OneFormerImageProcessor.post_process_semantic_segmentation`] or
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:889: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:893: pixel_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:897: transformer_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is 
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:915: attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:1223: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:2405: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:3109: >>> # you can pass them to processor for semantic postprocessing
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:3126: >>> # you can pass them to processor for instance postprocessing
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/modeling_oneformer.py:3143: >>> # you can pass them to processor for panoptic postprocessing
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/configuration_oneformer.py:52: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/image_processing_oneformer.py:648: # TODO: (Amy)
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/image_processing_oneformer.py:987: A mapping between object instance ids and class ids. If passed, `segmentation_maps` is treated as an
- .venv/lib/python3.12/site-packages/transformers/models/oneformer/image_processing_oneformer.py:1116: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/image_processing_mobilevit.py:207: passed in as positional arguments.
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/image_processing_mobilevit.py:349: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/image_processing_mobilevit.py:490: # TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/image_processing_mobilevit.py:497: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/modeling_tf_mobilevit.py:352: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/modeling_tf_mobilevit.py:825: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/modeling_tf_mobilevit.py:934: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/modeling_tf_mobilevit.py:936: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/modeling_tf_mobilevit.py:949: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/mobilevit/image_processing_mobilevit_fast.py:237: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/megatron_bert/configuration_megatron_bert.py:38: by the `inputs_ids` passed when calling [`MegatronBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/megatron_bert/configuration_megatron_bert.py:58: The vocabulary size of the `token_type_ids` passed when calling [`MegatronBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/megatron_bert/modeling_megatron_bert.py:453: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/megatron_bert/modeling_megatron_bert.py:517: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/megatron_bert/modeling_megatron_bert.py:731: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/megatron_bert/modeling_megatron_bert.py:1437: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/timm_backbone/modeling_timm_backbone.py:120: pass
- .venv/lib/python3.12/site-packages/transformers/models/bros/modeling_bros.py:433: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers by setting `config.ad
- .venv/lib/python3.12/site-packages/transformers/models/bros/configuration_bros.py:37: `inputs_ids` passed when calling [`BrosModel`] or [`TFBrosModel`].
- .venv/lib/python3.12/site-packages/transformers/models/bros/configuration_bros.py:57: The vocabulary size of the `token_type_ids` passed when calling [`BrosModel`] or [`TFBrosModel`].
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/modular_glm4_moe.py:55: `inputs_ids` passed when calling [`Glm4MoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/modular_glm4_moe.py:287: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/modular_glm4_moe.py:306: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/modular_glm4_moe.py:310: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/modular_glm4_moe.py:322: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/configuration_glm4_moe.py:39: `inputs_ids` passed when calling [`Glm4MoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/modeling_glm4_moe.py:115: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/modeling_glm4_moe.py:116: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/modeling_glm4_moe.py:123: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4_moe/modeling_glm4_moe.py:124: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi/configuration_phi.py:39: `inputs_ids` passed when calling [`PhiModel`].
- .venv/lib/python3.12/site-packages/transformers/models/phi/modular_phi.py:77: query_rot, query_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/phi/modular_phi.py:81: key_rot, key_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/phi/modular_phi.py:89: query_states = torch.cat((query_rot, query_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi/modular_phi.py:90: key_states = torch.cat((key_rot, key_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi/modular_phi.py:118: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi/modular_phi.py:171: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi/modular_phi.py:288: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi/modular_phi.py:292: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:155: query_rot, query_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:159: key_rot, key_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:167: query_states = torch.cat((query_rot, query_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:168: key_states = torch.cat((key_rot, key_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:509: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:513: pass
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/processing_markuplm.py:75: passes the `nodes` and `xpaths` along with the additional arguments to [`~MarkupLMTokenizer.__call__`] and
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/processing_markuplm.py:78: Optionally, one can also provide a `text` argument which is passed along as first sequence.
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/processing_markuplm.py:85: raise ValueError("Make sure to pass HTML strings in case `parse_html` is set to `True`")
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/processing_markuplm.py:89: "Please don't pass nodes, xpaths nor node labels in case `parse_html` is set to `True`"
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/processing_markuplm.py:97: raise ValueError("You have passed HTML strings but `parse_html` is set to `False`.")
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/processing_markuplm.py:99: raise ValueError("Make sure to pass nodes and xpaths in case `parse_html` is set to `False`")
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/tokenization_markuplm.py:475: Create a mask from the two sequences passed to be used in a sequence-pair classification task. RoBERTa does not
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/tokenization_markuplm.py:729: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/tokenization_markuplm.py:974: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/tokenization_markuplm_fast.py:204: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/tokenization_markuplm_fast.py:906: Create a mask from the two sequences passed to be used in a sequence-pair classification task. RoBERTa does not
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/configuration_markuplm.py:39: *inputs_ids* passed to the forward method of [`MarkupLMModel`].
- .venv/lib/python3.12/site-packages/transformers/models/markuplm/configuration_markuplm.py:59: The vocabulary size of the `token_type_ids` passed into [`MarkupLMModel`].
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py:1295: from 0 to 255. If passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py:1530: # POSTPROCESSING METHODS - TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py:1555: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py:1604: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py:1668: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modular_conditional_detr.py:47: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modular_conditional_detr.py:95: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modular_conditional_detr.py:128: raise NotImplementedError("Segmentation post-processing is not implemented for Conditional DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modular_conditional_detr.py:131: raise NotImplementedError("Instance post-processing is not implemented for Conditional DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modular_conditional_detr.py:134: raise NotImplementedError("Panoptic post-processing is not implemented for Conditional DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:52: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:358: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:411: # TODO find a better way of exposing other arguments
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1006: - object_queries are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1037: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1119: - object_queries and query_position_embeddings are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1161: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1353: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1354: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1356: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1375: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1429: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1542: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1543: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1545: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1706: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1707: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1709: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1747: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1794: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/configuration_conditional_detr.py:98: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr_fast.py:756: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr_fast.py:804: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr_fast.py:867: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/aya_vision/modeling_aya_vision.py:121: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/aya_vision/modeling_aya_vision.py:148: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/aya_vision/modeling_aya_vision.py:528: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/aya_vision/modular_aya_vision.py:102: pass
- .venv/lib/python3.12/site-packages/transformers/models/aya_vision/modular_aya_vision.py:106: pass
- .venv/lib/python3.12/site-packages/transformers/models/eomt/image_processing_eomt.py:683: A mapping between object instance ids and class ids. If passed, `segmentation_maps` is treated as an
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modeling_eomt.py:55: This output can be directly passed to [`~EomtImageProcessor.post_process_semantic_segmentation`] or
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modeling_eomt.py:73: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modeling_eomt.py:76: attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modeling_eomt.py:527: uncertainty is calculated for each point using the passed `uncertainty function` that takes points logit
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modular_eomt.py:207: This output can be directly passed to [`~EomtImageProcessor.post_process_semantic_segmentation`] or
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modular_eomt.py:225: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modular_eomt.py:228: attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modular_eomt.py:245: pass
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modular_eomt.py:249: pass
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modular_eomt.py:289: pass
- .venv/lib/python3.12/site-packages/transformers/models/eomt/modular_eomt.py:293: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/image_processing_glm4v.py:321: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/image_processing_glm4v.py:324: passing in videos with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/processing_glm4v.py:186: "Probably `video_metadata` was missing from inputs and you passed pre-sampled frames. "
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/processing_glm4v.py:277: Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/processing_glm4v.py:279: Whether or not to clean up the tokenization spaces. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/processing_glm4v.py:281: Additional arguments to be passed to the tokenizer's `batch_decode method`.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modeling_glm4v.py:150: Forward pass with integrated position encoding adaptation using 2D interpolation.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modeling_glm4v.py:490: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modeling_glm4v.py:491: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modeling_glm4v.py:498: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modeling_glm4v.py:499: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modeling_glm4v.py:658: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modeling_glm4v.py:1313: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modeling_glm4v.py:1515: These parameters are not passed through the processor to avoid unpredictable impacts from interface modifications.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/video_processing_glm4v.py:140: "Please pass in `VideoMetadata` object or set `do_sample_frames=False`"
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:176: `inputs_ids` passed when calling [`Glm4vModel`]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:379: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:401: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:436: Forward pass with integrated position encoding adaptation using 2D interpolation.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:526: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:579: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:580: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:587: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:588: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:669: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:726: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:1299: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:1445: These parameters are not passed through the processor to avoid unpredictable impacts from interface modifications.
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:1496: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/modular_glm4v.py:1631: "Probably `video_metadata` was missing from inputs and you passed pre-sampled frames. "
- .venv/lib/python3.12/site-packages/transformers/models/glm4v/configuration_glm4v.py:135: `inputs_ids` passed when calling [`Glm4vModel`]
- .venv/lib/python3.12/site-packages/transformers/models/gemma/modular_gemma.py:61: `inputs_ids` passed when calling [`GemmaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/gemma/modular_gemma.py:204: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/gemma/modular_gemma.py:461: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma/modular_gemma.py:465: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma/tokenization_gemma.py:63: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/gemma/tokenization_gemma.py:276: Creates a mask from the two sequences passed to be used in a sequence-pair classification task. An ALBERT
- .venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:491: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:495: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_flax_gemma.py:111: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_flax_gemma.py:506: raise ValueError("Make sure to provide `position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_flax_gemma.py:520: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed down to ens
- .venv/lib/python3.12/site-packages/transformers/models/gemma/configuration_gemma.py:36: `inputs_ids` passed when calling [`GemmaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/configuration_fsmt.py:53: `inputs_ids` passed to the forward method in the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/configuration_fsmt.py:56: `inputs_ids` passed to the forward method in the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/tokenization_fsmt.py:322: def _tokenize(self, text, lang="en", bypass_tokenizer=False):
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/tokenization_fsmt.py:334: - bypass_tokenizer: Allow users to preprocess and tokenize the sentences externally (default = False)
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/tokenization_fsmt.py:340: # ignore `lang` which is currently isn't explicitly passed in tokenization_utils.py and always results in lang=en
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/tokenization_fsmt.py:348: if bypass_tokenizer:
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:78: #   to match fairseq outputs, you need to pass ``early_stopping=True`` to ``generate()``.
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:99: # TODO:
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:201: This mimics the default behavior in fairseq. To override it pass in masks. Note: this is not called during
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:657: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:978: raise ValueError("Make sure that `decoder_input_ids` or `decoder_inputs_embeds` are passed.")
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:990: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:1150: # TODO(SS): do we need to ignore pad tokens in labels?
- .venv/lib/python3.12/site-packages/transformers/models/aimv2/modular_aimv2.py:152: the `inputs_ids` passed when calling [`Aimv2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/aimv2/modular_aimv2.py:288: pass
- .venv/lib/python3.12/site-packages/transformers/models/aimv2/modular_aimv2.py:292: pass
- .venv/lib/python3.12/site-packages/transformers/models/aimv2/modular_aimv2.py:296: pass
- .venv/lib/python3.12/site-packages/transformers/models/aimv2/modular_aimv2.py:352: pass
- .venv/lib/python3.12/site-packages/transformers/models/aimv2/modular_aimv2.py:390: pass
- .venv/lib/python3.12/site-packages/transformers/models/aimv2/configuration_aimv2.py:143: the `inputs_ids` passed when calling [`Aimv2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/aimv2/modeling_aimv2.py:343: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/modular_mixtral.py:223: pass
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/modular_mixtral.py:227: pass
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/modular_mixtral.py:278: pass
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/modular_mixtral.py:450: pass
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/modular_mixtral.py:454: pass
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/modular_mixtral.py:458: pass
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/modeling_mixtral.py:671: pass
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/modeling_mixtral.py:675: pass
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/modeling_mixtral.py:679: pass
- .venv/lib/python3.12/site-packages/transformers/models/mixtral/configuration_mixtral.py:40: `inputs_ids` passed when calling [`MixtralModel`]
- .venv/lib/python3.12/site-packages/transformers/models/switch_transformers/modeling_switch_transformers.py:380: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/switch_transformers/modeling_switch_transformers.py:962: # do not pass cache object down the line for encoder stack
- .venv/lib/python3.12/site-packages/transformers/models/switch_transformers/modeling_switch_transformers.py:1352: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/switch_transformers/modeling_switch_transformers.py:1374: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/switch_transformers/modeling_switch_transformers.py:1584: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/switch_transformers/configuration_switch_transformers.py:37: represented by the `inputs_ids` passed when calling [`SwitchTransformersModel`].
- .venv/lib/python3.12/site-packages/transformers/models/focalnet/modeling_focalnet.py:47: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/focalnet/modeling_focalnet.py:68: pooler_output (`torch.FloatTensor` of shape `(batch_size, hidden_size)`, *optional*, returned when `add_pooling_layer=Tr
- .venv/lib/python3.12/site-packages/transformers/models/focalnet/modeling_focalnet.py:70: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/focalnet/modeling_focalnet.py:96: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/focalnet/modeling_focalnet.py:122: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py:375: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py:530: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py:697: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py:822: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py:900: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py:902: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py:915: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py:961: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_flax_roberta.py:841: # init input tensors if not passed
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_flax_roberta.py:862: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_flax_roberta.py:946: # make sure `token_type_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_flax_roberta.py:950: # make sure `position_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:100: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:292: # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:526: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:594: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:699: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:1291: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/roberta/configuration_roberta.py:43: `inputs_ids` passed when calling [`RobertaModel`] or [`TFRobertaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/roberta/configuration_roberta.py:63: The vocabulary size of the `token_type_ids` passed when calling [`RobertaModel`] or [`TFRobertaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:52: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:244: Create a mask from the two sequences passed to be used in a sequence-pair classification task. RoBERTa does not
- .venv/lib/python3.12/site-packages/transformers/models/roberta/tokenization_roberta.py:93: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/roberta/tokenization_roberta.py:376: Create a mask from the two sequences passed to be used in a sequence-pair classification task. RoBERTa does not
- .venv/lib/python3.12/site-packages/transformers/models/depth_pro/image_processing_depth_pro.py:213: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/depth_pro/image_processing_depth_pro.py:352: "Make sure that you pass in as many fov values as the batch dimension of the predicted depth"
- .venv/lib/python3.12/site-packages/transformers/models/depth_pro/modeling_depth_pro.py:1089: raise NotImplementedError("Training is not implemented yet")
- .venv/lib/python3.12/site-packages/transformers/models/depth_pro/image_processing_depth_pro_fast.py:140: "Make sure that you pass in as many fov values as the batch dimension of the predicted depth"
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:430: The goal of this forward pass is to have the same number of operation as the equivalent `NllbMoeDenseActDense`
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:555: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:849: # TODO: If anyone is up to it to make sure tests pass etc
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:954: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:1180: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:1192: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:1241: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:1360: # 2d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:1384: # 4d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:1520: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py:1536: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/nllb_moe/configuration_nllb_moe.py:38: `inputs_ids` passed when calling [`NllbMoeModel`] or
- .venv/lib/python3.12/site-packages/transformers/models/vitmatte/image_processing_vitmatte.py:154: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/vitmatte/modeling_vitmatte.py:41: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/vitmatte/modeling_vitmatte.py:275: raise NotImplementedError("Training is not yet supported")
- .venv/lib/python3.12/site-packages/transformers/models/vitmatte/configuration_vitmatte.py:51: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/encodec/feature_extraction_encodec.py:123: The sampling rate at which the `audio` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/encodec/feature_extraction_encodec.py:135: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/encodec/configuration_encodec.py:47: Whether the audio shall be normalized when passed.
- .venv/lib/python3.12/site-packages/transformers/models/encodec/modeling_encodec.py:63: outputted as a tensor. This value should be passed during decoding to ensure padding is removed from the
- .venv/lib/python3.12/site-packages/transformers/models/encodec/modeling_encodec.py:219: # as removing it here would require also passing the length at the matching layer
- .venv/lib/python3.12/site-packages/transformers/models/encodec/modeling_encodec.py:742: `padding_mask` should always be passed, unless the input was truncated or not padded. This is because in
- .venv/lib/python3.12/site-packages/transformers/models/encodec/modeling_encodec.py:759: outputted as a tensor. This value should be passed during decoding to ensure padding is removed from the
- .venv/lib/python3.12/site-packages/transformers/models/trocr/modeling_trocr.py:535: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/trocr/modeling_trocr.py:547: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/trocr/modeling_trocr.py:594: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/trocr/configuration_trocr.py:38: `inputs_ids` passed when calling [`TrOCRForCausalLM`].
- .venv/lib/python3.12/site-packages/transformers/models/cohere/configuration_cohere.py:43: `inputs_ids` passed when calling [`CohereModel`]
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:66: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer, but since
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:150: # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:265: Note that this argument will be passed to the chat template, and so it must be supported in the
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:285: **tokenizer_kwargs: Additional kwargs to pass to the tokenizer.
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:291: output is ready to pass to the model, either directly or via methods like `generate()`.
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:345: pass
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:352: pass
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:413: Note that this argument will be passed to the chat template, and so it must be supported in the
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:433: **tokenizer_kwargs: Additional kwargs to pass to the tokenizer.
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:439: output is ready to pass to the model, either directly or via methods like `generate()`.
- .venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:499: # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_swin.py:51: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_swin.py:73: pooler_output (`torch.FloatTensor` of shape `(batch_size, hidden_size)`, *optional*, returned when `add_pooling_layer=Tr
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_swin.py:75: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_swin.py:102: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_swin.py:138: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_swin.py:641: pass
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:76: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:81: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:87: reshaped_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:109: pooler_output (`tf.Tensor` of shape `(batch_size, hidden_size)`, *optional*, returned when `add_pooling_layer=True` is p
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:111: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:116: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:122: reshaped_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:147: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:152: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:158: reshaped_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:192: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:197: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:203: reshaped_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:671: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/swin/modeling_tf_swin.py:1230: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/tokenization_deberta_v2.py:68: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/tokenization_deberta_v2.py:230: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/tokenization_deberta_v2.py:327: # TODO add a deprecation cycle as this can have different behaviour from our API
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/tokenization_deberta_v2_fast.py:69: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py:1172: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py:1271: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py:1273: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py:1286: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py:1326: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/configuration_deberta_v2.py:46: the `inputs_ids` passed when calling [`DebertaV2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/configuration_deberta_v2.py:67: The vocabulary size of the `token_type_ids` passed when calling [`DebertaModel`] or [`TFDebertaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:741: raise NotImplementedError("The prune function is not implemented in DeBERTa model.")
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:895: # note that the input embeddings must be passed as an argument
- .venv/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:909: # note that the input embeddings must be passed as an argument
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:61: # TODO: Update before the merge
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:258: pass
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:261: pass
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:345: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:1258: _can_compile_fullgraph = False  # TODO: @raushan more involved due to local/global attn
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:1438: # do not pass cache object down the line for encoder stack
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:1820: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:1833: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:2029: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:2086: # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflo
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_flax_longt5.py:1591: past_key_values (`Dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_flax_longt5.py:1745: "Make sure to provide both `input_ids` and `decoder_input_ids`. `decoder_input_ids` is not passed"
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_flax_longt5.py:1927: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_flax_longt5.py:1928: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_flax_longt5.py:2069: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_flax_longt5.py:2129: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_flax_longt5.py:2315: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_flax_longt5.py:2316: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/longt5/configuration_longt5.py:40: `inputs_ids` passed when calling [`LongT5Model`].
- .venv/lib/python3.12/site-packages/transformers/models/hubert/configuration_hubert.py:41: `inputs_ids` passed when calling [`HubertModel`]. Vocabulary size of the model. Defines the different
- .venv/lib/python3.12/site-packages/transformers/models/hubert/configuration_hubert.py:42: tokens that can be represented by the *inputs_ids* passed to the forward method of [`HubertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:310: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:1047: passing `target_lang=...` to `from_pretrained(...)`.
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:1059: raise ValueError(f"Cannot pass `target_lang`: {target_lang} if `config.adapter_attn_dim` is not defined.")
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modular_hubert.py:93: pass
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modular_hubert.py:97: pass
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modular_hubert.py:119: pass
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modular_hubert.py:123: pass
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modular_hubert.py:295: pass
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modular_hubert.py:299: pass
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_tf_hubert.py:431: # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_tf_hubert.py:1346: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_tf_hubert.py:1348: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_tf_hubert.py:1361: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_tf_hubert.py:1407: Optionally, instead of passing `input_values` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modular_unispeech.py:75: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modular_unispeech.py:79: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modular_unispeech.py:83: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modular_unispeech.py:87: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modular_unispeech.py:91: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modular_unispeech.py:377: >>> # TODO: Add full pretraining example
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modular_unispeech.py:414: # TODO(PVP) - add negative sampling & loss computation
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modular_unispeech.py:432: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modular_unispeech.py:436: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:342: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1179: >>> # TODO: Add full pretraining example
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1216: # TODO(PVP) - add negative sampling & loss computation
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1274: passing `target_lang=...` to `from_pretrained(...)`.
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1286: raise ValueError(f"Cannot pass `target_lang`: {target_lang} if `config.adapter_attn_dim` is not defined.")
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/configuration_unispeech.py:41: the `inputs_ids` passed when calling [`UniSpeechModel`]. Vocabulary size of the model. Defines the
- .venv/lib/python3.12/site-packages/transformers/models/unispeech/configuration_unispeech.py:42: different tokens that can be represented by the *inputs_ids* passed to the forward method of
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv2/tokenization_layoutlmv2.py:110: Python's tokenizer, this method will raise `NotImplementedError`.
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv2/tokenization_layoutlmv2.py:115: **kwargs: passed to the `self.tokenize()` method
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv2/tokenization_layoutlmv2.py:622: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv2/tokenization_layoutlmv2.py:867: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv2/tokenization_layoutlmv2.py:1505: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv2/processing_layoutlmv2.py:94: [`LayoutLMv2ImageProcessor`] was initialized with `apply_ocr` set to `True`, it passes the obtained words and
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv2/processing_layoutlmv2.py:97: `False`, it passes the words (`text`/``text_pair`) and `boxes` specified by the user along with the additional
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv2/configuration_layoutlmv2.py:42: the `inputs_ids` passed when calling [`LayoutLMv2Model`] or [`TFLayoutLMv2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/layoutlmv2/configuration_layoutlmv2.py:62: The vocabulary size of the `token_type_ids` passed when calling [`LayoutLMv2Model`] or
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:345: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:365: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:636: # TODO: tests would need a rewrite to check for correct implementation
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:637: # Current tests always assume certain inputs to be passed
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:687: # 2d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:711: # 4d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:808: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:960: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:972: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1001: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1411: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/image_processing_siglip2.py:216: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modular_siglip2.py:43: pass
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modular_siglip2.py:117: pass
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modular_siglip2.py:121: pass
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modular_siglip2.py:125: pass
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modular_siglip2.py:129: pass
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modular_siglip2.py:285: pass
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modular_siglip2.py:289: pass
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modular_siglip2.py:454: >>> # important: we pass `padding=max_length` since the model was trained with this
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/configuration_siglip2.py:42: the `inputs_ids` passed when calling [`Siglip2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:391: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:1096: >>> # important: we pass `padding=max_length` since the model was trained with this
- .venv/lib/python3.12/site-packages/transformers/models/mra/configuration_mra.py:38: `inputs_ids` passed when calling [`MraModel`].
- .venv/lib/python3.12/site-packages/transformers/models/mra/configuration_mra.py:58: The vocabulary size of the `token_type_ids` passed when calling [`MraModel`].
- .venv/lib/python3.12/site-packages/transformers/models/mra/modeling_mra.py:499: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/mra/modeling_mra.py:1174: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/pix2struct/image_processing_pix2struct.py:206: Whether or not the image processor is for the VQA task. If `True` and `header_text` is passed in, text is
- .venv/lib/python3.12/site-packages/transformers/models/pix2struct/configuration_pix2struct.py:37: represented by the `inputs_ids` passed when calling [`Pix2StructTextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/pix2struct/modeling_pix2struct.py:95: pass
- .venv/lib/python3.12/site-packages/transformers/models/pix2struct/modeling_pix2struct.py:98: pass
- .venv/lib/python3.12/site-packages/transformers/models/pix2struct/modeling_pix2struct.py:650: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/pix2struct/modeling_pix2struct.py:1535: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/pix2struct/modeling_pix2struct.py:1544: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/roformer/tokenization_roformer.py:233: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_flax_roformer.py:664: # init input tensors if not passed
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_tf_roformer.py:73: raise NotImplementedError(f"odd embedding_dim {embedding_dim} not supported")
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_tf_roformer.py:359: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_tf_roformer.py:707: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_tf_roformer.py:769: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_tf_roformer.py:836: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_tf_roformer.py:838: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_tf_roformer.py:851: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_tf_roformer.py:892: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_roformer.py:484: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention "
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_roformer.py:548: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_roformer.py:645: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_roformer.py:700: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_roformer.py:799: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/roformer/modeling_roformer.py:1296: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/roformer/configuration_roformer.py:42: the `inputs_ids` passed when calling [`RoFormerModel`] or [`TFRoFormerModel`].
- .venv/lib/python3.12/site-packages/transformers/models/roformer/configuration_roformer.py:64: The vocabulary size of the `token_type_ids` passed when calling [`RoFormerModel`] or [`TFRoFormerModel`].
- .venv/lib/python3.12/site-packages/transformers/models/roformer/tokenization_utils.py:41: # this code slice normalized_string is too slow (6s) but test_alignment_methods can pass
- .venv/lib/python3.12/site-packages/transformers/models/roformer/tokenization_utils.py:53: # this code test_alignment_methods can't pass but fast (300ms)
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:413: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:561: # four values, three of which have been passed through a bottleneck: the query and key, passed through the same
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:565: # and the residual layer will be this value passed through a bottleneck.
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:929: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:985: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:1051: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:1056: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:1088: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:1090: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:1103: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py:1149: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/configuration_mobilebert.py:42: the `inputs_ids` passed when calling [`MobileBertModel`] or [`TFMobileBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/configuration_mobilebert.py:62: The vocabulary size of the `token_type_ids` passed when calling [`MobileBertModel`] or
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:434: # four values, three of which have been passed through a bottleneck: the query and key, passed through the same
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:438: # and the residual layer will be this value passed through a bottleneck.
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:1343: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/mobilebert/tokenization_mobilebert.py:444: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/configuration_phi4_multimodal.py:257: `inputs_ids` passed when calling [`Phi3Model`].
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/processing_phi4_multimodal.py:140: "You should add as much image tokens `<|image|>` in your prompt as you pass `images` to the processor. ",
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/processing_phi4_multimodal.py:145: "You should add as much audio tokens `<|audio|>` in your prompt as you pass `audios` to the processor. "
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modular_phi4_multimodal.py:294: `inputs_ids` passed when calling [`Phi3Model`].
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modular_phi4_multimodal.py:446: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modular_phi4_multimodal.py:699: # avoiding passing the attention_mask, which is equivalent to attending to the full sequence
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modular_phi4_multimodal.py:1381: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modular_phi4_multimodal.py:1385: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modular_phi4_multimodal.py:1447: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py:219: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py:575: # avoiding passing the attention_mask, which is equivalent to attending to the full sequence
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py:1361: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py:1362: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py:1364: q_embed = torch.cat([(q_rot * cos) + (rotate_half(q_rot) * sin), q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py:1365: k_embed = torch.cat([(k_rot * cos) + (rotate_half(k_rot) * sin), k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/feature_extraction_phi4_multimodal.py:99: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/feature_extraction_phi4_multimodal.py:135: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/phi4_multimodal/feature_extraction_phi4_multimodal.py:205: # TODO; @eustlb, move this to audio_utils in a general spectogram_batch function that handles torch and numpy
- .venv/lib/python3.12/site-packages/transformers/models/olmo2/modular_olmo2.py:41: `inputs_ids` passed when calling [`Olmo2Model`]
- .venv/lib/python3.12/site-packages/transformers/models/olmo2/modular_olmo2.py:293: pass
- .venv/lib/python3.12/site-packages/transformers/models/olmo2/modular_olmo2.py:297: pass
- .venv/lib/python3.12/site-packages/transformers/models/olmo2/modular_olmo2.py:313: pass
- .venv/lib/python3.12/site-packages/transformers/models/olmo2/configuration_olmo2.py:24: `inputs_ids` passed when calling [`Olmo2Model`]
- .venv/lib/python3.12/site-packages/transformers/models/glpn/modeling_glpn.py:519: # pass through convolutional layers
- .venv/lib/python3.12/site-packages/transformers/models/glpn/image_processing_glpn.py:155: passing in images with pixel values between 0 and 1, set `do_normalize=False`.
- .venv/lib/python3.12/site-packages/transformers/models/glpn/image_processing_glpn.py:260: "Make sure that you pass in as many target sizes as the batch dimension of the predicted depth"
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:190: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:253: query_rot, query_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:257: key_rot, key_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:265: query_states = torch.cat((query_rot, query_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:266: key_states = torch.cat((key_rot, key_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:325: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:358: query_rot, query_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:362: key_rot, key_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:370: query_states = torch.cat((query_rot, query_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:371: key_states = torch.cat((key_rot, key_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:423: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:430: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:472: query_rot, query_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:476: key_rot, key_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:483: query_states = torch.cat((query_rot, query_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:484: key_states = torch.cat((key_rot, key_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:495: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:703: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/stablelm/configuration_stablelm.py:40: can be represented by the `inputs_ids` passed when calling [`StableLmModel`].
- .venv/lib/python3.12/site-packages/transformers/models/glm/configuration_glm.py:31: `inputs_ids` passed when calling [`GlmModel`]
- .venv/lib/python3.12/site-packages/transformers/models/glm/modular_glm.py:39: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm/modular_glm.py:78: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm/modular_glm.py:79: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm/modular_glm.py:86: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm/modular_glm.py:87: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm/modular_glm.py:98: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm/modular_glm.py:102: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm/modular_glm.py:106: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:139: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:140: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:147: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:148: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:499: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:503: pass
- .venv/lib/python3.12/site-packages/transformers/models/git/modeling_git.py:131: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/git/modeling_git.py:408: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/git/modeling_git.py:767: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/git/modeling_git.py:1441: # Some generation methods already pass only the last input ID
- .venv/lib/python3.12/site-packages/transformers/models/git/configuration_git.py:120: `inputs_ids` passed when calling [`GitModel`].
- .venv/lib/python3.12/site-packages/transformers/models/poolformer/image_processing_poolformer.py:237: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/yoso/configuration_yoso.py:38: `inputs_ids` passed when calling [`YosoModel`].
- .venv/lib/python3.12/site-packages/transformers/models/yoso/configuration_yoso.py:58: The vocabulary size of the `token_type_ids` passed when calling [`YosoModel`].
- .venv/lib/python3.12/site-packages/transformers/models/yoso/modeling_yoso.py:269: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/yoso/modeling_yoso.py:999: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modular_minimax.py:68: `inputs_ids` passed when calling [`MiniMaxModel`]
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modular_minimax.py:185: pass
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modular_minimax.py:383: pass
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modular_minimax.py:387: pass
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modular_minimax.py:585: pass
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modular_minimax.py:589: pass
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modular_minimax.py:593: pass
- .venv/lib/python3.12/site-packages/transformers/models/minimax/configuration_minimax.py:40: `inputs_ids` passed when calling [`MiniMaxModel`]
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modeling_minimax.py:915: pass
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modeling_minimax.py:919: pass
- .venv/lib/python3.12/site-packages/transformers/models/minimax/modeling_minimax.py:923: pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py:147: Additional keyword arguments passed along to both [`SequenceFeatureExtractor`] and
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py:317: If you are decoding multiple batches, consider creating a `Pool` and passing it to `batch_decode`. Otherwise,
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py:332: Currently, only pools created with a 'fork' context can be used. If a 'spawn' pool is passed, it will
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py:425: "Parameter `num_process` was passed, but it will be ignored since `pool` was also specified."
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/tokenization_big_bird.py:66: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/configuration_big_bird.py:42: `inputs_ids` passed when calling [`BigBirdModel`].
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/configuration_big_bird.py:62: The vocabulary size of the `token_type_ids` passed when calling [`BigBirdModel`].
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:270: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:824: # this is just for visualizing; forward pass doesn't depend on following code
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:826: # TODO(PVP): need to verify if below code is correct
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:1491: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with                    "
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:1576: "You should pass an instance of `DynamicCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:1793: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:2646: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_flax_big_bird.py:69: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_flax_big_bird.py:74: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_flax_big_bird.py:100: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_flax_big_bird.py:105: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_flax_big_bird.py:1743: # init input tensors if not passed
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_flax_big_bird.py:1767: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_flax_big_bird.py:2484: # init input tensors if not passed
- .venv/lib/python3.12/site-packages/transformers/models/apertus/configuration_apertus.py:41: `inputs_ids` passed when calling [`ApertusModel`]
- .venv/lib/python3.12/site-packages/transformers/models/apertus/modeling_apertus.py:485: pass
- .venv/lib/python3.12/site-packages/transformers/models/apertus/modular_apertus.py:58: `inputs_ids` passed when calling [`ApertusModel`]
- .venv/lib/python3.12/site-packages/transformers/models/apertus/modular_apertus.py:226: pass
- .venv/lib/python3.12/site-packages/transformers/models/apertus/modular_apertus.py:230: pass
- .venv/lib/python3.12/site-packages/transformers/models/apertus/modular_apertus.py:327: pass
- .venv/lib/python3.12/site-packages/transformers/models/apertus/modular_apertus.py:331: pass
- .venv/lib/python3.12/site-packages/transformers/models/apertus/modular_apertus.py:362: pass
- .venv/lib/python3.12/site-packages/transformers/models/convnext/image_processing_convnext.py:211: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/convnext/modeling_tf_convnext.py:448: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/convnext/modeling_tf_convnext.py:450: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/convnext/modeling_tf_convnext.py:463: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/convnext/modeling_convnext.py:85: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/configuration_gemma3.py:45: `inputs_ids` passed when calling [`Gemma3TextModel`]
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/image_processing_gemma3.py:266: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:59: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:85: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:466: # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:917: # We need to pass an additional mask function to account for token type ids, and it needs to be an `or`
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:1164: # Otherwise we need pixel values to be passed to model. NOTE: use_cache=False needs pixel_values always
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:1192: # We need to pass an additional mask function to account for token type ids, and it needs to be an `or`
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:71: `inputs_ids` passed when calling [`Gemma3TextModel`]
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:359: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:363: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:549: # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:829: # We need to pass an additional mask function to account for token type ids, and it needs to be an `or`
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:1029: # Otherwise we need pixel values to be passed to model. NOTE: use_cache=False needs pixel_values always
- .venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:1060: # We need to pass an additional mask function to account for token type ids, and it needs to be an `or`
- .venv/lib/python3.12/site-packages/transformers/models/mistral/configuration_mistral.py:40: `inputs_ids` passed when calling [`MistralModel`]
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:463: pass
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:467: pass
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modular_mistral.py:178: pass
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modular_mistral.py:182: pass
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modular_mistral.py:186: pass
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_flax_mistral.py:116: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_flax_mistral.py:482: raise ValueError("Make sure to provide `position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_flax_mistral.py:496: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed down to ens
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_tf_mistral.py:171: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_tf_mistral.py:244: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_tf_mistral.py:650: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_tf_mistral.py:652: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_tf_mistral.py:665: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_tf_mistral.py:730: The model will output the same cache format that is fed as input. If no `past_key_values` are passed, the
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_tf_mistral.py:737: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_tf_mistral.py:913: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/phobert/tokenization_phobert.py:204: Create a mask from the two sequences passed to be used in a sequence-pair classification task. PhoBERT does not
- .venv/lib/python3.12/site-packages/transformers/models/univnet/feature_extraction_univnet.py:311: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/univnet/feature_extraction_univnet.py:373: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/janus/image_processing_janus.py:231: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/janus/image_processing_janus.py:360: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/janus/modeling_janus.py:101: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/janus/modeling_janus.py:136: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/janus/modeling_janus.py:442: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/janus/modeling_janus.py:1225: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/janus/modeling_janus.py:1307: # 4. Add CFG processor along with user passed logit processor.
- .venv/lib/python3.12/site-packages/transformers/models/janus/image_processing_janus_fast.py:121: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/janus/modular_janus.py:417: pass
- .venv/lib/python3.12/site-packages/transformers/models/janus/modular_janus.py:421: pass
- .venv/lib/python3.12/site-packages/transformers/models/janus/modular_janus.py:600: pass
- .venv/lib/python3.12/site-packages/transformers/models/janus/modular_janus.py:604: pass
- .venv/lib/python3.12/site-packages/transformers/models/janus/modular_janus.py:608: pass
- .venv/lib/python3.12/site-packages/transformers/models/janus/modular_janus.py:1085: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/janus/modular_janus.py:1167: # 4. Add CFG processor along with user passed logit processor.
- .venv/lib/python3.12/site-packages/transformers/models/janus/modular_janus.py:1370: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:262: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:363: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:370: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:415: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:477: `OlmoeAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:495: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:791: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/olmoe/configuration_olmoe.py:31: `inputs_ids` passed when calling [`OlmoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:125: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:420: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:474: # TODO find a better way of exposing other arguments
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1021: # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1046: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1122: - `position_embeddings`, `reference_points`, `spatial_shapes` and `valid_ratios` are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1161: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1482: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1483: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1485: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1594: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1761: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1762: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1764: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr.py:1293: from 0 to 255. If passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr.py:1528: # POSTPROCESSING METHODS - TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr.py:1553: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr.py:1601: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/configuration_deformable_detr.py:90: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modular_deformable_detr.py:45: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modular_deformable_detr.py:93: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modular_deformable_detr.py:126: raise NotImplementedError("Segmentation post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modular_deformable_detr.py:129: raise NotImplementedError("Instance post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modular_deformable_detr.py:132: raise NotImplementedError("Panoptic post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modular_deformable_detr.py:135: raise NotImplementedError("Segmentation post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modular_deformable_detr.py:138: raise NotImplementedError("Semantic segmentation post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modular_deformable_detr.py:141: raise NotImplementedError("Panoptic segmentation post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr_fast.py:747: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr_fast.py:795: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/arcee/configuration_arcee.py:42: `inputs_ids` passed when calling [`ArceeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/arcee/modular_arcee.py:48: `inputs_ids` passed when calling [`ArceeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/arcee/modular_arcee.py:194: pass
- .venv/lib/python3.12/site-packages/transformers/models/arcee/modular_arcee.py:199: pass
- .venv/lib/python3.12/site-packages/transformers/models/arcee/modular_arcee.py:204: pass
- .venv/lib/python3.12/site-packages/transformers/models/arcee/modular_arcee.py:209: pass
- .venv/lib/python3.12/site-packages/transformers/models/arcee/modular_arcee.py:214: pass
- .venv/lib/python3.12/site-packages/transformers/models/arcee/modeling_arcee.py:486: pass
- .venv/lib/python3.12/site-packages/transformers/models/arcee/modeling_arcee.py:496: pass
- .venv/lib/python3.12/site-packages/transformers/models/xmod/modeling_xmod.py:99: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/xmod/modeling_xmod.py:471: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/xmod/modeling_xmod.py:542: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/xmod/modeling_xmod.py:682: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/xmod/modeling_xmod.py:1253: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/xmod/configuration_xmod.py:43: `inputs_ids` passed when calling [`XmodModel`].
- .venv/lib/python3.12/site-packages/transformers/models/xmod/configuration_xmod.py:63: The vocabulary size of the `token_type_ids` passed when calling [`XmodModel`].
- .venv/lib/python3.12/site-packages/transformers/models/xmod/configuration_xmod.py:95: codes are explicitly passed to the forward method.
- .venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:148: Forward pass of the GraniteMoeSharedParallelExperts module.
- .venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:245: Forward pass of the mixture of experts layer.
- .venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:359: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:652: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/configuration_granitemoeshared.py:43: `inputs_ids` passed when calling [`GraniteMoeSharedModel`]
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:347: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1191: >>> # TODO: Add full pretraining example
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1208: # TODO(PVP) - add pretraining logic and add to tests
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1269: passing `target_lang=...` to `from_pretrained(...)`.
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1281: raise ValueError(f"Cannot pass `target_lang`: {target_lang} if `config.adapter_attn_dim` is not defined.")
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/configuration_unispeech_sat.py:42: by the `inputs_ids` passed when calling [`UniSpeechSatModel`]. Vocabulary size of the model. Defines the
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/configuration_unispeech_sat.py:43: different tokens that can be represented by the *inputs_ids* passed to the forward method of
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:83: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:87: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:91: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:95: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:99: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:396: >>> # TODO: Add full pretraining example
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:413: # TODO(PVP) - add pretraining logic and add to tests
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:434: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:438: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:442: pass
- .venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py:446: pass
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/configuration_pegasus.py:38: `inputs_ids` passed when calling [`PegasusModel`] or [`TFPegasusModel`].
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py:127: raise NotImplementedError(f"odd embedding_dim {embedding_dim} not supported")
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py:585: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py:587: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py:600: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py:691: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py:788: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py:993: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py:1200: # If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py:1207: # If the user passed a TFBaseModelOutput for encoder_outputs, we wrap it in a tuple when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/tokenization_pegasus.py:34: # TODO ArthurZ refactor this to only use the added_tokens_encoder
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/tokenization_pegasus.py:80: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_flax_pegasus.py:197: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_flax_pegasus.py:1099: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_flax_pegasus.py:1112: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_flax_pegasus.py:1113: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_flax_pegasus.py:1367: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_flax_pegasus.py:1380: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_flax_pegasus.py:1381: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_pegasus.py:179: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_pegasus.py:199: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_pegasus.py:777: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_pegasus.py:989: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_pegasus.py:1001: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_pegasus.py:1039: # important to apply scale outside of `if` in case users pass `embeds`
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_pegasus.py:1059: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/pegasus/modeling_pegasus.py:1289: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:53: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:72: question_enc_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed 
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:77: question_enc_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:85: generator_enc_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:90: generator_enc_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:96: generator_dec_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:101: generator_dec_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:107: generator_cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or 
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:144: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:163: question_enc_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed 
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:168: question_enc_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:176: generator_enc_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:181: generator_enc_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:187: generator_dec_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:192: generator_dec_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:198: generator_cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or 
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:279: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:475: has to be provided to the forward pass. `doc_scores` can be computed via
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:480: the forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:484: provided to the forward pass. `context_attention_mask` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:589: "Make sure that `context_input_ids` are passed, if no `retriever` is set. Alternatively, you can"
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:593: "Make sure that `context_attention_mask` are passed, if no `retriever` is set. Alternatively, you"
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:597: "Make sure that `doc_scores` are passed, if no `retriever` is set. Alternatively, you can set a"
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:602: "Make sure that `doc_scores` are passed when passing `encoder_outputs` to the forward function."
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:668: A RAG-sequence model implementation. It performs RAG-sequence specific marginalization in the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:753: the forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:757: provided to the forward pass. `context_attention_mask` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:761: has to be provided to the forward pass. `doc_scores` can be computed via
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:767: Only relevant if `labels` is passed. If `True`, the score of the BOS token is disregarded when computing
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:770: Only relevant if `labels` is passed. If `True`, the NLL loss is reduced using the `torch.Tensor.sum`
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:901: The sequence used as a prompt for the generation. If `input_ids` is not passed, then
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:918: `context_attention_mask` have to be provided to the forward pass. They are returned by
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:925: provided to the forward pass. `doc_scores` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:931: is not the value we pass to the `generator`'s `[`~generation.GenerationMixin.generate`]` function,
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:938: Additional kwargs will be passed to [`~generation.GenerationMixin.generate`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:999: "Make sure that `context_attention_mask` are passed, if no `input_ids` is set. Alternatively, you"
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1003: "Make sure that `doc_scores` are passed, if no `input_ids` is set. Alternatively, you can set a"
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1105: A RAG-token model implementation. It performs RAG-token specific marginalization in the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1265: the forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1269: provided to the forward pass. `context_attention_mask` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1273: has to be provided to the forward pass. `doc_scores` can be computed via
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1282: Only relevant if `labels` is passed. If `True`, the NLL loss is reduced using the `torch.Tensor.sum`
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1413: The sequence used as a prompt for the generation. If `input_ids` is not passed, then
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1427: forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1433: forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1439: forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1444: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1458: model's config. If a logit processor is passed that is already created with the arguments or a model's
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1462: model's config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_rag.py:1609: # because RAG expands input for doc-size internally. TODO: raushan, remove me when all models support
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:57: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:79: question_enc_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when 
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:84: question_enc_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:92: generator_enc_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:97: generator_enc_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:103: generator_dec_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:108: generator_dec_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:141: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:163: question_enc_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when 
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:168: question_enc_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:176: generator_enc_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:181: generator_enc_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:187: generator_dec_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:192: generator_dec_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:270: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:391: During a forward pass, we encode the input with the question encoder and pass it to the retriever to extract
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:392: relevant context documents. The documents are then prepended to the input. Such contextualized inputs is passed to
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:462: has to be provided to the forward pass. `doc_scores` can be computed via
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:469: forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`]. context_attention_mask
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:475: forward pass. `context_attention_mask` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:651: "Make sure that `context_input_ids` are passed, if no `retriever` is set. Alternatively, you can"
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:655: "Make sure that `context_attention_mask` are passed, if no `retriever` is set. Alternatively, you"
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:659: "Make sure that `doc_scores` are passed, if no `retriever` is set. Alternatively, you can set a"
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:664: "Make sure that `doc_scores` are passed when passing `encoder_outputs` to the forward function."
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:738: A TF RAG-token model implementation. It performs RAG-token specific marginalization in the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:890: Only relevant if `labels` is passed. If `True`, the NLL loss is reduced using the `tf.Tensor.sum`
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1027: The sequence used as a prompt for the generation. If `input_ids` is not passed, then
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1041: forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1047: forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1053: forward pass. `context_input_ids` are returned by [`~RagRetriever.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1058: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1065: model's config. If a logit processor is passed that is already created with the arguments or a model's
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1318: A TF RAG-sequence model implementation. It performs RAG-sequence specific marginalization in the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1397: Only relevant if `labels` is passed. If `True`, the score of the BOS token is disregarded when computing
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1404: Only relevant if `labels` is passed. If `True`, the NLL loss is reduced using the `tf.Tensor.sum`
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1623: The sequence used as a prompt for the generation. If `input_ids` is not passed, then
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1635: `context_input_ids` and `context_attention_mask` have to be provided to the forward pass. They are
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1640: `input_ids` is not given, `doc_scores` has to be provided to the forward pass. `doc_scores` are
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1647: is not the value we pass to the `generator`'s `[`~generation.GenerationMixin.generate`]` function,
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1654: Additional kwargs will be passed to [`~generation.GenerationMixin.generate`]
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1712: "Make sure that `context_attention_mask` are passed, if no `input_ids` is set. Alternatively, you"
- .venv/lib/python3.12/site-packages/transformers/models/rag/modeling_tf_rag.py:1716: "Make sure that `doc_scores` are passed, if no `input_ids` is set. Alternatively, you can set a"
- .venv/lib/python3.12/site-packages/transformers/models/rag/configuration_rag.py:50: passages_path (`str`, *optional*):
- .venv/lib/python3.12/site-packages/transformers/models/rag/configuration_rag.py:51: A path to text passages compatible with the faiss index. Required if using
- .venv/lib/python3.12/site-packages/transformers/models/rag/configuration_rag.py:103: passages_path=None,
- .venv/lib/python3.12/site-packages/transformers/models/rag/configuration_rag.py:130: f"both `question_encoder` and `generator` sub-configurations were not passed, only {kwargs}"
- .venv/lib/python3.12/site-packages/transformers/models/rag/configuration_rag.py:158: self.passages_path = passages_path
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:58: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:74: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:80: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:88: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:110: self.passages = self._load_passages()
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:133: def _load_passages(self):
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:134: logger.info(f"Loading passages from {self.index_path}")
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:135: passages_path = self._resolve_path(self.index_path, self.PASSAGE_FILENAME)
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:143: with open(passages_path, "rb") as passages_file:
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:144: passages = pickle.load(passages_file)
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:145: return passages
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:180: docs = [self.passages[doc_id] for doc_id in ids]
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:224: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:249: vector_size (`int`): the dimension of the passages embeddings used by the index
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:283: logger.info(f"Loading passages from {self.dataset_name}")
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:318: vector_size (`int`): the dimension of the passages embeddings used by the index
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:333: logger.info(f"Loading passages from {dataset_path}")
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:370: >>> # To load the default "wiki_dpr" dataset with 21M passages from wikipedia (index name is 'compressed' or 'exact')
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:393: ...     passages_path=dataset_path,
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:431: dataset_path=config.passages_path,
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:470: if self.config.passages_path is None:
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:471: passages_path = os.path.join(save_directory, "hf_dataset")
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:474: self.index.dataset.save_to_disk(passages_path)
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:476: self.config.passages_path = passages_path
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:510: # TODO(Patrick): if we train more RAG models, I want to put the input first to take advantage of effortless truncation
- .venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:511: # TODO(piktus): better handling of truncation
- .venv/lib/python3.12/site-packages/transformers/models/patchtst/modeling_patchtst.py:110: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/patchtst/modeling_patchtst.py:754: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/patchtst/modeling_patchtst.py:829: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/tokenization_biogpt.py:202: def _tokenize(self, text, bypass_tokenizer=False):
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/tokenization_biogpt.py:204: if bypass_tokenizer:
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:158: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:178: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:564: "You should pass an instance of `DynamicCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:844: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/modular_biogpt.py:71: pass
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/modular_biogpt.py:75: pass
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/modular_biogpt.py:388: "You should pass an instance of `DynamicCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/modular_biogpt.py:668: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/biogpt/configuration_biogpt.py:38: `inputs_ids` passed when calling [`BioGptModel`].
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_moe/configuration_hunyuan_v1_moe.py:40: `inputs_ids` passed when calling [`HunYuanMoEV1Model`]
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_moe/configuration_hunyuan_v1_moe.py:162: # self._rope_scaling_validation()   # TODO: Need validation?
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_moe/modular_hunyuan_v1_moe.py:52: pass
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_moe/modular_hunyuan_v1_moe.py:258: pass
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_moe/modular_hunyuan_v1_moe.py:262: pass
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_moe/modular_hunyuan_v1_moe.py:266: pass
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_moe/modeling_hunyuan_v1_moe.py:576: pass
- .venv/lib/python3.12/site-packages/transformers/models/swin2sr/modeling_swin2sr.py:1047: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/swin2sr/modeling_swin2sr.py:1060: raise NotImplementedError("Training is not supported at the moment")
- .venv/lib/python3.12/site-packages/transformers/models/swin2sr/image_processing_swin2sr.py:128: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/florence2/modeling_florence2.py:977: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/florence2/modeling_florence2.py:999: # override to handle merging image and text embeddings before passing to language encoder
- .venv/lib/python3.12/site-packages/transformers/models/florence2/processing_florence2.py:298: Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/florence2/processing_florence2.py:300: Additional arguments to be passed to the tokenizer's `batch_decode method`.
- .venv/lib/python3.12/site-packages/transformers/models/florence2/modular_florence2.py:243: pass
- .venv/lib/python3.12/site-packages/transformers/models/florence2/modular_florence2.py:497: Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/florence2/modular_florence2.py:499: Additional arguments to be passed to the tokenizer's `batch_decode method`.
- .venv/lib/python3.12/site-packages/transformers/models/florence2/modular_florence2.py:1003: pass
- .venv/lib/python3.12/site-packages/transformers/models/florence2/modular_florence2.py:1775: # override to handle merging image and text embeddings before passing to language encoder
- .venv/lib/python3.12/site-packages/transformers/models/deberta/modeling_tf_deberta.py:1066: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deberta/modeling_tf_deberta.py:1164: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/deberta/modeling_tf_deberta.py:1166: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/deberta/modeling_tf_deberta.py:1179: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/deberta/modeling_tf_deberta.py:1219: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py:663: raise NotImplementedError("The prune function is not implemented in DeBERTa model.")
- .venv/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py:817: # note that the input embeddings must be passed as an argument
- .venv/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py:823: )  # original used MaskedLayerNorm, but passed no mask. This is equivalent.
- .venv/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py:833: # note that the input embeddings must be passed as an argument
- .venv/lib/python3.12/site-packages/transformers/models/deberta/configuration_deberta.py:46: `inputs_ids` passed when calling [`DebertaModel`] or [`TFDebertaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deberta/configuration_deberta.py:67: The vocabulary size of the `token_type_ids` passed when calling [`DebertaModel`] or [`TFDebertaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deberta/tokenization_deberta_fast.py:49: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer, but since
- .venv/lib/python3.12/site-packages/transformers/models/deberta/tokenization_deberta.py:90: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/emu3/configuration_emu3.py:127: `inputs_ids` passed when calling [`Emu3Model`]
- .venv/lib/python3.12/site-packages/transformers/models/emu3/modular_emu3.py:46: pass
- .venv/lib/python3.12/site-packages/transformers/models/emu3/modular_emu3.py:124: pass
- .venv/lib/python3.12/site-packages/transformers/models/emu3/image_processing_emu3.py:327: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/timesfm/modular_timesfm.py:115: pass
- .venv/lib/python3.12/site-packages/transformers/models/segformer/modular_segformer.py:53: pass
- .venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer.py:291: passed in as positional arguments.
- .venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer.py:319: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer.py:443: # TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer.py:450: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/segformer/modeling_segformer.py:45: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/segformer/modeling_segformer.py:49: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer_fast.py:220: # TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer_fast.py:227: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/zamba/modeling_zamba.py:185: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/models/zamba/modeling_zamba.py:299: undergoes an independent forward pass, identical to the original `MambaMixer`, up until the pre-activations of
- .venv/lib/python3.12/site-packages/transformers/models/zamba/modeling_zamba.py:476: # In training mode, we don't want to perform in-place operations on ssm_state so we can compute the backwards pass
- .venv/lib/python3.12/site-packages/transformers/models/zamba/modeling_zamba.py:611: layer_idx (`int`): layer_idx in the forward pass. Used to distinguish Zamba's tied transformer layers.
- .venv/lib/python3.12/site-packages/transformers/models/zamba/modeling_zamba.py:1149: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/zamba/modeling_zamba.py:1172: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/zamba/modeling_zamba.py:1201: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/zamba/configuration_zamba.py:41: `inputs_ids` passed when calling [`ZambaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/processing_musicgen_melody.py:70: Remaining dictionary of keyword arguments that will be passed to the feature extractor and/or the
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/configuration_musicgen_melody.py:39: represented by the `inputs_ids` passed when calling [`MusicgenMelodyDecoder`].
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:78: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:241: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:477: target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)` in the forward pass. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:480: target_sequence_length)` to `(batch_size * num_codebooks, target_sequence_length)` prior to passing them as
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:529: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:623: # 2d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:647: # 4d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:664: pass
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:711: target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)` in the forward pass. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:714: target_sequence_length)` to `(batch_size * num_codebooks, target_sequence_length)` prior to passing them as
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:832: target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)` in the forward pass. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:835: target_sequence_length)` to `(batch_size * num_codebooks, target_sequence_length)` prior to passing them as
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1077: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1078: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1094: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1101: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1105: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1111: Streamer object that will be used to stream the generated sequences. Generated tokens are passed
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1190: # stash the delay mask so that we don't have to recompute it in each forward pass
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1420: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1565: "passed to `.from_sub_models_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1610: target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)` in the forward pass. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1613: target_sequence_length)` to `(batch_size * num_codebooks, target_sequence_length)` prior to passing them as
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1785: # Some generation methods already pass only the last input ID
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1822: # we also allow the user to pass it under `input_ids`, if the encoder does not use it as the main input.
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:1961: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:2041: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:2042: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:2058: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:2065: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:2069: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:2075: Streamer object that will be used to stream the generated sequences. Generated tokens are passed
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:2186: # stash the delay mask so that we don't have to recompute in each forward pass
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/feature_extraction_musicgen_melody.py:74: For Whisper models, `attention_mask` should always be passed for batched inference, to avoid subtle
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/feature_extraction_musicgen_melody.py:79: Stem channels to extract if demucs outputs are passed.
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/feature_extraction_musicgen_melody.py:175: wav, sampling_rate, self.sampling_rate, rolloff=0.945, lowpass_filter_width=24
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/feature_extraction_musicgen_melody.py:240: The sampling rate at which the `audio` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/feature_extraction_musicgen_melody.py:247: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/feature_extraction_musicgen_melody.py:261: audio, sampling_rate, self.sampling_rate, rolloff=0.945, lowpass_filter_width=24
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:88: start_logits (`torch.FloatTensor` of shape `(n_passages, sequence_length)`):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:89: Logits of the start index of the span for each passage.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:90: end_logits (`torch.FloatTensor` of shape `(n_passages, sequence_length)`):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:91: Logits of the end index of the span for each passage.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:92: relevance_logits (`torch.FloatTensor` of shape `(n_passages, )`):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:93: Outputs of the QA classifier of the DPRReader that corresponds to the scores of each passage to answer the
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:94: question, compared to all the other passages.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:201: # notations: N - number of questions in a batch, M - number of passages per questions, L - sequence length
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:202: n_passages, sequence_length = input_ids.size() if input_ids is not None else inputs_embeds.size()[:2]
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:222: start_logits = start_logits.view(n_passages, sequence_length)
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:223: end_logits = end_logits.view(n_passages, sequence_length)
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:224: relevance_logits = relevance_logits.view(n_passages)
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:516: input_ids (`tuple[torch.LongTensor]` of shapes `(n_passages, sequence_length)`):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:518: and 2) the passages titles and 3) the passages texts To match pretraining, DPR `input_ids` sequence should
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:529: inputs_embeds (`torch.FloatTensor` of shape `(n_passages, sequence_length, hidden_size)`, *optional*):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_dpr.py:530: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:65: It converts the strings of a question and different passages (title and text) in a sequence of IDs (integers),
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:66: using the tokenizer and vocabulary. The resulting `input_ids` is a matrix of size `(n_passages, sequence_length)`
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:75: The questions to be encoded. You can specify one question for many passages. In this case, the question
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:76: will be duplicated like `[questions] * n_passages`. Otherwise you have to specify as many questions as in
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:79: The passages titles to be encoded. This can be a string or a list of strings if there are several passages.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:81: The passages texts to be encoded. This can be a string or a list of strings if there are several passages.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:170: n_passages = len(titles)
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:171: questions = questions if not isinstance(questions, str) else [questions] * n_passages
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:199: num_spans_per_passage: int = 4,
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:208: spans in the same passage. It corresponds to the sum of the start and end logits of the span.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:209: - **relevance_score**: `float` that corresponds to the score of the each passage to answer the question,
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:210: compared to all the other passages. It corresponds to the output of the QA classifier of the DPRReader.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:211: - **doc_id**: `int` the id of the passage. - **start_index**: `int` the start index of the span
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:234: n_passages = len(relevance_logits)
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:235: sorted_docs = sorted(range(n_passages), reverse=True, key=relevance_logits.__getitem__)
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:240: passage_offset = sequence_ids.index(self.sep_token_id, 2) + 1  # second sep id
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:247: start_logits=start_logits[doc_id][passage_offset:sequence_len],
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:248: end_logits=end_logits[doc_id][passage_offset:sequence_len],
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:250: top_spans=num_spans_per_passage,
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:253: start_index += passage_offset
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:254: end_index += passage_offset
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr.py:277: Finds the best answer span for the extractive Q&A model for one passage. It returns the best span by descending
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:68: It converts the strings of a question and different passages (title and text) in a sequence of IDs (integers),
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:69: using the tokenizer and vocabulary. The resulting `input_ids` is a matrix of size `(n_passages, sequence_length)`
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:76: The questions to be encoded. You can specify one question for many passages. In this case, the question
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:77: will be duplicated like `[questions] * n_passages`. Otherwise you have to specify as many questions as in
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:80: The passages titles to be encoded. This can be a string or a list of strings if there are several passages.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:82: The passages texts to be encoded. This can be a string or a list of strings if there are several passages.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:171: n_passages = len(titles)
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:172: questions = questions if not isinstance(questions, str) else [questions] * n_passages
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:199: num_spans_per_passage: int = 4,
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:208: spans in the same passage. It corresponds to the sum of the start and end logits of the span.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:209: - **relevance_score**: `float` that corresponds to the score of the each passage to answer the question,
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:210: compared to all the other passages. It corresponds to the output of the QA classifier of the DPRReader.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:211: - **doc_id**: `int` the id of the passage. - ***start_index**: `int` the start index of the span
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:234: n_passages = len(relevance_logits)
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:235: sorted_docs = sorted(range(n_passages), reverse=True, key=relevance_logits.__getitem__)
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:240: passage_offset = sequence_ids.index(self.sep_token_id, 2) + 1  # second sep id
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:247: start_logits=start_logits[doc_id][passage_offset:sequence_len],
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:248: end_logits=end_logits[doc_id][passage_offset:sequence_len],
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:250: top_spans=num_spans_per_passage,
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:253: start_index += passage_offset
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:254: end_index += passage_offset
- .venv/lib/python3.12/site-packages/transformers/models/dpr/tokenization_dpr_fast.py:277: Finds the best answer span for the extractive Q&A model for one passage. It returns the best span by descending
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:57: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:62: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:85: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:90: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:109: start_logits (`tf.Tensor` of shape `(n_passages, sequence_length)`):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:110: Logits of the start index of the span for each passage.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:111: end_logits (`tf.Tensor` of shape `(n_passages, sequence_length)`):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:112: Logits of the end index of the span for each passage.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:113: relevance_logits (`tf.Tensor` of shape `(n_passages, )`):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:114: Outputs of the QA classifier of the DPRReader that corresponds to the scores of each passage to answer the
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:115: question, compared to all the other passages.
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:116: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:121: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:236: # notations: N - number of questions in a batch, M - number of passages per questions, L - sequence length
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:237: n_passages, sequence_length = shape_list(input_ids) if input_ids is not None else shape_list(inputs_embeds)[:2]
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:258: start_logits = tf.reshape(start_logits, [n_passages, sequence_length])
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:259: end_logits = tf.reshape(end_logits, [n_passages, sequence_length])
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:260: relevance_logits = tf.reshape(relevance_logits, [n_passages])
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:409: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:411: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:424: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:477: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:498: input_ids (`Numpy array` or `tf.Tensor` of shapes `(n_passages, sequence_length)`):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:500: and 2) the passages titles and 3) the passages texts To match pretraining, DPR `input_ids` sequence should
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:509: attention_mask (`Numpy array` or `tf.Tensor` of shape `(n_passages, sequence_length)`, *optional*):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:516: inputs_embeds (`Numpy array` or `tf.Tensor` of shape `(n_passages, sequence_length, hidden_size)`, *optional*):
- .venv/lib/python3.12/site-packages/transformers/models/dpr/modeling_tf_dpr.py:517: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/dpr/configuration_dpr.py:40: passed to the forward method of [`BertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/dpr/configuration_dpr.py:60: The vocabulary size of the *token_type_ids* passed into [`BertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2.py:196: passed in as positional arguments.
- .venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2.py:348: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2.py:495: # TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2.py:502: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2_fast.py:227: # TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2_fast.py:234: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/modeling_mobilenet_v2.py:510: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/prompt_depth_anything/image_processing_prompt_depth_anything.py:305: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/prompt_depth_anything/image_processing_prompt_depth_anything.py:489: "Make sure that you pass in as many target sizes as the batch dimension of the predicted depth"
- .venv/lib/python3.12/site-packages/transformers/models/prompt_depth_anything/configuration_prompt_depth_anything.py:55: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/prompt_depth_anything/modeling_prompt_depth_anything.py:443: raise NotImplementedError("Training is not implemented yet")
- .venv/lib/python3.12/site-packages/transformers/models/prompt_depth_anything/modular_prompt_depth_anything.py:191: pass
- .venv/lib/python3.12/site-packages/transformers/models/prompt_depth_anything/modular_prompt_depth_anything.py:286: raise NotImplementedError("Training is not implemented yet")
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py:154: past_key_values (`dict[str, jnp.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_value
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py:234: # variable has and can better optimize. Also passing `None` can lead to some problems when jitting the model.
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py:235: # In Flax/JAX, we only want to pass `None` for non-tensor function inputs. For all tensor function inputs, we
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py:236: # should always pass a tensor and not `None`.
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py:531: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py:544: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py:545: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py:752: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py:846: "passed to `.from_encoder_decoder_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:49: " labels, no need to pass them yourself anymore."
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:118: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:339: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:433: "passed to `.from_encoder_decoder_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:543: # Handle the case where the inputs are passed as a single dict which contains `labels`.
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:544: # The `labels` shouldn't be passed to `self.encoder` below, because it is a based model without this
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:661: "pixel_values": None,  # needs to be passed to make Keras.layer.__call__ happy
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:665: # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:676: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py:325: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py:423: "passed to `.from_encoder_decoder_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py:471: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/configuration_vision_encoder_decoder.py:91: f"not both `encoder` and `decoder` sub-configurations are passed, but only {kwargs}"
- .venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/configuration_vision_encoder_decoder.py:179: pass
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modeling_wavlm.py:158: # first pass of attention layer creates position bias
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modeling_wavlm.py:1150: passing `target_lang=...` to `from_pretrained(...)`.
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modeling_wavlm.py:1162: raise ValueError(f"Cannot pass `target_lang`: {target_lang} if `config.adapter_attn_dim` is not defined.")
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modular_wavlm.py:32: pass
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modular_wavlm.py:36: pass
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modular_wavlm.py:89: # first pass of attention layer creates position bias
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modular_wavlm.py:206: pass
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modular_wavlm.py:562: pass
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modular_wavlm.py:566: pass
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modular_wavlm.py:570: pass
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modular_wavlm.py:574: pass
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/modular_wavlm.py:578: pass
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/configuration_wavlm.py:41: `inputs_ids` passed when calling [`WavLMModel`]. Vocabulary size of the model. Defines the different tokens
- .venv/lib/python3.12/site-packages/transformers/models/wavlm/configuration_wavlm.py:42: that can be represented by the *inputs_ids* passed to the forward method of [`WavLMModel`].
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:162: # If q_pass/k_pass is empty, rotary pos embedding is applied to all tensor q/k
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:163: q, q_pass = q[..., :rot_dim], q[..., rot_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:164: k, k_pass = k[..., :rot_dim], k[..., rot_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:168: return torch.cat((q_embed, q_pass), dim=-1), torch.cat((k_embed, k_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:207: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:286: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:290: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:297: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:344: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:407: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:411: `NemotronAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:429: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:858: # TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->NEMOTRON,Llam
- .venv/lib/python3.12/site-packages/transformers/models/nemotron/configuration_nemotron.py:39: `inputs_ids` passed when calling [`NemotronModel`]
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:71: pass
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:75: pass
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:79: pass
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:83: pass
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:87: pass
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:91: pass
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:138: # 2d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:162: # 4d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:207: pass
- .venv/lib/python3.12/site-packages/transformers/models/informer/modular_informer.py:555: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:297: # 2d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:321: # 4d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:427: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:447: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:1030: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:1183: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:1195: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:1224: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/informer/modeling_informer.py:1634: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/hgnet_v2/configuration_hgnet_v2.py:27: # TODO: Modular conversion for resnet must be fixed as
- .venv/lib/python3.12/site-packages/transformers/models/hgnet_v2/modular_hgnet_v2.py:38: # TODO: Modular conversion for resnet must be fixed as
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:261: `inputs_ids` passed when calling [`Qwen2VLModel`]
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:588: `inputs_ids` passed when calling [`Qwen2VLModel`]
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:1548: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:1628: cu_seq_lens_q=cu_seqlens,  # pass cu seq lens for FA2
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:2071: f"Instantiating {self.__class__.__name__} without passing `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:2096: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:2503: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:3410: Forward pass of the function.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:4083: # TODO: raushan, defaults should be saved in generation config
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py:4132: raise NotImplementedError("Qwen2.5-Omni currently does not support batched inference with audio output")
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/configuration_qwen2_5_omni.py:226: `inputs_ids` passed when calling [`Qwen2VLModel`]
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/configuration_qwen2_5_omni.py:553: `inputs_ids` passed when calling [`Qwen2VLModel`]
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:493: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:611: cu_seq_lens_q=cu_seqlens,  # pass cu seq lens for FA2
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:1287: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:1325: f"Instantiating {self.__class__.__name__} without passing `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:1393: position_ids=position_ids,  # pass positions for FA2
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:1575: # NOTE: we need to pass text position ids for packing. Qwen2-VL uses 3D positions
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:1578: # 1. User specifically passed packed `position_ids` and no attention mask.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:1583: #    prepended by us when creating positions so that the mask is constructed correctly. NOTE: failing to pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:2054: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:2150: # NOTE: we need to pass text position ids for packing. Qwen2-VL uses 3D positions
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:2153: # 1. User specifically passed packed `position_ids` and no attention mask.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:2158: #    prepended by us when creating positions so that the mask is constructed correctly. NOTE: failing to pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:3109: Forward pass of the function.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:3782: # TODO: raushan, defaults should be saved in generation config
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py:3831: raise NotImplementedError("Qwen2.5-Omni currently does not support batched inference with audio output")
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:77: Python's tokenizer, this method will raise `NotImplementedError`.
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:82: **kwargs: passed to the `self.tokenize()` method
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:198: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:346: # TODO check if the t5/llama PR also applies here
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:565: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:574: raise NotImplementedError("is_split_into_words is not supported in this tokenizer.")
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:649: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:656: raise NotImplementedError("is_split_into_words is not supported in this tokenizer.")
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:1243: `self.padding_side`, `self.pad_token_id` and `self.pad_token_type_id`) .. note:: If the `encoded_inputs` passed
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:1293: # The model's main input name, usually `input_ids`, has be passed for padding
- .venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:1619: Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLM-RoBERTa does
- .venv/lib/python3.12/site-packages/transformers/models/timm_wrapper/configuration_timm_wrapper.py:49: Additional keyword arguments to pass to the `timm.create_model` function. e.g. `model_args={"depth": 3}`
- .venv/lib/python3.12/site-packages/transformers/models/timm_wrapper/configuration_timm_wrapper.py:108: # passed num_labels has priority over num_classes in config_dict
- .venv/lib/python3.12/site-packages/transformers/models/timm_wrapper/image_processing_timm_wrapper.py:118: # Otherwise, we need to pass in a list of PIL images
- .venv/lib/python3.12/site-packages/transformers/models/timm_wrapper/modeling_timm_wrapper.py:66: # used in Trainer to avoid passing `loss_kwargs` to model forward
- .venv/lib/python3.12/site-packages/transformers/models/timm_wrapper/modeling_timm_wrapper.py:161: Whether to do pooling for the last_hidden_state in `TimmWrapperModel` or not. If `None` is passed, the
- .venv/lib/python3.12/site-packages/transformers/models/timm_wrapper/modeling_timm_wrapper.py:184: >>> # Forward pass
- .venv/lib/python3.12/site-packages/transformers/models/timm_wrapper/modeling_timm_wrapper.py:286: Additional keyword arguments passed along to the `timm` model forward.
- .venv/lib/python3.12/site-packages/transformers/models/timm_wrapper/modeling_timm_wrapper.py:308: >>> # Forward pass
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/tokenization_layoutlm.py:443: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py:363: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py:518: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py:813: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py:881: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py:889: # Need to pass these required positional arguments to `Encoder`
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py:965: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py:967: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py:980: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py:1029: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/configuration_layoutlm.py:44: *inputs_ids* passed to the forward method of [`LayoutLMModel`].
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/configuration_layoutlm.py:64: The vocabulary size of the `token_type_ids` passed into [`LayoutLMModel`].
- .venv/lib/python3.12/site-packages/transformers/models/layoutlm/configuration_layoutlm.py:202: raise NotImplementedError("Exporting LayoutLM to ONNX is currently only supported for PyTorch.")
- .venv/lib/python3.12/site-packages/transformers/models/mbart50/tokenization_mbart50.py:70: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/levit/image_processing_levit.py:201: from 0 to 255. If passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/levit/modeling_levit.py:86: LeViT patch embeddings, for final embeddings to be passed to transformer blocks. It consists of multiple
- .venv/lib/python3.12/site-packages/transformers/models/textnet/image_processing_textnet.py:175: The value to be passed to `get_size_dict` as `default_to_square` when computing the image size. If the
- .venv/lib/python3.12/site-packages/transformers/models/textnet/image_processing_textnet.py:229: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/modeling_zamba2.py:186: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/modeling_zamba2.py:1572: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/modeling_zamba2.py:1595: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/modeling_zamba2.py:1624: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/modular_zamba2.py:96: pass
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/modular_zamba2.py:162: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/modular_zamba2.py:171: pass
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/modular_zamba2.py:1143: pass
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/modular_zamba2.py:1147: pass
- .venv/lib/python3.12/site-packages/transformers/models/zamba2/configuration_zamba2.py:39: `inputs_ids` passed when calling [`Zamba2Model`]
- .venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:270: # TODO: maybe jit, otherwise move inside forward
- .venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:550: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:558: If passed along, the model uses the previous state in all the blocks (which will give the output for the
- .venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:571: logger.warning_once("`attention_mask` was passed, but it is unused in this model.")
- .venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:710: # only last token for inputs_ids if the state is passed along.
- .venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:714: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:744: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:752: If passed along, the model uses the previous state in all the blocks (which will give the output for the
- .venv/lib/python3.12/site-packages/transformers/models/rwkv/configuration_rwkv.py:39: `inputs_ids` passed when calling [`RwkvModel`].
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:86: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:88: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:101: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:157: The dictionary object will be modified in-place during the forward pass to add newly computed
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:166: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:319: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:619: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:753: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:797: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py:802: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/tokenization_flaubert.py:208: "`do_lowercase_and_remove_accent` is passed as a keyword argument, but this won't do anything."
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/tokenization_flaubert.py:378: def _tokenize(self, text, bypass_tokenizer=False):
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/tokenization_flaubert.py:388: - bypass_tokenizer: Allow users to preprocess and tokenize the sentences externally (default = False)
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/tokenization_flaubert.py:401: if bypass_tokenizer:
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_flaubert.py:610: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_flaubert.py:665: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_flaubert.py:725: raise NotImplementedError("Currently Flaubert can only be used as an encoder")
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_flaubert.py:841: decoding. The dictionary object will be modified in-place during the forward pass to add newly computed
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_flaubert.py:886: # when tracing the model without passing position-ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_flaubert.py:1059: decoding. The dictionary object will be modified in-place during the forward pass to add newly computed
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/modeling_flaubert.py:1626: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/flaubert/configuration_flaubert.py:47: the `inputs_ids` passed when calling [`FlaubertModel`] or [`TFFlaubertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/squeezebert/modeling_squeezebert.py:752: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/squeezebert/tokenization_squeezebert.py:442: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/squeezebert/configuration_squeezebert.py:42: the `inputs_ids` passed when calling [`SqueezeBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/squeezebert/configuration_squeezebert.py:62: The vocabulary size of the `token_type_ids` passed when calling [`BertModel`] or [`TFBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:158: the cos_sin_cache will be recomputed during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:642: pass
- .venv/lib/python3.12/site-packages/transformers/models/modernbert/configuration_modernbert.py:40: `inputs_ids` passed when calling [`ModernBertModel`]
- .venv/lib/python3.12/site-packages/transformers/models/modernbert/configuration_modernbert.py:114: applies when using Flash Attention 2 with passed labels. Otherwise output logits always have a gradient.
- .venv/lib/python3.12/site-packages/transformers/models/modernbert/modular_modernbert.py:69: `inputs_ids` passed when calling [`ModernBertModel`]
- .venv/lib/python3.12/site-packages/transformers/models/modernbert/modular_modernbert.py:143: applies when using Flash Attention 2 with passed labels. Otherwise output logits always have a gradient.
- .venv/lib/python3.12/site-packages/transformers/models/modernbert/modular_modernbert.py:422: the cos_sin_cache will be recomputed during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/modernbert/modular_modernbert.py:510: pass
- .venv/lib/python3.12/site-packages/transformers/models/modernbert/modular_modernbert.py:840: pass
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:746: vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:750: text_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when 
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:1160: # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:1190: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:1207: Flattened text features that are passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:1440: - `position_embeddings`, `reference_points`, `spatial_shapes` and `valid_ratios` are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:1486: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:1691: encoder_vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passe
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:1695: encoder_text_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed 
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:1699: encoder_attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:2103: # If the user passed a tuple for encoder_outputs, we wrap it in a MMGroundingDinoEncoderOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:2271: encoder_vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passe
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py:2275: encoder_text_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed 
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/configuration_mm_grounding_dino.py:54: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modular_mm_grounding_dino.py:66: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modular_mm_grounding_dino.py:323: pass
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modular_mm_grounding_dino.py:327: pass
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modular_mm_grounding_dino.py:331: pass
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modular_mm_grounding_dino.py:335: pass
- .venv/lib/python3.12/site-packages/transformers/models/mm_grounding_dino/modular_mm_grounding_dino.py:391: pass
- .venv/lib/python3.12/site-packages/transformers/models/hiera/modeling_hiera.py:52: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/hiera/modeling_hiera.py:74: pooler_output (`torch.FloatTensor` of shape `(batch_size, hidden_size)`, *optional*, returned when `add_pooling_layer=Tr
- .venv/lib/python3.12/site-packages/transformers/models/hiera/modeling_hiera.py:80: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/hiera/modeling_hiera.py:151: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/mvp/modeling_mvp.py:600: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mvp/modeling_mvp.py:804: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/mvp/modeling_mvp.py:816: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mvp/modeling_mvp.py:867: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/mvp/modeling_mvp.py:1053: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/mvp/modeling_mvp.py:1078: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/mvp/modeling_mvp.py:1407: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/mvp/tokenization_mvp_fast.py:54: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/mvp/tokenization_mvp_fast.py:254: Create a mask from the two sequences passed to be used in a sequence-pair classification task. MVP does not
- .venv/lib/python3.12/site-packages/transformers/models/mvp/tokenization_mvp.py:92: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/mvp/tokenization_mvp.py:368: Create a mask from the two sequences passed to be used in a sequence-pair classification task. MVP does not
- .venv/lib/python3.12/site-packages/transformers/models/mvp/configuration_mvp.py:40: `inputs_ids` passed when calling [`MvpModel`].
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/processing_samhq.py:252: are, it converts the coordinates of the points and bounding boxes. If a user passes directly a `torch.Tensor`,
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:79: The attention weights from the mask decoder, if `output_attentions=True` was passed during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:100: vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:105: vision_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:111: mask_decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:572: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:1279: Returns the image embeddings by passing the pixel values through the vision encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:1299: Returns the prompt embeddings by passing the input points, labels, boxes and masks through the prompt encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:1311: processor. users can also pass manually the input boxes.
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:1343: better results. The points can be obtained by passing a list of list of list to the processor that will
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:1346: per input point), the third dimension is the number of points per segmentation mask (it is possible to pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:1348: coordinates of the point. If a different number of points is passed either for each image, or for each
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modeling_sam_hq.py:1366: much better generated masks. The boxes can be obtained by passing a list of list of list to the processor,
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:71: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:75: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:143: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:167: The attention weights from the mask decoder, if `output_attentions=True` was passed during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:177: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:181: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:185: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:189: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:227: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:231: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:235: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:440: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:466: Returns the image embeddings by passing the pixel values through the vision encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:495: better results. The points can be obtained by passing a list of list of list to the processor that will
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:498: per input point), the third dimension is the number of points per segmentation mask (it is possible to pass
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:500: coordinates of the point. If a different number of points is passed either for each image, or for each
- .venv/lib/python3.12/site-packages/transformers/models/sam_hq/modular_sam_hq.py:518: much better generated masks. The boxes can be obtained by passing a list of list of list to the processor,
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_flax_whisper.py:181: past_key_values (`dict[str, numpy.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_val
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_flax_whisper.py:1074: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_flax_whisper.py:1093: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_flax_whisper.py:1094: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_flax_whisper.py:1325: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_flax_whisper.py:1343: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_flax_whisper.py:1344: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:277: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:298: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:820: in the cross-attention blocks (2). The `past_key_values` are returned when `use_cache=True` is passed or
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:833: shape `(batch_size, sequence_length, hidden_size)`, *optional*): Optionally, instead of passing
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:834: `input_ids` you can choose to directly pass an embedded representation. This is useful if you want more
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:1133: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:1464: # If the user passed a tuple or `BaseModelOutput` for encoder_outputs, we extract only the hidden states
- .venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper_fast.py:358: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper_fast.py:590: """Converts prompt text to IDs that can be passed to [`~WhisperForConditionalGeneration.generate`]."""
- .venv/lib/python3.12/site-packages/transformers/models/whisper/configuration_whisper.py:74: `decoder_input_ids` passed when calling [`WhisperModel`]
- .venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:721: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:866: """Converts prompt text to IDs that can be passed to [`~WhisperForConditionalGeneration.generate`]."""
- .venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:1013: # TODO Handle when language is different from the previous
- .venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:1030: pass
- .venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:1072: pass
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:278: # The first forward pass (prefill) may have processed more than one token and, therefore, contain
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:421: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:422: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:440: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:447: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:451: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:470: batched generation, a list of language tokens can be passed. You can find all the possible language
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:475: Rank-1 tensor of token IDs created by passing text to [`~WhisperProcessor.get_prompt_ids`] that is
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:488: generation using sampling. For long-form transcription, temperature fallback can be activated by passing
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:517: `attention_mask` needs to be passed when doing long-form transcription using a batch size > 1.
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:571: - *Longform transcription*: To transcribe or translate audios longer than 30 seconds, process the audio files without tr
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:600: " Folks, if you watch the show, you know, I spent a lot of time right over there. Patiently and astutely scrutinizing th
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:624: " Folks, if you watch the show, you know, I spent a lot of time right over there. Patiently and astutely scrutinizing th
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:627: - *Shortform transcription*: If passed mel input features are <= 30 seconds, there are two possibilities:
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:703: # pass self.config for backward compatibility
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:712: # passing `decoder_input_ids` is deprecated - the only exception is for assisted generation
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:958: "You have passed `return_dict_in_generate=True` and `return_timestamps=True`, this automatically sets `return_segments=T
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1150: # remove all previously passed decoder input ids
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1403: "You have passed more than 3000 mel input features (> 30 seconds) which automatically "
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1405: "either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features."
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1446: "multilingual, pass `is_multilingual=True` to generate, or update the generation config."
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1523: "use case. If you want to instead always translate your audio to English, make sure to pass "
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1553: "When passing a list of languages, the length of the list must match the batch size. "
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1617: # let's make sure we don't pass `None` tokens as prompt tokens
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1645: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1693: "Passing `decoder_input_ids` is deprecated. Consider passing `prompt_ids` instead.",
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1721: "When setting `return_token_timestamps` to `True`, make sure to pass an `attention_mask` to get precise token-level time
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1786: "When doing batched long-form audio transcription, make sure to pass an `attention_mask`. You can retrieve the `attentio
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1935: # make sure `"decoder_attention_mask"` is not passed to forward
- .venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:1938: # make sure `"decoder_attention_mask"` is not passed to forward
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:648: past_key_values (`tuple(tuple(tf.Tensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:660: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:942: past_key_values (`tuple(tuple(tf.Tensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:954: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1167: # If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1486: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1487: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1503: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1510: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1526: Rank-1 tensor of token IDs created by passing text to [`~WhisperProcessor.get_prompt_ids`] that is
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1665: # TODO: Implement `WhisperTimeStampLogitsProcessor`.
- .venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1736: "input_features": None,  # Needs to be passed to make Keras.layer.__call__ happy
- .venv/lib/python3.12/site-packages/transformers/models/whisper/feature_extraction_whisper.py:231: For Whisper models, `attention_mask` should always be passed for batched inference, to avoid subtle
- .venv/lib/python3.12/site-packages/transformers/models/whisper/feature_extraction_whisper.py:243: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/whisper/feature_extraction_whisper.py:269: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/shieldgemma2/processing_shieldgemma2.py:111: *   `custom_policies`: Additional policy definitions that augment the `self.policy_definitions` passed
- .venv/lib/python3.12/site-packages/transformers/models/shieldgemma2/processing_shieldgemma2.py:153: # TODO(ryanmullins): Support images from PIL or URLs.
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:245: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:265: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:815: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:1002: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:1014: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:1063: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:1268: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/configuration_m2m_100.py:45: `inputs_ids` passed when calling [`M2M100Model`] or
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/configuration_m2m_100.py:275: # TODO: test this.
- .venv/lib/python3.12/site-packages/transformers/models/m2m_100/tokenization_m2m_100.py:80: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/video_llava/modeling_video_llava.py:47: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/video_llava/modeling_video_llava.py:81: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/video_llava/modeling_video_llava.py:658: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/video_llava/image_processing_video_llava.py:197: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/video_llava/image_processing_video_llava.py:200: passing in videos with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/llama/tokenization_llama.py:75: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/llama/tokenization_llama.py:385: Creates a mask from the two sequences passed to be used in a sequence-pair classification task. An ALBERT
- .venv/lib/python3.12/site-packages/transformers/models/llama/configuration_llama.py:40: `inputs_ids` passed when calling [`LlamaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/llama/modeling_flax_llama.py:117: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/llama/modeling_flax_llama.py:488: raise ValueError("Make sure to provide `position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/llama/modeling_flax_llama.py:502: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed down to ens
- .venv/lib/python3.12/site-packages/transformers/models/llama/tokenization_llama_fast.py:237: # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modular_gpt_neox.py:68: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modular_gpt_neox.py:69: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modular_gpt_neox.py:76: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modular_gpt_neox.py:77: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modular_gpt_neox.py:242: pass
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modular_gpt_neox.py:309: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modular_gpt_neox.py:495: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/tokenization_gpt_neox_fast.py:49: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer, but since
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/configuration_gpt_neox.py:39: `inputs_ids` passed when calling [`GPTNeoXModel`].
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:84: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:85: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:92: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:93: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:431: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:623: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/mllama/configuration_mllama.py:155: by the `inputs_ids` passed when calling [`MllamaTextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:342: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:1199: the forward pass of cross-attention layers.
- .venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:1337: the forward pass of cross-attention layers.
- .venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:181: The preferred way of passing kwargs is as a dictionary per modality, see usage example below.
- .venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:261: TODO: add aspect_ratio_ids and aspect_ratio_mask and cross_attention_mask
- .venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:312: add_message = "Make sure to pass your images as a nested list, where each sub-list holds images per batch"
- .venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:355: Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:357: Whether or not to clean up the tokenization spaces. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:359: Additional arguments to be passed to the tokenizer's `batch_decode method`.
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:156: pass
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:333: passage_embeddings: Union["torch.Tensor", list["torch.Tensor"]],
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:340: query embeddings (`qs`) and passage embeddings (`ps`). For ColQwen2, a passage is the
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:346: (2) a single tensor of shape (n_passages, max_sequence_length, embedding_dim) -> usually
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:351: passage_embeddings (`Union[torch.Tensor, list[torch.Tensor]`): Passage embeddings.
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:358: `torch.Tensor`: A tensor of shape `(n_queries, n_passages)` containing the scores. The score
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:364: if len(passage_embeddings) == 0:
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:365: raise ValueError("No passages provided")
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:367: if query_embeddings[0].device != passage_embeddings[0].device:
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:368: raise ValueError("Queries and passages must be on the same device")
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:370: if query_embeddings[0].dtype != passage_embeddings[0].dtype:
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:371: raise ValueError("Queries and passages must have the same dtype")
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:383: for j in range(0, len(passage_embeddings), batch_size):
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:384: batch_passages = torch.nn.utils.rnn.pad_sequence(
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:385: passage_embeddings[j : j + batch_size], batch_first=True, padding_value=0
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/processing_colqwen2.py:388: torch.einsum("bnd,csd->bcns", batch_queries, batch_passages).max(dim=3)[0].sum(dim=2)
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/modeling_colqwen2.py:77: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/modular_colqwen2.py:156: pass
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/modular_colqwen2.py:266: pass
- .venv/lib/python3.12/site-packages/transformers/models/colqwen2/modular_colqwen2.py:281: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/helium/configuration_helium.py:31: `inputs_ids` passed when calling [`HeliumModel`]
- .venv/lib/python3.12/site-packages/transformers/models/helium/modular_helium.py:51: pass
- .venv/lib/python3.12/site-packages/transformers/models/helium/modular_helium.py:55: pass
- .venv/lib/python3.12/site-packages/transformers/models/helium/modular_helium.py:115: pass
- .venv/lib/python3.12/site-packages/transformers/models/helium/modular_helium.py:133: pass
- .venv/lib/python3.12/site-packages/transformers/models/helium/modular_helium.py:137: pass
- .venv/lib/python3.12/site-packages/transformers/models/helium/modular_helium.py:141: pass
- .venv/lib/python3.12/site-packages/transformers/models/helium/modeling_helium.py:484: pass
- .venv/lib/python3.12/site-packages/transformers/models/helium/modeling_helium.py:488: pass
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py:221: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py:1284: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/albert/tokenization_albert.py:90: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/albert/configuration_albert.py:38: `inputs_ids` passed when calling [`AlbertModel`] or [`TFAlbertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/albert/configuration_albert.py:64: The vocabulary size of the `token_type_ids` passed when calling [`AlbertModel`] or [`TFAlbertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_tf_albert.py:620: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_tf_albert.py:682: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_tf_albert.py:738: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_tf_albert.py:743: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_tf_albert.py:775: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_tf_albert.py:777: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_tf_albert.py:790: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_tf_albert.py:836: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_flax_albert.py:65: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_flax_albert.py:70: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_flax_albert.py:574: # init input tensors if not passed
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_flax_albert.py:634: # make sure `token_type_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/albert/modeling_flax_albert.py:638: # make sure `position_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/processing_qwen2_vl.py:238: Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/processing_qwen2_vl.py:240: Whether or not to clean up the tokenization spaces. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/processing_qwen2_vl.py:242: Additional arguments to be passed to the tokenizer's `batch_decode method`.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/video_processing_qwen2_vl.py:147: If `fps` is passed along with metadata, `fps` frames per second are sampled uniformty. Arguments `num_frames`
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/video_processing_qwen2_vl.py:185: "Please pass in `VideoMetadata` object or use a fixed `num_frames` per input video"
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/configuration_qwen2_vl.py:72: `inputs_ids` passed when calling [`Qwen2VLModel`]
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/configuration_qwen2_vl.py:250: # TODO: @raushan update config in the hub
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/image_processing_qwen2_vl.py:326: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/image_processing_qwen2_vl.py:329: passing in videos with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:66: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:95: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:178: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:476: f"Instantiating {self.__class__.__name__} without passing `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:549: position_ids=position_ids,  # pass positions for FA2
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:827: # NOTE: we need to pass text position ids for packing. Qwen2-VL uses 3D positions
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:830: # 1. User specifically passed packed `position_ids` and no attention mask.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:835: #    prepended by us when creating positions so that the mask is constructed correctly. NOTE: failing to pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:1487: These parameters are not passed through the processor to avoid unpredictable impacts from interface modifications.
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:184: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:191: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:455: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:469: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:470: "Training is not implemented yet for Bark - ensure you do not pass `labels` to the model."
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:479: # of Bark which concatenate two bits of the input_embeds on the first forward pass of the semantic model
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:480: pass
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:484: pass
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:506: "You should pass an instance of `DynamicCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:680: # pass input_ids in order to stay consistent with the transformers generate method even though it is not used
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1091: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. If
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1104: raise NotImplementedError("Training is not implemented yet")
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1429: # this layer is used outside the first forward pass of semantic so need to be loaded before semantic
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1506: >>> # To add a voice preset, you can pass `voice_preset` to `BarkProcessor.__call__(...)`
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1515: # TODO (joao):workaround until nested generation config is compatible with PreTrained Model
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1522: # if "attention_mask" is set, it should not be passed to CoarseModel and FineModel
- .venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1593: # since bark doesn't use codec_model forward pass
- .venv/lib/python3.12/site-packages/transformers/models/bark/configuration_bark.py:42: `inputs_ids` passed when calling [`{model}`]. Defaults to 10_048 but should be carefully thought with
- .venv/lib/python3.12/site-packages/transformers/models/bark/configuration_bark.py:46: by the: `output_ids` when passing forward a [`{model}`]. Defaults to 10_048 but should be carefully thought
- .venv/lib/python3.12/site-packages/transformers/models/bark/processing_bark.py:85: Additional keyword arguments passed along to both
- .venv/lib/python3.12/site-packages/transformers/models/bark/processing_bark.py:148: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/models/bark/generation_configuration_bark.py:238: pass
- .venv/lib/python3.12/site-packages/transformers/models/bark/generation_configuration_bark.py:244: # TODO (joao): nested from_dict
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:281: passage_embeddings: Union["torch.Tensor", list["torch.Tensor"]],
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:288: query embeddings (`qs`) and passage embeddings (`ps`). For ColPali, a passage is the
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:294: (2) a single tensor of shape (n_passages, max_sequence_length, embedding_dim) -> usually
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:299: passage_embeddings (`Union[torch.Tensor, list[torch.Tensor]`): Passage embeddings.
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:306: `torch.Tensor`: A tensor of shape `(n_queries, n_passages)` containing the scores. The score
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:312: if len(passage_embeddings) == 0:
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:313: raise ValueError("No passages provided")
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:315: if query_embeddings[0].device != passage_embeddings[0].device:
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:316: raise ValueError("Queries and passages must be on the same device")
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:318: if query_embeddings[0].dtype != passage_embeddings[0].dtype:
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:319: raise ValueError("Queries and passages must have the same dtype")
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:331: for j in range(0, len(passage_embeddings), batch_size):
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:332: batch_passages = torch.nn.utils.rnn.pad_sequence(
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:333: passage_embeddings[j : j + batch_size], batch_first=True, padding_value=0
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modular_colpali.py:336: torch.einsum("bnd,csd->bcns", batch_queries, batch_passages).max(dim=3)[0].sum(dim=2)
- .venv/lib/python3.12/site-packages/transformers/models/colpali/modeling_colpali.py:69: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:352: passage_embeddings: Union["torch.Tensor", list["torch.Tensor"]],
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:359: query embeddings (`qs`) and passage embeddings (`ps`). For ColPali, a passage is the
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:365: (2) a single tensor of shape (n_passages, max_sequence_length, embedding_dim) -> usually
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:370: passage_embeddings (`Union[torch.Tensor, list[torch.Tensor]`): Passage embeddings.
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:377: `torch.Tensor`: A tensor of shape `(n_queries, n_passages)` containing the scores. The score
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:383: if len(passage_embeddings) == 0:
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:384: raise ValueError("No passages provided")
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:386: if query_embeddings[0].device != passage_embeddings[0].device:
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:387: raise ValueError("Queries and passages must be on the same device")
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:389: if query_embeddings[0].dtype != passage_embeddings[0].dtype:
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:390: raise ValueError("Queries and passages must have the same dtype")
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:402: for j in range(0, len(passage_embeddings), batch_size):
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:403: batch_passages = torch.nn.utils.rnn.pad_sequence(
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:404: passage_embeddings[j : j + batch_size], batch_first=True, padding_value=0
- .venv/lib/python3.12/site-packages/transformers/models/colpali/processing_colpali.py:407: torch.einsum("bnd,csd->bcns", batch_queries, batch_passages).max(dim=3)[0].sum(dim=2)
- .venv/lib/python3.12/site-packages/transformers/models/colpali/configuration_colpali.py:37: use a different VLM backbone model than PaliGemma by passing the corresponding VLM configuration to the class constructo
- .venv/lib/python3.12/site-packages/transformers/models/tapas/tokenization_tapas.py:693: raise NotImplementedError("Currently TapasTokenizer only supports questions as strings.")
- .venv/lib/python3.12/site-packages/transformers/models/tapas/tokenization_tapas.py:696: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/tapas/tokenization_tapas.py:969: raise NotImplementedError("Currently TapasTokenizer only supports questions as strings.")
- .venv/lib/python3.12/site-packages/transformers/models/tapas/tokenization_tapas.py:972: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/tapas/tokenization_tapas.py:1027: "TAPAS is a question answering model but you have not passed a query. Please be aware that the "
- .venv/lib/python3.12/site-packages/transformers/models/tapas/tokenization_tapas.py:1924: # Any value over 88.72284 will overflow when passed through the exponential, sending a warning
- .venv/lib/python3.12/site-packages/transformers/models/tapas/tokenization_tapas.py:2170: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/tapas/tokenization_tapas.py:2280: # Pairs of patterns to pass to 'datetime.strptime' and masks specifying which
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tapas.py:529: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tapas.py:585: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tapas.py:1271: pass
- .venv/lib/python3.12/site-packages/transformers/models/tapas/configuration_tapas.py:44: `inputs_ids` passed when calling [`TapasModel`].
- .venv/lib/python3.12/site-packages/transformers/models/tapas/configuration_tapas.py:64: The vocabulary sizes of the `token_type_ids` passed when calling [`TapasModel`].
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:79: pass
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:102: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:106: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:406: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:561: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:856: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:918: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:1002: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:1004: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:1017: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:1061: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/tapas/modeling_tf_tapas.py:1605: pass
- .venv/lib/python3.12/site-packages/transformers/models/nllb/tokenization_nllb.py:106: Additional keyword arguments to pass to the model initialization.
- .venv/lib/python3.12/site-packages/transformers/models/nllb/tokenization_nllb.py:276: Create a mask from the two sequences passed to be used in a sequence-pair classification task. nllb does not
- .venv/lib/python3.12/site-packages/transformers/models/nllb/tokenization_nllb_fast.py:211: Create a mask from the two sequences passed to be used in a sequence-pair classification task. nllb does not
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:938: passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it's missing, by
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:954: Will be passed along to the Tokenizer `__init__()` method.
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:987: Will be passed to the Tokenizer `__init__()` method. Can be used to set special tokens like
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1028: # First, let's see whether the tokenizer_type is passed so that we can leverage it
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1174: raise ValueError("You need to pass either a `slow_tokenizer_class` or a `fast_tokenizer_class")
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1176: raise ValueError("You passed a fast tokenizer in the `slow_tokenizer_class`.")
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1178: raise ValueError("You passed a slow tokenizer in the `fast_tokenizer_class`.")
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1187: "The fast tokenizer class you are passing has a `slow_tokenizer_class` attribute that is not "
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1188: "consistent with the slow tokenizer class you passed (fast tokenizer has "
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1189: f"{fast_tokenizer_class.slow_tokenizer_class} and you passed {slow_tokenizer_class}. Fix one of those "
- .venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1193: # Avoid resetting a set slow/fast tokenizer if we are passing just the other ones.
- .venv/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:38: pass
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:90: passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it's missing, by
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:110: Will be passed along to the underlying model `__init__()` method.
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:164: - If a configuration is provided with `config`, `**kwargs` will be directly passed to the
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:167: - If a configuration is not provided, `kwargs` will be first passed to the configuration class
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:171: will be passed to the underlying model's `__init__` function.
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:198: passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it's missing, by
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:215: Will be passed along to the underlying model `__init__()` method.
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:263: - If a configuration is provided with `config`, `**kwargs` will be directly passed to the
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:266: - If a configuration is not provided, `kwargs` will be first passed to the configuration class
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:270: will be passed to the underlying model's `__init__` function.
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:297: passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it's missing, by
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:314: Will be passed along to the underlying model `__init__()` method.
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:362: - If a configuration is provided with `config`, `**kwargs` will be directly passed to the
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:365: - If a configuration is not provided, `kwargs` will be first passed to the configuration class
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:369: will be passed to the underlying model's `__init__` function.
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:558: # if torch_dtype=auto was passed here, ensure to pass it on
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:625: "The model class you are passing has a `config_class` attribute that is not consistent with the "
- .venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:626: f"config class you passed (model has {model_class.config_class} and you passed {config_class}. Fix "
- .venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1346: "The config you are passing has a `model_type` attribute that is not consistent with the model type "
- .venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1347: f"you passed (config has {config.model_type} and you passed {model_type}. Fix one of those so they "
- .venv/lib/python3.12/site-packages/transformers/models/auto/processing_auto.py:204: passed as an argument or loaded from `pretrained_model_name_or_path` if possible):
- .venv/lib/python3.12/site-packages/transformers/models/auto/processing_auto.py:410: pass
- .venv/lib/python3.12/site-packages/transformers/models/auto/processing_auto.py:417: pass
- .venv/lib/python3.12/site-packages/transformers/models/auto/video_processing_auto.py:223: (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it's
- .venv/lib/python3.12/site-packages/transformers/models/auto/feature_extraction_auto.py:274: (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it's
- .venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:372: (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it's
- .venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:457: # TODO: @yoni, change in v4.48 (use_fast set to True by default)
- .venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:522: # TODO: @yoni, change logic in v4.52 (when use_fast set to True by default)
- .venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:655: raise ValueError("You passed a fast image processor in as the `slow_image_processor_class`.")
- .venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:668: "The fast processor class you are passing has a `slow_image_processor_class` attribute that is not "
- .venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:669: "consistent with the slow processor class you passed (fast tokenizer has "
- .venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:670: f"{fast_image_processor_class.slow_image_processor_class} and you passed {slow_image_processor_class}. Fix one of those 
- .venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:674: # Avoid resetting a set slow/fast image processor if we are passing just the other ones.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py:46: loss (*optional*, returned when `sample_negative_indices` are passed, `torch.FloatTensor` of shape `(1,)`):
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py:57: contrastive_loss (*optional*, returned when `sample_negative_indices` are passed, `torch.FloatTensor` of shape `(1,)`):
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py:59: diversity_loss (*optional*, returned when `sample_negative_indices` are passed, `torch.FloatTensor` of shape `(1,)`):
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py:1358: # if attention_mask is passed, make sure that padded feature vectors cannot be sampled
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:46: loss (*optional*, returned when `sample_negative_indices` are passed, `torch.FloatTensor` of shape `(1,)`):
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:57: contrastive_loss (*optional*, returned when `sample_negative_indices` are passed, `torch.FloatTensor` of shape `(1,)`):
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:59: diversity_loss (*optional*, returned when `sample_negative_indices` are passed, `torch.FloatTensor` of shape `(1,)`):
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:74: pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:162: pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:166: pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:170: pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:536: pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:540: pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py:544: pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/configuration_wav2vec2_conformer.py:42: represented by the `inputs_ids` passed when calling [`Wav2Vec2ConformerModel`]. Vocabulary size of the
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_conformer/configuration_wav2vec2_conformer.py:43: model. Defines the different tokens that can be represented by the *inputs_ids* passed to the forward
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:197: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:240: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:337: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:432: `PhimoeAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:450: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:555: Forward pass for the custom autograd function.
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:566: torch.Tensor: Result of the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:577: Backward pass for the custom autograd function.
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:580: ctx: Context object with saved tensors from the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:977: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/phimoe/configuration_phimoe.py:37: `inputs_ids` passed when calling [`PhimoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:45: by the `inputs_ids` passed when calling [`BigBirdPegasusModel`].
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:211: # TODO: figure this case out.
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:310: # TODO: test this.
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:637: # this is just for visualizing; forward pass doesn't depend on following code
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:639: # TODO(PVP): need to verify if below code is correct
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:1239: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:1259: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:1838: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:2147: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:2159: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:2212: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:2397: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:2422: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:2702: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:539: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:596: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:1137: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:1495: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:1496: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:1498: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:1550: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:1857: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:1858: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:1860: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py:1885: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modular_rt_detr_v2.py:77: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modular_rt_detr_v2.py:591: pass
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modular_rt_detr_v2.py:608: pass
- .venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/configuration_rt_detr_v2.py:66: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/superpoint/modeling_superpoint.py:96: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or
- .venv/lib/python3.12/site-packages/transformers/models/superpoint/image_processing_superpoint.py:67: Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
- .venv/lib/python3.12/site-packages/transformers/models/superpoint/image_processing_superpoint.py:205: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/superpoint/image_processing_superpoint.py:321: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the mask")
- .venv/lib/python3.12/site-packages/transformers/models/superpoint/image_processing_superpoint_fast.py:151: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the mask")
- .venv/lib/python3.12/site-packages/transformers/models/mamba2/configuration_mamba2.py:44: `inputs_ids` passed when calling [`Mamba2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/mamba2/modeling_mamba2.py:865: If passed along, the model uses the previous state in all the blocks (which will give the output for the
- .venv/lib/python3.12/site-packages/transformers/models/mamba2/modeling_mamba2.py:871: If `cache_params` is passed, `cache_position` should also be passed.
- .venv/lib/python3.12/site-packages/transformers/models/mamba2/modeling_mamba2.py:899: "You have to specify the `cache_position` manually when `use_cache=True` and `cache_params` is passed, "
- .venv/lib/python3.12/site-packages/transformers/models/mamba2/modeling_mamba2.py:900: "you don't have to pass a `cache_params` if you are in prefilling stage because in that case it will "
- .venv/lib/python3.12/site-packages/transformers/models/mamba2/modeling_mamba2.py:1014: If passed along, the model uses the previous state in all the blocks (which will give the output for the
- .venv/lib/python3.12/site-packages/transformers/models/mamba2/modeling_mamba2.py:1024: If `cache_params` is passed, `cache_position` should also be passed.
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/image_processing_owlv2_fast.py:107: # TODO: (amy) add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/image_processing_owlv2_fast.py:117: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/image_processing_owlv2_fast.py:166: raise ValueError("Make sure that you pass in as many target sizes as images")
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/image_processing_owlv2_fast.py:215: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/modeling_owlv2.py:1269: raise ValueError("feature_map has been deprecated as an input. Please pass in num_patches instead")
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/modeling_owlv2.py:1511: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/image_processing_owlv2.py:390: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/image_processing_owlv2.py:447: # hence, these arguments don't need to be passed in validate_preprocess_arguments.
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/image_processing_owlv2.py:532: raise ValueError("Make sure that you pass in as many target sizes as images")
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/image_processing_owlv2.py:582: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/processing_owlv2.py:244: raise ValueError("Make sure that you pass in as many lists of text labels as images")
- .venv/lib/python3.12/site-packages/transformers/models/owlv2/configuration_owlv2.py:39: by the `inputs_ids` passed when calling [`Owlv2TextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:51: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:71: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:99: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:127: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:152: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:177: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:202: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:227: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:250: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:278: entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:543: raise NotImplementedError("LUKE does not support the pruning of attention heads")
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:842: raise NotImplementedError("LUKE does not support the pruning of attention heads")
- .venv/lib/python3.12/site-packages/transformers/models/luke/modeling_luke.py:2080: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:78: Python's tokenizer, this method will raise `NotImplementedError`.
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:83: **kwargs: passed to the `self.tokenize()` method
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:192: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:530: Create a mask from the two sequences passed to be used in a sequence-pair classification task. LUKE does not
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:733: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:742: raise NotImplementedError("is_split_into_words is not supported in this tokenizer.")
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:816: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:823: raise NotImplementedError("is_split_into_words is not supported in this tokenizer.")
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:1405: `self.padding_side`, `self.pad_token_id` and `self.pad_token_type_id`) .. note:: If the `encoded_inputs` passed
- .venv/lib/python3.12/site-packages/transformers/models/luke/tokenization_luke.py:1455: # The model's main input name, usually `input_ids`, has be passed for padding
- .venv/lib/python3.12/site-packages/transformers/models/luke/configuration_luke.py:38: `inputs_ids` passed when calling [`LukeModel`].
- .venv/lib/python3.12/site-packages/transformers/models/luke/configuration_luke.py:41: by the `entity_ids` passed when calling [`LukeModel`].
- .venv/lib/python3.12/site-packages/transformers/models/luke/configuration_luke.py:63: The vocabulary size of the `token_type_ids` passed when calling [`LukeModel`].
- .venv/lib/python3.12/site-packages/transformers/models/dinov3_convnext/modeling_dinov3_convnext.py:82: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/esm/configuration_esm.py:26: # TODO Update this
- .venv/lib/python3.12/site-packages/transformers/models/esm/configuration_esm.py:43: `inputs_ids` passed when calling [`ESMModel`].
- .venv/lib/python3.12/site-packages/transformers/models/esm/configuration_esm.py:183: bypass_lm: bool = False
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esmfold.py:670: iteration. Once i exceeds n/2, the cache is "reoriented" to encompass the 3rd and 4th quadrants of z instead.
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esmfold.py:1912: no_recycles += 1  # First 'recycle' is just the standard forward pass through the model.
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esmfold.py:1979: # TODO Add information to the docstring about any methods that convert to PDB format, or otherwise prepare
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esmfold.py:2075: consists of passing the output of the folding trunk back in as input to the trunk. During training, the
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esmfold.py:2205: if self.config.esmfold_config.bypass_lm:
- .venv/lib/python3.12/site-packages/transformers/models/esm/tokenization_esm.py:65: # TODO, all the tokens are added? But they are also part of the vocab... bit strange.
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_tf_esm.py:480: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_tf_esm.py:623: f"If `encoder_hidden_states` are passed, {self} has to be instantiated"
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_tf_esm.py:853: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_tf_esm.py:881: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_tf_esm.py:925: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_tf_esm.py:1044: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esm.py:515: f"If `encoder_hidden_states` are passed, {self} has to be instantiated"
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esm.py:645: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esm.py:709: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:364: # TODO: ^ interpret this
- .venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:416: # TODO: this file should be downloaded in a setup script
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/configuration_table_transformer.py:98: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:58: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:308: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:361: # TODO find a better way of exposing other arguments
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:723: - object_queries are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:754: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:839: - object_queries and query_position_embeddings are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:874: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:1052: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:1053: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:1055: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:1074: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:1128: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:1211: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:1212: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:1214: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:163: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:183: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:748: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:929: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:941: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:996: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:1205: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/tokenization_blenderbot_small.py:75: Additional keyword arguments passed along to [`PreTrainedTokenizer`]
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py:546: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py:548: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py:561: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py:754: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py:957: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py:1157: # If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py:1164: # If the user passed a TFBaseModelOutput for encoder_outputs, we wrap it in a tuple when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/tokenization_blenderbot_small_fast.py:83: Create a mask from the two sequences passed to be used in a sequence-pair classification task. BlenderbotSmall
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py:203: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py:895: # make sure initialization pass will work for FlaxBlenderbotSmallForSequenceClassificationModule
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py:1090: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py:1103: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py:1104: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py:1358: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py:1371: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py:1372: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:46: represented by the `inputs_ids` passed when calling [`BlenderbotSmallModel`] or [`TFBlenderbotSmallModel`].
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:189: # TODO: figure this case out.
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:288: # TODO: test this.
- .venv/lib/python3.12/site-packages/transformers/models/efficientnet/image_processing_efficientnet.py:237: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:286: f"Instantiating {self.__class__.__name__} without passing `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:375: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:379: as the weights of the module stays untouched. The only required change would be on the forward pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:388: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:492: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:496: `Qwen2MoeAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:514: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:826: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/configuration_qwen2_moe.py:38: `inputs_ids` passed when calling [`Qwen2MoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/ernie4_5_moe/configuration_ernie4_5_moe.py:37: `inputs_ids` passed when calling [`Ernie4_5_MoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/ernie4_5_moe/modular_ernie4_5_moe.py:43: pass
- .venv/lib/python3.12/site-packages/transformers/models/rembert/configuration_rembert.py:42: `inputs_ids` passed when calling [`RemBertModel`] or [`TFRemBertModel`]. Vocabulary size of the model.
- .venv/lib/python3.12/site-packages/transformers/models/rembert/configuration_rembert.py:43: Defines the different tokens that can be represented by the *inputs_ids* passed to the forward method of
- .venv/lib/python3.12/site-packages/transformers/models/rembert/configuration_rembert.py:70: The vocabulary size of the `token_type_ids` passed when calling [`RemBertModel`] or [`TFRemBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_rembert.py:448: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_rembert.py:513: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_rembert.py:647: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_rembert.py:1148: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_tf_rembert.py:319: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_tf_rembert.py:474: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_tf_rembert.py:754: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_tf_rembert.py:879: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_tf_rembert.py:957: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_tf_rembert.py:959: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_tf_rembert.py:972: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/rembert/modeling_tf_rembert.py:1018: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/phi3/configuration_phi3.py:38: `inputs_ids` passed when calling [`Phi3Model`].
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modular_phi3.py:92: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modular_phi3.py:93: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modular_phi3.py:95: q_embed = torch.cat([(q_rot * cos) + (rotate_half(q_rot) * sin), q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modular_phi3.py:96: k_embed = torch.cat([(k_rot * cos) + (rotate_half(k_rot) * sin), k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modular_phi3.py:260: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modular_phi3.py:264: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:137: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:138: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:140: q_embed = torch.cat([(q_rot * cos) + (rotate_half(q_rot) * sin), q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:141: k_embed = torch.cat([(k_rot * cos) + (rotate_half(k_rot) * sin), k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:534: pass
- .venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:538: pass
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:174: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:291: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:292: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:299: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:300: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:932: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:1457: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:1481: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:156: pass
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:187: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:188: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:195: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:196: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:201: pass
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:205: pass
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:690: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:702: pass
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:706: pass
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:1176: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:1200: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/bamba/configuration_bamba.py:39: `inputs_ids` passed when calling [`BambaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/bertweet/tokenization_bertweet.py:225: Create a mask from the two sequences passed to be used in a sequence-pair classification task. BERTweet does
- .venv/lib/python3.12/site-packages/transformers/models/bertweet/tokenization_bertweet.py:667: pass
- .venv/lib/python3.12/site-packages/transformers/models/upernet/configuration_upernet.py:49: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/ijepa/modeling_ijepa.py:457: # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
- .venv/lib/python3.12/site-packages/transformers/models/groupvit/modeling_tf_groupvit.py:73: pass
- .venv/lib/python3.12/site-packages/transformers/models/groupvit/modeling_tf_groupvit.py:237: The logits returned do not necessarily have the same size as the `pixel_values` passed as inputs. This is
- .venv/lib/python3.12/site-packages/transformers/models/groupvit/modeling_tf_groupvit.py:2127: # TODO: As is this currently fails with saved_model=True, because
- .venv/lib/python3.12/site-packages/transformers/models/groupvit/configuration_groupvit.py:47: by the `inputs_ids` passed when calling [`GroupViTModel`].
- .venv/lib/python3.12/site-packages/transformers/models/groupvit/modeling_groupvit.py:278: The logits returned do not necessarily have the same size as the `pixel_values` passed as inputs. This is
- .venv/lib/python3.12/site-packages/transformers/models/groupvit/modeling_groupvit.py:870: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mpt/modeling_mpt.py:323: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/mpt/modeling_mpt.py:362: "You should pass an instance of `DynamicCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/mpt/modeling_mpt.py:464: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/mpt/modeling_mpt.py:528: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/mpt/modeling_mpt.py:560: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/mpt/modeling_mpt.py:684: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/mpt/modeling_mpt.py:762: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/mpt/configuration_mpt.py:50: Whether the model should operate as a Prefix LM. This requires passing an extra `prefix_mask` argument
- .venv/lib/python3.12/site-packages/transformers/models/mpt/configuration_mpt.py:57: mode, this requires passing an extra *token_type_ids* argument which indicates which sub-sequence each
- .venv/lib/python3.12/site-packages/transformers/models/mpt/configuration_mpt.py:123: the `inputs_ids` passed when calling [`MptModel`]. Check [this
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:346: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:375: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:745: # TODO: This leads to ~1e-07 max diff and ~1e-09 avg diff for q_embed and k_embed from the original implementation, most
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:768: k_rot, k_pass = k[..., : k.shape[-2] - num_k_exclude_rope, :], k[..., k.shape[-2] - num_k_exclude_rope :, :]
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:773: return q_embed.type_as(q), torch.cat([k_rot, k_pass], dim=-2)
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:789: k_embed = torch.cat([k_embed.type_as(k), k_pass], dim=-2)
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:1115: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:1119: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:1641: Returns the image embeddings by passing the pixel values through the vision encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:1670: Returns the prompt embeddings by passing the input points, labels, boxes and masks through the prompt encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:1682: processor. users can also pass manually the input boxes.
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:1870: better results. The points can be obtained by passing a list of list of list to the processor that will
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:1873: per input point), the third dimension is the number of points per segmentation mask (it is possible to pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:1875: coordinates of the point. If a different number of points is passed either for each image, or for each
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modeling_sam2_video.py:1893: much better generated masks. The boxes can be obtained by passing a list of list of list to the processor,
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/processing_sam2_video.py:98: Additional keyword arguments to pass to the image processor.
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/processing_sam2_video.py:129: "original_sizes must be of length 1 or len(images). If you are passing a single image, you must pass a single original_s
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:76: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:80: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:934: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:938: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:942: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:946: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1083: # TODO: This leads to ~1e-07 max diff and ~1e-09 avg diff for q_embed and k_embed from the original implementation, most
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1106: k_rot, k_pass = k[..., : k.shape[-2] - num_k_exclude_rope, :], k[..., k.shape[-2] - num_k_exclude_rope :, :]
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1111: return q_embed.type_as(q), torch.cat([k_rot, k_pass], dim=-2)
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1127: k_embed = torch.cat([k_embed.type_as(k), k_pass], dim=-2)
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1513: Returns the prompt embeddings by passing the input points, labels, boxes and masks through the prompt encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1525: processor. users can also pass manually the input boxes.
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1581: better results. The points can be obtained by passing a list of list of list to the processor that will
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1584: per input point), the third dimension is the number of points per segmentation mask (it is possible to pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1586: coordinates of the point. If a different number of points is passed either for each image, or for each
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/modular_sam2_video.py:1604: much better generated masks. The boxes can be obtained by passing a list of list of list to the processor,
- .venv/lib/python3.12/site-packages/transformers/models/sam2_video/video_processing_sam2_video.py:95: The target size the images were padded to before being passed to the model. If None, the target size is
- .venv/lib/python3.12/site-packages/transformers/models/resnet/modeling_tf_resnet.py:429: # We transpose to NHWC format and then transpose back after the full forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/vipllava/modular_vipllava.py:39: pass
- .venv/lib/python3.12/site-packages/transformers/models/vipllava/modular_vipllava.py:43: pass
- .venv/lib/python3.12/site-packages/transformers/models/vipllava/modular_vipllava.py:71: pass
- .venv/lib/python3.12/site-packages/transformers/models/vipllava/modeling_vipllava.py:46: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/vipllava/modeling_vipllava.py:72: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/vipllava/modeling_vipllava.py:458: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modular_data2vec_audio.py:70: pass
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modular_data2vec_audio.py:126: pass
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modular_data2vec_audio.py:130: pass
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modular_data2vec_audio.py:134: pass
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modular_data2vec_audio.py:249: pass
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modular_data2vec_audio.py:253: pass
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modular_data2vec_audio.py:257: pass
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/configuration_data2vec_audio.py:40: by the `inputs_ids` passed when calling [`Data2VecAudioModel`] or [`TFData2VecAudioModel`]. Vocabulary size
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/configuration_data2vec_audio.py:41: of the model. Defines the different tokens that can be represented by the *inputs_ids* passed to the
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_tf_data2vec_vision.py:79: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_tf_data2vec_vision.py:84: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_tf_data2vec_vision.py:411: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_tf_data2vec_vision.py:777: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_tf_data2vec_vision.py:805: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_tf_data2vec_vision.py:913: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_tf_data2vec_vision.py:915: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_tf_data2vec_vision.py:928: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_text.py:102: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_text.py:425: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_text.py:493: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_text.py:598: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_text.py:1127: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/configuration_data2vec_text.py:42: the `inputs_ids` passed when calling [`Data2VecModel`].
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/configuration_data2vec_text.py:62: The vocabulary size of the `token_type_ids` passed when calling [`Data2VecModel`].
- .venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py:250: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/doge/modular_doge.py:65: Vocabulary size of the Doge2 model. Defines the number of different tokens that can be represented by the `inputs_ids` p
- .venv/lib/python3.12/site-packages/transformers/models/doge/modular_doge.py:270: pass
- .venv/lib/python3.12/site-packages/transformers/models/doge/modular_doge.py:274: pass
- .venv/lib/python3.12/site-packages/transformers/models/doge/modular_doge.py:457: pass
- .venv/lib/python3.12/site-packages/transformers/models/doge/modular_doge.py:591: pass
- .venv/lib/python3.12/site-packages/transformers/models/doge/modular_doge.py:791: pass
- .venv/lib/python3.12/site-packages/transformers/models/doge/configuration_doge.py:37: Vocabulary size of the Doge2 model. Defines the number of different tokens that can be represented by the `inputs_ids` p
- .venv/lib/python3.12/site-packages/transformers/models/doge/modeling_doge.py:809: pass
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:83: Hidden states are cached from the previous call to the MimiConv1d forward pass, given the padding size.
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:101: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:372: # as removing it here would require also passing the length at the matching layer
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:618: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:708: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:712: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:719: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:764: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:826: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:830: `MimiAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:848: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:1069: The model will output the same cache format that is fed as input. If no `past_key_values` are passed, the
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:1101: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:1471: # TODO: @eustlb, let's make the encoder support padding_mask so that batched inputs are supported.
- .venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:1474: # TODO: @eustlb, convert the padding mask to attention mask.
- .venv/lib/python3.12/site-packages/transformers/models/t5/configuration_t5.py:40: `inputs_ids` passed when calling [`T5Model`] or [`TFT5Model`].
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:275: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:722: raise NotImplementedError  # Not implemented yet in the library fr TF 2.0 models
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1011: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1013: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1026: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1090: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1094: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1138: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1238: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1247: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1428: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1483: # If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_tf_t5.py:1550: "input_ids": None,  # needs to be passed to make Keras.layer.__call__ happy
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_flax_t5.py:854: past_key_values (`Dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_flax_t5.py:1007: "Make sure to provide both `input_ids` and `decoder_input_ids`. `decoder_input_ids` is not passed"
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_flax_t5.py:1189: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_flax_t5.py:1190: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_flax_t5.py:1329: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_flax_t5.py:1392: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_flax_t5.py:1440: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_flax_t5.py:1667: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_flax_t5.py:1668: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5_fast.py:38: # TODO(PVP) - this should be removed in Transformers v5
- .venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5_fast.py:149: " `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please"
- .venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5_fast.py:206: Create a mask from the two sequences passed to be used in a sequence-pair classification task. T5 does not make
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:273: pass
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:276: pass
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:368: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1019: # do not pass cache object down the line for encoder stack
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1461: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1474: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1723: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1800: # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflo
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:2031: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:2041: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:2305: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:2319: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5.py:79: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5.py:166: # for legacy purpose, we keep this. Will be removed and tests updated. (when `added_tokens_decoder` is not passed as kwa
- .venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5.py:232: " `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please"
- .venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5.py:299: Create a mask from the two sequences passed to be used in a sequence-pair classification task. T5 does not make
- .venv/lib/python3.12/site-packages/transformers/models/olmo/modular_olmo.py:167: pass
- .venv/lib/python3.12/site-packages/transformers/models/olmo/configuration_olmo.py:42: `inputs_ids` passed when calling [`OlmoModel`]
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/modeling_kosmos2.py:102: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/modeling_kosmos2.py:150: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/modeling_kosmos2.py:469: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/modeling_kosmos2.py:583: # Similar to `transformers.models.m2m_100.modeling_m2m_100.M2M100SinusoidalPositionalEmbedding` but allowing to pass `po
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/modeling_kosmos2.py:888: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/modeling_kosmos2.py:1062: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/modeling_kosmos2.py:1838: f"`inputs`: {inputs} were passed alongside `pixel_values` which is not allowed."
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/modeling_kosmos2.py:1839: f"Make sure to either pass `inputs` or pixel_values=..."
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/configuration_kosmos2.py:37: `inputs_ids` passed when calling [`Kosmos2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/processing_kosmos2.py:328: "make sure the arguments `texts` and `bboxes` passed to `preprocess_text` are both in "
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/processing_kosmos2.py:387: raise ValueError("`bboxes` should be `None` or a list (as a batch) when `texts` is passed as a batch.")
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/processing_kosmos2.py:423: Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/kosmos2/processing_kosmos2.py:425: Additional arguments to be passed to the tokenizer's `batch_decode method`.
- .venv/lib/python3.12/site-packages/transformers/models/paligemma/modeling_paligemma.py:52: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/paligemma/modeling_paligemma.py:78: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/paligemma/modeling_paligemma.py:558: # Otherwise we need pixel values to be passed to model. NOTE: use_cache=False needs pixel_values always
- .venv/lib/python3.12/site-packages/transformers/models/paligemma/configuration_paligemma.py:44: `inputs_ids` passed when calling [`~PaliGemmaForConditionalGeneration`]
- .venv/lib/python3.12/site-packages/transformers/models/paligemma/processing_paligemma.py:168: The usage for PaliGemma fine-tuning preparation is slightly different than usual. suffix passed are suffixes to
- .venv/lib/python3.12/site-packages/transformers/models/paligemma/processing_paligemma.py:239: pass
- .venv/lib/python3.12/site-packages/transformers/models/paligemma/processing_paligemma.py:244: "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special "
- .venv/lib/python3.12/site-packages/transformers/models/chinese_clip/configuration_chinese_clip.py:49: by the `inputs_ids` passed when calling [`ChineseCLIPModel`].
- .venv/lib/python3.12/site-packages/transformers/models/chinese_clip/configuration_chinese_clip.py:69: The vocabulary size of the `token_type_ids` passed when calling [`ChineseCLIPModel`].
- .venv/lib/python3.12/site-packages/transformers/models/chinese_clip/modeling_chinese_clip.py:132: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/chinese_clip/modeling_chinese_clip.py:719: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/chinese_clip/modeling_chinese_clip.py:829: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/chinese_clip/image_processing_chinese_clip.py:193: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/altclip/configuration_altclip.py:38: `inputs_ids` passed when calling [`AltCLIPTextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/altclip/configuration_altclip.py:58: The vocabulary size of the `token_type_ids` passed when calling [`AltCLIPTextModel`]
- .venv/lib/python3.12/site-packages/transformers/models/altclip/modeling_altclip.py:142: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/altclip/modeling_altclip.py:668: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:183: The scaled dot product scores between `image_embeddings` and `text_embeddings` but passed through FLAVA's
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:187: The scaled dot product scores between `text_embeddings` and `image_embeddings` but passed through FLAVA's
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:405: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:604: # TODO: Check fp32 layer norm possibility
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:1456: Pixel values. Codebook pixel values can be obtained using [`AutoImageProcessor`] by passing
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:1488: Pixel values. Codebook pixel values can be obtained using [`AutoImageProcessor`] by passing
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:1628: If passed, the image codebook will be set to this. Otherwise, it will be initialized using the
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:1723: computed for the tokens with labels in `[0, ..., image_config.vocab_size - 1]`. If not passed, they are
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:1771: "`input_ids_masked` isn't passed which means MLM loss won't be calculated correctlySetting it to"
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:1772: " `input_ids` so that model can work. Please pass it if this is unintentional. This is usually OKAY if"
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:1823: " have been passed. Reinstantiate the model with `init_codebook` set to True or "
- .venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:1824: "pass in your custom `mim_labels`"
- .venv/lib/python3.12/site-packages/transformers/models/flava/image_processing_flava.py:501: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/flava/configuration_flava.py:143: `inputs_ids` passed when calling [`FlavaTextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/flava/configuration_flava.py:145: The vocabulary size of the `token_type_ids` passed when calling [`FlavaTextModel`]. Note that even though
- .venv/lib/python3.12/site-packages/transformers/models/flava/configuration_flava.py:150: just in case (e.g., 512 or 1024 or 2048). For VL, max_length passed to model is 77.
- .venv/lib/python3.12/site-packages/transformers/models/flava/configuration_flava.py:345: Number of channels in the image to be passed.
- .venv/lib/python3.12/site-packages/transformers/models/mgp_str/modeling_mgp_str.py:86: a3_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_a3_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/mlcd/modeling_mlcd.py:386: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/mlcd/modular_mlcd.py:135: pass
- .venv/lib/python3.12/site-packages/transformers/models/mlcd/modular_mlcd.py:325: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos.py:1208: from 0 to 255. If passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos.py:1439: # POSTPROCESSING METHODS - TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos.py:1465: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos.py:1507: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos_fast.py:795: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos_fast.py:843: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/yolos/modular_yolos.py:94: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/yolos/modular_yolos.py:142: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/yolos/modular_yolos.py:175: raise NotImplementedError("Segmentation post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/yolos/modular_yolos.py:178: raise NotImplementedError("Instance post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/yolos/modular_yolos.py:181: raise NotImplementedError("Panoptic post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/yolos/modular_yolos.py:184: raise NotImplementedError("Segmentation post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/yolos/modular_yolos.py:187: raise NotImplementedError("Semantic segmentation post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/yolos/modular_yolos.py:190: raise NotImplementedError("Panoptic segmentation post-processing is not implemented for Deformable DETR yet.")
- .venv/lib/python3.12/site-packages/transformers/models/lilt/configuration_lilt.py:36: `inputs_ids` passed when calling [`LiltModel`].
- .venv/lib/python3.12/site-packages/transformers/models/lilt/configuration_lilt.py:56: The vocabulary size of the `token_type_ids` passed when calling [`LiltModel`].
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former_fast.py:76: Some backbones need images divisible by a certain number. If not passed, it defaults to the value used in
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former_fast.py:488: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:303: # TODO: (Amy) Move to image_transforms
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:409: Some backbones need images divisible by a certain number. If not passed, it defaults to the value used in
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:464: # We make max_size a private attribute so we can pass it as a default value in the preprocess method whilst
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:465: # `size` can still be pass in as an int
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:687: # TODO: (Amy)
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:938: A mapping between object instance ids and class ids. If passed, `segmentation_maps` is treated as an
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:1053: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:64: sequence_length)`. Attentions weights from pixel decoder. Returned when `output_attentions=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:148: `output_hidden_states=True` is passed.
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:156: model at the output of each stage. Returned when `output_hidden_states=True` is passed.
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:157: pixel_decoder_hidden_states (`tuple(torch.FloatTensor)`, , *optional*, returned when `output_hidden_states=True` is pass
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:160: decoder model at the output of each stage. Returned when `output_hidden_states=True` is passed.
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:164: transformer decoder at the output of each stage. Returned when `output_hidden_states=True` is passed.
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:170: attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed):
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:191: This output can be directly passed to [`~Mask2FormerImageProcessor.post_process_semantic_segmentation`] or
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:215: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:219: pixel_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:223: transformer_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is 
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:227: attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:682: uncertainty is calculated for each point using the passed `uncertainty function` that takes points logit
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:853: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:1143: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modeling_mask2former.py:1820: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/configuration_mask2former.py:55: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modular_mask2former.py:79: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/mask2former/modular_mask2former.py:312: raise NotImplementedError("Segmentation post-processing is not implemented for Mask2Former yet.")
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:122: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:545: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:557: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:873: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_flax_opt.py:613: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_tf_opt.py:410: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_tf_opt.py:412: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_tf_opt.py:425: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_tf_opt.py:615: shape `(batch_size, sequence_length, hidden_size)`, *optional*): Optionally, instead of passing
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_tf_opt.py:616: `input_ids` you can choose to directly pass an embedded representation. This is useful if you want more
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_tf_opt.py:997: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/opt/modeling_tf_opt.py:1010: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/opt/configuration_opt.py:38: `inputs_ids` passed when calling [`OPTModel`]
- .venv/lib/python3.12/site-packages/transformers/models/gpt_sw3/tokenization_gpt_sw3.py:63: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/gpt_sw3/tokenization_gpt_sw3.py:215: # TODO: Check if this is needed, as it ensures that decode(encode(doc)) != doc by adding extra whitespace in the decoded
- .venv/lib/python3.12/site-packages/transformers/models/clap/modeling_clap.py:267: This module converts the hidden states reshaped as an image to patch embeddings ready to be passed to the
- .venv/lib/python3.12/site-packages/transformers/models/clap/modeling_clap.py:610: pass
- .venv/lib/python3.12/site-packages/transformers/models/clap/modeling_clap.py:1048: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/clap/modeling_clap.py:1472: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/clap/feature_extraction_clap.py:238: raise NotImplementedError(f"data_truncating {truncation} not implemented")
- .venv/lib/python3.12/site-packages/transformers/models/clap/feature_extraction_clap.py:297: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/clap/feature_extraction_clap.py:313: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/clap/configuration_clap.py:38: `inputs_ids` passed when calling [`ClapTextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/clap/configuration_clap.py:58: The vocabulary size of the `token_type_ids` passed when calling [`ClapTextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/tokenization_xlnet.py:98: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/tokenization_xlnet.py:343: Create a mask from the two sequences passed to be used in a sequence-pair classification task. An XLNet
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:121: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:518: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:525: qlen: TODO Lysandre didn't fill
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:526: mlen: TODO Lysandre didn't fill
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:760: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:850: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:852: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:857: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:886: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:888: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:893: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:920: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:922: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:927: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:954: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:956: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:961: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:990: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:992: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:997: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:1026: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:1028: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:1033: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:1066: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:1068: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:1081: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:1109: decoding. The token ids which have their past given to this model should not be passed as `input_ids` as
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:1150: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:1251: # At every pass, the attention values for the new token and the two last generated tokens
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:219: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:732: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:787: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:850: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:877: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:902: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:927: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:954: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:981: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1017: token ids which have their past given to this model should not be passed as `input_ids` as they have
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1061: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1182: decoding. The token ids which have their past given to this model should not be passed as `input_ids` as
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1210: states from previous forward passes to compute attention, which can significantly improve performance for
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1452: # At every pass, the attention values for the new token and the two last generated tokens
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1510: decoding. The token ids which have their past given to this model should not be passed as `input_ids` as
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1548: states from previous forward passes to compute attention, which can significantly improve performance for
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1695: decoding. The token ids which have their past given to this model should not be passed as `input_ids` as
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1727: states from previous forward passes to compute attention, which can significantly improve performance for
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1823: decoding. The token ids which have their past given to this model should not be passed as `input_ids` as
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1854: states from previous forward passes to compute attention, which can significantly improve performance for
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1856: states from previous forward passes to compute attention, which can significantly improve performance for
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1958: decoding. The token ids which have their past given to this model should not be passed as `input_ids` as
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1975: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:1982: states from previous forward passes to compute attention, which can significantly improve performance for
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:2080: decoding. The token ids which have their past given to this model should not be passed as `input_ids` as
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:2108: states from previous forward passes to compute attention, which can significantly improve performance for
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:2209: decoding. The token ids which have their past given to this model should not be passed as `input_ids` as
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_xlnet.py:2245: states from previous forward passes to compute attention, which can significantly improve performance for
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/tokenization_xlnet_fast.py:184: Create a mask from the two sequences passed to be used in a sequence-pair classification task. An XLNet
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/configuration_xlnet.py:40: `inputs_ids` passed when calling [`XLNetModel`] or [`TFXLNetModel`].
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/configuration_xlnet.py:64: forward pass won't be re-computed. See the
- .venv/lib/python3.12/site-packages/transformers/models/xlnet/configuration_xlnet.py:235: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_dense/modeling_hunyuan_v1_dense.py:506: pass
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_dense/modular_hunyuan_v1_dense.py:51: pass
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_dense/modular_hunyuan_v1_dense.py:178: pass
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_dense/modular_hunyuan_v1_dense.py:182: pass
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_dense/modular_hunyuan_v1_dense.py:186: pass
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_dense/configuration_hunyuan_v1_dense.py:38: `inputs_ids` passed when calling [`HunYuanDenseV1Config`]
- .venv/lib/python3.12/site-packages/transformers/models/hunyuan_v1_dense/configuration_hunyuan_v1_dense.py:148: # self._rope_scaling_validation()   # TODO: Need validation?
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/tokenization_layoutxlm.py:110: Python's tokenizer, this method will raise `NotImplementedError`.
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/tokenization_layoutxlm.py:115: **kwargs: passed to the `self.tokenize()` method
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/tokenization_layoutxlm.py:206: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/tokenization_layoutxlm.py:369: Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLM-RoBERTa does
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/tokenization_layoutxlm.py:619: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/tokenization_layoutxlm.py:746: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/processing_layoutxlm.py:93: [`LayoutLMv2ImagePrpcessor`] was initialized with `apply_ocr` set to `True`, it passes the obtained words and
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/processing_layoutxlm.py:96: `False`, it passes the words (`text`/``text_pair`) and `boxes` specified by the user along with the additional
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/tokenization_layoutxlm_fast.py:112: Python's tokenizer, this method will raise `NotImplementedError`.
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/tokenization_layoutxlm_fast.py:117: **kwargs: passed to the `self.tokenize()` method
- .venv/lib/python3.12/site-packages/transformers/models/layoutxlm/tokenization_layoutxlm_fast.py:774: Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLM-RoBERTa does
- .venv/lib/python3.12/site-packages/transformers/models/dinov2_with_registers/modular_dinov2_with_registers.py:174: pass
- .venv/lib/python3.12/site-packages/transformers/models/dinov2_with_registers/modular_dinov2_with_registers.py:277: pass
- .venv/lib/python3.12/site-packages/transformers/models/dinov2_with_registers/modular_dinov2_with_registers.py:314: pass
- .venv/lib/python3.12/site-packages/transformers/models/csm/modeling_csm.py:62: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/csm/modeling_csm.py:72: depth_decoder_past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed o
- .venv/lib/python3.12/site-packages/transformers/models/csm/modeling_csm.py:75: depth_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/csm/modeling_csm.py:80: depth_decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/csm/modeling_csm.py:845: # TODO: @eustlb, this should be batched !!!
- .venv/lib/python3.12/site-packages/transformers/models/csm/processing_csm.py:68: The preferred way of passing kwargs is as a dictionary per modality, see usage example below.
- .venv/lib/python3.12/site-packages/transformers/models/csm/processing_csm.py:169: # TODO: @eustlb, this should be in AudioProcessor
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:97: It ensures that the depth decoder generation config is initialized and that passed args as depth_decoder_* are properly 
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:200: # in the case where the passed input_ids correspond to text tokens, i.e. don't have a third dimension for codebook ids,
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:265: # TODO (joao): this OP throws "skipping cudagraphs due to ['incompatible ops']", find solution
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:361: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:362: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:379: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:386: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:390: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:392: sure you pass `return_dict_in_generate=True, output_scores=True` to `generate`. This feature is
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:399: Streamer object that will be used to stream the generated sequences. Generated tokens are passed
- .venv/lib/python3.12/site-packages/transformers/models/csm/generation_csm.py:472: # TODO: @eustlb, this should be batched !!!
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:61: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:71: depth_decoder_past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed o
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:74: depth_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:79: depth_decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:101: pass
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:105: pass
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:109: pass
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:113: pass
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:117: pass
- .venv/lib/python3.12/site-packages/transformers/models/csm/modular_csm.py:523: # TODO: @eustlb, this should be batched !!!
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/modular_seed_oss.py:49: pass
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/modular_seed_oss.py:146: pass
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/modular_seed_oss.py:150: pass
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/modular_seed_oss.py:154: pass
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/modular_seed_oss.py:188: pass
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/modular_seed_oss.py:192: pass
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/modular_seed_oss.py:196: pass
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/configuration_seed_oss.py:34: `inputs_ids` passed when calling [`SeedOssModel`]
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/modeling_seed_oss.py:495: pass
- .venv/lib/python3.12/site-packages/transformers/models/seed_oss/modeling_seed_oss.py:499: pass
- .venv/lib/python3.12/site-packages/transformers/models/swinv2/modeling_swinv2.py:52: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/swinv2/modeling_swinv2.py:75: pooler_output (`torch.FloatTensor` of shape `(batch_size, hidden_size)`, *optional*, returned when `add_pooling_layer=Tr
- .venv/lib/python3.12/site-packages/transformers/models/swinv2/modeling_swinv2.py:77: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/swinv2/modeling_swinv2.py:105: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/swinv2/modeling_swinv2.py:142: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/modular_smollm3.py:58: `inputs_ids` passed when calling [`SmolLM3Model`]
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/modular_smollm3.py:330: pass
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/modular_smollm3.py:334: pass
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/modular_smollm3.py:338: pass
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/modular_smollm3.py:342: pass
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/modular_smollm3.py:346: pass
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/modular_smollm3.py:350: pass
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/modeling_smollm3.py:509: pass
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/modeling_smollm3.py:513: pass
- .venv/lib/python3.12/site-packages/transformers/models/smollm3/configuration_smollm3.py:39: `inputs_ids` passed when calling [`SmolLM3Model`]
- .venv/lib/python3.12/site-packages/transformers/models/mistral3/modular_mistral3.py:42: pass
- .venv/lib/python3.12/site-packages/transformers/models/mistral3/modular_mistral3.py:110: pass
- .venv/lib/python3.12/site-packages/transformers/models/mistral3/modular_mistral3.py:114: pass
- .venv/lib/python3.12/site-packages/transformers/models/mistral3/modular_mistral3.py:118: pass
- .venv/lib/python3.12/site-packages/transformers/models/mistral3/modeling_mistral3.py:138: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/mistral3/modeling_mistral3.py:165: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/mistral3/modeling_mistral3.py:533: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:66: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:71: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:86: global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:113: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:118: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:133: global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:159: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:164: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:179: global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:207: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:212: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:227: global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:254: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:259: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:274: global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:302: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:307: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:322: global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:348: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:353: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:368: global_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:1030: # TODO: This code is most likely not very efficient and should be improved
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:1293: """compute global attn indices required throughout forward pass"""
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:1572: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:1775: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:2008: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:2010: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:2023: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:2081: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:2344: " for this forward pass."
- .venv/lib/python3.12/site-packages/transformers/models/longformer/tokenization_longformer_fast.py:53: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/longformer/tokenization_longformer_fast.py:245: Create a mask from the two sequences passed to be used in a sequence-pair classification task. Longformer does not
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:45: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:60: global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:87: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:102: global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:130: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:145: global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:171: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:186: global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:215: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:230: global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:260: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:275: global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:303: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:318: global_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:621: # TODO: remove the redundant computation
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:736: # TODO replace this with
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:883: """compute global attn indices required throughout forward pass"""
- .venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:2142: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/longformer/configuration_longformer.py:51: the `inputs_ids` passed when calling [`LongformerModel`] or [`TFLongformerModel`].
- .venv/lib/python3.12/site-packages/transformers/models/longformer/configuration_longformer.py:71: The vocabulary size of the `token_type_ids` passed when calling [`LongformerModel`] or
- .venv/lib/python3.12/site-packages/transformers/models/longformer/tokenization_longformer.py:93: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/longformer/tokenization_longformer.py:376: Create a mask from the two sequences passed to be used in a sequence-pair classification task. Longformer does not
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modular_instructblipvideo.py:47: pass
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modular_instructblipvideo.py:51: pass
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modular_instructblipvideo.py:73: The number of query tokens passed through the Transformer.
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modular_instructblipvideo.py:180: pass
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modular_instructblipvideo.py:184: pass
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modular_instructblipvideo.py:188: pass
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modular_instructblipvideo.py:192: pass
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modular_instructblipvideo.py:373: pass
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/configuration_instructblipvideo.py:130: the `inputs_ids` passed when calling the model.
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/configuration_instructblipvideo.py:239: The number of query tokens passed through the Transformer.
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/image_processing_instructblipvideo.py:45: # TODO (raushan): processor can be removed after v5 release. Kept for backwards compatibility
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/image_processing_instructblipvideo.py:185: ranging from 0 to 255. If passing in video with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1142: _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1186: " Please pass a `device_map` that contains `language_model` to remove this warning."
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1354: One can optionally pass `input_ids` to the model, which serve as a text prompt, to make the language model continue
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1363: _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1426: " Please pass a `device_map` that contains `language_model` to remove this warning."
- .venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1449: pass
- .venv/lib/python3.12/site-packages/transformers/models/clip/tokenization_clip_fast.py:140: Create a mask from the two sequences passed. CLIP does not make use of token type ids, therefore a list of
- .venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:518: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/clip/image_processing_clip.py:227: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/clip/modeling_tf_clip.py:1053: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/clip/modeling_tf_clip.py:1055: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/clip/modeling_tf_clip.py:1068: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/clip/modeling_tf_clip.py:1446: # TODO: As is this currently fails with saved_model=True, because
- .venv/lib/python3.12/site-packages/transformers/models/clip/tokenization_clip.py:398: Create a mask from the two sequences passed. CLIP does not make use of token type ids, therefore a list of
- .venv/lib/python3.12/site-packages/transformers/models/clip/configuration_clip.py:47: the `inputs_ids` passed when calling [`CLIPModel`].
- .venv/lib/python3.12/site-packages/transformers/models/clip/modeling_flax_clip.py:170: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/clip/modeling_flax_clip.py:175: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/models/byt5/tokenization_byt5.py:97: additional_special_tokens=additional_special_tokens,  # TODO extra ids are not used :sweatywmile:
- .venv/lib/python3.12/site-packages/transformers/models/byt5/tokenization_byt5.py:153: Create a mask from the two sequences passed to be used in a sequence-pair classification task. ByT5 does not
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:240: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:395: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:738: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:791: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:920: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:925: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:955: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:957: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:970: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_tf_electra.py:1008: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:176: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:480: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:548: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:863: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:918: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:1406: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/electra/tokenization_electra.py:442: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/electra/configuration_electra.py:43: `inputs_ids` passed when calling [`ElectraModel`] or [`TFElectraModel`].
- .venv/lib/python3.12/site-packages/transformers/models/electra/configuration_electra.py:65: The vocabulary size of the `token_type_ids` passed when calling [`ElectraModel`] or [`TFElectraModel`].
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_flax_electra.py:67: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_flax_electra.py:72: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_flax_electra.py:794: # init input tensors if not passed
- .venv/lib/python3.12/site-packages/transformers/models/electra/modeling_flax_electra.py:815: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/reformer/configuration_reformer.py:87: Whether or not to use a causal mask in addition to the `attention_mask` passed to [`ReformerModel`]. When
- .venv/lib/python3.12/site-packages/transformers/models/reformer/configuration_reformer.py:131: the `inputs_ids` passed when calling [`ReformerModel`].
- .venv/lib/python3.12/site-packages/transformers/models/reformer/tokenization_reformer.py:64: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:144: # `ReformerLocalAttn` passes `None` to buckets as the module uses no buckets
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:195: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:211: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:487: f" that input sequence length {sequence_length} equals 1, when `past_buckets_states` is passed."
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1394: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1526: # seed for forward and backward pass
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1580: # every forward pass we sample a different seed
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1581: # for dropout and save for forward fn in backward pass
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1605: # every forward pass we sample a different seed
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1620: def backward_pass(
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1630: # Implements the backward pass for reversible ResNets.
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1692: This way it is made sure that no memory expensive activations are saved during the forward pass. This function is
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1783: output = layer.backward_pass(
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1833: "You should pass an instance of `ReformerDynamicCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1946: past_buckets_states (`list[tuple(torch.LongTensor, torch.FloatTensor)]`, *optional*, returned when `use_cache=True` is p
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:1976: past_buckets_states (`list[tuple(torch.LongTensor, torch.FloatTensor)]`, *optional*, returned when `use_cache=True` is p
- .venv/lib/python3.12/site-packages/transformers/models/reformer/modeling_reformer.py:2584: >>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v2/configuration_deepseek_v2.py:38: `input_ids` passed when calling [`DeepseekV2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v2/modeling_deepseek_v2.py:632: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v2/modular_deepseek_v2.py:57: `input_ids` passed when calling [`DeepseekV2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v2/modular_deepseek_v2.py:362: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v2/modular_deepseek_v2.py:516: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v2/modular_deepseek_v2.py:520: pass
- .venv/lib/python3.12/site-packages/transformers/models/deepseek_v2/modular_deepseek_v2.py:524: pass
- .venv/lib/python3.12/site-packages/transformers/models/videomae/image_processing_videomae.py:261: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/videomae/modeling_videomae.py:85: # TODO: make it with torch instead of numpy
- .venv/lib/python3.12/site-packages/transformers/models/videomae/modeling_videomae.py:538: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/cohere2/modular_cohere2.py:61: `inputs_ids` passed when calling [`CohereModel`]
- .venv/lib/python3.12/site-packages/transformers/models/cohere2/modular_cohere2.py:267: pass
- .venv/lib/python3.12/site-packages/transformers/models/cohere2/modular_cohere2.py:271: pass
- .venv/lib/python3.12/site-packages/transformers/models/cohere2/modular_cohere2.py:454: pass
- .venv/lib/python3.12/site-packages/transformers/models/cohere2/configuration_cohere2.py:41: `inputs_ids` passed when calling [`CohereModel`]
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_convbert.py:212: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_convbert.py:573: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_convbert.py:708: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_convbert.py:763: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_convbert.py:1121: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_tf_convbert.py:359: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_tf_convbert.py:639: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_tf_convbert.py:664: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_tf_convbert.py:760: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_tf_convbert.py:762: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_tf_convbert.py:775: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/convbert/modeling_tf_convbert.py:821: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/convbert/configuration_convbert.py:42: the `inputs_ids` passed when calling [`ConvBertModel`] or [`TFConvBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/convbert/configuration_convbert.py:62: The vocabulary size of the `token_type_ids` passed when calling [`ConvBertModel`] or [`TFConvBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/convbert/tokenization_convbert.py:443: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/ernie/modeling_ernie.py:97: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/ernie/modeling_ernie.py:409: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/ernie/modeling_ernie.py:477: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/ernie/modeling_ernie.py:1455: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/ernie/configuration_ernie.py:43: `inputs_ids` passed when calling [`ErnieModel`] or [`TFErnieModel`].
- .venv/lib/python3.12/site-packages/transformers/models/ernie/configuration_ernie.py:63: The vocabulary size of the `token_type_ids` passed when calling [`ErnieModel`] or [`TFErnieModel`].
- .venv/lib/python3.12/site-packages/transformers/models/imagegpt/modeling_imagegpt.py:124: pass  # array is used to initialize only part of the pointer so sizes won't match
- .venv/lib/python3.12/site-packages/transformers/models/imagegpt/modeling_imagegpt.py:470: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with "
- .venv/lib/python3.12/site-packages/transformers/models/imagegpt/modeling_imagegpt.py:597: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/imagegpt/modeling_imagegpt.py:654: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/imagegpt/modeling_imagegpt.py:825: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/imagegpt/modeling_imagegpt.py:954: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/imagegpt/image_processing_imagegpt.py:198: passing in images with pixel values between 0 and 1, set `do_normalize=False`.
- .venv/lib/python3.12/site-packages/transformers/models/imagegpt/configuration_imagegpt.py:46: `inputs_ids` passed when calling [`ImageGPTModel`] or [`TFImageGPTModel`].
- .venv/lib/python3.12/site-packages/transformers/models/qwen3_moe/modeling_qwen3_moe.py:694: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3_moe/modeling_qwen3_moe.py:698: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3_moe/modular_qwen3_moe.py:123: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3_moe/modular_qwen3_moe.py:183: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3_moe/modular_qwen3_moe.py:278: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3_moe/modular_qwen3_moe.py:282: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3_moe/modular_qwen3_moe.py:286: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3_moe/configuration_qwen3_moe.py:38: `inputs_ids` passed when calling [`Qwen3MoeModel`]
- .venv/lib/python3.12/site-packages/transformers/models/pvt/image_processing_pvt.py:170: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/xlstm/configuration_xlstm.py:73: `inputs_ids` passed when calling [`xLSTMModel`]. Defaults to the GPT2-NeoX tokenizer size.
- .venv/lib/python3.12/site-packages/transformers/models/xlstm/modeling_xlstm.py:229: # we need the denominator and the overall max state for the backward pass
- .venv/lib/python3.12/site-packages/transformers/models/xlstm/modeling_xlstm.py:782: """Forward pass of the mLSTM backend.
- .venv/lib/python3.12/site-packages/transformers/models/xlstm/modeling_xlstm.py:1320: >>> # Prepare a cache class and pass it to model's forward
- .venv/lib/python3.12/site-packages/transformers/models/xlstm/modeling_xlstm.py:1538: attention_mask=None,  # not used but needed, otherwise generate complains when passing tokenizer inputs
- .venv/lib/python3.12/site-packages/transformers/models/dbrx/configuration_dbrx.py:141: the `inputs_ids` passed when calling [`DbrxModel`].
- .venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:220: f"Instantiating {self.__class__.__name__} without passing a `block_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:317: untouched. The only required change would be on the forward pass where it
- .venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:324: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:379: # TODO: These transpose are quite inefficient but Flash Attention requires the layout
- .venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:442: `DbrxAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:458: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:913: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.py:177: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.py:196: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/pegasus_x/modeling_pegasus_x.py:200: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/pegasus_x/modeling_pegasus_x.py:220: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/pegasus_x/modeling_pegasus_x.py:1068: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/pegasus_x/modeling_pegasus_x.py:1249: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/pegasus_x/modeling_pegasus_x.py:1261: shape `(batch_size, sequence_length, hidden_size)`, *optional*): Optionally, instead of passing
- .venv/lib/python3.12/site-packages/transformers/models/pegasus_x/modeling_pegasus_x.py:1262: `input_ids` you can choose to directly pass an embedded representation. This is useful if you want more
- .venv/lib/python3.12/site-packages/transformers/models/pegasus_x/modeling_pegasus_x.py:1313: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/pegasus_x/modeling_pegasus_x.py:1529: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/pegasus_x/configuration_pegasus_x.py:38: the `inputs_ids` passed when calling [`PegasusXModel`].
- .venv/lib/python3.12/site-packages/transformers/models/dpt/modular_dpt.py:294: "Make sure that you pass in as many target sizes as the batch dimension of the predicted depth"
- .venv/lib/python3.12/site-packages/transformers/models/dpt/configuration_dpt.py:77: - "add" passes the information from the CLS token to all other tokens by adding the representations.
- .venv/lib/python3.12/site-packages/transformers/models/dpt/configuration_dpt.py:78: - "project" passes information to the other tokens by concatenating the readout to all other tokens before
- .venv/lib/python3.12/site-packages/transformers/models/dpt/configuration_dpt.py:120: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt_fast.py:285: # TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt_fast.py:292: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt_fast.py:406: "Make sure that you pass in as many target sizes as the batch dimension of the predicted depth"
- .venv/lib/python3.12/site-packages/transformers/models/dpt/modeling_dpt.py:1040: raise NotImplementedError("Training is not implemented yet")
- .venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt.py:433: # be passed in as positional arguments.
- .venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt.py:464: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt.py:610: # TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt.py:617: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt.py:663: "Make sure that you pass in as many target sizes as the batch dimension of the predicted depth"
- .venv/lib/python3.12/site-packages/transformers/models/llava/modeling_llava.py:47: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava/modeling_llava.py:73: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava/modeling_llava.py:508: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/llava/image_processing_llava_fast.py:105: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/llava/image_processing_llava.py:166: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/llava/image_processing_llava.py:305: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/llava/image_processing_llava.py:378: # we don't pass `do_pad` here since LLaVa uses a custom padding to a square
- .venv/lib/python3.12/site-packages/transformers/models/nougat/tokenization_nougat_fast.py:313: # backwards pass, at most 5 lines
- .venv/lib/python3.12/site-packages/transformers/models/nougat/tokenization_nougat_fast.py:327: # forward pass, at most 5 lines
- .venv/lib/python3.12/site-packages/transformers/models/nougat/tokenization_nougat_fast.py:356: pass
- .venv/lib/python3.12/site-packages/transformers/models/nougat/tokenization_nougat_fast.py:537: # TODO Come up with footnote formatting inside a table
- .venv/lib/python3.12/site-packages/transformers/models/nougat/tokenization_nougat_fast.py:602: Optional number of workers to pass to leverage multiprocessing (postprocessing several texts in
- .venv/lib/python3.12/site-packages/transformers/models/vits/modeling_vits.py:53: The log-mel spectrogram predicted at the output of the flow model. This spectrogram is passed to the Hi-Fi
- .venv/lib/python3.12/site-packages/transformers/models/vits/modeling_vits.py:1323: raise NotImplementedError("Training of VITS is not supported yet.")
- .venv/lib/python3.12/site-packages/transformers/models/vits/configuration_vits.py:37: `inputs_ids` passed to the forward method of [`VitsModel`].
- .venv/lib/python3.12/site-packages/transformers/models/timesformer/modeling_timesformer.py:578: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/myt5/tokenization_myt5.py:265: Create a mask from the two sequences passed to be used in a sequence-pair classification task. MyT5 does not
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:130: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:225: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:232: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:284: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:374: `DiffLlamaAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:749: pass
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:757: pass
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/configuration_diffllama.py:37: `inputs_ids` passed when calling [`DiffLlamaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:51: pass
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:67: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:162: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:169: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:221: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:311: `DiffLlamaAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:421: pass
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:425: pass
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:429: pass
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:433: pass
- .venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:437: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/processing_qwen2_5_vl.py:254: Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/processing_qwen2_5_vl.py:256: Whether or not to clean up the tokenization spaces. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/processing_qwen2_5_vl.py:258: Additional arguments to be passed to the tokenizer's `batch_decode method`.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:486: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:576: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:614: f"Instantiating {self.__class__.__name__} without passing `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:687: position_ids=position_ids,  # pass positions for FA2
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:854: # NOTE: we need to pass text position ids for packing. Qwen2-VL uses 3D positions
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:857: # 1. User specifically passed packed `position_ids` and no attention mask.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:862: #    prepended by us when creating positions so that the mask is constructed correctly. NOTE: failing to pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1349: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1602: These parameters are not passed through the processor to avoid unpredictable impacts from interface modifications.
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:60: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:130: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:134: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:177: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:342: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:652: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:846: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/configuration_qwen2_5_vl.py:83: `inputs_ids` passed when calling [`Qwen2_5_VLModel`]
- .venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/configuration_qwen2_5_vl.py:261: # TODO: @raushan update config in the hub
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/configuration_ctrl.py:37: `inputs_ids` passed when calling [`CTRLModel`] or [`TFCTRLModel`].
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_ctrl.py:292: If `past_key_values` is used, only input IDs that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_ctrl.py:346: "You should pass an instance of `DynamicCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_ctrl.py:478: If `past_key_values` is used, only input IDs that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_ctrl.py:564: # Some generation methods already pass only the last input ID
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_ctrl.py:583: guess the padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_ctrl.py:618: If `past_key_values` is used, only input IDs that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_ctrl.py:655: >>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_ctrl.py:689: >>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py:298: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py:370: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py:484: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py:486: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py:499: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py:517: If `past` is used, only input IDs that do not have their past calculated should be passed as `input_ids`.
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py:526: given to this model should not be passed as input ids as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py:554: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py:800: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/gemma2/modular_gemma2.py:60: `inputs_ids` passed when calling [`Gemma2Model`]
- .venv/lib/python3.12/site-packages/transformers/models/gemma2/modular_gemma2.py:207: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma2/modular_gemma2.py:569: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma2/modular_gemma2.py:573: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma2/configuration_gemma2.py:36: `inputs_ids` passed when calling [`Gemma2Model`]
- .venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:583: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:587: pass
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_flax_blenderbot.py:192: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_flax_blenderbot.py:898: # make sure initialization pass will work for FlaxBlenderbotForSequenceClassificationModule
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_flax_blenderbot.py:1093: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_flax_blenderbot.py:1106: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_flax_blenderbot.py:1107: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_flax_blenderbot.py:1361: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_flax_blenderbot.py:1374: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_flax_blenderbot.py:1375: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/tokenization_blenderbot_fast.py:57: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/tokenization_blenderbot_fast.py:248: Create a mask from the two sequences passed to be used in a sequence-pair classification task. Blenderbot does not
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_tf_blenderbot.py:546: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_tf_blenderbot.py:548: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_tf_blenderbot.py:561: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_tf_blenderbot.py:749: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_tf_blenderbot.py:953: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_tf_blenderbot.py:1156: # If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_tf_blenderbot.py:1163: # If the user passed a TFBaseModelOutput for encoder_outputs, we wrap it in a tuple when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_blenderbot.py:179: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_blenderbot.py:199: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_blenderbot.py:757: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_blenderbot.py:943: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_blenderbot.py:955: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_blenderbot.py:1010: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/modeling_blenderbot.py:1233: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/configuration_blenderbot.py:46: the `inputs_ids` passed when calling [`BlenderbotModel`] or [`TFBlenderbotModel`].
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/tokenization_blenderbot.py:98: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/blenderbot/tokenization_blenderbot.py:367: Create a mask from the two sequences passed to be used in a sequence-pair classification task. Blenderbot does not
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/feature_extraction_kyutai_speech_to_text.py:133: The sampling rate at which the `audio` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/feature_extraction_kyutai_speech_to_text.py:145: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py:112: The sampling rate at which the `audio` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py:124: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py:217: pass
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py:221: pass
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py:303: # this should be passed to the model kwargs for the input preparation
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py:444: # TODO: @eustlb, this should be standardized
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py:472: # TODO: @eustlb, this should be standardized
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py:489: # TODO: @eustlb, we should have per-batch-idx values
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/configuration_kyutai_speech_to_text.py:41: `input_ids` passed when calling the model.
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:149: Hidden states are cached from the previous call to the KyutaiSpeechToTextConv1d forward pass, given the padding size.
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:167: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:392: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:498: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:502: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:509: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:559: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:621: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:625: `KyutaiSpeechToTextAttention` as the weights of the module stays untouched. The only changes are on the forward pass to 
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:643: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:871: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:1169: # this should be passed to the model kwargs for the input preparation
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:1309: # TODO: @eustlb, this should be standardized
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:1337: # TODO: @eustlb, this should be standardized
- .venv/lib/python3.12/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py:1354: # TODO: @eustlb, we should have per-batch-idx values
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py:848: # init input tensors if not passed
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py:869: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py:953: # make sure `token_type_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py:957: # make sure `position_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta.py:83: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta.py:229: Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLM-RoBERTa does
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta.py:260: # TODO check if the t5/llama PR also applies here
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py:153: Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLM-RoBERTa does
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/configuration_xlm_roberta.py:43: the `inputs_ids` passed when calling [`XLMRobertaModel`] or [`TFXLMRobertaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/configuration_xlm_roberta.py:63: The vocabulary size of the `token_type_ids` passed when calling [`XLMRobertaModel`] or
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:101: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:293: # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:527: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:595: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1287: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py:86: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py:88: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py:101: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py:136: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py:465: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py:620: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py:788: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py:913: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/granite_speech/processing_granite_speech.py:68: # TODO (@alex-jw-brooks); we should add a util to get_num_audio_tokens
- .venv/lib/python3.12/site-packages/transformers/models/granite_speech/modeling_granite_speech.py:48: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/granite_speech/modeling_granite_speech.py:166: # TODO (@avihu111) find a fast alternative to einsum
- .venv/lib/python3.12/site-packages/transformers/models/granite_speech/modeling_granite_speech.py:383: # TODO (@alex-jw-brooks) add an example to this docstring once models are released
- .venv/lib/python3.12/site-packages/transformers/models/granite_speech/modeling_granite_speech.py:490: # input feature values to be passed to the model
- .venv/lib/python3.12/site-packages/transformers/models/granite_speech/modeling_granite_speech.py:499: Adds the audio token to the model's LLM vocabulary so that we can pass it
- .venv/lib/python3.12/site-packages/transformers/models/granite_speech/feature_extraction_granite_speech.py:81: # TODO (@alex-jw-brooks): Currently input_features_mask is not
- .venv/lib/python3.12/site-packages/transformers/models/granite_speech/feature_extraction_granite_speech.py:97: Compute the Mel features to be passed to the conformer encoder.
- .venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:53: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:86: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:365: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:566: # avoiding passing the attention_mask, which is equivalent to attending to the full sequence
- .venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:736: For efficiency, we only pass through the vision_model's forward the real images by
- .venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:924: >>> # Note that passing the image urls (instead of the actual pil images) to the processor is also possible
- .venv/lib/python3.12/site-packages/transformers/models/idefics3/processing_idefics3.py:273: f"The total number of {self.image_token} tokens in the prompts should be the same as the number of images passed."
- .venv/lib/python3.12/site-packages/transformers/models/idefics3/processing_idefics3.py:351: f"Found {sum(n_images_in_text)} {self.image_token} tokens in the text but no images were passed."
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:79: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:126: query_pass = query[..., self.rotary_ndims :]
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:128: key_pass = key[..., self.rotary_ndims :]
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:132: query = torch.cat((query, query_pass), dim=-1).contiguous()
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:133: key = torch.cat((key, key_pass), dim=-1).contiguous()
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:453: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/configuration_gpt_neox_japanese.py:38: represented by the `inputs_ids` passed when calling [`GPTNeoXJapanese`].
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:75: Attention mask used in the model's forward pass to avoid performing attention on padding token indices.
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:79: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:86: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:90: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:94: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:466: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:942: pass
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:1239: # do not pass cache object down the line for encoder stack
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:1603: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:1612: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/udop/modeling_udop.py:1817: # Encode if needed (training, first prediction pass)
- .venv/lib/python3.12/site-packages/transformers/models/udop/tokenization_udop.py:112: Python's tokenizer, this method will raise `NotImplementedError`.
- .venv/lib/python3.12/site-packages/transformers/models/udop/tokenization_udop.py:117: **kwargs: passed to the `self.tokenize()` method
- .venv/lib/python3.12/site-packages/transformers/models/udop/tokenization_udop.py:198: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/udop/tokenization_udop.py:365: Create a mask from the two sequences passed to be used in a sequence-pair classification task. T5 does not make
- .venv/lib/python3.12/site-packages/transformers/models/udop/tokenization_udop.py:916: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/udop/tokenization_udop.py:1043: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/udop/tokenization_udop_fast.py:111: Python's tokenizer, this method will raise `NotImplementedError`.
- .venv/lib/python3.12/site-packages/transformers/models/udop/tokenization_udop_fast.py:116: **kwargs: passed to the `self.tokenize()` method
- .venv/lib/python3.12/site-packages/transformers/models/udop/tokenization_udop_fast.py:986: Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLM-RoBERTa does
- .venv/lib/python3.12/site-packages/transformers/models/udop/processing_udop.py:67: Additionally, it also supports passing `text_target` and `text_pair_target` to the tokenizer, which can be used to
- .venv/lib/python3.12/site-packages/transformers/models/udop/processing_udop.py:94: [`UdopImageProcessor`] was initialized with `apply_ocr` set to `True`, it passes the obtained words and
- .venv/lib/python3.12/site-packages/transformers/models/udop/processing_udop.py:97: to `False`, it passes the words (`text`/``text_pair`) and `boxes` specified by the user along with the
- .venv/lib/python3.12/site-packages/transformers/models/udop/processing_udop.py:101: Alternatively, one can pass `text_target` and `text_pair_target` to prepare the targets of UDOP.
- .venv/lib/python3.12/site-packages/transformers/models/udop/configuration_udop.py:37: `inputs_ids` passed when calling [`UdopForConditionalGeneration`].
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modular_qwen3.py:53: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modular_qwen3.py:57: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modular_qwen3.py:114: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modular_qwen3.py:118: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modular_qwen3.py:122: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modular_qwen3.py:156: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modular_qwen3.py:160: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modular_qwen3.py:164: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:510: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:514: pass
- .venv/lib/python3.12/site-packages/transformers/models/qwen3/configuration_qwen3.py:39: `inputs_ids` passed when calling [`Qwen3Model`]
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modeling_ovis2.py:48: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modeling_ovis2.py:74: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modeling_ovis2.py:376: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modeling_ovis2.py:884: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/image_processing_ovis2.py:337: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modular_ovis2.py:46: pass
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modular_ovis2.py:50: pass
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modular_ovis2.py:54: pass
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modular_ovis2.py:58: pass
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modular_ovis2.py:67: raise NotImplementedError("Not needed for Ovis2")
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modular_ovis2.py:81: pass
- .venv/lib/python3.12/site-packages/transformers/models/ovis2/modular_ovis2.py:85: pass
- .venv/lib/python3.12/site-packages/transformers/models/donut/modeling_donut_swin.py:49: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/donut/modeling_donut_swin.py:72: pooler_output (`torch.FloatTensor` of shape `(batch_size, hidden_size)`, *optional*, returned when `add_pooling_layer=Tr
- .venv/lib/python3.12/site-packages/transformers/models/donut/modeling_donut_swin.py:74: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/donut/modeling_donut_swin.py:102: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/donut/modeling_donut_swin.py:616: pass
- .venv/lib/python3.12/site-packages/transformers/models/donut/image_processing_donut.py:337: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/feature_extraction_speech_to_text.py:224: For Speech2TextTransformer models, `attention_mask` should always be passed for batched inference, to
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/feature_extraction_speech_to_text.py:236: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/feature_extraction_speech_to_text.py:251: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:257: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:395: # TODO: change copy when applying cache class
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:517: # TODO: tests would need a rewrite to check for correct implementation
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:518: # Current tests always assume certain inputs to be passed
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:824: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:836: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:881: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:975: # 2d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:999: # 4d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py:1143: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:206: # model attribute in the forward pass. This is extremely forbidden in TF, which wants forward calls to be
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:662: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:664: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:677: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:750: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:1065: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:1256: # If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:1263: # If the user passed a TFBaseModelOutput for encoder_outputs, we wrap it in a tuple when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:1417: # TODO (Joao): investigate why Speech2Text has numerical issues in XLA generate
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:1571: "input_features": None,  # needs to be passed to make Keras.layer.__call__ happy
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/tokenization_speech_to_text.py:78: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/tokenization_speech_to_text.py:94: Additional keyword arguments passed along to [`PreTrainedTokenizer`]
- .venv/lib/python3.12/site-packages/transformers/models/speech_to_text/configuration_speech_to_text.py:38: the `inputs_ids` passed when calling [`Speech2TextModel`]
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:233: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:509: target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)` in the forward pass. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:512: target_sequence_length)` to `(batch_size * num_codebooks, target_sequence_length)` prior to passing them as
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:567: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:663: # 2d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:687: # 4d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:773: target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)` in the forward pass. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:776: target_sequence_length)` to `(batch_size * num_codebooks, target_sequence_length)` prior to passing them as
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:902: target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)` in the forward pass. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:905: target_sequence_length)` to `(batch_size * num_codebooks, target_sequence_length)` prior to passing them as
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1142: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1143: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1159: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1166: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1170: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1176: Streamer object that will be used to stream the generated sequences. Generated tokens are passed
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1276: # stash the delay mask so that we don't have to recompute it in each forward pass
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1452: "The selected decoder is not prepared for the encoder hidden states to be passed. Please see the "
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1534: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1679: "passed to `.from_sub_models_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1730: target_sequence_length)` to `(batch_size, num_codebooks, target_sequence_length)` in the forward pass. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1733: target_sequence_length)` to `(batch_size * num_codebooks, target_sequence_length)` prior to passing them as
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:1938: # we also allow the user to pass it under `input_ids`, if the encoder does not use it as the main input.
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:2102: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:2187: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:2188: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:2204: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:2211: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:2215: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:2221: Streamer object that will be used to stream the generated sequences. Generated tokens are passed
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:2321: # stash the delay mask so that we don't have to recompute in each forward pass
- .venv/lib/python3.12/site-packages/transformers/models/musicgen/configuration_musicgen.py:39: represented by the `inputs_ids` passed when calling [`MusicgenDecoder`].
- .venv/lib/python3.12/site-packages/transformers/models/cvt/modeling_tf_cvt.py:61: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/cvt/modeling_tf_cvt.py:480: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/barthez/tokenization_barthez.py:35: # TODO this class is useless. This is the most standard sentencpiece model. Let's find which one is closest and nuke thi
- .venv/lib/python3.12/site-packages/transformers/models/barthez/tokenization_barthez.py:87: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/barthez/tokenization_barthez.py:200: Create a mask from the two sequences passed to be used in a sequence-pair classification task.
- .venv/lib/python3.12/site-packages/transformers/models/barthez/tokenization_barthez_fast.py:155: Create a mask from the two sequences passed to be used in a sequence-pair classification task.
- .venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:54: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:88: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:406: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:559: # avoiding passing the attention_mask, which is equivalent to attending to the full sequence
- .venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:1012: For efficiency, we only pass through the vision_model's forward the real images by
- .venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:1061: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:1199: >>> # Note that passing the image urls (instead of the actual pil images) to the processor is also possible
- .venv/lib/python3.12/site-packages/transformers/models/idefics2/processing_idefics2.py:231: f"The total number of {image_token} tokens in the prompts should be the same as the number of images passed."
- .venv/lib/python3.12/site-packages/transformers/models/dots1/modular_dots1.py:40: pass
- .venv/lib/python3.12/site-packages/transformers/models/dots1/modular_dots1.py:44: pass
- .venv/lib/python3.12/site-packages/transformers/models/dots1/modular_dots1.py:48: pass
- .venv/lib/python3.12/site-packages/transformers/models/dots1/modular_dots1.py:52: pass
- .venv/lib/python3.12/site-packages/transformers/models/dots1/modular_dots1.py:56: pass
- .venv/lib/python3.12/site-packages/transformers/models/dots1/modular_dots1.py:60: pass
- .venv/lib/python3.12/site-packages/transformers/models/dots1/modular_dots1.py:70: pass
- .venv/lib/python3.12/site-packages/transformers/models/dots1/modular_dots1.py:74: pass
- .venv/lib/python3.12/site-packages/transformers/models/dots1/configuration_dots1.py:35: `input_ids` passed when calling [`Dots1Model`].
- .venv/lib/python3.12/site-packages/transformers/models/dots1/configuration_dots1.py:109: base_model_tp_plan = {  # TODO: only replicate attention layers when > first_k_dense_replace
- .venv/lib/python3.12/site-packages/transformers/models/efficientloftr/image_processing_efficientloftr.py:73: Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
- .venv/lib/python3.12/site-packages/transformers/models/efficientloftr/image_processing_efficientloftr.py:242: pixel values ranging from 0 to 255. If passing in images with pixel values between 0 and 1, set
- .venv/lib/python3.12/site-packages/transformers/models/efficientloftr/image_processing_efficientloftr.py:363: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the mask")
- .venv/lib/python3.12/site-packages/transformers/models/efficientloftr/modeling_efficientloftr.py:58: num_keypoints)`, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/efficientloftr/modeling_efficientloftr.py:62: num_keypoints)`, returned when `output_attentions=True` is passed or when `config.output_attentions=True`)
- .venv/lib/python3.12/site-packages/transformers/models/cohere2_vision/modeling_cohere2_vision.py:86: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/cohere2_vision/modeling_cohere2_vision.py:112: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/cohere2_vision/modeling_cohere2_vision.py:421: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/cohere2_vision/modular_cohere2_vision.py:87: pass
- .venv/lib/python3.12/site-packages/transformers/models/cohere2_vision/modular_cohere2_vision.py:91: pass
- .venv/lib/python3.12/site-packages/transformers/models/internvl/video_processing_internvl.py:84: If `fps` is passed along with metadata, `fps` frames per second are sampled uniformty. Arguments `num_frames`
- .venv/lib/python3.12/site-packages/transformers/models/internvl/video_processing_internvl.py:110: "Please pass in `VideoMetadata` object or use a fixed `num_frames` per input video"
- .venv/lib/python3.12/site-packages/transformers/models/internvl/modular_internvl.py:77: pass
- .venv/lib/python3.12/site-packages/transformers/models/internvl/modular_internvl.py:310: pass
- .venv/lib/python3.12/site-packages/transformers/models/internvl/modular_internvl.py:457: pass
- .venv/lib/python3.12/site-packages/transformers/models/internvl/modular_internvl.py:482: pass
- .venv/lib/python3.12/site-packages/transformers/models/internvl/modular_internvl.py:649: pass
- .venv/lib/python3.12/site-packages/transformers/models/internvl/modeling_internvl.py:539: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/internvl/modeling_internvl.py:779: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/internvl/modeling_internvl.py:994: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py:100: Whether the tokenizer should phonetize the input or not. Only if a sequence of phonemes is passed to the
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py:109: Additional keyword arguments passed along to [`PreTrainedTokenizer`]
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py:210: Whether the tokenizer should phonetize the input text or not. Only if a sequence of phonemes is passed
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py:489: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py:542: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/sew_d/configuration_sew_d.py:41: `inputs_ids` passed when calling [`SEWD`].
- .venv/lib/python3.12/site-packages/transformers/models/sew_d/modeling_sew_d.py:572: # TODO: We should check if the opset_version being used to export
- .venv/lib/python3.12/site-packages/transformers/models/sew_d/modeling_sew_d.py:1418: passing `target_lang=...` to `from_pretrained(...)`.
- .venv/lib/python3.12/site-packages/transformers/models/sew_d/modeling_sew_d.py:1430: raise ValueError(f"Cannot pass `target_lang`: {target_lang} if `config.adapter_attn_dim` is not defined.")
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:204: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:421: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:428: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:467: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:734: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:762: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:857: # TODO: As of torch==2.2.0, the `attention_mask` passed to the model in `generate` is 2D and of dynamic length even when
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1033: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1098: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1131: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1257: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1336: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/falcon/configuration_falcon.py:38: `inputs_ids` passed when calling [`FalconModel`]
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:51: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:55: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:59: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:106: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:132: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:147: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:151: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:155: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:186: # 2d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:454: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/modular_sew.py:458: pass
- .venv/lib/python3.12/site-packages/transformers/models/sew/configuration_sew.py:41: `inputs_ids` passed when calling [`SEW`].
- .venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:303: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:438: # 2d mask is passed through the layers
- .venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:865: passing `target_lang=...` to `from_pretrained(...)`.
- .venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:877: raise ValueError(f"Cannot pass `target_lang`: {target_lang} if `config.adapter_attn_dim` is not defined.")
- .venv/lib/python3.12/site-packages/transformers/models/dinov3_vit/modular_dinov3_vit.py:277: pass
- .venv/lib/python3.12/site-packages/transformers/models/dinov3_vit/modular_dinov3_vit.py:281: pass
- .venv/lib/python3.12/site-packages/transformers/models/dinov3_vit/modular_dinov3_vit.py:285: pass
- .venv/lib/python3.12/site-packages/transformers/models/dinov3_vit/modular_dinov3_vit.py:289: pass
- .venv/lib/python3.12/site-packages/transformers/models/x_clip/configuration_x_clip.py:38: the `inputs_ids` passed when calling [`XCLIPModel`].
- .venv/lib/python3.12/site-packages/transformers/models/x_clip/modeling_x_clip.py:593: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/x_clip/modeling_x_clip.py:799: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/x_clip/modeling_x_clip.py:1457: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modeling_gemma3n.py:59: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modeling_gemma3n.py:90: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modeling_gemma3n.py:1531: # TODO (raushan): Fix this after RoPE refactor. For now we hack it by
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modeling_gemma3n.py:2380: # tokens anymore. Otherwise multimodal inputs should be passed to model.
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/feature_extraction_gemma3n.py:266: # TODO: The filtered mask is always exactly 3 elements longer than the mel_spectrogram. Why???
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modular_gemma3n.py:78: the `inputs_ids` passed when calling [`Gemma3nTextModel`]
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modular_gemma3n.py:184: The number of layer that share KV cache values. During the forward pass, the last `num_kv_shared_layers`
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modular_gemma3n.py:650: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modular_gemma3n.py:673: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modular_gemma3n.py:1560: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modular_gemma3n.py:1711: pass
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modular_gemma3n.py:1982: # TODO (raushan): Fix this after RoPE refactor. For now we hack it by
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/modular_gemma3n.py:2662: # tokens anymore. Otherwise multimodal inputs should be passed to model.
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/configuration_gemma3n.py:50: the `inputs_ids` passed when calling [`Gemma3nTextModel`]
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/configuration_gemma3n.py:156: The number of layer that share KV cache values. During the forward pass, the last `num_kv_shared_layers`
- .venv/lib/python3.12/site-packages/transformers/models/gemma3n/configuration_gemma3n.py:544: # passed num_labels has priority over num_classes in config_dict
- .venv/lib/python3.12/site-packages/transformers/models/llama4/processing_llama4.py:40: chat_template = "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\
- .venv/lib/python3.12/site-packages/transformers/models/llama4/modeling_llama4.py:659: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llama4/modeling_llama4.py:742: # TODO there is a different RoPE for vision encoder, defined as below
- .venv/lib/python3.12/site-packages/transformers/models/llama4/modeling_llama4.py:812: scaling=None,  # TODO Might be enforced here for TP compatibility as scaling is not just sqrt(head_dim)
- .venv/lib/python3.12/site-packages/transformers/models/llama4/modeling_llama4.py:900: freqs_ci: torch.Tensor,  # TODO move this to an attribute instead of keeping it around
- .venv/lib/python3.12/site-packages/transformers/models/llama4/modeling_llama4.py:909: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/llama4/modeling_llama4.py:1392: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:59: vision_feature_layer (``, *optional*, defaults to -1): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:60: vision_feature_select_strategy (`int`, *optional*, defaults to `"default"`): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:63: pixel_shuffle_ratio (`int`, *optional*, defaults to 0.5): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:64: projector_input_dim (`int`, *optional*, defaults to 4096): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:65: projector_output_dim (`int`, *optional*, defaults to 4096): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:66: multi_modal_projector_bias (`int`, *optional*, defaults to `False`): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:67: projector_dropout (`int`, *optional*, defaults to 0.0): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:68: attention_dropout (`int`, *optional*, defaults to 0.0): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:69: rope_theta (`int`, *optional*, defaults to 10000): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:145: by the `inputs_ids` passed when calling [`Llama4TextModel`].
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:150: intermediate_size_mlp (`int`, *optional*, defaults to 16384): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:158: head_dim (`int`, *optional*, defaults to 128): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:179: attention_dropout (`int`, *optional*, defaults to 0.0): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:180: num_experts_per_tok (`int`, *optional*, defaults to 1): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:181: num_local_experts (`int`, *optional*, defaults to 16): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:182: moe_layers (`int`, *optional*): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:183: interleave_moe_layer_step (`int`, *optional*, defaults to 1): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:184: use_qk_norm (`int`, *optional*, defaults to `True`): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:185: output_router_logits (`int`, *optional*, defaults to `False`): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:186: router_aux_loss_coef (`int`, *optional*, defaults to 0.001): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:187: router_jitter_noise (`int`, *optional*, defaults to 0.0): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:225: <TODO>
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:226: <TODO>
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:235: <TODO>
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:241: floor_scale (`int`, *optional*, defaults to 8192): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/configuration_llama4.py:242: attn_scale (`int`, *optional*, defaults to 0.1): TODO
- .venv/lib/python3.12/site-packages/transformers/models/llama4/image_processing_llama4_fast.py:200: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:182: query_rot, query_pass = torch.chunk(query_states, int(1 / self.partial_rotary_factor), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:183: key_rot, key_pass = torch.chunk(key_states, int(1 / self.partial_rotary_factor), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:185: query_states = torch.cat((query_rot, query_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:186: key_states = torch.cat((key_rot, key_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:265: """The forward pass, which is a normal `sqrt`."""
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:271: """The backward pass, which clips the `sqrt` gradient."""
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:323: # `sqrt` in order to prevent NaNs during training in bfloat16. TODO a bit annoying
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:340: # TODO refactor
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:569: pass
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:624: if use_cache and inputs_embeds.shape[1] != 1:  # TODO let's maybe only call in the `generate`?
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:688: # TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->RECURRENTGEMM
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:758: # Soft-cap the logits TODO remove if always done.
- .venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/configuration_recurrent_gemma.py:42: `inputs_ids` passed when calling [`RecurrentGemmaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/bert_japanese/tokenization_bert_japanese.py:85: Dictionary passed to the `MecabTokenizer` constructor.
- .venv/lib/python3.12/site-packages/transformers/models/bert_japanese/tokenization_bert_japanese.py:87: Dictionary passed to the `SudachiTokenizer` constructor.
- .venv/lib/python3.12/site-packages/transformers/models/bert_japanese/tokenization_bert_japanese.py:89: Dictionary passed to the `JumanppTokenizer` constructor.
- .venv/lib/python3.12/site-packages/transformers/models/bert_japanese/tokenization_bert_japanese.py:371: String passed to MeCab constructor.
- .venv/lib/python3.12/site-packages/transformers/models/bert_japanese/tokenization_bert_japanese.py:644: This should have already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/bert_japanese/tokenization_bert_japanese.py:843: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:62: TODO @thomasw21 this doesn't work as nicely due to the masking strategy, and so masking varies slightly.
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:206: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:511: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:520: # `position_ids` could have been `torch.Tensor` or `None` so defaulting pop to `False` allows to detect if users were pa
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:523: " passing `position_ids`.",
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:548: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:778: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:782: # Exception 4: If input_embeds are passed then slice it through `cache_position`, to keep only the unprocessed tokens an
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:795: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:848: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:863: # `position_ids` could have been `torch.Tensor` or `None` so defaulting pop to `False` allows to detect if users were pa
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:866: " passing `position_ids`.",
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:925: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:959: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:972: # `position_ids` could have been `torch.Tensor` or `None` so defaulting pop to `False` allows to detect if users were pa
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:975: " passing `position_ids`.",
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:1095: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:1108: # `position_ids` could have been `torch.Tensor` or `None` so defaulting pop to `False` allows to detect if users were pa
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:1111: " passing `position_ids`.",
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:1186: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_flax_bloom.py:97: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_flax_bloom.py:492: # If past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/bloom/tokenization_bloom_fast.py:49: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer, but since
- .venv/lib/python3.12/site-packages/transformers/models/bloom/tokenization_bloom_fast.py:113: # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
- .venv/lib/python3.12/site-packages/transformers/models/bloom/configuration_bloom.py:49: by the `inputs_ids` passed when calling [`BloomModel`]. Check [this
- .venv/lib/python3.12/site-packages/transformers/models/bloom/configuration_bloom.py:157: # TODO: how to do that better?
- .venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:79: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:164: # TODO(enijkamp): factor out number of logical TPU-v4 cores or make forward pass agnostic
- .venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:186: k_pass = key[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:189: q_pass = query[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:194: key = torch.cat([k_rot, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:195: query = torch.cat([q_rot, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:355: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:379: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:615: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/codegen/tokenization_codegen_fast.py:61: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer, but since
- .venv/lib/python3.12/site-packages/transformers/models/codegen/tokenization_codegen_fast.py:188: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/codegen/configuration_codegen.py:42: `inputs_ids` passed when calling [`CodeGenModel`].
- .venv/lib/python3.12/site-packages/transformers/models/codegen/configuration_codegen.py:160: # TODO: how to do that better?
- .venv/lib/python3.12/site-packages/transformers/models/codegen/tokenization_codegen.py:102: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/codegen/tokenization_codegen.py:341: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:111: `inputs_ids` passed when calling [`LlamaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:312: pass
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:368: Forward pass of the AriaCrossAttention module.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:428: Forward pass of the Projector module.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:1146: Forward pass of the Grouped MLP.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:1153: torch.Tensor: Output tensor after passing through the MLP.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:1184: Forward pass of the MoE Layer.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:1191: torch.Tensor: Output tensor after passing through the MoE layer.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:1245: pass
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:1328: pass
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:1332: pass
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:1497: >>> # Note that passing the image urls (instead of the actual pil images) to the processor is also possible
- .venv/lib/python3.12/site-packages/transformers/models/aria/modular_aria.py:1595: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/aria/configuration_aria.py:38: `inputs_ids` passed when calling [`LlamaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:122: Forward pass of the AriaCrossAttention module.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:182: Forward pass of the Projector module.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:332: Forward pass of the Grouped MLP.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:339: torch.Tensor: Output tensor after passing through the MLP.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:370: Forward pass of the MoE Layer.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:377: torch.Tensor: Output tensor after passing through the MoE layer.
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:875: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:902: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:1168: >>> # Note that passing the image urls (instead of the actual pil images) to the processor is also possible
- .venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:1266: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/blip_2/modeling_blip_2.py:1820: One can optionally pass `input_ids` to the model, which serve as a text prompt, to make the language model continue
- .venv/lib/python3.12/site-packages/transformers/models/blip_2/modeling_blip_2.py:1896: " Please pass a `device_map` that contains `language_model` to remove this warning."
- .venv/lib/python3.12/site-packages/transformers/models/blip_2/configuration_blip_2.py:124: the `inputs_ids` passed when calling the model.
- .venv/lib/python3.12/site-packages/transformers/models/blip_2/configuration_blip_2.py:236: The number of query tokens passed through the Transformer.
- .venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:68: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:75: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:363: # so we pad the tensor manually before passing it to the conv layer
- .venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:382: # TODO add support for MLM
- .venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:383: raise NotImplementedError("CanineForMaskedLM is currently not supported")
- .venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:1310: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/canine/configuration_canine.py:54: The vocabulary size of the `token_type_ids` passed when calling [`CanineModel`].
- .venv/lib/python3.12/site-packages/transformers/models/llava_next_video/image_processing_llava_next_video.py:201: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/llava_next_video/image_processing_llava_next_video.py:300: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/llava_next_video/modular_llava_next_video.py:185: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava_next_video/modular_llava_next_video.py:208: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava_next_video/modular_llava_next_video.py:260: pass
- .venv/lib/python3.12/site-packages/transformers/models/llava_next_video/modular_llava_next_video.py:709: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/llava_next_video/modeling_llava_next_video.py:54: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava_next_video/modeling_llava_next_video.py:85: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava_next_video/modeling_llava_next_video.py:911: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:180: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:200: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:804: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:987: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:999: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1054: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1255: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1280: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1599: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:596: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:598: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:611: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:718: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:807: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:998: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:1186: "passed, `input_ids` cannot be `None`. Please pass either "
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:1205: # If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:1212: # If the user passed a TFBaseModelOutput for encoder_outputs, we wrap it in a tuple when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_tf_bart.py:1625: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:46: `inputs_ids` passed when calling [`BartModel`] or [`TFBartModel`].
- .venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:204: # TODO: figure this case out.
- .venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:303: # TODO: test this.
- .venv/lib/python3.12/site-packages/transformers/models/bart/tokenization_bart_fast.py:54: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/bart/tokenization_bart_fast.py:251: Create a mask from the two sequences passed to be used in a sequence-pair classification task. BART does not
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_flax_bart.py:206: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_flax_bart.py:925: # make sure initialization pass will work for FlaxBartForSequenceClassificationModule
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_flax_bart.py:1118: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_flax_bart.py:1131: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_flax_bart.py:1132: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_flax_bart.py:1385: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_flax_bart.py:1398: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_flax_bart.py:1399: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/bart/modeling_flax_bart.py:1836: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/bart/tokenization_bart.py:92: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/bart/tokenization_bart.py:367: Create a mask from the two sequences passed to be used in a sequence-pair classification task. BART does not
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:132: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:138: decoder_ngram_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:144: decoder_ngram_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:193: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:199: decoder_ngram_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:205: decoder_ngram_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:252: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:258: hidden_states_ngram (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:264: ngram_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:290: ngram_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:304: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:310: hidden_states_ngram (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:316: ngram_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:377: based on padding_idx or by setting padding_idx to None and ensuring that the appropriate position ids are passed to
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:1083: raise ValueError("Either input_ids or inputs_embeds has to be passed.")
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:1085: raise ValueError("Make sure to only pass input_ids or inputs_embeds.")
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:1226: raise ValueError("Either `decoder_input_ids` or `decoder_inputs_embeds` has to be passed.")
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:1228: raise ValueError("Make sure to only pass `decoder_input_ids` or `decoder_inputs_embeds`.")
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/modeling_prophetnet.py:1250: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/tokenization_prophetnet.py:221: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/configuration_prophetnet.py:44: the `inputs_ids` passed when calling [`ProphetNetModel`].
- .venv/lib/python3.12/site-packages/transformers/models/prophetnet/configuration_prophetnet.py:174: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/patchtsmixer/modeling_patchtsmixer.py:313: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/patchtsmixer/modeling_patchtsmixer.py:1328: Backbone embeddings before passing through the head.
- .venv/lib/python3.12/site-packages/transformers/models/patchtsmixer/modeling_patchtsmixer.py:1441: Backbone embeddings before passing through the head.
- .venv/lib/python3.12/site-packages/transformers/models/patchtsmixer/modeling_patchtsmixer.py:1598: pass the target data with all channels, as channel Filtering for both prediction and target will be
- .venv/lib/python3.12/site-packages/transformers/models/patchtsmixer/modeling_patchtsmixer.py:1751: Backbone embeddings before passing through the head.
- .venv/lib/python3.12/site-packages/transformers/models/patchtsmixer/modeling_patchtsmixer.py:1817: pass the target data with all channels, as channel Filtering for both prediction and target will be
- .venv/lib/python3.12/site-packages/transformers/models/patchtsmixer/modeling_patchtsmixer.py:1885: Backbone embeddings before passing through the head.
- .venv/lib/python3.12/site-packages/transformers/models/patchtsmixer/modeling_patchtsmixer.py:2006: pass the target data with all channels, as channel Filtering for both prediction and target will be
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modular_falcon_mamba.py:74: `inputs_ids` passed when calling [`FalconMambaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modular_falcon_mamba.py:204: pass
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modular_falcon_mamba.py:252: # Triton expects to pass RMS weights even if they are non learnable, thus we need to create these weights here
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modular_falcon_mamba.py:502: pass
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modular_falcon_mamba.py:507: pass
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modular_falcon_mamba.py:511: pass
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modular_falcon_mamba.py:515: pass
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modular_falcon_mamba.py:537: pass
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/configuration_falcon_mamba.py:41: `inputs_ids` passed when calling [`FalconMambaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py:90: >>> # Prepare a cache class and pass it to model's forward
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py:100: # TODO (joao): add layer_device_map arg and update code in `generate` accordingly
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py:141: # This `if` blocks is only reached in multigpu and if `layer_device_map` is not passed. It is used
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py:142: # when the cache is initialized in the forward pass (e.g. FalconMamba)
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py:236: # Triton expects to pass RMS weights even if they are non learnable, thus we need to create these weights here
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py:697: If passed along, the model uses the previous state in all the blocks (which will give the output for the
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py:728: "You have to specify the `cache_position` manually when `use_cache=True` and `cache_params` is passed, "
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py:729: "you don't have to pass a `cache_params` if you are in prefilling stage because in that case it will "
- .venv/lib/python3.12/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py:862: If passed along, the model uses the previous state in all the blocks (which will give the output for the
- .venv/lib/python3.12/site-packages/transformers/models/swiftformer/modeling_tf_swiftformer.py:129: raise NotImplementedError("Drop path is not implemented in TF port")
- .venv/lib/python3.12/site-packages/transformers/models/swiftformer/modeling_tf_swiftformer.py:132: raise NotImplementedError("Drop path is not implemented in TF port")
- .venv/lib/python3.12/site-packages/transformers/models/swiftformer/modeling_tf_swiftformer.py:668: # We transpose to NHWC format and then transpose back after the full forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/configuration_visual_bert.py:38: the `inputs_ids` passed when calling [`VisualBertModel`]. Vocabulary size of the model. Defines the
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/configuration_visual_bert.py:39: different tokens that can be represented by the `inputs_ids` passed to the forward method of
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/configuration_visual_bert.py:44: Dimensionality of the visual embeddings to be passed to the model.
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/configuration_visual_bert.py:62: The vocabulary size of the `token_type_ids` passed when calling [`VisualBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/configuration_visual_bert.py:67: bypass_transformer (`bool`, *optional*, defaults to `False`):
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/configuration_visual_bert.py:68: Whether or not the model should bypass the transformer for the visual embeddings. If set to `True`, the
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/configuration_visual_bert.py:70: transformers, and then pass it to a self-attention layer.
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/configuration_visual_bert.py:109: bypass_transformer=False,
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/configuration_visual_bert.py:131: self.bypass_transformer = bypass_transformer
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/modeling_visual_bert.py:565: self.bypass_transformer = config.bypass_transformer
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/modeling_visual_bert.py:567: if self.bypass_transformer:
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/modeling_visual_bert.py:708: if self.bypass_transformer and visual_embeds is not None:
- .venv/lib/python3.12/site-packages/transformers/models/visual_bert/modeling_visual_bert.py:961: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/image_processing_llava_onevision.py:462: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/image_processing_llava_onevision.py:544: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/modular_llava_onevision.py:114: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/modular_llava_onevision.py:247: pass
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/modular_llava_onevision.py:251: pass
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/modular_llava_onevision.py:255: pass
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/modular_llava_onevision.py:746: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/image_processing_llava_onevision_fast.py:325: tuple of integers representing for multi-channel images. If passed as integer
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/modeling_llava_onevision.py:55: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/modeling_llava_onevision.py:86: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/llava_onevision/modeling_llava_onevision.py:894: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/configuration_maskformer.py:53: The configuration passed to the backbone, if unset, the configuration corresponding to
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/configuration_maskformer.py:65: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/configuration_maskformer.py:68: The configuration passed to the transformer decoder model, if unset the base config for `detr-resnet-50`
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer_fast.py:112: Some backbones need images divisible by a certain number. If not passed, it defaults to the value used in
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer_fast.py:534: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:67: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:96: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:100: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:144: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:148: pixel_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:152: transformer_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is 
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:156: hidden_states `tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:176: This output can be directly passed to [`~MaskFormerImageProcessor.post_process_semantic_segmentation`] or or
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:200: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:204: pixel_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:208: transformer_decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is 
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:212: hidden_states `tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:637: - object_queries and query_position_embeddings are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:671: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:1240: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:1515: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:1703: >>> # you can pass them to image_processor for postprocessing
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/modeling_maskformer.py:1734: >>> # you can pass them to image_processor for postprocessing
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:309: # TODO: (Amy) Move to image_transforms
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:414: Some backbones need images divisible by a certain number. If not passed, it defaults to the value used in
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:470: # We make max_size a private attribute so we can pass it as a default value in the preprocess method whilst
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:471: # `size` can still be pass in as an int
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:690: # TODO: (Amy)
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:940: A mapping between object instance ids and class ids. If passed, `segmentation_maps` is treated as an
- .venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:1100: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/configuration_zoedepth.py:49: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/configuration_zoedepth.py:63: - "add" passes the information from the CLS token to all other tokens by adding the representations.
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/configuration_zoedepth.py:64: - "project" passes information to the other tokens by concatenating the readout to all other tokens before
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/configuration_zoedepth.py:109: In case only a single configuration is passed, the model will use a single head with the specified configuration.
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/configuration_zoedepth.py:110: In case multiple configurations are passed, the model will use multiple heads with the specified configurations.
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth_fast.py:234: "required" unless the user passes `do_remove_padding=False` as input to this function.
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth_fast.py:258: "Make sure that you pass in as many target sizes as the batch dimension of the predicted depth"
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth_fast.py:266: "Either `source_sizes` should be passed in, or `do_remove_padding` should be set to False"
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth_fast.py:271: "Make sure that you pass in as many source image sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/modeling_zoedepth.py:606: The forward pass of the attractor layer. This layer predicts the new bin centers based on the previous bin centers
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/modeling_zoedepth.py:699: The forward pass of the attractor layer. This layer predicts the new bin centers based on the previous bin centers
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/modeling_zoedepth.py:926: """Forward pass
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/modeling_zoedepth.py:1305: raise NotImplementedError("Training is not implemented yet")
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:233: # TODO support align_corners=True in image_transforms.resize
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:323: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:471: "required" unless the user passes `do_remove_padding=False` as input to this function.
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:495: "Make sure that you pass in as many target sizes as the batch dimension of the predicted depth"
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:503: "Either `source_sizes` should be passed in, or `do_remove_padding` should be set to False"
- .venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:508: "Make sure that you pass in as many source image sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/modernbert_decoder/modular_modernbert_decoder.py:61: `inputs_ids` passed when calling [`ModernBertDecoderModel`]
- .venv/lib/python3.12/site-packages/transformers/models/modernbert_decoder/modular_modernbert_decoder.py:232: pass
- .venv/lib/python3.12/site-packages/transformers/models/modernbert_decoder/modular_modernbert_decoder.py:236: pass
- .venv/lib/python3.12/site-packages/transformers/models/modernbert_decoder/modular_modernbert_decoder.py:240: pass
- .venv/lib/python3.12/site-packages/transformers/models/modernbert_decoder/modular_modernbert_decoder.py:411: pass
- .venv/lib/python3.12/site-packages/transformers/models/modernbert_decoder/modular_modernbert_decoder.py:695: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/modernbert_decoder/modeling_modernbert_decoder.py:624: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/modernbert_decoder/configuration_modernbert_decoder.py:38: `inputs_ids` passed when calling [`ModernBertDecoderModel`]
- .venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:67: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:89: pooler_output (`torch.FloatTensor` of shape `(batch_size, hidden_size)`, *optional*, returned when `add_pooling_layer=Tr
- .venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:91: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:118: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:169: pass
- .venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:171: # TODO: Support arbitrary patch sizes.
- .venv/lib/python3.12/site-packages/transformers/models/bartpho/tokenization_bartpho.py:86: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/bartpho/tokenization_bartpho.py:237: Create a mask from the two sequences passed to be used in a sequence-pair classification task. BARTPho does not
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/tokenization_lxmert.py:442: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/configuration_lxmert.py:38: `inputs_ids` passed when calling [`LxmertModel`] or [`TFLxmertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/configuration_lxmert.py:66: The vocabulary size of the *token_type_ids* passed into [`BertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:61: language_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:64: vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:67: language_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `c
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:71: vision_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:75: cross_encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:104: language_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:107: vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:110: language_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `c
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:114: vision_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:118: cross_encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:151: language_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:154: vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:157: language_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `c
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:161: vision_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_lxmert.py:165: cross_encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:71: language_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:74: vision_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:77: language_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.ou
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:81: vision_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:85: cross_encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:117: language_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:120: vision_hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:123: language_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.ou
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:127: vision_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.outp
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:131: cross_encoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:812: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:998: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:1000: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:1013: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py:1066: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/moonshine/configuration_moonshine.py:38: `inputs_ids` passed when calling [`MoonshineModel`].
- .venv/lib/python3.12/site-packages/transformers/models/moonshine/modeling_moonshine.py:156: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/moonshine/modeling_moonshine.py:157: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/moonshine/modeling_moonshine.py:164: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/moonshine/modeling_moonshine.py:165: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/moonshine/modeling_moonshine.py:472: # TODO arthur, how do we separate when it cross / self coming from different layer?
- .venv/lib/python3.12/site-packages/transformers/models/moonshine/modular_moonshine.py:63: `inputs_ids` passed when calling [`MoonshineModel`].
- .venv/lib/python3.12/site-packages/transformers/models/moonshine/modular_moonshine.py:398: pass
- .venv/lib/python3.12/site-packages/transformers/models/moonshine/modular_moonshine.py:504: # TODO arthur, how do we separate when it cross / self coming from different layer?
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:103: The pre-computed word embeddings. Can only be passed if the input ids are `None`.
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:115: # when tracing the model without passing position-ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:238: stays untouched. The only required change would be on the forward pass where it needs to correctly call the public
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:245: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:687: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:806: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:1015: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:1205: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:152: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:415: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:449: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:506: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:508: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:521: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:554: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/tokenization_distilbert.py:452: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/distilbert/configuration_distilbert.py:41: the `inputs_ids` passed when calling [`DistilBertModel`] or [`TFDistilBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_tf_marian.py:125: raise NotImplementedError(f"odd embedding_dim {embedding_dim} not supported")
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_tf_marian.py:583: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_tf_marian.py:585: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_tf_marian.py:598: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_tf_marian.py:691: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_tf_marian.py:784: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_tf_marian.py:983: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_tf_marian.py:1185: # If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_tf_marian.py:1192: # If the user passed a TFBaseModelOutput for encoder_outputs, we wrap it in a tuple when return_dict=False
- .venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:45: `inputs_ids` passed when calling [`MarianModel`] or [`TFMarianModel`].
- .venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:189: # TODO: figure this case out.
- .venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:289: # TODO: test this.
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:180: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:200: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:765: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:939: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:951: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:994: # Important to apply outside of the above `if`, in case user passes `embeds`
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:1007: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:1271: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:75: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:218: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:244: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_flax_marian.py:205: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_flax_marian.py:893: # make sure initialization pass will work for FlaxMarianForSequenceClassificationModule
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_flax_marian.py:1082: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_flax_marian.py:1095: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_flax_marian.py:1096: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_flax_marian.py:1349: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_flax_marian.py:1362: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/marian/modeling_flax_marian.py:1363: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/configuration_xlm_roberta_xl.py:42: by the `inputs_ids` passed when calling [`XLMRobertaXLModel`].
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/configuration_xlm_roberta_xl.py:62: The vocabulary size of the `token_type_ids` passed when calling [`XLMRobertaXLModel`] or
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:97: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:290: # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:521: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:583: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:985: # Overwritten -- model logic breaks when `inputs_embeds` are passed from this function
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:1003: # Some generation methods already pass only the last input ID
- .venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:1268: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/sam/processing_sam.py:249: are, it converts the coordinates of the points and bounding boxes. If a user passes directly a `torch.Tensor`,
- .venv/lib/python3.12/site-packages/transformers/models/sam/image_processing_sam.py:392: # be passed in as positional arguments.
- .venv/lib/python3.12/site-packages/transformers/models/sam/image_processing_sam.py:423: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/sam/image_processing_sam.py:605: The target size the images were padded to before being passed to the model. If None, the target size is
- .venv/lib/python3.12/site-packages/transformers/models/sam/image_processing_sam.py:653: The target size the images were padded to before being passed to the model. If None, the target size is
- .venv/lib/python3.12/site-packages/transformers/models/sam/image_processing_sam.py:699: The target size the images were padded to before being passed to the model. If None, the target size is
- .venv/lib/python3.12/site-packages/transformers/models/sam/image_processing_sam.py:1185: also passed.
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:59: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:64: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:88: vision_hidden_states  (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:93: vision_attentions  (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:99: mask_decoder_attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `confi
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:197: raise NotImplementedError(f"Unsupported data format: {self.data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:692: # TODO Matt: What is going on here? Why is a non-trainable weight randomly initialized?
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:1351: better results. The points can be obtained by passing a list of list of list to the processor that will
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:1354: input point), the third dimension is the number of points per segmentation mask (it is possible to pass
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:1356: coordinates of the point. If a different number of points is passed either for each image, or for each
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:1374: much better generated masks. The boxes can be obtained by passing a list of list of list to the processor,
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:1513: Returns the image embeddings by passing the pixel values through the vision encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:1543: Returns the prompt embeddings by passing the input points, labels, boxes and masks through the prompt encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:1555: processor. users can also pass manually the input boxes.
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:1614: # Ensures that later checks pass even with an all-None shape from the serving signature
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:1654: " if you want to pass multiple points for the same image, make sure that you passed ",
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:75: vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:80: vision_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `con
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:86: mask_decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or whe
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:160: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:1154: Returns the image embeddings by passing the pixel values through the vision encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:1176: Returns the prompt embeddings by passing the input points, labels, boxes and masks through the prompt encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:1188: processor. users can also pass manually the input boxes.
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:1218: better results. The points can be obtained by passing a list of list of list to the processor that will
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:1221: per input point), the third dimension is the number of points per segmentation mask (it is possible to pass
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:1223: coordinates of the point. If a different number of points is passed either for each image, or for each
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:1241: much better generated masks. The boxes can be obtained by passing a list of list of list to the processor,
- .venv/lib/python3.12/site-packages/transformers/models/sam/modeling_sam.py:1338: " if you want to pass multiple points for the same image, make sure that you passed ",
- .venv/lib/python3.12/site-packages/transformers/models/sam/image_processing_sam_fast.py:470: The target size the images were padded to before being passed to the model. If None, the target size is
- .venv/lib/python3.12/site-packages/transformers/models/sam/image_processing_sam_fast.py:738: also passed.
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modeling_got_ocr2.py:364: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modeling_got_ocr2.py:488: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modeling_got_ocr2.py:515: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modeling_got_ocr2.py:837: # Otherwise we need pixel values to be passed to model
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/image_processing_got_ocr2.py:279: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/processing_got_ocr2.py:117: logger.warning("Multi-page inference is enabled but only one image is passed.")
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modular_got_ocr2.py:234: pass
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modular_got_ocr2.py:238: pass
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modular_got_ocr2.py:252: pass
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modular_got_ocr2.py:256: pass
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modular_got_ocr2.py:281: pass
- .venv/lib/python3.12/site-packages/transformers/models/got_ocr2/modular_got_ocr2.py:285: pass
- .venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit_fast.py:206: # TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit_fast.py:213: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit.py:301: # be passed in as positional arguments.
- .venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit.py:330: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit.py:333: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit.py:476: # TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit.py:483: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/beit/modeling_flax_beit.py:56: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/beit/modeling_flax_beit.py:60: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/models/dia/processing_dia.py:167: # TODO: dac with batching is currently broken, but non-batch is working
- .venv/lib/python3.12/site-packages/transformers/models/dia/processing_dia.py:177: # compute non-padded forward pass; one extra bos (and eos if training) is added
- .venv/lib/python3.12/site-packages/transformers/models/dia/processing_dia.py:319: # TODO: see above, dac doesn't work in batches yet
- .venv/lib/python3.12/site-packages/transformers/models/dia/processing_dia.py:373: # TODO: @eustlb, this should be in AudioProcessor
- .venv/lib/python3.12/site-packages/transformers/models/dia/feature_extraction_dia.py:99: The sampling rate at which the `audio` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/dia/feature_extraction_dia.py:111: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/dia/generation_dia.py:219: # Depending on cache usage we need to pass all or just one
- .venv/lib/python3.12/site-packages/transformers/models/dia/generation_dia.py:331: # logit matrix. This can save a lot of memory during the first forward pass. Note that assisted decoding
- .venv/lib/python3.12/site-packages/transformers/models/dia/modular_dia.py:99: pass
- .venv/lib/python3.12/site-packages/transformers/models/dia/modular_dia.py:103: pass
- .venv/lib/python3.12/site-packages/transformers/models/dia/modular_dia.py:107: pass
- .venv/lib/python3.12/site-packages/transformers/models/dia/modular_dia.py:613: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput
- .venv/lib/python3.12/site-packages/transformers/models/dia/modeling_dia.py:798: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput
- .venv/lib/python3.12/site-packages/transformers/models/dia/configuration_dia.py:54: `inputs_ids` passed when calling [`DiaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/dia/configuration_dia.py:176: `inputs_ids` passed when calling [`DiaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/glm4/configuration_glm4.py:31: `inputs_ids` passed when calling [`Glm4Model`]
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modular_glm4.py:39: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modular_glm4.py:92: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modular_glm4.py:126: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modular_glm4.py:130: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modeling_glm4.py:189: q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modeling_glm4.py:190: k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modeling_glm4.py:197: q_embed = torch.cat([q_embed, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modeling_glm4.py:198: k_embed = torch.cat([k_embed, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modeling_glm4.py:508: pass
- .venv/lib/python3.12/site-packages/transformers/models/glm4/modeling_glm4.py:512: pass
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:66: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:70: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:91: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:95: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:120: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:124: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:539: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:771: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:798: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:867: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:869: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:882: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:1167: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:1175: interpolation flag passed during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py:1272: interpolation flag passed during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_vit_mae.py:805: interpolation flag passed during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/vit_mae/modeling_vit_mae.py:891: interpolation flag passed during the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/plbart/configuration_plbart.py:42: `inputs_ids` passed when calling [`PLBartModel`].
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:364: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:384: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:603: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:903: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:915: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:970: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:1199: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:1509: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modular_plbart.py:56: pass
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modular_plbart.py:263: pass
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modular_plbart.py:267: pass
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modular_plbart.py:373: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/plbart/modular_plbart.py:581: pass
- .venv/lib/python3.12/site-packages/transformers/models/plbart/tokenization_plbart.py:90: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/plbart/tokenization_plbart.py:309: Create a mask from the two sequences passed to be used in a sequence-pair classification task. PLBart does not
- .venv/lib/python3.12/site-packages/transformers/models/bit/image_processing_bit.py:200: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/starcoder2/configuration_starcoder2.py:39: `inputs_ids` passed when calling [`Starcoder2Model`]
- .venv/lib/python3.12/site-packages/transformers/models/starcoder2/modeling_starcoder2.py:472: pass
- .venv/lib/python3.12/site-packages/transformers/models/starcoder2/modeling_starcoder2.py:476: pass
- .venv/lib/python3.12/site-packages/transformers/models/starcoder2/modular_starcoder2.py:142: pass
- .venv/lib/python3.12/site-packages/transformers/models/starcoder2/modular_starcoder2.py:222: pass
- .venv/lib/python3.12/site-packages/transformers/models/starcoder2/modular_starcoder2.py:226: pass
- .venv/lib/python3.12/site-packages/transformers/models/starcoder2/modular_starcoder2.py:230: pass
- .venv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:65: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:74: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:105: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:952: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:1109: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:1121: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:1162: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:1578: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/clipseg/configuration_clipseg.py:37: by the `inputs_ids` passed when calling [`CLIPSegModel`].
- .venv/lib/python3.12/site-packages/transformers/models/clipseg/modeling_clipseg.py:506: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/clipseg/modeling_clipseg.py:1233: raise ValueError("Make sure to pass as many prompt texts as there are query images")
- .venv/lib/python3.12/site-packages/transformers/models/clipseg/modeling_clipseg.py:1241: raise ValueError("Make sure to pass as many prompt images as there are query images")
- .venv/lib/python3.12/site-packages/transformers/models/clipseg/modeling_clipseg.py:1340: "Make sure to pass as many conditional embeddings as there are query images in the batch"
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:57: should be passed.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:61: passed for batched inference.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:152: `attention_mask` should be passed.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:156: be passed for batched inference.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:167: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:181: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:68: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:73: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:461: # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:1417: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:1419: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:1432: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:1478: Optionally, instead of passing `input_values` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:86: loss (*optional*, returned when `sample_negative_indices` are passed, `torch.FloatTensor` of shape `(1,)`):
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:97: contrastive_loss (*optional*, returned when `sample_negative_indices` are passed, `torch.FloatTensor` of shape `(1,)`):
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:99: diversity_loss (*optional*, returned when `sample_negative_indices` are passed, `torch.FloatTensor` of shape `(1,)`):
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:534: # TODO: we need a refactor so that the different attention modules can get their specific kwargs
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1184: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1661: # if attention_mask is passed, make sure that padded feature vectors cannot be sampled
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1800: passing `target_lang=...` to `from_pretrained(...)`.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1812: raise ValueError(f"Cannot pass `target_lang`: {target_lang} if `config.adapter_attn_dim` is not defined.")
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py:55: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py:60: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py:89: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py:94: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py:269: [What are attention masks?](../glossary#attention-mask) .. warning:: `attention_mask` should only be passed
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py:273: passed to avoid degraded performance when doing batched inference. For such models `input_values` should
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py:274: simply be padded with 0 and passed without `attention_mask`. Be aware that these models also yield slightly
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py:387: raise NotImplementedError("At the moment only ``config.feat_extact_norm == 'layer'`` is supported")
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py:954: raise NotImplementedError("``config.do_stable_layer_norm is False`` is currently not supported.")
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:143: Additional keyword arguments passed along to [`PreTrainedTokenizer`]
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:502: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:571: Will be passed to the underlying model specific decode method.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:682: should be passed.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:686: passed for batched inference.
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:691: Additional keyword arguments passed along to [`PreTrainedTokenizer`]
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:85: [`PreTrainedTokenizer.__call__`] depending on the input modality and returns their outputs. If both modalities are passe
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:89: An audio input is passed to [`Wav2Vec2FeatureExtractor.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:91: A text input is passed to [`PreTrainedTokenizer.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:134: [`Wav2Vec2FeatureExtractor.pad`] and/or [`PreTrainedTokenizer.pad`] depending on the input modality and returns their ou
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:138: When the first argument is a dictionary containing a batch of tensors, or the `input_features` argument is present, it i
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:140: When the `label` argument is present, it is passed to [`PreTrainedTokenizer.pad`].
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/configuration_wav2vec2.py:41: the `inputs_ids` passed when calling [`Wav2Vec2Model`] or [`TFWav2Vec2Model`]. Vocabulary size of the
- .venv/lib/python3.12/site-packages/transformers/models/wav2vec2/configuration_wav2vec2.py:42: model. Defines the different tokens that can be represented by the *inputs_ids* passed to the forward
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/processing_seamless_m4t.py:67: Remaining dictionary of keyword arguments that will be passed to the feature extractor and/or the
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/processing_seamless_m4t.py:84: "Text and audios are mututally exclusive when passed to `SeamlessM4T`. Specify one or another."
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/tokenization_seamless_m4t.py:110: Additional keyword arguments to pass to the model initialization.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/tokenization_seamless_m4t.py:266: Remaining dictionary of keyword arguments that will be passed to [`PreTrainedTokenizer.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/tokenization_seamless_m4t.py:374: Create a mask from the two sequences passed to be used in a sequence-pair classification task. nllb does not
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:78: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:187: except for `decoder_input_ids` which will only be passed through the text components.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:1022: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:1609: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:1629: "You cannot pass input_ids to the encoder of the text_to_units model. Pass inputs_embeds instead."
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:1808: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:1939: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2395: forward pass because the samples are interleaved."""
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2550: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2615: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2616: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2636: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2643: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2647: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2672: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2695: """You must either specify a `tgt_lang` or pass a correct `text_decoder_input_ids` to get
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2802: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2874: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2875: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2892: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2899: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2903: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2927: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:2957: """You must either specify a `tgt_lang` or pass a correct `text_decoder_input_ids` to get
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3077: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3142: arguments at two different levels: general arguments that will be passed to both models, or prefixed arguments
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3143: that will be passed to one of them.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3169: Remaining dictionary of keyword arguments that will be passed to [`GenerationMixin.generate`]. Keyword
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3173: except for `decoder_input_ids` which will only be passed through the text components.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3215: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3243: # get decoder last hidden state - must do a pass through the text decoder
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3395: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3466: arguments at two different levels: general arguments that will be passed to both models, or prefixed arguments
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3467: that will be passed to one of them.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3490: Remaining dictionary of keyword arguments that will be passed to [`GenerationMixin.generate`]. Keyword
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3494: except for `decoder_input_ids` which will only be passed through the text components.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3535: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3573: # get decoder last hidden state - must do a pass through the text decoder
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3784: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3858: arguments at two different levels: general arguments that will be passed to both models, or prefixed arguments
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3859: that will be passed to one of them.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3893: Remaining dictionary of keyword arguments that will be passed to [`GenerationMixin.generate`]. Keyword
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3897: except for `decoder_input_ids` which will only be passed through the text components.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3948: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:3979: # get last_hidden_state from encoder - must do a pass through the speech encoder
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:4007: # get decoder last hidden state - must do a pass through the text decoder
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/configuration_seamless_m4t.py:38: the `inputs_ids` passed when calling [`~SeamlessM4TModel`], [`~SeamlessM4TForTextToSpeech`] or
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/configuration_seamless_m4t.py:42: represented by the `inputs_ids` passed when calling the Text-To-Units sub-model of [`~SeamlessM4TModel`],
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/configuration_seamless_m4t.py:206: represented by the `inputs_ids` passed when calling the vocoder of [`~SeamlessM4TModel`],
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/feature_extraction_seamless_m4t.py:199: For SeamlessM4T models, `attention_mask` should always be passed for batched inference, to avoid subtle
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/feature_extraction_seamless_m4t.py:211: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/feature_extraction_seamless_m4t.py:216: Remaining dictionary of keyword arguments that will be passed to the tokenizer or the feature
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/feature_extraction_seamless_m4t.py:228: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/tokenization_seamless_m4t_fast.py:213: Create a mask from the two sequences passed to be used in a sequence-pair classification task. nllb does not
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t/tokenization_seamless_m4t_fast.py:426: Remaining dictionary of keyword arguments that will be passed to [`PreTrainedTokenizerFast.__call__`].
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/image_processing_perceiver.py:236: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:695: >>> # you can then do a forward pass as follows:
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:740: >>> # you can then do a forward pass as follows:
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:944: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1636: raise NotImplementedError("Optical flow training is not yet supported")
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1673: created based on the inputs after preprocessing. However, autoencoding an entire video in a single forward pass is
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1676: input to the forward pass of [`PerceiverForMultimodalAutoencoding`].
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1731: # Autoencoding, don't pass inputs to the queries.
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1748: # Autoencoding, don't pass inputs to the queries.
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1755: # Autoencoding, don't pass inputs to the queries.
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1772: # Autoencoding, don't pass inputs to the queries.
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1871: raise NotImplementedError("Multimodal autoencoding training is not yet supported")
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1918: raise ValueError("Make sure to pass trainable_position_encoding_kwargs")
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1921: # We don't use the index_dims argument, as this is only known during the forward pass
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1923: raise ValueError("Make sure to pass fourier_position_encoding_kwargs")
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1942: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1947: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:1951: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:2630: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:2634: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:2638: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/modeling_perceiver.py:2773: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/models/perceiver/tokenization_perceiver.py:182: # TODO @ArthurZ refactor this as well....
- .venv/lib/python3.12/site-packages/transformers/models/deit/modeling_tf_deit.py:80: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/deit/modeling_tf_deit.py:84: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/deit/modeling_tf_deit.py:382: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deit/modeling_tf_deit.py:616: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deit/modeling_tf_deit.py:620: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deit/modeling_deit.py:470: # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
- .venv/lib/python3.12/site-packages/transformers/models/deit/image_processing_deit.py:188: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modular_smolvlm.py:95: pass
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modular_smolvlm.py:99: pass
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modular_smolvlm.py:103: pass
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modular_smolvlm.py:145: pass
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modular_smolvlm.py:149: pass
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modular_smolvlm.py:153: pass
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modular_smolvlm.py:157: pass
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modular_smolvlm.py:252: For efficiency, we only pass through the vision_model's forward the real images by
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modular_smolvlm.py:371: >>> # Note that passing the image urls (instead of the actual pil images) to the processor is also possible
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/video_processing_smolvlm.py:279: "Please pass in `VideoMetadata` object or set `do_sample_frames=False`"
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/processing_smolvlm.py:221: "Probably `video_metadata` was missing from inputs and you passed pre-sampled frames. "
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/processing_smolvlm.py:321: raise ValueError(f"We detected {n_images_in_text} tokens in the text but no images/videos were passed")
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:342: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:453: # avoiding passing the attention_mask, which is equivalent to attending to the full sequence
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:492: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:707: For efficiency, we only pass through the vision_model's forward the real images by
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:814: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:921: >>> # Note that passing the image urls (instead of the actual pil images) to the processor is also possible
- .venv/lib/python3.12/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:707: pass
- .venv/lib/python3.12/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:711: pass
- .venv/lib/python3.12/site-packages/transformers/models/gpt_oss/modular_gpt_oss.py:450: pass
- .venv/lib/python3.12/site-packages/transformers/models/gpt_oss/modular_gpt_oss.py:454: pass
- .venv/lib/python3.12/site-packages/transformers/models/gpt_oss/modular_gpt_oss.py:458: pass
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py:206: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py:304: "passed to `.from_encoder_decoder_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py:361: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py:498: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/configuration_speech_encoder_decoder.py:82: f" `decoder` sub-configurations are passed, but only {kwargs}"
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py:186: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py:594: raise ValueError("Make sure to provide `decoder_position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py:607: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py:608: # passed down to ensure cache is used. It has to be made sure that cache is marked as mutable so that
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py:811: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py:909: "passed to `.from_encoder_decoder_pretrained(...)` are set to `True` or do not pass a "
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/configuration_fuyu.py:39: `inputs_ids` passed when calling [`FuyuForCausalLM`]
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:127: # TODO Remove this logic in a subsequent release since subsequences are not supported.
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:360: self.max_position_embeddings = 16384  # TODO Can't derive this from model files: where to set it?
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:413: # Cast images to tensor as well, if only one image passed and no padding needed
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:737: raise ValueError("Make sure that you pass in as many target sizes as output sequences")
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:756: Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:758: Additional arguments to be passed to the tokenizer's `batch_decode method`.
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/image_processing_fuyu.py:130: Will be passed to the `to(...)` function of the tensors.
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/image_processing_fuyu.py:132: Will be passed to the `to(...)` function of the tensors.
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/image_processing_fuyu.py:148: pass
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/image_processing_fuyu.py:579: # TODO refer to https://github.com/ArthurZucker/transformers/blob/0f0a3fe5ca5697ee58faeb5b53f049af720b5e98/src/transform
- .venv/lib/python3.12/site-packages/transformers/models/fuyu/modeling_fuyu.py:352: # don't pass kwargs because Persimmon-backbone doesn't accept FA2 kwargs yet, TODO: raushan
- .venv/lib/python3.12/site-packages/transformers/models/decision_transformer/modeling_decision_transformer.py:425: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with "
- .venv/lib/python3.12/site-packages/transformers/models/decision_transformer/modeling_decision_transformer.py:576: "You should pass an instance of `Cache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/decision_transformer/modeling_decision_transformer.py:855: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/decision_transformer/configuration_decision_transformer.py:49: `inputs_ids` passed when calling [`DecisionTransformerModel`].
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:67: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:71: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:163: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:1053: raise NotImplementedError(f"Unsupported data format: {data_format}")
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:1339: Returns the image embeddings by passing the pixel values through the vision encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:1368: Returns the prompt embeddings by passing the input points, labels, boxes and masks through the prompt encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:1380: processor. users can also pass manually the input boxes.
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:1410: better results. The points can be obtained by passing a list of list of list to the processor that will
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:1413: per input point), the third dimension is the number of points per segmentation mask (it is possible to pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:1415: coordinates of the point. If a different number of points is passed either for each image, or for each
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modeling_sam2.py:1433: much better generated masks. The boxes can be obtained by passing a list of list of list to the processor,
- .venv/lib/python3.12/site-packages/transformers/models/sam2/processing_sam2.py:94: Additional keyword arguments to pass to the image processor.
- .venv/lib/python3.12/site-packages/transformers/models/sam2/processing_sam2.py:125: "original_sizes must be of length 1 or len(images). If you are passing a single image, you must pass a single original_s
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:112: raise NotImplementedError("No pad_image for SAM 2.")
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:115: raise NotImplementedError("No _get_preprocess_shape for SAM 2.")
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:118: raise NotImplementedError("No need to override resize for SAM 2.")
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:278: # TODO: add connected components kernel for postprocessing
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:307: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:311: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:392: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:840: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:978: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:982: pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:1222: Returns the image embeddings by passing the pixel values through the vision encoder.
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:1307: better results. The points can be obtained by passing a list of list of list to the processor that will
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:1310: per input point), the third dimension is the number of points per segmentation mask (it is possible to pass
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:1312: coordinates of the point. If a different number of points is passed either for each image, or for each
- .venv/lib/python3.12/site-packages/transformers/models/sam2/modular_sam2.py:1330: much better generated masks. The boxes can be obtained by passing a list of list of list to the processor,
- .venv/lib/python3.12/site-packages/transformers/models/sam2/image_processing_sam2_fast.py:288: also passed.
- .venv/lib/python3.12/site-packages/transformers/models/sam2/image_processing_sam2_fast.py:684: # TODO: add connected components kernel for postprocessing
- .venv/lib/python3.12/site-packages/transformers/models/lfm2/configuration_lfm2.py:33: `inputs_ids` passed when calling [`Lfm2Model`]
- .venv/lib/python3.12/site-packages/transformers/models/lfm2/modeling_lfm2.py:224: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/models/lfm2/modular_lfm2.py:56: pass
- .venv/lib/python3.12/site-packages/transformers/models/lfm2/modular_lfm2.py:60: pass
- .venv/lib/python3.12/site-packages/transformers/models/lfm2/modular_lfm2.py:182: """Returns the sequence length of the cached states. A layer index can be optionally passed."""
- .venv/lib/python3.12/site-packages/transformers/models/lfm2/modular_lfm2.py:517: pass
- .venv/lib/python3.12/site-packages/transformers/models/cpmant/configuration_cpmant.py:37: `input` passed when calling [`CpmAntModel`].
- .venv/lib/python3.12/site-packages/transformers/models/cpmant/modeling_cpmant.py:644: "You should pass an instance of `DynamicCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/modeling_voxtral.py:106: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/modeling_voxtral.py:528: # Overwritten -- we should not pass input_features when we are in cached decoding stage
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/modeling_voxtral.py:536: # input_features should only be passed when we are not in cached decoding stage
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/configuration_voxtral.py:109: # TODO: @eustlb, we do not use dropout and layerdrop, yet we need to hardcode them
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/modular_voxtral.py:39: pass
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/modular_voxtral.py:43: pass
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/modular_voxtral.py:55: # TODO: @eustlb, I would really prefer to use WhisperEncoder but it's messing with modular
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/modular_voxtral.py:263: # Overwritten -- we should not pass input_features when we are in cached decoding stage
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/modular_voxtral.py:271: # input_features should only be passed when we are not in cached decoding stage
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/processing_voxtral.py:192: f"{overlapping_keys[0] if len(overlapping_keys) == 1 else ', '.join(overlapping_keys)} load multimodal data kwarg{'s' if
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/processing_voxtral.py:286: # TODO: @eustlb, this should be moved to mistral_common + testing
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/processing_voxtral.py:322: Used to avoid silent errors when passing audio that is not in the expected sampling rate.
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/processing_voxtral.py:372: f"When passed as a list of audio, the length ({len(audio)}) must match the number of format ({len(format)})"
- .venv/lib/python3.12/site-packages/transformers/models/voxtral/processing_voxtral.py:394: f"When passed as a list of languages, the length ({len(language)}) must match the number of audio ({n_audio})"
- .venv/lib/python3.12/site-packages/transformers/models/clvp/tokenization_clvp.py:96: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/clvp/feature_extraction_clvp.py:156: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/clvp/feature_extraction_clvp.py:191: f"It is strongly recommended to pass the `sampling_rate` argument to `{self.__class__.__name__}()`. "
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:86: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:336: query_rot, query_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:340: key_rot, key_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:344: value_rot, value_pass = (
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:353: query_states = torch.cat((query_rot, query_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:354: key_states = torch.cat((key_rot, key_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:355: value_states = torch.cat((value_rot, value_pass), dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:517: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:572: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:656: Both of these vectors are concatenated and then passed to the decoder model.
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:883: input embeddings for the model. This bypasses the model's internal embedding lookup matrix.
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:1077: "You should pass an instance of `DynamicCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:1284: f"`inputs`: {inputs}` were passed alongside {input_name} which is not allowed."
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:1285: f"Make sure to either pass {inputs} or {input_name}=..."
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:1297: # Then we must subtract the positional_ids because during the forward pass it will be added anyways, so we must cancel t
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:1525: inputs_embeds for the text encoder model passed in place of `input_ids`.
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:1678: inputs_embeds for the text encoder model passed in place of `input_ids`.
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:1732: # since we will get the embeds of shape `(batch_size, seq_len, embedding_dim)` during the forward pass
- .venv/lib/python3.12/site-packages/transformers/models/clvp/modeling_clvp.py:1827: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py:621: # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/vit_hybrid/configuration_vit_hybrid.py:49: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/vit_hybrid/image_processing_vit_hybrid.py:217: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/configuration_deta.py:48: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/image_processing_deta.py:918: from 0 to 255. If passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/image_processing_deta.py:1176: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:168: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:172: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:176: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:204: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:208: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:212: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:218: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:222: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:276: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:280: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:284: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:290: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:294: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:424: # TODO fix this
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:465: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:517: # TODO find a better way of exposing other arguments
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1098: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1099: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1101: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1157: # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1181: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1253: - `position_embeddings`, `reference_points`, `spatial_shapes` and `valid_ratios` are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1291: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1697: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py:290: self.soft_bypass_mlp = nn.Linear(config.d_model, config.d_model, bias=False)
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py:305: forwarded_states += torch.tanh(self.soft_bypass_mlp(hidden_states))
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py:825: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py:829: Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py:841: router_logits (`tuple(torch.FloatTensor)`, *optional*, returned when `output_router_logits=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py:914: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py:915: "GPTSanJapaneseModel does not use `inputs_embeds`. Make sure to pass in `input_ids` instead."
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py:925: # It should passed instead of the first past_key_values.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/gptsan_japanese/configuration_gptsan_japanese.py:37: by the `inputs_ids` passed when calling [`GPTSanJapaneseModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/modeling_mega.py:66: # registering a buffer here allows model tracing when not passing optional token type IDs
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/modeling_mega.py:699: # - residual_weight is passed through sigmoid and sent through elementwise multiplication to the gated/weighted targets 
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/modeling_mega.py:701: # - attention_query is the part that is passed to the attention function
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/modeling_mega.py:1426: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/modeling_mega.py:1455: `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/modeling_mega.py:1584: # pass through mega layers
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/configuration_mega.py:42: `inputs_ids` passed when calling [`MegaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/configuration_mega.py:65: Whether to normalize before (`True`) or after (`False`) passing through Mega encoder blocks
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/configuration_mega.py:86: Whether to use the normalized feed-forward sub-layer in Mega blocks (`True`) or pass Mega encoder output
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/configuration_mega.py:103: The vocabulary size of the `token_type_ids` passed when calling [`MegaModel`]. Only used if
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mega/configuration_mega.py:127: Whether to include a hidden layer for projection between encoder outputs and LM heads (`True`) or pass
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/configuration_xlm_prophetnet.py:45: the `inputs_ids` passed when calling [`XLMProphetNetModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/configuration_xlm_prophetnet.py:175: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:264: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:270: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:275: decoder_ngram_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:281: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:287: decoder_ngram_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:293: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:301: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:306: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:349: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:355: decoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:360: decoder_ngram_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:366: decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:372: decoder_ngram_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:378: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:386: encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or wh
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:391: encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `co
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:434: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:440: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:445: ngram_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:451: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:457: ngram_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:463: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:495: past_key_values (`list[torch.FloatTensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cac
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:501: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:506: ngram_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:512: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:518: ngram_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:524: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:584: based on padding_idx or by setting padding_idx to None and ensuring that the appropriate position ids are passed to
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:1295: raise ValueError("Either input_ids or inputs_embeds has to be passed.")
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:1297: raise ValueError("Make sure to only pass input_ids or inputs_embeds.")
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:1457: raise ValueError("Either `decoder_input_ids` or `decoder_inputs_embeds` has to be passed.")
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:1459: raise ValueError("Make sure to only pass `decoder_input_ids` or `decoder_inputs_embeds`.")
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py:1998: assert encoder_outputs is not None, "`encoder_outputs` have to be passed for generation."
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py:90: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py:158: # TODO ArthurZ fairseq_ids_to_tokens should be removed
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py:227: Create a mask from the two sequences passed to be used in a sequence-pair classification task. XLMProphetNet
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nezha/configuration_nezha.py:18: *inputs_ids* passed to the forward method of [`NezhaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nezha/configuration_nezha.py:37: The vocabulary size of the *token_type_ids* passed into [`NezhaModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nezha/modeling_nezha.py:198: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nezha/modeling_nezha.py:493: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nezha/modeling_nezha.py:741: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nezha/modeling_nezha.py:746: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nezha/modeling_nezha.py:808: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nezha/modeling_nezha.py:836: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/tokenization_jukebox.py:63: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:739: Forward pass of the VQ-VAE, encodes the `raw_audio` to latent states, which are then decoded for each level.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:1039: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:1308: Number of tokens or lyrics tokens provided in a single pass.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:1501: n_passes = (length + chunk_size - 1) // chunk_size
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:1502: chunk_sizes = [*[chunk_size] * (n_passes - 1), (length - 1) % chunk_size + 1]
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:1538: # Fill up key/value cache for past context by running forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:1539: # We do so in chunks instead of doing the whole past in one forward pass to reduce max memory usage.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:1784: Encoding method of the VQVAE encoder used in the forward pass of the model. Passing functions instead of
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:1787: Decoding method of the VQVAE decoder used in the forward pass of the model. Passing functions instead of
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:2184: Applies a forward pass using the conditioning tokens. Different from the classic forward as it does not use the
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:2329: n_passes = (n_samples + split_size - 1) // split_size
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py:2335: return [None] * n_passes
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/efficientformer/modeling_efficientformer.py:710: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/efficientformer/modeling_efficientformer.py:714: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/efficientformer/image_processing_efficientformer.py:202: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/efficientformer/modeling_tf_efficientformer.py:1078: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/efficientformer/modeling_tf_efficientformer.py:1083: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/trajectory_transformer/modeling_trajectory_transformer.py:129: past_key_values (`tuple[tuple[torch.Tensor]]`, *optional*, returned when `use_cache=True` is passed or when `config.use_
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/trajectory_transformer/modeling_trajectory_transformer.py:133: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/trajectory_transformer/modeling_trajectory_transformer.py:137: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/trajectory_transformer/modeling_trajectory_transformer.py:197: their past given to this model should not be passed as `input_ids` as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/trajectory_transformer/configuration_trajectory_transformer.py:40: represented by the `trajectories` passed when calling [`TrajectoryTransformerModel`]
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:81: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:86: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:92: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:114: pooler_output (`torch.FloatTensor` of shape `(batch_size, hidden_size)`, *optional*, returned when `add_pooling_layer=Tr
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:116: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:121: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:127: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:152: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:157: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:163: reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:214: pass
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:216: # TODO: Support arbitrary patch sizes.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:931: # TODO can we simplify this?
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py:371: Create a mask from the two sequences passed to be used in a sequence-pair classification task. TAPEX does not:
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py:740: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py:950: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py:1266: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py:1345: # TODO (Qian): is it possible to revert the original cell if it is in the final answer?
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mctct/configuration_mctct.py:38: `inputs_ids` passed when calling [`MCTCTModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mctct/modeling_mctct.py:149: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mctct/feature_extraction_mctct.py:214: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mctct/feature_extraction_mctct.py:228: "It is strongly recommended to pass the ``sampling_rate`` argument to this function. "
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/configuration_transfo_xl.py:38: `inputs_ids` passed when calling [`TransfoXLModel`] or [`TFTransfoXLModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/configuration_transfo_xl.py:184: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:359: raise NotImplementedError  # Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoi
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:389: raise NotImplementedError  # Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoi
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:472: raise NotImplementedError  # Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoi
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:480: raise NotImplementedError  # Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoi
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:496: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:505: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:573: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:627: raise NotImplementedError  # Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoi
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:678: be passed as input ids as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:679: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:684: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:711: be passed as input ids as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:712: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:717: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:744: be passed as input ids as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:745: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:750: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:782: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:784: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:797: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:819: given to this model should not be passed as `input_ids` as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:826: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:909: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py:1011: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:69: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:606: be passed as input ids as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:607: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:612: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:639: be passed as input ids as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:640: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:645: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:673: be passed as input ids as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:674: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:679: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:734: given to this model should not be passed as `input_ids` as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:742: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:803: raise NotImplementedError  # Removed them to avoid maintaining dead code
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:811: raise NotImplementedError  # Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoi
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:830: pass
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:966: raise NotImplementedError  # Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoi
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py:1185: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py:817: pass
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl_utilities.py:203: a parameter passed to `AdaptiveLogSoftmaxWithLoss` constructor. Shape:
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/qdqbert/configuration_qdqbert.py:38: `inputs_ids` passed when calling [`QDQBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/qdqbert/configuration_qdqbert.py:58: The vocabulary size of the `token_type_ids` passed when calling [`QDQBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/qdqbert/modeling_qdqbert.py:188: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/qdqbert/modeling_qdqbert.py:506: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/qdqbert/modeling_qdqbert.py:788: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/qdqbert/modeling_qdqbert.py:816: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/qdqbert/modeling_qdqbert.py:1130: # Some generation methods already pass only the last input ID
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/retribert/modeling_retribert.py:105: # reproduces BERT forward pass with checkpointing
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/retribert/tokenization_retribert.py:435: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/retribert/configuration_retribert.py:38: the `inputs_ids` passed when calling [`RetriBertModel`]
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/retribert/configuration_retribert.py:58: The vocabulary size of the *token_type_ids* passed into [`BertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/graphormer/modeling_graphormer.py:69: raise NotImplementedError("Module unsupported for quant_noise.")
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/graphormer/modeling_graphormer.py:317: raise NotImplementedError("The Graphormer model only supports self attention for now.")
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/graphormer/modeling_graphormer.py:610: raise NotImplementedError("Freezing embeddings is not implemented yet.")
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/graphormer/modeling_graphormer.py:823: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/open_llama/configuration_open_llama.py:43: the `inputs_ids` passed when calling [`OpenLlamaModel`]
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/open_llama/modeling_open_llama.py:179: used to pass offsetted position ids when working with a KV-cache.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/open_llama/modeling_open_llama.py:496: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/open_llama/modeling_open_llama.py:508: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/open_llama/modeling_open_llama.py:780: # Some generation methods already pass only the last input ID
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/open_llama/modeling_open_llama.py:797: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/open_llama/modeling_open_llama.py:833: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/modeling_realm.py:196: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/modeling_realm.py:502: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/modeling_realm.py:645: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/modeling_realm.py:650: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/modeling_realm.py:706: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/modeling_realm.py:711: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/modeling_realm.py:926: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/modeling_realm.py:1267: Optionally, instead of passing `candidate_input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/configuration_realm.py:47: `inputs_ids` passed when calling [`RealmEmbedder`], [`RealmScorer`], [`RealmKnowledgeAugEncoder`], or
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/configuration_realm.py:72: The vocabulary size of the `token_type_ids` passed when calling [`RealmEmbedder`], [`RealmScorer`],
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/realm/tokenization_realm.py:494: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/speech_to_text_2/modeling_speech_to_text_2.py:515: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/speech_to_text_2/modeling_speech_to_text_2.py:527: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/speech_to_text_2/modeling_speech_to_text_2.py:753: past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/speech_to_text_2/modeling_speech_to_text_2.py:878: # Some generation methods already pass only the last input ID
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/speech_to_text_2/configuration_speech_to_text_2.py:38: the `inputs_ids` passed when calling [`Speech2TextModel`]
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/speech_to_text_2/tokenization_speech_to_text_2.py:76: Additional keyword arguments passed along to [`PreTrainedTokenizer`]
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/mmbt/modeling_mmbt.py:152: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/ernie_m/modeling_ernie_m.py:470: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/ernie_m/tokenization_ernie_m.py:317: Create the token type IDs corresponding to the sequences passed. [What are token type
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/ernie_m/configuration_ernie_m.py:37: Defines the number of different tokens that can be represented by the `inputs_ids` passed when calling
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/image_processing_tvlt.py:304: 255. If passing in frames with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/feature_extraction_tvlt.py:144: For TvltTransformer models, `attention_mask` should always be passed for batched inference, to avoid
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/feature_extraction_tvlt.py:150: The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/feature_extraction_tvlt.py:176: "It is strongly recommended to pass the `sampling_rate` argument to this function. "
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/modeling_tvlt.py:69: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/modeling_tvlt.py:73: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/modeling_tvlt.py:98: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/modeling_tvlt.py:102: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/modeling_tvlt.py:129: hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/deprecated/tvlt/modeling_tvlt.py:133: attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/camembert/tokenization_camembert_fast.py:158: Create a mask from the two sequences passed to be used in a sequence-pair classification task. CamemBERT, like
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:101: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:293: # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:527: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:595: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:756: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:1199: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_tf_camembert.py:84: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_tf_camembert.py:86: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_tf_camembert.py:99: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_tf_camembert.py:145: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_tf_camembert.py:474: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_tf_camembert.py:629: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_tf_camembert.py:797: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_tf_camembert.py:922: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/camembert/configuration_camembert.py:43: `inputs_ids` passed when calling [`CamembertModel`] or [`TFCamembertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/camembert/configuration_camembert.py:63: The vocabulary size of the `token_type_ids` passed when calling [`CamembertModel`] or [`TFCamembertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/camembert/tokenization_camembert.py:87: Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for
- .venv/lib/python3.12/site-packages/transformers/models/camembert/tokenization_camembert.py:196: # TODO decode outputs do not match between fast and slow
- .venv/lib/python3.12/site-packages/transformers/models/camembert/tokenization_camembert.py:303: Create a mask from the two sequences passed to be used in a sequence-pair classification task. CamemBERT, like
- .venv/lib/python3.12/site-packages/transformers/models/fastspeech2_conformer/modeling_fastspeech2_conformer.py:84: Speech output as a result of passing the predicted mel spectrogram through the vocoder.
- .venv/lib/python3.12/site-packages/transformers/models/pixtral/image_processing_pixtral_fast.py:47: pass
- .venv/lib/python3.12/site-packages/transformers/models/pixtral/image_processing_pixtral.py:343: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:85: # TODO maybe make it torch compatible later on. We can also just slice
- .venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:485: # pass images through initial convolution independently
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_flax_bert.py:72: hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.out
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_flax_bert.py:77: attentions (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_at
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_flax_bert.py:881: # init input tensors if not passed
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_flax_bert.py:902: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_flax_bert.py:985: # make sure `token_type_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_flax_bert.py:989: # make sure `position_ids` is correctly initialized when not passed
- .venv/lib/python3.12/site-packages/transformers/models/bert/configuration_bert.py:43: `inputs_ids` passed when calling [`BertModel`] or [`TFBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/bert/configuration_bert.py:63: The vocabulary size of the `token_type_ids` passed when calling [`BertModel`] or [`TFBertModel`].
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:169: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:342: # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:571: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:638: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:838: `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1583: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/bert/tokenization_bert.py:438: already been passed through *BasicTokenizer*.
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:372: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:524: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers"
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:840: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:964: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:1036: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:1041: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:1073: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:1075: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:1088: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py:1134: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/configuration_gpt2.py:45: `inputs_ids` passed when calling [`GPT2Model`] or [`TFGPT2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/configuration_gpt2.py:203: # TODO: how to do that better?
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:49: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer, but since
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/tokenization_gpt2.py:93: You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py:96: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py:352: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with "
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py:486: raise ValueError("Make sure to provide `position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py:500: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed down to ens
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:431: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with "
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:498: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:553: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:625: past_key_values (`tuple[tuple[torch.Tensor]]`, *optional*, returned when `use_cache=True` is passed or when `config.use_
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:801: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:848: "You should pass an instance of `Cache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1056: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1204: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1313: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1353: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1486: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1572: If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:88: pass
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:296: f"If `encoder_hidden_states` are passed, {self} has to be instantiated with "
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:392: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:478: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:593: # means that passing token_type_ids=0 yields different outputs from token_type_ids=None.
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:611: past_key_values (`list[tf.Tensor]`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:617: hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.outpu
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:622: attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_atte
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:654: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:656: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:669: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:685: If `past_key_values` is used, only input IDs that do not have their past calculated should be passed as
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:695: their past given to this model should not be passed as input ids as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:727: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py:1119: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/vivit/modeling_vivit.py:531: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/vivit/image_processing_vivit.py:314: to 255. If passing in frames with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:38: that can be represented by the `inputs_ids` passed when calling [`~SeamlessM4Tv2Model`],
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:42: represented by the `inputs_ids` passed when calling the Text-To-Units sub-model of [`~SeamlessM4Tv2Model`],
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:46: can be represented by the `char_inputs_ids` passed when calling the Text-To-Units sub-model of
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:209: represented by the `inputs_ids` passed when calling the vocoder of [`~SeamlessM4Tv2Model`],
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:388: self.t2u_variance_predictor_embed_dim = t2u_variance_predictor_embed_dim  # TODO: add to docstrings
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:389: self.t2u_variance_predictor_hidden_dim = t2u_variance_predictor_hidden_dim  # TODO: add to docstrings
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:390: self.t2u_variance_predictor_kernel_size = t2u_variance_predictor_kernel_size  # TODO: add to docstrings
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:391: self.t2u_variance_pred_dropout = t2u_variance_pred_dropout  # TODO: add to docstrings
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:75: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:236: except for `decoder_input_ids` which will only be passed through the text components.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:894: f"Instantiating a decoder {self.__class__.__name__} without passing `layer_idx` is not recommended and "
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:1474: forward pass because the samples are interleaved."""
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:1651: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:1671: "You cannot pass input_ids to the encoder of the text_to_units model. Pass inputs_embeds instead."
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:1851: "You should pass an instance of `EncoderDecoderCache` instead, e.g. "
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2147: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2255: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2599: forward pass because the samples are interleaved."""
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2758: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2823: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2824: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2844: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2851: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2855: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2880: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2903: """You must either specify a `tgt_lang` or pass a correct `text_decoder_input_ids` to get
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3017: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3090: Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3091: model's default generation configuration. You can override any `generation_config` by passing the corresponding
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3108: passed to generate matching the attributes of `generation_config` will override them. If
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3115: generation config. If a logit processor is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3119: generation config. If a stopping criteria is passed that is already created with the arguments or a
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3143: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3173: """You must either specify a `tgt_lang` or pass a correct `text_decoder_input_ids` to get
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3300: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3365: arguments at two different levels: general arguments that will be passed to both models, or prefixed arguments
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3366: that will be passed to one of them.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3392: Remaining dictionary of keyword arguments that will be passed to [`GenerationMixin.generate`]. Keyword
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3396: except for `decoder_input_ids` which will only be passed through the text components.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3438: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3460: # get decoder last hidden state - must do a pass through the text decoder
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3494: # second pass
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3656: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3727: arguments at two different levels: general arguments that will be passed to both models, or prefixed arguments
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3728: that will be passed to one of them.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3751: Remaining dictionary of keyword arguments that will be passed to [`GenerationMixin.generate`]. Keyword
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3755: except for `decoder_input_ids` which will only be passed through the text components.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3796: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3828: # get decoder last hidden state - must do a pass through the text decoder
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:3862: # second pass
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4082: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4156: arguments at two different levels: general arguments that will be passed to both models, or prefixed arguments
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4157: that will be passed to one of them.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4191: Remaining dictioy of keyword arguments that will be passed to [`GenerationMixin.generate`]. Keyword
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4195: except for `decoder_input_ids` which will only be passed through the text components.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4250: # overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4281: # get last_hidden_state from encoder - must do a pass through the speech encoder
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4304: # get decoder last hidden state - must do a pass through the text decoder
- .venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4338: # second pass
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:90: The generated audio codes. Returned if `return_audio_codes=True`. Intermediate audio "tokens" which transforms to `audio
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:117: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:145: past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:155: depth_past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:157: depth_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:159: depth_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `conf
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:184: The audio codes used as audio user prompt for the generation. Has priority over `user_input_values` and represents the a
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:186: The audio codes used as audio Moshi prompt for the generation. Has priority over `moshi_input_values` and represents the
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:395: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:501: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:505: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:512: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:562: # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:624: # TODO cyril: modular
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:628: `MoshiAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:646: # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:922: The model will output the same cache format that is fed as input. If no `past_key_values` are passed, the
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:929: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1278: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1653: The audio codes used as audio user prompt for the generation. Has priority over `user_input_values` and represents the a
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1657: The audio codes used as audio Moshi prompt for the generation. Has priority over `moshi_input_values` and represents the
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1659: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1755: # To use depth decoder forward here, we actually need oracle input ids since we're supposed to pass the true input ids
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1860: # in case inputs_embeds is passed, we might still need to create delay pattern masks
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1958: The audio codes used as audio user prompt for the generation. Has priority over `user_input_values` and represents the a
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1962: The audio codes used as audio Moshi prompt for the generation. Has priority over `moshi_input_values` and represents the
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1964: Optionally, instead of passing `input_ids` and the audio inputs you can choose to directly pass an embedded representati
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1970: If `True`, will also returns the generated audio codes, i.e the intermediate audio "tokens" which transforms to `audio_s
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:1974: Remaining dictionary of keyword arguments that are passed to the `generate` method. Refers to the
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2208: # Exception 1: when passing input_embeds, input_ids may be missing entries
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2222: # if `inputs_embeds` are passed, we only want to use them in the 1st generation step
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2452: one_input_has_been_passed = (user_input is not None) or (moshi_input is not None) or (inputs is not None)
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2459: # if one or two of the three required inputs have been passed, throws an error
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2460: if one_input_has_been_passed and (user_input is None):
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2462: "No user audio inputs have been passed alongside the other inputs. Make sure either `user_input_values` or `user_audio_c
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2464: elif one_input_has_been_passed and (moshi_input is None):
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2466: "No Moshi audio inputs have been passed alongside the other inputs. Make sure either `moshi_input_values` or `moshi_audi
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2468: elif one_input_has_been_passed and (inputs is None):
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2470: "No `input_ids` or `inputs_embeds` have been passed alongside the other inputs. Make sure `input_ids` is passed or use `
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2472: elif not one_input_has_been_passed:
- .venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:2473: # if no inputs have been passed, use default values
- .venv/lib/python3.12/site-packages/transformers/models/moshi/configuration_moshi.py:36: represented by the `inputs_ids` passed when calling [`MoshiDepthDecoder`].
- .venv/lib/python3.12/site-packages/transformers/models/moshi/configuration_moshi.py:54: represented by the `audio_codes` passed when calling the Moshi models.
- .venv/lib/python3.12/site-packages/transformers/models/moshi/configuration_moshi.py:162: represented by the `inputs_ids` passed when calling [`MoshiDecoder`].
- .venv/lib/python3.12/site-packages/transformers/models/moshi/configuration_moshi.py:178: represented by the `audio_codes` passed when calling the Moshi models.
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/configuration_metaclip_2.py:28: the `inputs_ids` passed when calling [`MetaClip2Model`].
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:32: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:36: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:40: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:44: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:48: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:52: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:56: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:224: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:228: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py:232: pass
- .venv/lib/python3.12/site-packages/transformers/models/metaclip_2/modeling_metaclip_2.py:414: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/detr/configuration_detr.py:98: Keyword arguments to be passed to AutoBackbone when loading from a checkpoint
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:57: cross_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` and `config.add_cross_a
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:352: raise ValueError("normalize should be True if scale is passed")
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:403: # TODO find a better way of exposing other arguments
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:762: - object_queries are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:793: Flattened feature map (output of the backbone + projection layer) that is passed to the encoder.
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:875: - object_queries and query_position_embeddings are added to the forward pass.
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:910: The query embeddings that are passed into the decoder.
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1087: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1088: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1090: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1109: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1163: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1267: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1268: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1270: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1413: Optionally, instead of passing the flattened feature map (output of the backbone + projection layer), you
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1414: can choose to directly pass a flattened representation of an image.
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1416: Optionally, instead of initializing the queries with a tensor of zeros, you can choose to directly pass an
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1447: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1495: # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr_fast.py:769: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr_fast.py:860: raise ValueError("Make sure to pass in as many orig_target_sizes as max_target_sizes")
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr_fast.py:907: raise ValueError("Make sure to pass in as many processed_sizes as target_sizes")
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr_fast.py:916: "Make sure that you pass in as many target sizes as the batch dimension of the logits and masks"
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr_fast.py:1040: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr_fast.py:1101: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:638: # TODO - (Amy) make compatible with other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:661: # TODO - (Amy) make compatible with other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1042: # TODO (Amy) - update to use `rescale_factor` instead of `scale`
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1268: from 0 to 255. If passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1503: # POSTPROCESSING METHODS - TODO: add support for other frameworks
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1529: raise ValueError("Make sure that you pass in as many target sizes as the batch dimension of the logits")
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1619: raise ValueError("Make sure to pass in as many orig_target_sizes as max_target_sizes")
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1666: raise ValueError("Make sure to pass in as many processed_sizes as target_sizes")
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1675: "Make sure that you pass in as many target sizes as the batch dimension of the logits and masks"
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1799: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1859: "Make sure that you pass in as many target sizes as the batch dimension of the logits"
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:100: f"Instantiating {self.__class__.__name__} without passing a `layer_idx` is not recommended and will "
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:224: k_pass = key[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:227: q_pass = query[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:232: key = torch.cat([k_rot, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:233: query = torch.cat([q_rot, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:263: untouched. The only required change would be on the forward pass where it needs to correctly call the public API of
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:270: # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:310: k_pass = key[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:313: q_pass = query[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:318: key = torch.cat([k_rot, k_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:319: query = torch.cat([q_rot, q_pass], dim=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:635: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:659: # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:951: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:1024: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:1060: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:1177: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:223: k_pass = key[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:226: q_pass = query[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:231: key = tf.concat((k_rot, k_pass), axis=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:232: query = tf.concat((q_rot, q_pass), axis=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:412: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:473: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:588: The reason the second format is supported is that Keras methods prefer this format when passing inputs to models
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:590: pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:603: about any of this, as you can just pass inputs like you would to any other Python function!
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:619: If `past` is used, only input IDs that do not have their past calculated should be passed as `input_ids`.
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:628: given to this model should not be passed as input ids as they have already been computed.
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:656: Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_tf_gptj.py:867: padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take the last value in
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_flax_gptj.py:95: past_key_values (`dict[str, np.ndarray]`, *optional*, returned by `init_cache` or when passing previous `past_key_values
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_flax_gptj.py:227: k_pass = key[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_flax_gptj.py:230: q_pass = query[:, :, :, self.rotary_dim :]
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_flax_gptj.py:235: key = jnp.concatenate([k_rot, k_pass], axis=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_flax_gptj.py:236: query = jnp.concatenate([q_rot, q_pass], axis=-1)
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_flax_gptj.py:459: raise ValueError("Make sure to provide `position_ids` when passing `past_key_values`.")
- .venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_flax_gptj.py:473: # if past_key_values are passed then cache is already initialized a private flag init_cache has to be passed down to ens
- .venv/lib/python3.12/site-packages/transformers/models/gptj/configuration_gptj.py:42: `inputs_ids` passed when calling [`GPTJModel`].
- .venv/lib/python3.12/site-packages/transformers/models/gptj/configuration_gptj.py:149: # TODO: how to do that better?
- .venv/lib/python3.12/site-packages/transformers/models/vilt/image_processing_vilt.py:364: passing in images with pixel values between 0 and 1, set `do_rescale=False`.
- .venv/lib/python3.12/site-packages/transformers/models/vilt/image_processing_vilt.py:429: # Hence, it does not need to be passed to a validate_preprocess_arguments() method.
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:58: hidden_states (`list[tuple(torch.FloatTensor)]`, *optional*, returned when `output_hidden_states=True` is passed or when
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:258: # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:617: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:776: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:802: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:954: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:978: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:1060: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:1079: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:1091: raise NotImplementedError("Training is not yet supported.")
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:1165: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:1187: >>> # forward pass
- .venv/lib/python3.12/site-packages/transformers/models/vilt/modeling_vilt.py:1295: Optionally, instead of passing `pixel_values`, you can choose to directly pass an embedded representation.
- .venv/lib/python3.12/site-packages/transformers/models/vilt/configuration_vilt.py:37: represented by the `inputs_ids` passed when calling [`ViltModel`].
- .venv/lib/python3.12/site-packages/transformers/models/vilt/configuration_vilt.py:39: The vocabulary size of the `token_type_ids` passed when calling [`ViltModel`]. This is used when encoding
- .venv/lib/python3.12/site-packages/transformers/models/vilt/configuration_vilt.py:42: The vocabulary size of the modalities passed when calling [`ViltModel`]. This is used after concatenating the
- .venv/lib/python3.12/site-packages/transformers/models/vision_text_dual_encoder/modeling_flax_vision_text_dual_encoder.py:447: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/vision_text_dual_encoder/modeling_tf_vision_text_dual_encoder.py:493: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py:334: All remaining positional arguments will be passed to the underlying model's `__init__` method.
- .venv/lib/python3.12/site-packages/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py:388: # TODO: Should we use the pre-trained projection as well ?
- .venv/lib/python3.12/site-packages/transformers/integrations/bitnet.py:218: (STE) for the backward pass.
- .venv/lib/python3.12/site-packages/transformers/integrations/bitnet.py:241: It uses the Straight-Through Estimator (STE) for the backward pass.
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:163: Simplified forward pass for inference with guaranteed non-null input_ids and cache_position.
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:173: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:191: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:245: Forward pass of the module, which is compatible with the ExecuTorch llm runner.
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:398: # Forward pass
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:408: # Forward pass to get next token logits
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:554: Forward pass of the module, which is compatible with the ExecuTorch runtime.
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:722: Forward pass of the module, which is compatible with the ExecuTorch llm runner.
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:732: # Forward pass with the model
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:778: # TODO: The default inputs only work for text models. We need to add support for vision/audio models.
- .venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:1077: # TODO (tmanlaibaatar) This won't be needed in torch 2.7.
- .venv/lib/python3.12/site-packages/transformers/integrations/finegrained_fp8.py:385: # when changing a layer the TP PLAN for that layer should be updated. TODO
- .venv/lib/python3.12/site-packages/transformers/integrations/flash_attention.py:61: # Instead of relying on the value set in the module directly, we use the is_causal passed in kwargs if it is presented
- .venv/lib/python3.12/site-packages/transformers/integrations/flex_attention.py:108: # TODO: deprecate / rename to make_flex_block_mask for clarity as it's not only causal anymore
- .venv/lib/python3.12/site-packages/transformers/integrations/flex_attention.py:123: Create Block (causal) logic and passing it into :func:`torch.nn.attention.flex_attention.create_block_mask`.
- .venv/lib/python3.12/site-packages/transformers/integrations/flex_attention.py:158: # Instead of passing a tensor mask, flex attention requires a mask_mod function
- .venv/lib/python3.12/site-packages/transformers/integrations/spqr.py:44: A list that contains the current key name. This is used for recursion and should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/spqr.py:47: should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/spqr.py:111: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/vptq.py:42: A list that contains the current key name. This is used for recursion and should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/vptq.py:45: should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/bitsandbytes.py:194: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/bitsandbytes.py:358: f"The model is going to be dequantized in {output_tensor.dtype} - if you want to upcast it to another dtype, make sure t
- .venv/lib/python3.12/site-packages/transformers/integrations/ggml.py:323: "tokens and scores need to be passed for a LLaMa tokenizer without merges to be instantiated."
- .venv/lib/python3.12/site-packages/transformers/integrations/ggml.py:472: # This is tricky as the additional kwargs are passed after legacy is force-set in LlamaTokenizer's
- .venv/lib/python3.12/site-packages/transformers/integrations/mxfp4.py:76: # TODO: Add absolute link when the repo is public
- .venv/lib/python3.12/site-packages/transformers/integrations/mxfp4.py:82: rows_per_chunk: int = 32768 * 1024,  # TODO these values are not here by mistake ;)
- .venv/lib/python3.12/site-packages/transformers/integrations/mxfp4.py:86: pass of GPT_OSS.
- .venv/lib/python3.12/site-packages/transformers/integrations/mxfp4.py:95: scales = scales.to(torch.int32) - 127  # TODO that's because 128=2**7
- .venv/lib/python3.12/site-packages/transformers/integrations/mxfp4.py:203: # TODO: Add absolute link when the repo is public
- .venv/lib/python3.12/site-packages/transformers/integrations/mxfp4.py:390: # triton_weight_tensor is what needs to be passed in oai kernels. It stores the data, the shapes and any more objects. I
- .venv/lib/python3.12/site-packages/transformers/integrations/quanto.py:44: A list that contains the current key name. This is used for recursion and should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/quanto.py:47: should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/higgs.py:438: raise NotImplementedError(f"Unsupported p={p}, n={n}")
- .venv/lib/python3.12/site-packages/transformers/integrations/higgs.py:570: A list that contains the current key name. This is used for recursion and should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/higgs.py:573: should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/deepspeed.py:374: "--adafactor was passed, but also found `optimizer` configured in the DeepSpeed config. "
- .venv/lib/python3.12/site-packages/transformers/integrations/deepspeed.py:419: If `resume_from_checkpoint` was passed then an attempt to resume from a previously saved checkpoint will be made.
- .venv/lib/python3.12/site-packages/transformers/integrations/__init__.py:141: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/__init__.py:152: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/__init__.py:163: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/__init__.py:284: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/__init__.py:292: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/__init__.py:304: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:401: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:473: # TODO: figure out dynamo support for instance method and switch this to instance method
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:480: param = param / device_mesh.size()  # TODO should be optionable
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:481: # TODO: assumes parent module will allreduce the output afterwards (e.g rowlinear bias is IsolatedParallel and parent mo
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:508: # TODO: figure out dynamo support for instance method and switch this to instance method
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:550: # TODO: figure out dynamo support for instance method and switch this to instance method
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:697: raise NotImplementedError("RowwiseParallel currently only support nn.Linear and nn.Embedding!")
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:730: If the input passed in to this ``nn.Module`` is a :class:`torch.Tensor`, it assumes that the input is already sharded
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:732: passed in to this ``nn.Module`` is already a :class:`DTensor` but is not sharded on the sequence dimension, it would
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:842: raise NotImplementedError("RouterParallel does not support DTensor input for now")
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:889: # TODO: i'd like for this to be the default
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:896: # TODO: need an abstract Parallel class that is different from TensorParallelLayer
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:945: # TODO: this logic should be wrapped in a function, this is copied from corresponding tp classes.
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:990: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:1001: ):  # TODO: rename to shard_and_distribute_param
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:1017: module_to_tp = model.get_submodule(param_name)  # TODO: can i loop over modules?
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:1033: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:1072: pass  # we couldn't find the rule for this parameter, so it's not sharded
- .venv/lib/python3.12/site-packages/transformers/integrations/flash_paged.py:11: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/flash_paged.py:29: r"""Perform the forward pass of attention with paged key-value cache.
- .venv/lib/python3.12/site-packages/transformers/integrations/awq.py:117: A list that contains the current key name. This is used for recursion and should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/awq.py:120: should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/awq.py:234: "Fusing mapping not found either on the quantization config or the supported `AWQ_FUSED_MAPPINGS`. Please pass a `fused_
- .venv/lib/python3.12/site-packages/transformers/integrations/awq.py:291: # For AWQ fused + Llama we need to set `config._attn_implementation` = "custom" to avoid unexpected behavior and pass
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:128: To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>"`.
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:139: same device. If we only pass the device (*e.g.*, `"cpu"`, `"cuda:1"`, `"mps"`, or a GPU ordinal rank
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:152: `offload_index` argument to be passed to `accelerate.dispatch_model` method.
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:155: methods. This argument is used in case users directly pass PEFT state dicts
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:157: The state dict of the adapter to load. This argument is used in case users directly pass PEFT state
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:166: Additional keyword arguments passed along to the `from_pretrained` method of the adapter config and
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:198: "You should either pass a `peft_model_id` or a `peft_config` and `adapter_state_dict` to load an adapter."
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:215: "You passed a `revision` argument both in `adapter_kwargs` and as a standalone argument. "
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:232: f"adapter model file not found in {peft_model_id}. Make sure you are passing the correct path to the "
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:319: Adds a fresh new adapter to the current model for training purpose. If no adapter name is passed, a default
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:328: The name of the adapter to add. If no name is passed, a default name is assigned to the adapter.
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:369: f"Following adapter(s) could not be found: {', '.join(missing)}. Make sure you are passing the correct adapter name(s)."
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:374: f"Adapter with name {adapter_name} not found. Please pass the correct adapter name among {list(self.peft_config.keys())}
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:486: If no adapter_name is passed, the active adapter is used.
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:490: The name of the adapter to get the state dict from. If no name is passed, the active adapter is used.
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:524: same device. If we only pass the device (*e.g.*, `"cpu"`, `"cuda:1"`, `"mps"`, or a GPU ordinal rank
- .venv/lib/python3.12/site-packages/transformers/integrations/peft.py:537: The offload_index argument to be passed to `accelerate.dispatch_model` method.
- .venv/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:74: # The last condition is for encoder (decoder) models which specify this by passing their own `is_causal` flag
- .venv/lib/python3.12/site-packages/transformers/integrations/aqlm.py:44: A list that contains the current key name. This is used for recursion and should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/aqlm.py:47: should not be passed by the user.
- .venv/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:328: pass
- .venv/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:382: "No `resources_per_trial` arg was passed into "
- .venv/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:408: "make sure you pass `do_eval=True` and `eval_strategy='steps'` in the "
- .venv/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:1589: `project` by saving them as environment variables or passing them to the callback.
- .venv/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:1616: Additional keyword arguments to be passed directly to the
- .venv/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:2349: - If a string is passed to the login interface, this environment variable is ignored.
- .venv/lib/python3.12/site-packages/transformers/commands/chat.py:219: "help": "Name of the pre-trained model. The positional argument will take precedence if both are passed."
- .venv/lib/python3.12/site-packages/transformers/commands/chat.py:237: "`generation_config.json` file. Other generation settings passed as CLI arguments will be applied on "
- .venv/lib/python3.12/site-packages/transformers/commands/chat.py:259: "help": "Override the default `torch.dtype` and load the model under this dtype. If `'auto'` is passed, "
- .venv/lib/python3.12/site-packages/transformers/commands/chat.py:327: "Flags to pass to `generate`, using a space as a separator between flags. Accepts booleans, numbers, "
- .venv/lib/python3.12/site-packages/transformers/commands/chat.py:492: # `model_kwargs` contain non-generation flags in `parsed_generate_flags` that should be passed directly to
- .venv/lib/python3.12/site-packages/transformers/commands/add_fast_image_processor.py:110: "    pass\n"
- .venv/lib/python3.12/site-packages/transformers/commands/add_fast_image_processor.py:131: "        pass\n"
- .venv/lib/python3.12/site-packages/transformers/commands/__init__.py:23: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/commands/__init__.py:27: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/commands/add_new_model_like.py:369: f"class {class_.replace(old_cased_name, new_cased_name)}({class_}):\n    pass" for class_ in all_classes
- .venv/lib/python3.12/site-packages/transformers/commands/add_new_model_like.py:535: pass
- .venv/lib/python3.12/site-packages/transformers/commands/add_new_model_like.py:590: If set, the answer will be passed to this function. If this function raises an error on the provided
- .venv/lib/python3.12/site-packages/transformers/commands/add_new_model_like.py:596: `Any`: The answer provided by the user (or the default), passed through the potential conversion function.
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:201: # TODO (joao, matt): streamline tool token detection logic
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:233: Creates a generation config from the parameters of the request. If a generation config is passed in the request,
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:373: "help": "Override the default `torch.dtype` and load the model under this dtype. If `'auto'` is passed, "
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:424: # TODO
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:684: # TODO: add other fields
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:789: # TODO (Joao, Lysandre): the logits processors should be fixed in continuous batching
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:794: # TODO (Joao, Lysandre): this should also work with tool support
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:930: # TODO: trigger 2 constrained generations after the tool call start token is emitted:
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:1055: # TODO: other models will likely need more elaborate processing here
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:1105: # TODO -- Implement non-streaming mode
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:1275: logprobs=[{"token": "", "logprob": 99.9}],  # TODO: add actual logprobs
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:1288: logprobs=[{"token": "", "logprob": 99.9}],  # TODO: add actual logprobs
- .venv/lib/python3.12/site-packages/transformers/commands/serving.py:1397: # TODO: implement streaming transcription (currently, it's not streaming)
- .venv/lib/python3.12/site-packages/transformers/commands/train.py:109: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/commands/train.py:111: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/commands/train.py:144: raise NotImplementedError
- .venv/lib/python3.12/site-packages/transformers/onnx/convert.py:142: # TODO: Check when exporting QA we provide "is_pair=True"
- .venv/lib/python3.12/site-packages/transformers/onnx/config.py:152: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/onnx/config.py:519: # TODO: should we set seq_length = 1 when self.use_past = True?
- .venv/lib/python3.12/site-packages/transformers/onnx/config.py:705: # TODO: test this.
- .venv/lib/python3.12/site-packages/transformers/onnx/utils.py:94: pass
- .venv/lib/python3.12/site-packages/transformers/onnx/utils.py:98: pass
- .venv/lib/python3.12/site-packages/transformers/kernels/falcon_mamba/selective_scan_with_ln_interface.py:84: # The kernel supports passing in a pre-allocated dz (e.g., in case we want to fuse the
- .venv/lib/python3.12/site-packages/transformers/kernels/falcon_mamba/selective_scan_with_ln_interface.py:86: # Here we just pass in None and dz will be allocated in the C++ code.
- .venv/lib/python3.12/site-packages/transformers/kernels/falcon_mamba/selective_scan_with_ln_interface.py:143: not considered in the backward pass.
- .venv/lib/python3.12/site-packages/transformers/kernels/falcon_mamba/selective_scan_with_ln_interface.py:324: if checkpoint_lvl >= 1:  # Will recompute conv1d_out and delta in the backward pass
- .venv/lib/python3.12/site-packages/transformers/kernels/falcon_mamba/selective_scan_with_ln_interface.py:399: # The kernel supports passing in a pre-allocated dz (e.g., in case we want to fuse the
- .venv/lib/python3.12/site-packages/transformers/kernels/falcon_mamba/selective_scan_with_ln_interface.py:450: # The kernel supports passing in a pre-allocated dx (e.g., in case we want to fuse the
- .venv/lib/python3.12/site-packages/transformers/pipelines/audio_utils.py:75: Additional arguments to pass to ffmpeg, can include arguments like -nostdin for running as a background
- .venv/lib/python3.12/site-packages/transformers/pipelines/audio_utils.py:76: process. For example, to pass -nostdin to the ffmpeg process, pass in ["-nostdin"]. If passing in flags
- .venv/lib/python3.12/site-packages/transformers/pipelines/audio_utils.py:169: Additional arguments to pass to ffmpeg, can include arguments like -nostdin for running as a background
- .venv/lib/python3.12/site-packages/transformers/pipelines/audio_utils.py:170: process. For example, to pass -nostdin to the ffmpeg process, pass in ["-nostdin"]. If passing in flags
- .venv/lib/python3.12/site-packages/transformers/pipelines/depth_estimation.py:70: Predict the depth(s) of the image(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/depth_estimation.py:80: The pipeline accepts either a single image or a batch of images, which must then be passed as a string.
- .venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_object_detection.py:85: Detect objects (bounding boxes & classes) in the image(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/keypoint_matching.py:108: The pipeline accepts either a single pair of images or a batch of image pairs, which must then be passed as a string.
- .venv/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:49: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial). You can pass text
- .venv/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:180: Additional keyword arguments to pass along to the generate method of the model (see the generate method
- .venv/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:216: # User-defined `generation_config` passed to the pipeline call take precedence
- .venv/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:293: Additional keyword arguments to pass along to the generate method of the model (see the generate method
- .venv/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:400: Additional keyword arguments to pass along to the generate method of the model (see the generate method
- .venv/lib/python3.12/site-packages/transformers/pipelines/object_detection.py:86: Detect objects (bounding boxes & classes) in the image(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/mask_generation.py:224: # TODO: Identifying the model by the type of its returned embeddings is brittle.
- .venv/lib/python3.12/site-packages/transformers/pipelines/audio_classification.py:125: - `dict` form can be used to pass raw audio sampled at arbitrary `sampling_rate` and let this
- .venv/lib/python3.12/site-packages/transformers/pipelines/audio_classification.py:135: the output of the model. Valid options: ["softmax", "sigmoid", "none"]. Note that passing Python's
- .venv/lib/python3.12/site-packages/transformers/pipelines/audio_classification.py:136: built-in `None` will default to "softmax", so you need to pass the string "none" to disable any
- .venv/lib/python3.12/site-packages/transformers/pipelines/audio_classification.py:203: "When passing a dictionary to AudioClassificationPipeline, the dict needs to contain a "
- .venv/lib/python3.12/site-packages/transformers/pipelines/fill_mask.py:28: When passed, the model will limit the scores to the passed targets instead of looking up in the whole
- .venv/lib/python3.12/site-packages/transformers/pipelines/fill_mask.py:32: Additional dictionary of keyword arguments passed along to the tokenizer.""",
- .venv/lib/python3.12/site-packages/transformers/pipelines/fill_mask.py:217: # XXX: If users encounter this pass
- .venv/lib/python3.12/site-packages/transformers/pipelines/fill_mask.py:228: raise ValueError("At least one target must be provided when passed.")
- .venv/lib/python3.12/site-packages/transformers/pipelines/fill_mask.py:269: When passed, the model will limit the scores to the passed targets instead of looking up in the whole
- .venv/lib/python3.12/site-packages/transformers/pipelines/fill_mask.py:273: When passed, overrides the number of predictions to return.
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_classification.py:139: Assign labels to the image(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_classification.py:149: The pipeline accepts either a single image or a batch of images, which must then be passed as a string.
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_to_audio.py:55: You can specify parameters passed to the model by using [`TextToAudioPipeline.__call__.forward_params`] or
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_to_audio.py:169: # User-defined `generation_config` passed to the pipeline call take precedence
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_to_audio.py:208: Parameters passed to the model generation/forward method. `forward_params` are always passed to the
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_to_audio.py:214: only passed to the underlying model if the latter is a generative model.
- .venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:104: # TODO: Update task_summary docs to include an example with document QA and then update the first sentence
- .venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:277: The maximum length of the total sentence (context + question) in tokens of each chunk passed to the
- .venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:286: Additional flags to pass to tesseract while running OCR.
- .venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:409: # TODO: check why slower `LayoutLMTokenizer` and `LayoutLMv2Tokenizer` don't have this key in outputs
- .venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:469: # User-defined `generation_config` passed to the pipeline call take precedence
- .venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:497: # TODO: A lot of this logic is specific to Donut and should probably be handled in the tokenizer
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_to_image.py:102: Transform the image(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_to_image.py:112: The pipeline accepts either a single image or a batch of images, which must then be passed as a string.
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:39: raise ValueError("When passing chat dicts as input, each dict must have a 'role' and 'content' key.")
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:74: >>> # Zephyr-beta is a conversational model, so let's pass it a chat instead of a single string
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:79: Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial). You can pass text
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:268: passed, this pipeline will continue each prompt. Alternatively, a "chat", in the form of a list
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:269: of dicts with "role" and "content" keys, can be passed, or a list of such chats. When chats are passed,
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:270: the model's chat template will be used to format them before passing them to the model.
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:297: Additional keyword arguments to pass along to the encoding step of the tokenizer. If the text input is
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:298: a chat, it is passed to `apply_chat_template`. Otherwise, it is passed to `__call__`.
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:300: Additional keyword arguments to pass along to the generate method of the model (see the generate method
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:359: # If the user passes a chat that ends in an assistant message, we treat it as a prefill by default
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:428: # User-defined `generation_config` passed to the pipeline call take precedence
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:527: # If the user passes a chat ending in an assistant message, we treat it as a prefill by
- .venv/lib/python3.12/site-packages/transformers/pipelines/visual_question_answering.py:120: For dataset: the passed in dataset must be of type `transformers.pipelines.pt_utils.KeyDataset`
- .venv/lib/python3.12/site-packages/transformers/pipelines/visual_question_answering.py:189: # User-defined `generation_config` passed to the pipeline call take precedence
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:116: # Bypass for `ImageGPT` which doesn't provide a padding value, yet
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:219: Select framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:237: Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:350: Select framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:366: Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:387: If both frameworks are installed, picks the one corresponding to the model passed (either a model class or
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:489: # If the model is passed as a string, load the model and the corresponding tokenizer
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:510: "The assistant model has a different tokenizer than the main model. You should pass the assistant "
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:541: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:591: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:601: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:798: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:802: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:851: When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number of
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:854: When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:861: the associated CUDA device id. You can pass native `torch.device` or a `str` too
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1049: # 2 - load the assistant model if it is passed.
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1080: # TODO (joao): no PT model should reach this line. However, some audio models with complex
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1136: Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1330: raise NotImplementedError("_sanitize_parameters not implemented")
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1338: raise NotImplementedError("preprocess not implemented")
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1351: raise NotImplementedError("_forward not implemented")
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1360: raise NotImplementedError("postprocess not implemented")
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1397: # TODO hack by collating feature_extractor and image_processor
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1440: # TODO make the get_iterator work also for `tf` (and `flax`).
- .venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1515: # TODO hack by collating feature_extractor and image_processor
- .venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:39: The parameters passed to `infer` along with every item
- .venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:99: # This can happen for optional data that get passed around
- .venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:173: The parameters passed to `infer` along with every item
- .venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:234: The parameters passed to `infer` along with every item
- .venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:259: # its a `is_last` and then just passes it on to the caller.
- .venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:31: "Make sure the passed template includes formatting syntax such as {} where the label should go."
- .venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:52: Any combination of sequences and labels can be passed and each combination will be posed as a premise/hypothesis
- .venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:53: pair and passed to the pretrained model. Then, the logit for *entailment* is taken as the logit for the candidate
- .venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:203: pass
- .venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_image_classification.py:99: Assign labels to the image(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:88: # TODO  Use a faster algorithm this can probably be done in O(n)
- .venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:148: can be passed for language model boosted decoding. See [`Wav2Vec2ProcessorWithLM`] for more information.
- .venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:233: - `dict` form can be used to pass raw audio sampled at arbitrary `sampling_rate` and let this
- .venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:321: # Check whether we have a valid setting for return_timestamps and throw an error before we perform a forward pass
- .venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:391: "When passing a dictionary to AutomaticSpeechRecognitionPipeline, the dict needs to contain a "
- .venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:525: # User-defined `generation_config` passed to the pipeline call take precedence
- .venv/lib/python3.12/site-packages/transformers/pipelines/table_question_answering.py:308: This dictionary can be passed in as such, or can be converted to a pandas DataFrame:
- .venv/lib/python3.12/site-packages/transformers/pipelines/table_question_answering.py:409: # User-defined `generation_config` passed to the pipeline call take precedence
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_feature_extraction.py:17: Additional dictionary of keyword arguments passed along to the image processor e.g.
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_feature_extraction.py:110: The pipeline accepts either a single image or a batch of images, which must then be passed as a string.
- .venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:737: models. Multi-modal models will also require a tokenizer to be passed.
- .venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:748: models will also require a tokenizer to be passed.
- .venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:770: When passing a task name or a string model identifier: The specific model version to use. It can be a
- .venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:801: Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,
- .venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:804: Additional keyword arguments passed along to the specific pipeline init (see the documentation for the
- .venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:823: >>> # Named entity recognition pipeline, passing in a specific model and tokenizer
- .venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:830: # Make sure we only pass use_auth_token once as a kwarg (it used to be possible to pass it in model_kwargs,
- .venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_audio_classification.py:77: Assign labels to the audio(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/feature_extraction.py:11: Additional dictionary of keyword arguments passed along to the tokenizer.
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:63: raise ValueError("When passing chat dicts as input, each dict must have a 'role' and 'content' key.")
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:73: Retrieve and combine images from the chat and the images passed as input.
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:88: # Insert the image passed as argument in the chat message
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:93: "The number of images in the chat messages should be the same as the number of images passed to the pipeline."
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:107: # The number of images passed should be consistent with the number of images in the chat without an image key
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:110: "The number of images in the chat messages should be the same as the number of images passed to the pipeline."
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:294: Generate a text given text and the image(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:307: The text to be used for generation. If a list of strings is passed, the length of the list should be
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:353: # Same as above, but the `images` argument contains the chat. This can happen e.g. is the user only passes a
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:391: # If the user passes a chat that ends in an assistant message, we treat it as a prefill by default
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:433: # User-defined `generation_config` passed to the pipeline call take precedence
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_text_to_text.py:490: # If the user passes a chat ending in an assistant message, we treat it as a prefill by
- .venv/lib/python3.12/site-packages/transformers/pipelines/video_classification.py:93: Assign labels to the video(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/video_classification.py:102: The pipeline accepts either a single video or a batch of videos, which must then be passed as a string.
- .venv/lib/python3.12/site-packages/transformers/pipelines/video_classification.py:115: the output of the model. Valid options: ["softmax", "sigmoid", "none"]. Note that passing Python's
- .venv/lib/python3.12/site-packages/transformers/pipelines/video_classification.py:116: built-in `None` will default to "softmax", so you need to pass the string "none" to disable any
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_segmentation.py:108: Perform segmentation (detect masks & classes) in the image(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:192: "Passing the `X` argument to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `qu
- .venv/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:198: "Passing the `data` argument to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the 
- .venv/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:374: The maximum length of the total sentence (context + question) in tokens of each chunk passed to the
- .venv/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:396: "Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:169: # TODO try and retrieve it in a nicer way from _sanitize_parameters.
- .venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:187: # This is likely an invalid usage of the pipeline attempting to pass text pairs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_to_text.py:126: Assign labels to the image(s) passed as inputs.
- .venv/lib/python3.12/site-packages/transformers/pipelines/image_to_text.py:221: # User-defined `generation_config` passed to the pipeline call take precedence
- .venv/lib/python3.12/site-packages/transformers/distributed/configuration_utils.py:29: # TODO: add tp_plan, pp_plan, device_mesh etc..
- .venv/lib/python3.12/site-packages/transformers/sagemaker/training_args_sm.py:29: # TODO: should be moved to `utils` after refactoring of SageMakerTrainer
- .venv/lib/python3.12/site-packages/transformers/data/data_collator.py:677: # this might occur when we pass {..., "labels": None}
- .venv/lib/python3.12/site-packages/transformers/data/data_collator.py:840: "You should pass `mlm=False` to train on causal language modeling instead."
- .venv/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:210: # TODO: randomness could apply a random seed, ex. rng = random.Random(random_seed)
- .venv/lib/python3.12/site-packages/transformers/data/processors/squad.py:181: encoded_dict = tokenizer.encode_plus(  # TODO(thom) update this logic
- .venv/lib/python3.12/site-packages/transformers/data/processors/utils.py:91: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/data/processors/utils.py:95: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/data/processors/utils.py:99: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/data/processors/utils.py:103: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/transformers/data/processors/utils.py:107: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/accelerate/parallelism_config.py:221: raise ("You need to pass a device_type e.g cuda to build the device mesh")
- .venv/lib/python3.12/site-packages/accelerate/checkpointing.py:210: Additional arguments that can be passed to the `load` function.
- .venv/lib/python3.12/site-packages/accelerate/checkpointing.py:212: Additional arguments that can be passed to the model's `load_state_dict` method.
- .venv/lib/python3.12/site-packages/accelerate/checkpointing.py:221: "Unsupported optimizer map location passed, please choose one of `None`, `'cpu'`, or `'on_device'`"
- .venv/lib/python3.12/site-packages/accelerate/launchers.py:76: Tuple of arguments to pass to the function (it will receive `*args`).
- .venv/lib/python3.12/site-packages/accelerate/launchers.py:288: Tuple of arguments to pass to the function (it will receive `*args`).
- .venv/lib/python3.12/site-packages/accelerate/state.py:135: Additional keyword arguments to pass to the relevant `init_process_group` function. Valid `kwargs` can be
- .venv/lib/python3.12/site-packages/accelerate/state.py:313: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/accelerate/state.py:429: number of elements. Useful when trying to perform actions such as `gather()` on the outputs or passing
- .venv/lib/python3.12/site-packages/accelerate/state.py:972: # The first plugin passed in is always the active one
- .venv/lib/python3.12/site-packages/accelerate/state.py:985: # TODO: Siro - remove when axolotl fixes their side
- .venv/lib/python3.12/site-packages/accelerate/state.py:1047: err = "AcceleratorState has already been initialized and cannot be changed, restart your runtime completely and pass `{f
- .venv/lib/python3.12/site-packages/accelerate/state.py:1132: number of elements. Useful when trying to perform actions such as `gather()` on the outputs or passing
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:46: with PyTorch existing hooks is that they get passed along the kwargs.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:49: - **no_grad** (`bool`, *optional*, defaults to `False`) -- Whether or not to execute the actual forward pass under
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:69: module (`torch.nn.Module`): The module whose forward pass will be executed just after this event.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:70: args (`Tuple[Any]`): The positional arguments passed to the module.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:71: kwargs (`Dict[Str, Any]`): The keyword arguments passed to the module.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:83: module (`torch.nn.Module`): The module whose forward pass been executed just before this event.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:137: If the module already contains a hook, this will replace it with the new hook passed by default. To chain two hooks
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:138: together, pass `append=True`, so it chains the current and new hook into an instance of the `SequentialHook` class.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:227: A generic `ModelHook` that ensures inputs and model weights are on the same device for the forward pass of the
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:228: associated module, potentially offloading the weights after the forward pass.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:232: The device on which inputs and model weights should be placed before the forward pass.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:234: Whether or not the weights should be offloaded after the forward pass.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:427: The device on which inputs and model weights should be placed before the forward pass.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:479: The device on which inputs and model weights should be placed before the forward pass.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:481: Whether or not the weights should be offloaded after the forward pass.
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:573: The device on which inputs and model weights should be placed before the forward pass. It can be one device
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:576: Whether or not the weights should be offloaded after the forward pass. It can be one boolean for the whole
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:691: Offloads a model on the CPU until its forward pass is called. The model will not be offloaded back to the CPU after
- .venv/lib/python3.12/site-packages/accelerate/hooks.py:700: passed, its offload method will be called just before the forward of the model to which this hook is
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:182: copy of the state dict of the model will be kept. During the forward pass, parameters will be extracted from that
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:183: state dict and put on the execution device passed as they are needed, then offloaded again.
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:189: The device on which the forward pass of the model will be executed (should be a GPU). Will default to the
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:236: The hook sent back by this function for a previous model in the pipeline you are running. If passed, its
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:272: memory-mapped array in a given folder. During the forward pass, parameters will be accessed from that folder and
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:273: put on the execution device passed as they are needed, then offloaded again.
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:280: The device on which the forward pass of the model will be executed (should be a GPU). Will default to the
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:608: "If passing a string for `device_map`, please choose 'auto', 'balanced', 'balanced_low_0' or 'sequential'."
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:664: `torch.float8_e4m3fn` and upcasted to a higher precision like `torch.bfloat16` during forward pass and downcasted
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:672: The dtype to cast the module to before/after the forward pass for storage.
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:674: The dtype to cast the module to during the forward pass for computation.
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:701: Users can also pass modules they want to avoid from getting downcasted.
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:777: # We hope (assume) that if user uses their own model (without this structure which transformers uses), they read the doc
- .venv/lib/python3.12/site-packages/accelerate/big_modeling.py:782: #    attention mask kwarg is passed -> hook will remove the attention mask and add
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:80: If a custom `generator` is passed, it will rely on its initial seed as well as the current iteration it is on
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:114: Depending on the value of the `drop_last` attribute of the batch sampler passed, it will either stop the iteration
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:271: `drop_last` attribute of the batch sampler passed, it will either stop the iteration at the first batch that would
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:508: If passed, the device to put all batches on.
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:524: All other keyword arguments to pass to the regular `DataLoader` initialization.
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:604: # In case it is manually passed in, the user can set it to what they like
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:826: "either pass `dispatch_batches=False` and have each process fetch its own batch "
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:827: " or pass `split_batches=True`. By doing so, the main process will fetch a full batch and "
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:929: # In case it is manually passed in, the user can set it to what they like
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:1016: Depending on the value of the `drop_last` attribute of the `dataloader` passed, it will either stop the iteration
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:1061: If passed, this function will be used to slice tensors across `num_processes`. Will default to
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:1157: "In order to use `split_batches==True` you must have a `batch_size` attribute either in the passed "
- .venv/lib/python3.12/site-packages/accelerate/data_loader.py:1346: All other keyword arguments to pass to the regular `DataLoader` initialization.
- .venv/lib/python3.12/site-packages/accelerate/local_sgd.py:79: raise NotImplementedError("LocalSGD is supported only for CPUs and GPUs (no DeepSpeed or MegatronLM)")
- .venv/lib/python3.12/site-packages/accelerate/inference.py:75: Attaches the split points to the model based on `self.device_map` and generates a `PipelineStage`. Requires passing
- .venv/lib/python3.12/site-packages/accelerate/inference.py:78: Users can pass in custom `num_chunks` as an optional hyper-parameter. By default will use
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:195: accelerate config of the current system or the flag passed with the `accelerate.launch` command. 'fp8'
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:198: The number of steps that should pass before gradients are accumulated. A number > 1 should be combined with
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:199: `Accelerator.accumulate`. If not passed, will default to the value in the environment variable
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:325: raise ValueError("You cannot pass in both `dynamo_plugin` and `dynamo_backend`, please only pass in one.")
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:332: raise ValueError("You cannot pass in both `deepspeed_plugins` and `deepspeed_plugin`.")
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:351: # If we're creating a second `Accelerator`, users shouldn't be passing in a `deepspeed_plugin`
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:357: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:358: "You cannot pass in a `deepspeed_plugin` when creating a second `Accelerator`. "
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:443: f"Unsupported kwargs handler passed: {handler}, must be one that inherits `accelerate.utils.KwargsHandler`."
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:447: raise ValueError(f"You can only pass one {handler.__class__} in `kwargs_handlers`.")
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:455: # TODO: Remove after deprecating tp_plugin
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:518: # TODO: S1ro - this is probably gonna be a problem with other fp8 backends too
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:530: warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:543: "You can only pass one of `gradient_accumulation_steps` and `gradient_accumulation_plugin`. Please only pass in the crea
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:609: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:781: # TODO: S1ro - this is a temporary solution until we figure out why `save_safe_file` is slow when not all processes
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:801: raise NotImplementedError("Pipeline parallelism is currently not supported in Accelerate.")
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:808: raise NotImplementedError("Context parallelism is currently not supported in Accelerate.")
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:848: or passing in less inputs than there are processes. If so, just remember to drop the padded elements
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1178: """Trigger the sync of the gradients in the next backward pass of the model after multiple forward passes under
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1196: ...     loss_a = loss_func(model(input_a))  # first forward pass
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1197: ...     loss_b = loss_func(model(input_b))  # second forward pass
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1256: PyTorch Modules that were prepared with `Accelerator.prepare`. Models passed to `accumulate()` will
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1257: skip gradient syncing during backward pass in distributed training
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1392: def _prepare_one(self, obj, first_pass=False, device_placement=None):
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1393: # First pass of preparation: DataLoader, model, optimizer
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1394: if first_pass:
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1402: # Second pass of preparation: LR scheduler (which need the full list of optimizers)
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1411: Prepare all objects passed in `args` for distributed training and mixed precision, then return them in the same
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1424: Used to customize whether automatic device placement should be performed for each object passed. Needs
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1449: >>> # Will place the first two items passed in automatically to the right device but not the last two.
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1461: f"`device_placement` should be a list with {len(args)} elements (the number of objects passed)."
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1465: # TODO: Look at enabling native TP training directly with a proper config
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1510: # This needs to be written as such, so that passing other objects other than models/optimizers doesn't raise an error
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1513: "When using FSDP2, a model and optimizer must be passed together to `Accelerator.prepare()`"
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1556: self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1579: # First pass: prepare everything except schedulers (and model, which is prepared separately below)
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1581: self._prepare_one(obj, first_pass=True) if not isinstance(obj, torch.nn.Module) else obj for obj in args
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1584: # Second pass: prepare schedulers
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1630: # First pass: prepare everything except schedulers (and model, which is prepared separately below)
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1632: self._prepare_one(obj, first_pass=True) if not isinstance(obj, torch.nn.Module) else obj for obj in args
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1635: # Second pass: prepare schedulers
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1733: # TODO: Look at enabling native TP training directly with a proper config
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1782: pass
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1809: # TODO: Look at enabling native TP training directly with a proper config
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1824: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:1825: "Model should undergo tensor parallel before passing it to accelerate."
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2011: # Invariant: with FSDP2, optimizer is always passed to `prepare()` together with model
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2041: "You must pass a model and an optimizer together to `accelerate.prepare()` when using TransformerEngine."
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2087: self._prepare_one(obj, first_pass=True) if isinstance(obj, torch.utils.data.DataLoader) else obj
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2096: "At least one of the dataloaders passed to `accelerate.prepare()` has `None` as batch size. "
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2106: "Since you passed both train and evaluation dataloader, `is_train_batch_min` (here "
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2111: "When using DeepSpeed, `accelerate.prepare()` requires you to pass at least one of training or evaluation dataloaders "
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2188: "pass in the `lr_scheduler_callable` parameter when using `accelerate.utils.DummyScheduler`."
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2349: "Since you passed both train and evaluation dataloader, `is_train_batch_min` (here "
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2362: "When you do not pass the dataloader parameter, the `data_parallel_size`, "
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2535: "You must pass a model and an optimizer together to `accelerate.prepare()` when using MS-AMP."
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2572: If passed, this function will be used to slice tensors across `num_processes`. Will default to
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2654: # NOTE: Special case with MS-AMP we do *not* pass in the scaler explicitly to the `AcceleratedOptimizer`,
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2804: that were passed to [`~Accelerator.prepare`].
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2821: # TODO: this unscales all optimizers where we should only unscale the one where parameters are.
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:2961: Whether to forcibly use gather_object instead of gather (which is already done if all objects passed do
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:3165: A nested dictionary of kwargs to be passed to a specific tracker's `__init__` function. Should be
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:3248: A nested dictionary of kwargs to be passed to a specific tracker's `log` function. Should be formatted
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:3290: Save the object passed to disk once per machine. Use in place of `torch.save`.
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:3298: If `save_on_each_node` was passed in as a `ProjectConfiguration`, will save the object once per node,
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:3442: argument are the state dicts of the `models`, and the `input_dir` argument is the `input_dir` argument passed
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:3465: If a `ProjectConfiguration` was passed to the `Accelerator` object with `automatic_checkpoint_naming` enabled
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:3485: Additional keyword arguments for saving model which can be passed to the underlying save function, such
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:3609: `input_dir` argument is the `input_dir` argument passed to [`Accelerator.load_state`].
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:3646: Additional keyword arguments for loading model which can be passed to the underlying load function,
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:4051: A different `autocast_handler` can be passed in to override the one set in the `Accelerator` object. This is
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:4068: # TODO: should the `yield` be in a try/finally block?
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:4078: A different `profile_handler` can be passed in to override the one set in the `Accelerator` object.
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:4082: The profile handler to use for this context manager. If not passed, will use the one set in the
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:4192: Runs backward pass on LOMO optimizers.
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:4200: raise ValueError("A learning rate must be passed in order to call backward pass with LOMO optimizers.")
- .venv/lib/python3.12/site-packages/accelerate/accelerator.py:4211: "Backward pass not properly called on LOMO optimizers. Are you sure you passed a LOMO optimizer in accelerator.prepare()
- .venv/lib/python3.12/site-packages/accelerate/logging.py:43: or only the main executed one. Default is `True` if not passed
- .venv/lib/python3.12/site-packages/accelerate/logging.py:49: `in_order` is ignored if `main_process_only` is passed.
- .venv/lib/python3.12/site-packages/accelerate/logging.py:89: If a log should be called on all processes, pass `main_process_only=False` If a log should be called on all
- .venv/lib/python3.12/site-packages/accelerate/logging.py:90: processes and in order, also pass `in_order=True`
- .venv/lib/python3.12/site-packages/accelerate/logging.py:96: The log level to use. If not passed, will default to the `LOG_LEVEL` environment variable, or `INFO` if not
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:105: Each function should take in `**kwargs` that will automatically be passed in from a base dictionary provided to
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:136: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:147: pass
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:159: pass
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:172: pass
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:179: pass
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:192: Additional key word arguments passed along to the `tensorboard.SummaryWriter.__init__` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:257: Additional key word arguments passed along to either `SummaryWriter.add_scaler`,
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:282: Additional key word arguments passed along to the `SummaryWriter.add_image` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:305: Additional key word arguments passed along to the `wandb.init` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:367: Additional key word arguments passed along to the `wandb.log` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:383: Additional key word arguments passed along to the `wandb.log` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:439: Additional key word arguments passed along to the `trackio.init` method. Refer to this
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:494: Additional key word arguments passed along to the `trackio.log` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:515: For `comet_ml` versions < 3.41.0, additional keyword arguments are passed to `comet_ml.Experiment` instead:
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:522: Additional key word arguments passed along to the `comet_ml.start` method:
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:579: Additional key word arguments passed along to either `Experiment.log_metric`, `Experiment.log_other`,
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:610: Additional key word arguments passed along to the `Run.__init__` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:659: Additional key word arguments passed along to the `Run.track` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:677: Additional key word arguments passed along to the `Run.Image` and `Run.track` method specified by the
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:861: Additional keyword arguments passed to the underlying mlflow.log_image function.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:921: Kwargs passed along to the `Task.__init__` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:978: Additional key word arguments passed along to the `clearml.Logger.report_single_value` or
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:1008: Additional key word arguments passed along to the `clearml.Logger.report_image` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:1041: Additional key word arguments passed along to the `clearml.Logger.report_table` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:1078: Additional key word arguments passed along to [`dvclive.Live()`](https://dvc.org/doc/dvclive/live).
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:1132: Additional key word arguments passed along to `dvclive.Live.log_metric()`.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:1166: Additional key word arguments passed along to the `swanlab.init` method.
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:1221: Additional key word arguments passed along to the `swanlab.log` method. Likes:
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:1239: Additional key word arguments passed along to the `swanlab.log` method. Likes:
- .venv/lib/python3.12/site-packages/accelerate/tracking.py:1320: f"Logging with `{log_type}` requires a `logging_dir` to be passed in."
- .venv/lib/python3.12/site-packages/accelerate/utils/imports.py:41: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/imports.py:76: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/imports.py:497: # TODO: Remove this function once stateful_dataloader is a stable feature in torchdata.
- .venv/lib/python3.12/site-packages/accelerate/utils/imports.py:522: # TODO: Rework this into `utils.deepspeed` and migrate the "core" chunks into `accelerate.deepspeed`
- .venv/lib/python3.12/site-packages/accelerate/utils/environment.py:171: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/environment.py:328: A context manager that will add each keyword argument passed to `os.environ` and remove them when exiting.
- .venv/lib/python3.12/site-packages/accelerate/utils/fsdp_utils.py:391: err += f"Please pass in either {checkpoint_dir}/pytorch_model_fsdp_0 or {checkpoint_dir}/optimizer_0"
- .venv/lib/python3.12/site-packages/accelerate/utils/fsdp_utils.py:395: err += f"Please try passing in {checkpoint_dir}/pytorch_model_fsdp_0 instead."
- .venv/lib/python3.12/site-packages/accelerate/utils/fsdp_utils.py:398: err += f"Please try passing in {checkpoint_dir}/optimizer_0 instead."
- .venv/lib/python3.12/site-packages/accelerate/utils/fsdp_utils.py:416: # if no tied names just passthrough
- .venv/lib/python3.12/site-packages/accelerate/utils/fsdp_utils.py:637: # bypassing the move to meta will still cause the VRAM spike, but at least it still will load
- .venv/lib/python3.12/site-packages/accelerate/utils/fsdp_utils.py:706: # TODO(siro1): Add a warning for each parameter that was upcasted
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:94: Positional arguments that will be passed to `func` when applied on the unpacked data.
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:101: Keyword arguments that will be passed to `func` when applied on the unpacked data.
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:129: f"Unsupported types ({type(data)}) passed to `{func.__name__}`. Only nested list/tuple/dicts of "
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:130: f"objects that are valid for `{test_type.__name__}` should be passed."
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:273: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:360: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:379: f"One or more of the tensors passed to {operation} were not on the {tensor.device.type} while the `Accelerator` is confi
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:456: raise NotImplementedError("gather objects in TPU is not supported")
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:623: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/operations.py:790: Decorator to apply to a function outputing tensors (like a model forward pass) that ensures the outputs in FP16
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:208: except NotImplementedError:
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:242: If passed along the value of the parameter will be cast to this `dtype`. Otherwise, `value` will be cast to
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:763: Get the maximum memory available if nothing is passed, converts string to int otherwise.
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:1638: Load a checkpoint from a given file. If the checkpoint is in the safetensors format and a device map is passed, the
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:1654: f"The safetensors archive passed at {checkpoint_file} does not contain metadata. "
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:1661: f"The safetensors archive passed at {checkpoint_file} does not contain the valid metadata. Make sure "
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:1665: raise ValueError(f"The checkpoint passed was saved with {metadata['format']}, we need a the pt format.")
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:1879: "At least one of the model submodule will be offloaded to disk, please pass along an `offload_folder`."
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:1993: # TODO: group all errors and raise at the end.
- .venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:2172: device or pass
- .venv/lib/python3.12/site-packages/accelerate/utils/bnb.py:55: This function will quantize the input model with the associated config passed in `bnb_quantization_config`. If the
- .venv/lib/python3.12/site-packages/accelerate/utils/bnb.py:56: model is in the meta device, we will load and dispatch the weights according to the `device_map` passed. If the
- .venv/lib/python3.12/site-packages/accelerate/utils/bnb.py:211: "If passing a string for `device_map`, please choose 'auto', 'balanced', 'balanced_low_0' or "
- .venv/lib/python3.12/site-packages/accelerate/utils/bnb.py:262: these modules in `torch_dtype`, you need to pass a custom `device_map` to
- .venv/lib/python3.12/site-packages/accelerate/utils/deepspeed.py:309: pass  # `accelerator.backward(loss)` is doing that automatically. Therefore, its implementation is not needed
- .venv/lib/python3.12/site-packages/accelerate/utils/deepspeed.py:312: pass  # `accelerator.backward(loss)` is doing that automatically. Therefore, its implementation is not needed
- .venv/lib/python3.12/site-packages/accelerate/utils/deepspeed.py:336: pass  # `accelerator.backward(loss)` is doing that automatically. Therefore, its implementation is not needed
- .venv/lib/python3.12/site-packages/accelerate/utils/memory.py:67: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/memory.py:124: CUDNN, the batch size is multiplied by 0.9 and passed to `function`
- .venv/lib/python3.12/site-packages/accelerate/utils/memory.py:167: f"Batch size was passed into `{function.__name__}` as the first argument when called."
- .venv/lib/python3.12/site-packages/accelerate/utils/memory.py:196: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:944: A plugin to configure gradient accumulation behavior. You can only pass one of `gradient_accumulation_plugin` or
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1008: A dictionary of options to pass to the backend.
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1033: metadata={"help": "A dictionary of options to pass to the backend."},
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1300: # NOTE: Set to False by default, will be set to `True` automatically if it's the first plugin passed
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1307: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1331: "pass it in kwargs."
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1529: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1554: A config to enable mixed precision training with FullyShardedDataParallel. If passing in a `dict`, it
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1566: A list of modules to ignore when wrapping with FSDP. When passing a string, will match the modules by name
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1572: State dict config to use. Is determined based on the `state_dict_type` if not passed in.
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1574: Optim state dict config to use. Is determined based on the `state_dict_type` if not passed in.
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1591: pass. only use with Static graphs.
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1594: backward pass. Effectively, this trades extra computation time for reduced memory usage.
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1642: "If passing in a `dict`, it should have the following keys: `param_dtype`, `reduce_dtype`, and `buffer_dtype`."
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1683: metadata={"help": "State dict config to use. Is determined based on the `state_dict_type` if not passed in."},
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1693: "help": "Optim state dict config to use. Is determined based on the `state_dict_type` if not passed in."
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1730: "all-gather while executing in the forward pass. only use with Static graphs. Defaults to `False`"
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1737: "certain layers and recomputing them during a backward pass. Effectively, this trades extra computation time "
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:1767: # Strategy: By default we should always assume that values are passed in, else we check the environment variables
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:2003: Given `model`, creates an `auto_wrap_policy` baesd on the passed in policy and if we can use the
- .venv/lib/python3.12/site-packages/accelerate/utils/dataclasses.py:2068: # TODO(s1ro1): `cast_forward_inputs` for FSDP2?
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:259: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:373: pass  # `model(**batch)` is doing that automatically. Therefore, its implementation is not needed
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:376: pass  # `model(**batch)` is doing that automatically. Therefore, its implementation is not needed
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:429: """Abstract class for batching, forward pass and loss handler."""
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:436: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:439: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:442: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:524: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:576: # Forward pass through the model.
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:665: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:828: pass
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:1102: # 3. forward pass and backward pass using Pipeline Parallelism
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:1245: # checking if required arguments are passed
- .venv/lib/python3.12/site-packages/accelerate/utils/megatron_lm.py:1248: raise NotImplementedError("Generate method is not implemented for this model")
- .venv/lib/python3.12/site-packages/accelerate/utils/ao.py:118: sufficient (what is passed when set to `None`).
- .venv/lib/python3.12/site-packages/accelerate/utils/other.py:114: Additional keyword arguments to pass to `torch.compile()`.
- .venv/lib/python3.12/site-packages/accelerate/utils/other.py:184: Additional keyword arguments to pass to `module.compile()`.
- .venv/lib/python3.12/site-packages/accelerate/utils/other.py:413: Additional keyword arguments to pass to `torch.load()`.
- .venv/lib/python3.12/site-packages/accelerate/commands/env.py:110: print("- `Accelerate` default config:" if args.config_file is None else "- `Accelerate` config passed:")
- .venv/lib/python3.12/site-packages/accelerate/commands/tpu.py:69: help="A command to run on the pod. Can be passed multiple times.",
- .venv/lib/python3.12/site-packages/accelerate/commands/estimate.py:101: f"Model `{model_name}` does not have any library metadata on the Hub, please manually pass in a `--library_name` to use 
- .venv/lib/python3.12/site-packages/accelerate/commands/estimate.py:125: # we need to pass the dtype, otherwise it is going to use the torch_dtype that is saved in the config
- .venv/lib/python3.12/site-packages/accelerate/commands/utils.py:20: Custom action that allows for `-` or `_` to be passed in for an argument.
- .venv/lib/python3.12/site-packages/accelerate/commands/utils.py:80: Custom argument group that allows for the use of `-` or `_` in arguments passed and overrides the help for each
- .venv/lib/python3.12/site-packages/accelerate/commands/utils.py:107: Custom argument parser that allows for the use of `-` or `_` in arguments passed and overrides the help for each
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:142: description = "Launch a python script in a distributed scenario. Arguments can be passed in with either hyphens (`--num-
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:381: help="Should not be passed explicitly, this is for internal use only.",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:427: help="DeepSpeed's ZeRO optimization stage (useful only when `use_deepspeed` flag is passed). "
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:434: help="Decides where (none|cpu|nvme) to offload optimizer states (useful only when `use_deepspeed` flag is passed). "
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:441: help="Decides where (none|cpu|nvme) to offload parameters (useful only when `use_deepspeed` flag is passed). "
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:448: help="Decides Nvme Path to offload optimizer states (useful only when `use_deepspeed` flag is passed). "
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:455: help="Decides Nvme Path to offload parameters (useful only when `use_deepspeed` flag is passed). "
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:462: help="No of gradient_accumulation_steps used in your training script (useful only when `use_deepspeed` flag is passed). 
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:469: help="gradient clipping value used in your training script (useful only when `use_deepspeed` flag is passed). "
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:515: " (useful only when `use_deepspeed` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:525: help="FSDP version to use. (useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:531: help="Decides Whether (true|false) to offload parameters and gradients to CPU. (useful only when `use_fsdp` flag is pass
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:537: help="FSDP's minimum number of parameters for Default Auto Wrapping. (useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:544: help="FSDP's sharding strategy. (useful only when `use_fsdp` flag is passed and `fsdp_version=1`).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:550: help="FSDP's Reshard After Forward Strategy. (useful only when `use_fsdp` flag is passed). Supports either boolean (FSDP
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:556: help="FSDP's auto wrap policy. (useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:563: "(useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:569: help="FSDP's backward prefetch policy. (useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:575: help="FSDP's state dict type. (useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:582: "all-gather while executing in the forward pass (useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:589: " (useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:597: "(useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:604: " (useful only when `use_fsdp` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:610: help="Decides Whether (true|false) intermediate activations are freed during the forward pass, and a checkpoint is left 
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:619: help="Megatron-LM's Tensor Parallelism (TP) degree. (useful only when `use_megatron_lm` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:625: help="Megatron-LM's Pipeline Parallelism (PP) degree. (useful only when `use_megatron_lm` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:631: help="Megatron-LM's number of micro batches when PP degree > 1. (useful only when `use_megatron_lm` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:638: "(useful only when `use_megatron_lm` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:645: "(useful only when `use_megatron_lm` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:653: "(useful only when `use_megatron_lm` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:660: "(useful only when `use_megatron_lm` flag is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:677: help="Whether to use FP8 autocast during eval mode (useful only when `--fp8_backend=te` is passed). Generally better met
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:683: help="The margin to use for the gradient scaling (useful only when `--fp8_backend=te` is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:689: help="The interval to use for how often the scaling factor is recomputed (useful only when `--fp8_backend=te` is passed)
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:696: help="The format to use for the FP8 recipe (useful only when `--fp8_backend=te` is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:702: help="The length of the history to use for the scaling factor computation (useful only when `--fp8_backend=te` is passed
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:709: help="The algorithm to use for the scaling factor computation. (useful only when `--fp8_backend=te` is passed).",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:715: help="Whether or not to execute `fprop`, `dgrad`, and `wgrad` GEMMS in higher precision. Should be passed in a comma-sep
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:722: help="What level of 8-bit collective communication should be used with MS-AMP (useful only when `--fp8_backend=msamp` is
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:760: "get passed to the MPI --hostfile or -f parameter, depending on which MPI program is installed.",
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:935: f"Your training script should have a function named {args.main_training_function}, or you should pass a "
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:1127: raise ValueError("You need to manually pass in `--num_processes` using this config yaml.")
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:1162: "\t\tIf this was unintended please pass in `--num_processes=1`."
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:1203: message = "The following values were not passed to `accelerate launch` and had defaults used instead:\n"
- .venv/lib/python3.12/site-packages/accelerate/commands/launch.py:1206: "\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`."
- .venv/lib/python3.12/site-packages/accelerate/commands/config/cluster.py:287: "How many gradient accumulation steps you're passing in your script? [1]: ",
- .venv/lib/python3.12/site-packages/accelerate/commands/config/default.py:45: Optional custom save location. Should be passed to `--config_file` when using `accelerate launch`. Default
- .venv/lib/python3.12/site-packages/accelerate/commands/config/default.py:53: f"Configuration already exists at {save_location}, will not override. Run `accelerate config` manually or pass a differe
- .venv/lib/python3.12/site-packages/accelerate/commands/config/config_args.py:47: f"The passed configuration file `{config_file}` does not exist. "
- .venv/lib/python3.12/site-packages/accelerate/commands/config/config_args.py:48: "Please pass an existing file to `accelerate launch`, or use the default one "
- .venv/lib/python3.12/site-packages/accelerate/commands/config/config_args.py:180: num_processes: int = -1  # For instance if we use SLURM and the user manually passes it in
- .venv/lib/python3.12/site-packages/accelerate/commands/config/update.py:34: raise ValueError(f"The passed config file located at {config_file} doesn't exist.")
- .venv/lib/python3.12/site-packages/accelerate/commands/menu/selection_menu.py:32: pass
- .venv/lib/python3.12/site-packages/accelerate/test_utils/examples.py:36: raise ValueError(f"Incorrect function name passed: {name}, choose either 'main' or 'training_function'")
- .venv/lib/python3.12/site-packages/accelerate/test_utils/examples.py:70: `complete_cv_example.py` script, it should be passed in for the `secondary_filename` parameter.
- .venv/lib/python3.12/site-packages/accelerate/test_utils/examples.py:116: passed_idxs = []  # We keep track of the idxs just in case it's a repeated statement
- .venv/lib/python3.12/site-packages/accelerate/test_utils/examples.py:119: if i not in passed_idxs:
- .venv/lib/python3.12/site-packages/accelerate/test_utils/examples.py:124: passed_idxs.append(i)
- .venv/lib/python3.12/site-packages/accelerate/test_utils/examples.py:131: passed_idxs = []  # We keep track of the idxs just in case it's a repeated statement
- .venv/lib/python3.12/site-packages/accelerate/test_utils/examples.py:133: if i not in passed_idxs:
- .venv/lib/python3.12/site-packages/accelerate/test_utils/examples.py:137: passed_idxs.append(i)
- .venv/lib/python3.12/site-packages/accelerate/test_utils/testing.py:797: pass
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/test_script.py:49: # TODO: remove RegressionModel4XPU once ccl support empty buffer in broadcasting.
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/test_script.py:222: print("Non-shuffled dataloader passing.")
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/test_script.py:250: print("Shuffled dataloader passing.")
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/test_script.py:284: print("Non-shuffled central dataloader passing.")
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/test_script.py:315: print("Shuffled central dataloader passing.")
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/test_distributed_data_loop.py:189: pass
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/test_distributed_data_loop.py:244: pass
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/test_distributed_data_loop.py:256: # TODO: Maybe this should be implemented as __eq__ for AcceleratorState?
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/external_deps/test_checkpointing.py:254: help="If passed, the training will stop after this number of epochs.",
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/external_deps/test_performance.py:236: # TODO: skip saving of the model test for TP until the feature lands
- .venv/lib/python3.12/site-packages/accelerate/test_utils/scripts/external_deps/test_performance.py:285: help="pass 'auto' to use TP",
- .venv/lib/python3.12/site-packages/sympy/abc.py:36: and ``_clash`` is the union of both. These can be passed for ``locals``
- .venv/lib/python3.12/site-packages/sympy/utilities/exceptions.py:129: argument is required and must be passed as a keyword argument.
- .venv/lib/python3.12/site-packages/sympy/utilities/exceptions.py:137: argument is required and must be passed as a keyword argument.
- .venv/lib/python3.12/site-packages/sympy/utilities/exceptions.py:141: The ``stacklevel`` parameter that is passed to ``warnings.warn``. If
- .venv/lib/python3.12/site-packages/sympy/utilities/pkgdata.py:30: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/autowrap.py:110: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/autowrap.py:175: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/autowrap.py:275: The following optional parameters get passed to ``setuptools.Extension``
- .venv/lib/python3.12/site-packages/sympy/utilities/autowrap.py:301: Keyword arguments passed on to cythonize.
- .venv/lib/python3.12/site-packages/sympy/utilities/autowrap.py:510: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/autowrap.py:570: Additional option flags that will be passed to the backend.
- .venv/lib/python3.12/site-packages/sympy/utilities/autowrap.py:883: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/autowrap.py:1053: Additional option flags that will be passed to the backend.
- .venv/lib/python3.12/site-packages/sympy/utilities/autowrap.py:1066: These kwargs will be passed to autowrap if the `f2py` or `cython`
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:173: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:249: nesting of the arguments that will be passed to the function.
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:257: arguments will be passed to the function. Simply enclose the
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:258: parameters as they will be passed in a list.
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:286: If two args will be passed and the first is a scalar but
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:367: the user may pass a function matching the ``cse`` signature.
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:466: If you pass tensorflow objects, you may get an ``EagerTensor``
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:640: passed in (by default, it uses the NumPy module)
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:675: You can change which printer ``lambdify`` uses by passing a custom printer
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:679: translations for each module, but you can provide your own by passing a
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:698: In more complicated cases, it may be necessary to create and pass in a
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:706: lambdified function for one module (say, NumPy), and pass it objects from
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:714: Now if we pass in a NumPy array, we get that array plus 1
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:721: But what happens if you make the mistake of passing in a SymPy expression
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:738: But if we try to pass in a SymPy expression, it fails
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:760: future versions of SymPy. The API of passing in custom modules and
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:767: NumPy), and only pass it input types that are compatible with that module
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:998: raise NotImplementedError("unhandled type: %s, %s" % (type(arg), arg))
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:1110: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:1117: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:1281: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:1365: us - that is - anything that could be passed as ``expr``.  Examples
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:1372: Something passed to lambdify, that will generate valid code from
- .venv/lib/python3.12/site-packages/sympy/utilities/lambdify.py:1497: The same objects that can be passed to the ``expr`` argument of
- .venv/lib/python3.12/site-packages/sympy/utilities/enumerative.py:538: capture all the possible failures -- if a part is passed that
- .venv/lib/python3.12/site-packages/sympy/utilities/enumerative.py:785: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/enumerative.py:1007: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/timeutils.py:12: def timed(func, setup="pass", limit=None):
- .venv/lib/python3.12/site-packages/sympy/utilities/matchpy_connector.py:335: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/decorator.py:112: ...     pass
- .venv/lib/python3.12/site-packages/sympy/utilities/decorator.py:210: ...     pass
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:143: OutputArguments or InOutArguments (e.g., pass-by-reference in C
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:157: Variables which will not be passed into the function.
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:367: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:371: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:582: right-hand-side or pass-by-reference).  Matrices are always returned
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:846: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:943: # body. These are the arguments that were passed by a reference
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:984: # body. These are the arguments that were passed by a reference
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:1512: match the filename (``prefix``).  If you pass multiple ``name_expr`` pairs,
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:1516: You should only pass inputs to ``argument_sequence``: outputs are ordered
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:1916: # body. These are the arguments that were passed by a reference
- .venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:1971: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/misc.py:16: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/misc.py:28: Additional keyword arguments will be passed to ``textwrap.fill()``.
- .venv/lib/python3.12/site-packages/sympy/utilities/misc.py:369: of the order they are given.  ``reps`` may be passed as tuples
- .venv/lib/python3.12/site-packages/sympy/utilities/misc.py:453: raise ValueError('c should be None when a=None is passed, instead got %s' % c)
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:86: ...     pass
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:317: through ``[1, 1, ..., 1]`` are desired, pass a non-integer for bits, e.g.
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:320: If the bit *string* is desired pass ``str=True``.
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:331: If all lists corresponding to 0 to 2**n - 1, pass a non-integer
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:532: Additional positional and keyword arguments are passed to the *cls* class.
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:1338: The output of _set_partitions can be passed as follows:
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:1974: to pass anything for this.
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:1977: RuntimeError if the size of the sequence is known; if you pass
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:2362: remaining in their original positions--pass `strict=False`. To produce a
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:2363: pseudorandom derangment, pass a pseudorandom selector like `choice` (see
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:3022: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:3034: exclude multiple items, pass them as a tuple.
- .venv/lib/python3.12/site-packages/sympy/utilities/iterables.py:3088: type; multiple types should be passed as a tuple of types.
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_misc.py:101: pass # Exception raised successfully
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_misc.py:110: pass # Exception raised successfully
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_lambdify.py:53: from sympy.printing.codeprinter import PrintMethodNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_lambdify.py:663: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_lambdify.py:1029: # check that we can pass in a Function as input
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_lambdify.py:1092: # Unless flag passed
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_lambdify.py:1557: raises(PrintMethodNotImplementedError, lambda: lambdify([x], expr1))
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_lambdify.py:1562: raises(PrintMethodNotImplementedError, lambda: lambdify([x], expr2, printer=MyPrinter))
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_lambdify.py:1671: assert Abs(res1[0]).n() < 1e-15        # First functionality: only one argument passed
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_lambdify.py:1674: assert Abs(res2[0]).n() < 1e-15        # Second functionality: two arguments passed
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_lambdify.py:1819: raise NotImplementedError("Need to handle other than unary & binary functions in test")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen.py:430: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:89: # FIXME: how to pass inline to the RustCodePrinter?
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:248: # FIXME: how to pass inline to the RustCodePrinter?
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:56: raises(NotImplementedError, lambda: pickle.dumps(a, protocol))
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:382: # TODO: fix pickling of Options class (see GroebnerBasis._options)
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:409: check(c, exclude=[0, 1], check_attr=False) # TODO: Py3k
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:412: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:420: # TODO: AssertionError: assert id(obj) not in self.memo
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:424: # TODO: AssertionError: assert id(obj) not in self.memo
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:438: # TODO: fix pickling of ModularInteger
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:444: # TODO: fix pickling of RealElement
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:448: # TODO: fix pickling of ComplexElement
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:457: # TODO: fix pickling of ModularInteger
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:472: # TODO: fix pickling of ModularInteger
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:489: # TODO: fix pickling of RealElement
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:493: # TODO: fix pickling of ComplexElement
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:500: # TODO: AssertionError
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:504: # TODO: AttributeError: 'PolyElement' object has no attribute 'ring'
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:526: # TODO: Argh, Python is so naive. No lambdas nor inner function support in
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:559: # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:563: # TODO: TypeError: can't pickle instancemethod objects
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:612: # TODO: PicklingError: Can't pickle <function <lambda> at 0x38578c0>: it's not found as __main__.<lambda>
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:622: # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:635: # TODO: fix pickling of `symbols' flag
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:639: # TODO: def test_pickling_polys_rootisolation():
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_iterables.py:71: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_iterables.py:860: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_iterables.py:870: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:266: raise NotImplementedError("2**aleph_null == aleph_1")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:290: raise NotImplementedError("cubic_spline([1, 2, 4, 5], [1, 4, 2, 3], x)(3) == 27/8")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:295: raise NotImplementedError("translate sum(a[i]*x**i, (i,1,n)) to FORTRAN")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:300: raise NotImplementedError("translate sum(a[i]*x**i, (i,1,n)) to C")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:308: raise NotImplementedError("apply Horner's rule to sum(a[i]*x**i, (i,1,5))")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:313: raise NotImplementedError("translate D8 to FORTRAN")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:318: raise NotImplementedError("translate D8 to C")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:324: raise NotImplementedError("flops(sum(product(f[i][k], (i,1,k)), (k,1,n)))")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:334: raise NotImplementedError("discretize a PDE: diff(f(x,t),t) == diff(diff(f(x,t),x),x)")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:391: raise NotImplementedError("find the primitive root of 191 == 19")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:396: raise NotImplementedError("(a+b)**p mod p == a**p + b**p mod p; p prime")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:561: raise NotImplementedError("let a**2==2; (x**3 + (a-2)*x**2 - "
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:567: raise NotImplementedError("evaluate (b+c)**4 assuming b**3==2, c**2==3. \
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:608: raise NotImplementedError("expand ((1 - c**2)**5 * (1 - s**2)**5 * "
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:631: raise NotImplementedError("[A*B*C - (A*B*C)**(-1)]*A*C*B (product \
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:668: raise NotImplementedError("assuming -3*pi<x<-5*pi/2, abs(cos(x)) == -cos(x), abs(sin(x)) == -sin(x)")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:716: raise NotImplementedError("Jacobi elliptic functions: diff(dn(u,k), u) == -k**2*sn(u,k)*cn(u,k)")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:771: raise NotImplementedError("F((n+2)/2,-(n-2)/2,R(3,2),sin(z)**2) == sin(n*z)/(n*sin(z)*cos(z)); F(.) is hypergeometric fu
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:776: raise NotImplementedError("diff(zeta(x), x) @ x=0 == -log(2*pi)/2")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:785: raise NotImplementedError("define an antisymmetric function")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:920: # TODO: Replace solve with solveset, as of now test fails for solveset
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:952: raise NotImplementedError("solveset(exp(2-x**2)-exp(-x),x) has complex solutions.")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:956: # TODO: Replace solve with solveset when it gives Lambert solution
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:966: # TODO: x = [-1, 2*(+/-asinh(1)*I + n*pi}, 3*(pi/6 + n*pi/3)]
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:967: # TODO: Replace solve with solveset, as of now test fails for solveset
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1014: # TODO: Replace solve with solveset, as of now test fails for solveset
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1032: # TODO: Replace solve with solveset, as of now test fails for solveset
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1038: # TODO: Replace solve with solveset, as of now test fails for solveset
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1047: # TODO: Replace solve with solveset, as of now test fails for solveset
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1052: # TODO: Replace solve with solveset, as of now test fails for solveset
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1059: # TODO: Replace solve with solveset which gives both [+/- current answer]
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1077: # TODO: Replace solve with solveset, as of now
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1084: # TODO: Replace solve with solveset, as of now
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1092: # TODO: Replace solve with solveset, as of now
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1099: # TODO: Replace solve with solveset, as of now
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1118: # TODO: Replace solve with solveset, as of now
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1194: # TODO: Replace solve with solveset, as of now
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1296: # raises NotImplementedError: only univariate inequalities are supported
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1326: raise NotImplementedError("""The vector module has no way of representing
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1341: raise NotImplementedError("""The vector module has no way of representing
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1404: raise NotImplementedError("Block matrix diagonalization not supported")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1455: # raises NotImplementedError("Matrix([[x,y],[1,x*y]]).inv()
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1559: raise NotImplementedError("Matrix minimal polynomial not supported")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1669: raise NotImplementedError("Generalized eigenvectors not supported \
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1675: raise NotImplementedError("Generalized eigenvectors not supported \
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1695: raise NotImplementedError("Smith normal form not implemented")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1786: raise NotImplementedError("Singular value decomposition not implemented")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1842: raise NotImplementedError('Unknown result')
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1888: raise NotImplementedError("Indefinite sum not supported")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2161: # raises NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2252: # TODO: Replace solve with solveset, current test fails for solveset
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2288: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2299: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2311: raise NotImplementedError("minimize(), maximize() not supported")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2316: raise NotImplementedError("minimize() not supported and also solve does \
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2322: raise NotImplementedError("minimize() not supported in SymPy and also \
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2328: raise NotImplementedError("Linear programming, symbolic simplex not \
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2382: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2497: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2681: # series() raises NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2832: raise NotImplementedError("Solve using series not supported. \
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2847: raise NotImplementedError("Symbolic Pade approximant not supported")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2898: raise NotImplementedError("Fourier series not supported")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:3023: raise NotImplementedError("z-transform not supported")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:3029: raise NotImplementedError("z-transform not supported")
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:3082: # TODO: Replace solve with solveset, when it works for solveset
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:3088: raise NotImplementedError('ODE solving with initial conditions \
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:83: # FIXME: how to pass inline=False to the OctaveCodePrinter?
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:225: # FIXME: how to pass inline=False to the OctaveCodePrinter?
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:448: # more dimensions.  Also, size(A) would be used rather than passing in m
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:85: # FIXME: how to pass inline=False to the JuliaCodePrinter?
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:235: # FIXME: how to pass inline=False to the JuliaCodePrinter?
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:473: # more dimensions.  Also, size(A) would be used rather than passing in m
- .venv/lib/python3.12/site-packages/sympy/utilities/tests/test_decorator.py:86: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/runners.py:131: pass  # already enforced
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/runners.py:136: pass  # already disabled
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/runners.py:159: """ List of arguments (str) to be passed to e.g. ``subprocess.Popen``. """
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:53: Default keyword arguments to pass to ``Runner``.
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:144: Keyword arguments passed to ``Runner``.
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:214: Keyword arguments passed to ``link(...)``.
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:254: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:264: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:290: Second argument passed to cy_compile. Generates a .cpp file if ``cplus=True`` in ``cy_kwargs``,
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:369: keyword arguments passed to Runner or pyx2obj
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:440: Keyword arguments passed onto `simple_cythonize`
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:444: keyword arguments passed onto src2obj
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:532: keyword arguments passed to ``compile_sources``
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:534: keyword arguments passed to ``link_py_so``
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:596: Keyword arguments passed onto `compile_link_import_py_ext`.
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:628: Keyword arguments passed onto ``compile_sources``
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/compilation.py:630: Keyword arguments passed onto ``link``
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/__init__.py:9: TODO:
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/util.py:22: pass
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/util.py:133: # passing a (possible non-existent) destination directory
- .venv/lib/python3.12/site-packages/sympy/utilities/_compilation/tests/test_compilation.py:90: pass  # we cannot test contents of object file
- .venv/lib/python3.12/site-packages/sympy/testing/pytest.py:148: pass
- .venv/lib/python3.12/site-packages/sympy/testing/pytest.py:151: pass
- .venv/lib/python3.12/site-packages/sympy/testing/pytest.py:154: pass
- .venv/lib/python3.12/site-packages/sympy/testing/pytest.py:157: pass
- .venv/lib/python3.12/site-packages/sympy/testing/pytest.py:225: ...     pass
- .venv/lib/python3.12/site-packages/sympy/testing/pytest.py:355: ...     pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests_pytest.py:102: """Appends valid paths and flags to the args `list` passed to `pytest.main`.
- .venv/lib/python3.12/site-packages/sympy/testing/runtests_pytest.py:104: The are three different types of "path" that a user may pass to the `paths`
- .venv/lib/python3.12/site-packages/sympy/testing/runtests_pytest.py:107: 1. Nothing is passed
- .venv/lib/python3.12/site-packages/sympy/testing/runtests_pytest.py:110: 2. Full, valid paths are passed
- .venv/lib/python3.12/site-packages/sympy/testing/runtests_pytest.py:113: 3. Partial paths are passed.
- .venv/lib/python3.12/site-packages/sympy/testing/runtests_pytest.py:226: This function assumes that partial_paths will be passed in such that they
- .venv/lib/python3.12/site-packages/sympy/testing/runtests_pytest.py:254: all tests successfully pass the `pytest.ExitCode.OK` with value `0` is
- .venv/lib/python3.12/site-packages/sympy/testing/runtests_pytest.py:461: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:89: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:92: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:95: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:203: function is passed to sys.exit(), so the return value of the function will
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:212: PYTHONHASHSEED is set, pass ``force=True``.  This flag will not force a
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:241: # pass, 1 if they fail, and False if it does not support hash
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:297: You can pass arguments and keyword arguments to the test functions that
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:365: .       passed
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:367: X       XPassed (expected to fail but passed)
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:438: The ``split`` option can be passed to split the test run into parts. The
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:445: The ``time_balance`` option can be passed in conjunction with ``split``.
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:520: All keyword arguments from ``test()`` are passed to this function except for
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:523: Returns 0 if tests passed and 1 if they failed.  See the docstring of
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:623: The ``split`` option can be passed to split the test run into parts. The
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:793: All keyword arguments from ``doctest()`` are passed to this function
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:796: Returns 0 if tests passed and 1 if they failed.  See the docstrings of
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:865: # of necessary modules by doctest.testfile. If you try to pass *.py files
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:993: # find the first time the cumulative sum surpasses x
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1057: detailed, else very brief (in fact, empty if all tests passed).
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1164: Runs the tests returning True if all tests pass, otherwise False.
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1171: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1240: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1332: reporter.test_xpass(v)
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1338: reporter.test_pass()
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1403: Runs the tests and returns True if all tests pass, otherwise False.
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1501: self._reporter.test_pass()
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1606: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1609: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1612: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1615: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1936: # TODO parse integers as well ?
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1996: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2011: self._xpassed = []
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2014: self._passed = 0
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2023: # TODO: Should these be protected?
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2071: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2092: pass
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2246: text = "tests finished: %d passed, " % self._passed
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2266: if len(self._xpassed) > 0:
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2267: add_text("%d expected to fail but passed, " % len(self._xpassed))
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2285: if len(self._xpassed) > 0:
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2286: self.write_center("xpassed tests", "_")
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2287: for e in self._xpassed:
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2352: def test_xpass(self, v):
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2354: self._xpassed.append((self._active_file, message))
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2369: def test_pass(self, char="."):
- .venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2370: self._passed += 1
- .venv/lib/python3.12/site-packages/sympy/testing/tests/test_runtests_pytest.py:37: """If no paths are passed, only `sympy` and `doc/src` are appended.
- .venv/lib/python3.12/site-packages/sympy/testing/tests/test_runtests_pytest.py:40: need to be manually added as if any path-related arguments are passed
- .venv/lib/python3.12/site-packages/sympy/testing/tests/test_pytest.py:27: def test_unexpected_exception_is_passed_through_callable():
- .venv/lib/python3.12/site-packages/sympy/testing/tests/test_pytest.py:52: def test_unexpected_exception_is_passed_through_with():
- .venv/lib/python3.12/site-packages/sympy/testing/tests/test_pytest.py:78: pass
- .venv/lib/python3.12/site-packages/sympy/testing/tests/test_pytest.py:136: pass
- .venv/lib/python3.12/site-packages/sympy/testing/tests/test_pytest.py:170: pass
- .venv/lib/python3.12/site-packages/sympy/testing/tests/test_code_quality.py:143: ...         pass  # no checking there
- .venv/lib/python3.12/site-packages/sympy/testing/tests/test_code_quality.py:171: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/assume.py:333: t = (t,)  # for convenience, allow passing `type` to mean `(type,)`
- .venv/lib/python3.12/site-packages/sympy/assumptions/assume.py:349: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/assumptions/assume.py:350: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/refine.py:53: # TODO: this will probably not work with Integral or Polynomial
- .venv/lib/python3.12/site-packages/sympy/assumptions/satask.py:25: will be found and passed to SAT solver because ``Q.nonnegative`` is
- .venv/lib/python3.12/site-packages/sympy/assumptions/satask.py:46: module are passed to SAT solver as well.
- .venv/lib/python3.12/site-packages/sympy/assumptions/satask.py:103: # TODO: Run additional checks to see which combination of the
- .venv/lib/python3.12/site-packages/sympy/assumptions/satask.py:213: extracted. On the first run, set containing the expression is passed
- .venv/lib/python3.12/site-packages/sympy/assumptions/satask.py:239: We pass the first run's results to the second run, and get the expressions
- .venv/lib/python3.12/site-packages/sympy/assumptions/tests/test_sathandlers.py:17: # The predicate doesn't matter here, so just pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/tests/test_sathandlers.py:20: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/tests/test_sathandlers.py:23: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/tests/test_query.py:2228: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/tests/test_query.py:2247: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/tests/test_query.py:2469: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/tests/test_query.py:2489: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/tests/test_query.py:2520: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/tests/test_context.py:29: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:19: from sympy.multipledispatch import MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:53: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:134: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:215: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:254: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:279: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:409: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:422: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:443: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:447: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:451: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:457: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:463: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:477: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:496: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:537: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:553: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:689: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:702: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:725: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:734: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/sets.py:748: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/ntheory.py:12: from sympy.multipledispatch import MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/ntheory.py:38: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/ntheory.py:102: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/ntheory.py:148: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/ntheory.py:210: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/ntheory.py:268: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:13: from sympy.multipledispatch import MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:56: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:94: pass
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:131: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:149: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:159: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:208: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:218: # TODO: This should be deducible from the nonzero handler
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:228: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:266: raise MDNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:47: # TODO: implement sathandlers system for the matrices.
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:77: # TODO: implement sathandlers system for the matrices.
- .venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:94: # TODO: implement sathandlers system for the matrices.
- .venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:238: # TODO: Add examples
- .venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:337: # TODO: Add examples
- .venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:394: # TODO: Add examples
- .venv/lib/python3.12/site-packages/sympy/assumptions/predicates/common.py:17: # TODO: Add examples
- .venv/lib/python3.12/site-packages/sympy/assumptions/predicates/calculus.py:57: # TODO: Add examples
- .venv/lib/python3.12/site-packages/sympy/assumptions/predicates/matrices.py:70: # TODO: Add handlers to make these keys work with
- .venv/lib/python3.12/site-packages/sympy/assumptions/relation/binrel.py:106: pass
- .venv/lib/python3.12/site-packages/sympy/physics/wigner.py:370: # the triangle test will only pass if a) all 3 values are ints or
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:71: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:75: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:79: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:83: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:87: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:91: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:353: raise NotImplementedError('implement apply_operator in a subclass')
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:357: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:361: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:365: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:1499: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:1782: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:1784: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:1883: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:1895: pass  # since sign==0, no permutations was necessary
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2401: pass
- .venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2972: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:35: """Function to check whether the dynamical system passed for plots is
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:38: raise NotImplementedError("Only SISO LTI systems are currently supported.")
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:48: raise NotImplementedError("Time delay terms are not supported.")
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:86: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:87: When a SISO LTI system is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:218: sampled response, then ``adaptive`` kwarg should be passed ``False``
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:219: and ``n`` must be passed as additional kwargs.
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:236: Additional keyword arguments are passed to the underlying
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:249: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:250: When a SISO LTI system is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:369: sampled response, then ``adaptive`` kwarg should be passed ``False``
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:370: and ``n`` must be passed as additional kwargs.
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:387: Additional keyword arguments are passed to the underlying
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:400: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:401: When a SISO LTI system is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:520: sampled response, then ``adaptive`` kwarg should be passed ``False``
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:521: and ``n`` must be passed as additional kwargs.
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:540: Additional keyword arguments are passed to the underlying
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:553: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:554: When a SISO LTI system is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:605: passing through origin ($f(x) = mx$). The slope of
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:708: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:709: When a SISO LTI system is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:821: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/control/control_plots.py:822: When a SISO LTI system is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:94: raise NotImplementedError("Not implemented for MIMO systems.")
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:216: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:220: When a SISO LTI system is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:269: raise NotImplementedError("Margins for systems with Time delay terms are not supported.")
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:299: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:303: When a SISO LTI system is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:344: raise NotImplementedError("Margins for systems with Time delay terms are not supported.")
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:372: raise NotImplementedError('The LTICommon class is not meant to be used directly.')
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:378: raise ValueError("At least 1 argument must be passed.")
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:390: """Returns `True` if the passed LTI system is SISO else returns False."""
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:661: is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:664: ``var`` is not passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:684: raise a ``ValueError``, if ``var`` is not passed by the user.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1463: When passed ``True``, returns the equivalent
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1470: When no argument is passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1474: Any of the passed ``*args`` has unsupported type
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1477: passed. There should be homogeneity in the
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1478: type of systems passed, SISO in this case.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1801: When passed ``True``, returns the equivalent
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1808: When no argument is passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1816: Any of the passed ``*args`` has unsupported type
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1819: passed. There should be homogeneity in the
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:1820: type of systems passed, MIMO in this case.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2077: When passed ``True``, returns the equivalent
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2084: When no argument is passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2088: Any of the passed ``*args`` has unsupported type
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2091: passed. There should be homogeneity in the
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2092: type of systems passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2370: When passed ``True``, returns the equivalent
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2377: When no argument is passed.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2381: All MIMO systems passed do not have same shape.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2383: Any of the passed ``*args`` has unsupported type
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2386: passed. There should be homogeneity in the
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:2387: type of systems passed, MIMO in this case.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:3044: systems passed is invertible or not.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:3426: canceling the common factors then the ``cancel`` kwarg should be passed ``False``.
- .venv/lib/python3.12/site-packages/sympy/physics/control/lti.py:3439: the ``expand`` kwarg should be passed as ``True``.
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_lti.py:271: raises(NotImplementedError, lambda: TransferFunction(x**2, a0*x**10 + x + x**2, x).poles())
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_lti.py:306: raises(NotImplementedError, lambda: TransferFunction(a0*x**10 + x + x**2, x**2, x).zeros())
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_lti.py:983: assert f5 == Feedback(tf5)  # When sys2 is not passed explicitly, it is assumed to be unit tf.
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_lti.py:1460: raises(NotImplementedError, lambda: phase_margin(tf4))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_lti.py:1475: raises(NotImplementedError, lambda: gain_margin(tf4))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_control_plots.py:68: raises(NotImplementedError, lambda: pole_zero_plot(tfm))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_control_plots.py:69: raises(NotImplementedError, lambda: pole_zero_numerical_data(expr))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_control_plots.py:70: raises(NotImplementedError, lambda: impulse_response_plot(expr))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_control_plots.py:71: raises(NotImplementedError, lambda: impulse_response_numerical_data(tfm))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_control_plots.py:72: raises(NotImplementedError, lambda: step_response_plot(tfm))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_control_plots.py:73: raises(NotImplementedError, lambda: step_response_numerical_data(expr))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_control_plots.py:74: raises(NotImplementedError, lambda: ramp_response_plot(expr))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_control_plots.py:75: raises(NotImplementedError, lambda: ramp_response_numerical_data(tfm))
- .venv/lib/python3.12/site-packages/sympy/physics/control/tests/test_control_plots.py:76: raises(NotImplementedError, lambda: bode_plot(tfm))
- .venv/lib/python3.12/site-packages/sympy/physics/optics/polarization.py:50: We calculate the very common operation of passing a beam through a half-wave
- .venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:526: #TODO A class Complex may be implemented. The BeamParameter may
- .venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:885: #TODO add the other possible arguments
- .venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:892: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:899: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:906: #TODO
- .venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:909: #    pass
- .venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:911: #TODO
- .venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:923: #    pass
- .venv/lib/python3.12/site-packages/sympy/physics/optics/waves.py:295: raise NotImplementedError("Interference of waves with different frequencies"
- .venv/lib/python3.12/site-packages/sympy/physics/tests/test_secondquant.py:451: raises(NotImplementedError, lambda:  NO(Bd(p)*F(q)))
- .venv/lib/python3.12/site-packages/sympy/physics/units/prefixes.py:128: pass as argument a subdict of them if you do not want all prefixed units.
- .venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:308: pass
- .venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:351: # TODO: should this raise a warning?
- .venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:522: #TODO: the inversion will fail if the system is inconsistent, for
- .venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:206: # TODO: decide whether to allow such expression in the future
- .venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:227: # TODO: Pow only support structural equality:
- .venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:244: # TODO: need better simplification routine:
- .venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:249: # TODO: need a better way to simplify expressions containing units:
- .venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:253: # TODO: fix this, it should give `m` without `Abs`
- .venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_dimensions.py:68: # others to pass
- .venv/lib/python3.12/site-packages/sympy/physics/hep/gamma_matrices.py:713: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body_base.py:82: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body_base.py:86: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body_base.py:90: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body_base.py:94: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/functions.py:348: raise TypeError("No bodies(instances of Particle or Rigidbody) were passed.")
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/functions.py:475: raise ValueError("You must provide reference_frame when passing a "
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:35: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:48: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:64: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:79: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:237: If the ``geodesic_length`` method is passed an argument, the ``Point``
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:322: axis passes are needed:
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:332: A cylinder with radius ``r``, and axis parallel to ``N.x`` passing through
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:344: A point through which the cylinder's axis passes.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:366: A point through which the cylinder's axis passes.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:386: """A point through which the cylinder's axis passes."""
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:478: If the ``geodesic_length`` method is passed an argument ``Point`` that
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:620: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:626: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/wrapping_geometry.py:639: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/system.py:493: """Helper to convert passed objects to a list."""
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/system.py:906: raise NotImplementedError(f'{eom_method} has not been implemented.')
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/system.py:1029: certain areas. However a well-defined system should always pass all
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/system.py:1098: raise NotImplementedError(f'{eom_method} has not been implemented.')
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/system.py:1173: whether or not the coordinate derivatives are passed in. If
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/system.py:1299: Now the equations of motion are ready to be formed and passed to the
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:45: f'Value {repr(attachments)} passed to `attachments` was an '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:53: f'Value {repr(point)} passed to `attachments` at index '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:63: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:69: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:79: passed to the ``loads`` parameters of its ``kanes_equations`` method
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:83: the list of loads and passed to ``KanesMethod.kanes_equations``. These
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:84: loads are also in the correct form to also be passed to the other
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:88: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:130: To construct a pathway, two points are required to be passed to the
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:172: Constructor expects two points to be passed, e.g.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:186: Constructor expects two points to be passed, e.g.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:210: passed to the ``loads`` parameters of its ``kanes_equations`` method
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:214: the list of loads and passed to ``KanesMethod.kanes_equations``. These
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:215: loads are also in the correct form to also be passed to the other
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:238: ``to_loads`` method with ``F`` passed as the only argument.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:281: be passed to the ``attachments`` parameter as a ``tuple``.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:359: f'Value {repr(attachments)} passed to `attachments` was an '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:367: f'Value {repr(point)} passed to `attachments` at index '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:398: passed to the ``loads`` parameters of its ``kanes_equations`` method
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:402: the list of loads and passed to ``KanesMethod.kanes_equations``. These
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:403: loads are also in the correct form to also be passed to the other
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:437: ``to_loads`` method with ``F`` passed as the only argument.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:508: be passed, followed by an instance of a wrapping geometry class as a
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:510: parallel to ``N.x`` passing through a point ``pO``.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:572: f'Value {repr(geometry)} passed to `geometry` was of type '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:595: passed to the ``loads`` parameters of its ``kanes_equations`` method
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:599: the list of loads and passed to ``KanesMethod.kanes_equations``. These
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:600: loads are also in the correct form to also be passed to the other
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:610: passes through a point ``pO``.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/pathway.py:639: ``to_loads`` method with ``F`` passed as the only argument.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/models.py:93: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/lagrange.py:392: Extra keyword arguments are passed to
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/method.py:8: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/method.py:12: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/method.py:16: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/method.py:20: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/method.py:24: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/method.py:28: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/method.py:32: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/method.py:36: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/method.py:39: raise NotImplementedError("Subclasses must implement this.")
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/kane.py:630: # TODO : Remove `new_method` after 1.1 has been released.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/kane.py:649: Extra keyword arguments are passed to
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:37: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:47: passed to the ``loads`` parameters of its ``kanes_equations`` method
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:51: the list of loads and passed to ``KanesMethod.kanes_equations``. These
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:52: loads are also in the correct form to also be passed to the other
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:56: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:178: f'Value {repr(pathway)} passed to `pathway` was of type '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:191: passed to the ``loads`` parameters of its ``kanes_equations`` method
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:195: the list of loads and passed to ``KanesMethod.kanes_equations``. These
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:196: loads are also in the correct form to also be passed to the other
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:275: to be passed to the ``pathway`` parameter.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:330: (or symbol) can be passed to the ``equilibrium_length`` parameter on
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:450: passed to the ``pathway`` parameter.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:611: when one is passed instead of a ``ReferenceFrame``.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:660: body, and child body to be passed to its constructor. It is also
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:685: variables previously instantiated, these can be passed to the alternate
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:712: f'Value {repr(pin_joint)} passed to `pin_joint` was of type '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:753: f'Value {repr(axis)} passed to `axis` was of type '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:776: f'Value {repr(target_frame)} passed to `target_frame` was of '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:802: f'Value {repr(reaction_frame)} passed to `reaction_frame` was '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:815: passed to the ``loads`` parameters of its ``kanes_equations`` method
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:819: the list of loads and passed to ``KanesMethod.kanes_equations``. These
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:820: loads are also in the correct form to also be passed to the other
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/actuator.py:954: f'Value {repr(pathway)} passed to `pathway` was of type '
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/joint.py:289: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/joint.py:294: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/joint.py:299: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/joint.py:304: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/joint.py:309: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/joint.py:329: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/joint.py:1969: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body.py:15: object depending on what is passed in during initialization. If a mass is
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body.py:16: passed in and central_inertia is left as None, the Particle object is
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body.py:61: mass is passed, one is generated.
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body.py:66: Central inertia dyadic of the body. If none is passed while creating
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body.py:103: involves simply passing in a name and a mass. ::
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/body.py:153: # If user passes masscenter and mass then a particle is created
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_linearize.py:330: # Check if passing a function to linear_solver works
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_kane.py:83: # pass relevant information, and form Fr & Fr*. Then we calculate the mass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_joint.py:1003: # pass the derivative of the generalized coordinates as generalized speeds
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_actuator.py:672: pass
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_particle.py:55: # TODO make the result not be system-dependent
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_body.py:143: # passing something else than point
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_system.py:40: # Set up a body and load to pass into the system
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_system.py:57: # Set up remaining arguments that can be passed to SymbolicSystem
- .venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_system_class.py:520: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:214: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:235: Additional keyword argument pairs to be recursively passed to
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:433: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:454: Additional keyword argument pairs to be recursively passed to
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:540: passive fiber force very close to 0 for all normalized fiber lengths
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:612: Returns a new instance of the muscle fiber passive force-length
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:649: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:670: Additional keyword argument pairs to be recursively passed to
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:743: r"""Inverse passive muscle fiber force-length curve based on De Groote et
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:750: passive muscle fiber force.
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:763: passive fiber force very close to 0 for all normalized fiber lengths
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:774: argument corresponding to the normalized passive muscle fiber length-force
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:825: Returns a new instance of the inverse muscle fiber passive force-length
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:838: Normalized passive muscle fiber force as a function of muscle fiber
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:854: Normalized passive muscle fiber force.
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:863: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:884: Additional keyword argument pairs to be recursively passed to
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1084: Normalized passive muscle fiber force as a function of muscle fiber
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1149: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1170: Additional keyword argument pairs to be recursively passed to
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1429: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1450: Additional keyword argument pairs to be recursively passed to
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1653: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1674: Additional keyword argument pairs to be recursively passed to
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1749: fiber_force_length_passive: CharacteristicCurveFunction
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1750: fiber_force_length_passive_inverse: CharacteristicCurveFunction
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1759: yield self.fiber_force_length_passive
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/curve.py:1760: yield self.fiber_force_length_passive_inverse
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:57: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:111: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:125: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:139: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:153: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:167: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:188: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:209: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:225: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:241: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/activation.py:256: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/_mixin.py:43: f'Name {repr(name)} passed to `name` was of type '
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:112: the tendon force-length, passive fiber force-length, active fiber force-
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:163: The muscle fiber length at which the muscle fibers produce no passive
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:257: f'passed to `musculotendon_dynamics` was of type '
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:353: passive force and their maximum active force. In all musculotendon
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:388: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:471: The muscle fiber length at which the muscle fibers produce no passive
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:488: The muscle fiber length at which the muscle fibers produce no passive
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:705: self._fl_M_pas = self.curves.fiber_force_length_passive.with_defaults(self._l_M_tilde)
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:712: self._fl_M_pas = self.curves.fiber_force_length_passive(self._l_M_tilde, *fl_M_pas_constants)
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:745: self._fl_M_pas = self.curves.fiber_force_length_passive.with_defaults(self._l_M_tilde)
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:751: self._fl_M_pas = self.curves.fiber_force_length_passive(self._l_M_tilde, *fl_M_pas_constants)
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:792: self._fl_M_pas = self.curves.fiber_force_length_passive.with_defaults(self._l_M_tilde)
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:796: self._fl_M_pas = self.curves.fiber_force_length_passive(self._l_M_tilde, *fl_M_pas_constants)
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:830: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:833: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:1125: The musculotendon class requires symbols or values to be passed to represent
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:1140: biomechanics module and create an instance by passing in the various objects
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:1165: When we created the musculotendon object, we passed in an instance of an
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:1240: pass a member of the ``MusculotendonFormulation`` enumeration to the
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:1242: enumeration is an ``IntEnum``, so you can also pass an integer, however it
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:1387: The muscle fiber length at which the muscle fibers produce no passive
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:1419: fiber_force_length_passive=FiberForceLengthPassiveDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/musculotendon.py:1420: fiber_force_length_passive_inverse=FiberForceLengthPassiveInverseDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:79: pass
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:477: def _fiber_force_length_passive_arguments_fixture(self):
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:664: def _fiber_force_length_passive_arguments_fixture(self):
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1622: fiber_force_length_passive=FiberForceLengthPassiveDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1623: fiber_force_length_passive_inverse=FiberForceLengthPassiveInverseDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1630: assert curves.fiber_force_length_passive is FiberForceLengthPassiveDeGroote2016
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1631: assert curves.fiber_force_length_passive_inverse is FiberForceLengthPassiveInverseDeGroote2016
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1658: 'fiber_force_length_passive': FiberForceLengthPassiveDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1659: 'fiber_force_length_passive_inverse': FiberForceLengthPassiveInverseDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1676: fiber_force_length_passive=FiberForceLengthPassiveDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1677: fiber_force_length_passive_inverse=FiberForceLengthPassiveInverseDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1687: curves.fiber_force_length_passive = None
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_curve.py:1689: curves.fiber_force_length_passive_inverse = None
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_musculotendon.py:232: fiber_force_length_passive=FiberForceLengthPassiveDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_musculotendon.py:233: fiber_force_length_passive_inverse=FiberForceLengthPassiveInverseDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_musculotendon.py:287: fl_M_pas = curve.fiber_force_length_passive.with_defaults(self.l_M_tilde)
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_musculotendon.py:380: fiber_force_length_passive=FiberForceLengthPassiveDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_musculotendon.py:381: fiber_force_length_passive_inverse=FiberForceLengthPassiveInverseDeGroote2016,
- .venv/lib/python3.12/site-packages/sympy/physics/biomechanics/tests/test_musculotendon.py:441: fl_M_pas = curve.fiber_force_length_passive.with_defaults(l_M_tilde)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:466: raise NotImplementedError('Joining beams with different Elastic modulus is not implemented.')
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:757: Returns a ValueError if the load passed as an argument is not
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1058: # slope, then above block gives NotImplementedError as
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1060: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1146: # slope, then above block gives NotImplementedError as solve
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1148: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1205: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1207: raise NotImplementedError("This method cannot be used when a whole region of "
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1491: raise ValueError('value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1552: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1610: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1668: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1727: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1786: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:1996: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:2000: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:2145: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:2149: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:2291: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:2295: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:2665: Single SymPy expression can be passed if both values are same
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:3115: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:3217: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:3319: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:3423: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/beam.py:3595: raise ValueError('Value of %s was not passed.' %sym)
- .venv/lib/python3.12/site-packages/sympy/physics/continuum_mechanics/tests/test_beam.py:460: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixutils.py:32: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixutils.py:39: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixutils.py:141: # TODO: Move this into sympy.matrices.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixutils.py:205: raise NotImplementedError('Invalid format: %r' % format)
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixutils.py:237: raise NotImplementedError('Invaild format: %r' % format)
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:202: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:242: # TODO: This can be optimized to reduce the number of Qubit
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:305: raise NotImplementedError('plot_gate is not implemented.')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:956: raise NotImplementedError('Commutator not implemented: %r' % other)
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:971: raise NotImplementedError('Commutator not implemented: %r' % other)
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:978: raise NotImplementedError('Commutator not implemented: %r' % other)
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:1082: qubits.  The format of this matrix must match that passed into
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:1134: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qasm.py:172: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/sho1d.py:132: raise NotImplementedError('Position representation is not implemented')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/sho1d.py:273: raise NotImplementedError('Position representation is not implemented')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/sho1d.py:393: raise NotImplementedError('Position representation is not implemented')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/sho1d.py:499: raise NotImplementedError('Position representation is not implemented')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:78: """ Returns the eigenstate instance for the passed operators.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:81: passed either an Operator instance or set of Operator instances. It
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:83: NotImplementedError. See cartesian.py for an example.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:86: raise NotImplementedError("Cannot map operators to states in this class. Method not implemented!")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:93: state instances and be passed the operator classes that we wish to make
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:95: appropriately, or raise a NotImplementedError if it cannot return
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:99: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:109: raise NotImplementedError("Cannot enumerate this state!")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:129: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:315: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:365: Compound labels are passed as tuples::
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:605: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:741: #Any passed tuples for coordinates and their bounds need to be
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:760: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:764: #If the passed value is outside the specified bounds, return 0
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:768: #Do the comparison to limits only if the passed symbol is actually
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/state.py:964: raise NotImplementedError("The function is not normalizable!")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/innerproduct.py:129: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/innerproduct.py:134: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:3: TODO:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:183: raise NotImplementedError('matrix_elements is not defined')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:334: raise NotImplementedError('Cannot represent infinite dimensional' +
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:339: raise NotImplementedError('Representation in format ' +
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:428: # TODO: make sure the hilbert spaces of the bra and ket are
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:491: # TODO if operands are tensorproducts this may be will be handled
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:500: It is initialized by passing two arguments. The first is an arbitrary
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixcache.py:39: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixcache.py:43: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixcache.py:47: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixcache.py:62: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixcache.py:78: # TODO: explore different sparse formats. But sparse.kron will use
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:1: #TODO:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:486: #TODO: Improve simplification method
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:495: is then passed to the simplification methods, which return the new cg_part
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:675: # TODO: Check for symmetries
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:742: raise NotImplementedError('term must be CG, Add, Mul or Pow')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/density.py:21: TODO: Density operator support for Qubits
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qft.py:91: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/identitysearch.py:55: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qexpr.py:26: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qexpr.py:32: This is like sympify, but it performs special logic for arguments passed
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qexpr.py:41: Strings are passed to Symbol, not sympify to make sure that variables like
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qexpr.py:141: This is used to bypass the more complex logic in the ``__new__``
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qexpr.py:182: raise NotImplementedError("No default arguments for this class!")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qexpr.py:198: """Process the args passed to the __new__ method.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qexpr.py:320: raise NotImplementedError('This object does not have a default basis')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qexpr.py:406: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:35: TODO: Handle condition such as symbols have subscripts/superscripts
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:94: # TODO: Need to handle printing
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:172: #TODO: Current version ignores the indices set for partial trace.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:189: # TODO : improve this implementation
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:192: #TODO: Review if the permute method is needed
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/cartesian.py:3: TODO:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:3: TODO:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:91: Key/value pairs of options that are passed to the underlying method
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:117: ...     pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:149: except NotImplementedError as strerr:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:158: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:159: raise NotImplementedError(strerr)
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:163: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:164: raise NotImplementedError(strerr)
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:166: raise NotImplementedError(strerr)
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:256: basis. Should only be passed an instance of KetBase or BraBase
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:279: raise TypeError("expr passed is not a Bra or Ket")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:284: raise NotImplementedError("Can't form this representation!")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:335: raise TypeError("The passed expression is not an operator")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:340: raise NotImplementedError("Could not get basis kets for this operator")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:360: passed to it in order to figure out the limits of integration.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:417: #TODO: Add support for sets of operators
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:449: only pass QExpr's.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:451: TODO (?): Support for Muls and other types of expressions?
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:525: 1. Two arguments are passed to it. The first is the base state which is to
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:528: 2. Three arguments are passed. The first is again the base state to be
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:557: raise NotImplementedError("Wrong number of arguments!")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:571: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/hilbert.py:35: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/hilbert.py:69: raise NotImplementedError('This Hilbert space has no dimension.')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/shor.py:29: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/shor.py:36: TODO: implement a decompose property that returns how to do this in terms
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/shor.py:45: raise NotImplementedError('The CMod gate has not been completed.')
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/pauli.py:111: raise NotImplementedError('Representation in format ' +
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/pauli.py:181: raise NotImplementedError('Representation in format ' +
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/pauli.py:251: raise NotImplementedError('Representation in format ' +
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/pauli.py:335: raise NotImplementedError('Representation in format ' +
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/pauli.py:425: raise NotImplementedError('Representation in format ' +
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/pauli.py:489: raise NotImplementedError('Representation in format ' +
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:13: TODO List:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:59: 1) A class or set of classes is passed: First, we try to
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:66: 2) An instance or set of instances is passed: In this case,
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:67: state._operators_to_state is called on the instances passed. If
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:102: raise NotImplementedError("Argument is not an Operator or a set!")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:108: raise NotImplementedError("Set is not all Operators!")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:118: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:137: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:160: 1) A state class is passed: In this case, we first try
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:207: raise NotImplementedError("Argument is not a state!")
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:214: except (NotImplementedError, TypeError):
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:227: except (NotImplementedError, TypeError):
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:252: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:263: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tensorproduct.py:151: # TODO: disallow nested TensorProducts.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:104: # TODO: don't expand the scalars in front of each Mul.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:234: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:244: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:251: # TODO: I may need to expand before returning the final result.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/commutator.py:219: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/commutator.py:222: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:122: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:145: # TODO: add methods for uncoupling operators
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:147: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:157: # TODO: move this to qapply_Mul
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:161: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:165: #TODO: use options to use different j values
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:437: the z-y-z convention for a passive transformation. That is the coordinate
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:616: # TODO: move evaluation up to represent function/implement elsewhere
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1017: # TODO: better way to get angles of rotation
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1065: # passed.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1417: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1487: # TODO: Need hilbert space fix, see issue 5732
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1687: The arguments that must be passed are ``j``, ``m``, ``jn``, and
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1725: state. This is done by passing coupled=False to the rewrite function:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qubit.py:62: # If we are passed a QubitState or subclass, we just take its qubit
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qubit.py:373: This number should be passed with keyword ``nqubits=N``.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qubit.py:388: We can also create an ``IntQubit`` by passing a ``Qubit`` instance.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qubit.py:591: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qubit.py:666: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qubit.py:714: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/qubit.py:809: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/anticommutator.py:129: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/anticommutator.py:132: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_density.py:269: #TODO: test for invalid arguments
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_trace.py:82: #TODO: needed while testing reduced density operations, etc.
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:3: TODO:
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:678: # TODO: Fix non-unicode pretty printing
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_anticommutator.py:39: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_operatorset.py:52: raises(NotImplementedError, lambda: operators_to_state(XKet))
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_operatorset.py:68: raises(NotImplementedError, lambda: state_to_operators(XOp))
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_commutator.py:59: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_state.py:204: raises(NotImplementedError, lambda: f.normalize())
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_cartesian.py:113: # TODO: Add tests for representations
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_innerproduct.py:28: pass
- .venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_innerproduct.py:51: pass
- .venv/lib/python3.12/site-packages/sympy/physics/vector/vector.py:735: # TODO : Circular dependency if imported at top. Should move
- .venv/lib/python3.12/site-packages/sympy/physics/vector/frame.py:53: # frame and index, which are not passed to Symbol.__xnew__.
- .venv/lib/python3.12/site-packages/sympy/physics/vector/frame.py:764: **Note carefully that** ``N.dcm(B)`` **(the transpose) would be passed
- .venv/lib/python3.12/site-packages/sympy/physics/vector/frame.py:1278: raise NotImplementedError('That is not an implemented rotation')
- .venv/lib/python3.12/site-packages/sympy/physics/vector/frame.py:1389: raise NotImplementedError('That is not an implemented rotation')
- .venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:47: # TODO : The unit vectors should print with subscripts but they just
- .venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:50: # TODO : The pretty print division does not print correctly here:
- .venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_frame.py:262: pass
- .venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_frame.py:408: raises(NotImplementedError, lambda: B.orient(N, 'Foo', [q0, q1, q2]))
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:26: # TODO you are a bit excessive in the use of Dummies
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:27: # TODO dummy point, literal field
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:28: # TODO too often one needs to call doit or simplify on the output, check the
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:174: By passing ``Symbols`` to *symbols* parameter, user can define the name and
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:175: assumptions of coordinate symbols of the coordinate system. If not passed,
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:178: By passing *relations* parameter, user can define the transform relations of
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:180: be found automatically. If this parameter is not passed, coordinate
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:433: raise NotImplementedError(temp.format(sys1_name, sys2_name))
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:554: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:884: is not passed, it returns the coordinates in the coordinate system in which
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1101: # TODO: you need a real dummy function for the next line
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1309: if c:  # TODO this is ugly - the Commutator can be Zero and
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1438: # TODO the calculation of signatures is slow
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1439: # TODO you do not need all these permutations (neither the prefactor)
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1584: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1594: # TODO: you need a real dummy function for the next line
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1647: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1892: # TODO Is this a good idea?
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1919: # TODO move some of this to class methods.
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1920: # TODO rewrite using the .as_blah_blah methods
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1965: # TODO move some of this to class methods.
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1966: # TODO rewrite using the .as_blah_blah methods
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:2262: pass
- .venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:2266: pass
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:19: #TODO assert point.subs(x, 2) == Point(cs, [2, y])
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:20: #TODO assert point.free_symbols == set([x, y])
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:32: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:103: #TODO assert m == R2_r.transform(R2_p, R2_p.transform(R2_r, [a, b])).applyfunc(simplify)
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:117: #TODO assert m == R3_r.transform(R3_c, R3_c.transform(R3_r, m)).applyfunc(simplify)
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:120: #TODO assert m == R3_r.transform(R3_s, R3_s.transform(R3_r, m)).applyfunc(simplify)
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:123: #TODO assert m == R3_c.transform(R3_s, R3_s.transform(R3_c, m)).applyfunc(simplify)
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:128: #TODO assert m == R3_r.coord_tuple_transform_to(R3_c, R3_c.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:131: #TODO assert m == R3_r.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:134: #TODO assert m == R3_c.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_c, m)).applyfunc(simplify)
- .venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_hyperbolic_space.py:86: #TODO - it would be nice to have index contraction built-in
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:70: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:302: pass  # use default return
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:606: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:691: # let it pass.
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:694: # TODO : We should not blindly recurse through all args of arbitrary expressions like this
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:780: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:850: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:1307: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:1593: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:1662: # TODO Case: A-> function of symbol, can be extended here
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2161: and the ``symbol`` should be passed as they would have been by
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2364: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2432: domain leads to a NotImplementedError.
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2468: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2604: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2631: raise NotImplementedError('solveset is unable to solve this equation.')
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2687: duplicate or unordered symbols are passed
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2712: situation does not pass silently past the caller's
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2948: Symbols can always be passed but are actually only needed
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2949: when 1) a system of equations is being passed and 2) the
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:2950: system is passed as an underdetermined matrix and one wants
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:3092: When passing a system of equations, the explicit
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:3604: except (NotImplementedError, ValueError):
- .venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:4116: # If solve_poly_system did succeed then we pass those solutions in as
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:53: if strict is True, NotImplementedError will be raised if
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:65: symbols in the order they were passed as gens
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:96: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:119: symbols in the order they were passed as gens
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:203: If strict is True, NotImplementedError will be raised if the solution
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:211: symbols in the order they were passed as gens
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:229: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:304: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:312: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:346: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/polysys.py:355: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:213: To check if an expression is zero using ``checksol()``, pass it
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:359: # TODO: improve solution testing
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:390: The expressions that are passed can be Expr, Equality, or Poly
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:417: If you pass symbols for which solutions are sought, the output will vary
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:418: depending on the number of symbols you passed, whether you are passing
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:453: When you pass all but one of the free symbols, an attempt
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:457: or more of the symbols, pass the expression to be solved in a list:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:585: When one or more expressions passed to ``solve`` is a relational,
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:637: NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:848: # keeping track of how f was passed
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:859: equations. Either pass your equation in a list or
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:937: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1007: raise NotImplementedError('solving %s when the argument '
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1090: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1313: If no method is implemented to solve the equation, a NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1365: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1370: raise NotImplementedError(not_impl_msg % f)
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1421: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1478: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1626: # if we aren't on the tsolve-pass, use roots
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1642: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1644: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1648: If you want to see any results, pass keyword incomplete=True to
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1653: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1664: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1689: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1700: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1708: pass  # for coverage
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1712: flags.pop('tsolve', None)  # allow tsolve to be used on next pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1718: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1722: raise NotImplementedError('\n'.join([msg, not_impl_msg % f]))
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1884: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1885: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1896: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1964: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:1994: raise NotImplementedError('could not solve %s' % eq2)
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2314: passed will not be modified.
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2368: solution, the solutions are passed as a list. The output can be modified using
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2369: the same semantics as for `solve` since the flags that are passed are sent
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2702: # _tsolve calls this with Dummy before passing the actual number in.
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2704: raise NotImplementedError # _tsolve will call here again...
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2757: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2758: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2808: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2809: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2861: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2867: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2875: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2876: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2878: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2894: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2895: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2897: pass  # here for coverage
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2902: # TODO: option for calculating J numerically
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3085: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3239: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3269: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3309: NotImplementedError is raised if there are radicals and they cannot be
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3375: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3528: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3532: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3533: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3558: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3575: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3577: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3580: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:3662: raise NotImplementedError('Cannot remove all radicals')
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:54: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:404: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:443: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:454: pass  # continue with attempt to solve in Real domain
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:524: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:527: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:557: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:583: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:589: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:590: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:591: raise NotImplementedError('sorting of these roots is not supported')
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:816: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:817: except (PolynomialError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:908: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/inequalities.py:976: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/solvers/deutils.py:183: # type is an argument passed by the solve functions in ode and pde.py
- .venv/lib/python3.12/site-packages/sympy/solvers/deutils.py:206: # being called more than it needs to be by passing its results through
- .venv/lib/python3.12/site-packages/sympy/solvers/deutils.py:217: #          information (including the internal pass-through magic).
- .venv/lib/python3.12/site-packages/sympy/solvers/deutils.py:241: raise NotImplementedError(dummy + "solve" + ": Cannot solve " + str(eq))
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:9: constraints, and an optional list of bounds can be passed to
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:26: The function and a list with the constraint is passed directly
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:33: uivariate constraint can be passed as a bound with None acting
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:40: ``-x <= -1`` as required by the routine, can be passed:
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:93: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:114: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:162: the system, pass `dual=True` and ``(o, y, x)`` will be returned.
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:316: pass  # error will raise below
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:528: If you pass the transpose of the matrix, the primal will be
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:682: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:765: By passing max, the maximum value for f under the constraints
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:920: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:955: individual ranges, pass a list with length equal to the
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:958: passed as a dictionary with keys giving the corresponding
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:1022: pass # individual bounds
- .venv/lib/python3.12/site-packages/sympy/solvers/simplex.py:1084: pass # individual bounds
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:97: meta-hints that you can pass to pdsolve():
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:108: pdsolve to raise the NotImplementedError, value of that
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:175: # TODO : 'best' hint should be implemented when adequate
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:186: except NotImplementedError as detail:
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:265: raise NotImplementedError("Right now only partial "
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:284: # TODO : For now pde.py uses support offered by the ode_order function
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:377: If a sequence of solutions is passed, the same sort of container will be
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:421: 'must pass func arg to checkpdesol for this case.')
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:455: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:521: # TODO : For now homogeneous first order linear PDE's having
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:611: # TODO : For now homogeneous first order linear PDE's having
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:707: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:708: raise NotImplementedError("Unable to find a solution"
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:715: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:716: raise NotImplementedError("Unable to find a solution"
- .venv/lib/python3.12/site-packages/sympy/solvers/pde.py:758: raise NotImplementedError("Cannot solve the partial differential equation due"
- .venv/lib/python3.12/site-packages/sympy/solvers/bivariate.py:34: # TODO it would be good to pick the smallest divisible power
- .venv/lib/python3.12/site-packages/sympy/solvers/bivariate.py:195: else raise NotImplementedError.
- .venv/lib/python3.12/site-packages/sympy/solvers/bivariate.py:288: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/solvers/bivariate.py:411: raise NotImplementedError('%s does not appear to have a solution in '
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:65: except (TypeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:179: NotImplementedError, lambda: solve(exp(x) + sin(x) + exp(y) + sin(y)))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:614: raises(NotImplementedError, lambda: solve(f(x, y) - f(1, 2), x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:615: raises(NotImplementedError, lambda: solve(f(x, y) - f(2 - x, 2), x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:623: raises(NotImplementedError, lambda:
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:627: raises(NotImplementedError, lambda: solve((x + 2)**y*x - 3, x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:869: raises(NotImplementedError, lambda: solve(log(x) - exp(x), x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:870: raises(NotImplementedError, lambda: solve(2**x - exp(x) - 3))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1086: # We do not want to pass this test just by using simplify so if the above
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1087: # passes then uncomment the additional test below:
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1104: raises(NotImplementedError, lambda:
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1106: raises(NotImplementedError, lambda:
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1225: raises(NotImplementedError, lambda:
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1228: raises(NotImplementedError, lambda: solve(-sqrt(2) + cosh(x)/x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1254: raises(NotImplementedError, lambda:
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1289: # why does this pass
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1392: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1727: # TODO: Investigate why currently solution [0] is preferred over [1].
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1821: # while the first one passed, this one failed
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1890: raises(NotImplementedError, lambda: solve(abs(x) - 3))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1963: raises(NotImplementedError, lambda: solve(x - sin(x)*log(y - x), x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1979: # tests passing current implementation
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:2084: # if this import passes then the test below should also pass
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:2220: raises(NotImplementedError, lambda:
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:2700: raises(NotImplementedError, lambda: solve(Mod(x**2, 49), x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:2703: raises(NotImplementedError, lambda: solve((Mod(f**2/(f + 1) + 2*f/(f + 1) + 1/(f + 1), 1))*f + Mod(f**2/(f + 1) + 2*f/(f
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_polysys.py:64: raises(NotImplementedError, lambda: solve_poly_system([x**3 - y**3], x, y))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_polysys.py:65: raises(NotImplementedError, lambda: solve_poly_system(
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_polysys.py:69: raises(NotImplementedError, lambda: solve_poly_system(
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_polysys.py:71: raises(NotImplementedError, lambda: solve_poly_system(
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_polysys.py:185: # TODO: does this really have to be so complicated?!
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_inequalities.py:231: raises(NotImplementedError, lambda: reduce_inequalities(Ge(sin(x) + x, 1)))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_inequalities.py:232: raises(NotImplementedError, lambda: reduce_inequalities(Ge(x**2*y + y, 1)))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_inequalities.py:314: raises(NotImplementedError, lambda: isolve(Abs(x) <= n, x, relational=False))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_inequalities.py:316: raises(NotImplementedError, lambda: isolve(n/c1 < 0, c1))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_inequalities.py:323: raises(NotImplementedError, lambda: isolve(x**2 < zero, x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_inequalities.py:324: raises(NotImplementedError, lambda: isolve(
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_inequalities.py:326: raises(NotImplementedError, lambda: isolve(1/(x - y) < 2, x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_inequalities.py:327: raises(NotImplementedError, lambda: isolve(1/(x - y) < 0, x))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_inequalities.py:335: raises(NotImplementedError, lambda: isolve(
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:323: # TODO: Is the above solution set definitely complete?
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:441: # help pass despite fp differences
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:1561: raises(NotImplementedError, lambda: solvify(sin(exp(x)), x, S.Complexes))
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:1622: # if non-symbols are passed, the user is responsible for interpreting
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:1862: # TODO: add more simple testcases when solveset returns
- .venv/lib/python3.12/site-packages/sympy/solvers/tests/test_pde.py:124: raises(NotImplementedError, lambda:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:34: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:39: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:229: NotImplementedError is raised.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:271: NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:283: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:304: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:762: variable, they can pass the substitution `tau` and the solution will have the independent variable
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:763: substituted with the passed expression(`tau`).
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:773: Non-homogeneous term in the system of ODEs. If None is passed,
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:777: is not passed and the solution requires the term, then the solver
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:780: Type of the system of ODEs passed. Depending on the type, the
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:789: the system passed.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:826: to finally pass it to the solver.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:837: We can also use the doit method to evaluate the solutions passed by the function.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:850: A user can also pass the commutative antiderivative required for type3 and type4 system of ODEs.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:852: with its antiderivative, then :obj:`sympy.solvers.ode.systems.linodesolve_type()` raises a NotImplementedError.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:857: Now, we can pass the antiderivative as an argument to get the solution. If the system information is not
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:858: passed, then the solver will compute the required arguments internally.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:878: or the antiderivative, if passed, are not a matrix or
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:881: When the coefficient matrix or its antiderivative, if passed is not a
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:883: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:891: linodesolve_type: Getting information about systems of ODEs to pass in this solver
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:947: passed_type = type
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:956: if passed_type != "auto":
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:961: The system passed isn't {}.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1028: If the system passed has a non-linear term with multiple solutions, then a list of
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1083: Helper function for determining if the Matrix passed is commutative with its antiderivative
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1088: This function checks if the Matrix $A$ passed is commutative with its antiderivative with respect
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1095: boolean value, if True, then the matrix $A(t)$ passed is commutative with $B(t)$, else the matrix
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1096: passed isn't commutative with $B(t)$.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1239: Then a check is made to determine if the system passed can be reduced or not, if
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1280: Returns a second order system based on the coefficient matrix passed.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1291: coefficient matrix passed.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1294: dependent variables with the new independent variable `t_` passed.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1326: Returns a dictionary with details of the eqs if the system passed is linear
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1390: 11. is_higher_order: True if the system passed has an order greater than 1.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1392: 12. is_second_order: True if the system passed is a second order ODE. This
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1476: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1578: # and that the system passed is in its first order
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1651: # NotImplementedError may be raised when the system may be actually
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1656: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1663: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1759: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1760: The system of ODEs passed cannot be solved by dsolve_system.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1794: 1. "type0": If this is passed, then the system will be reduced to first order by
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1796: 2. "type1": If this is passed, then a particular substitution will be used to reduce the
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1798: 3. "type2": If this is passed, then the system will be transformed with new dependent
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1811: Default value for `b` is None but if `A1` and `A0` are passed and `b` is not passed, then the
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:1989: function can solve the above types irrespective of the number of equations in the system passed.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:2031: You can also pass the initial conditions for the system of ODEs:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:2036: Optionally, you can pass the dependent variables and the independent
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:2057: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:2060: When the parameters passed are not in the required form.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:2067: List of equations should be passed. The input is not valid.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/systems.py:2105: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:90: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:108: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:203: heuristic needs to be found, it can be passed as a flag to ``hint``.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:236: raise NotImplementedError("Infinitesimals for only "
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:253: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:254: raise NotImplementedError("Infinitesimals for the "
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:276: raise NotImplementedError("Infinitesimals could not be found for "
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:286: raise NotImplementedError("Infinitesimals could not be found for"
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:351: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:352: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:365: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:366: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:379: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:380: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:393: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:394: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:675: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:676: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:769: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:770: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:782: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:783: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:798: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:799: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:812: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:813: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:943: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:944: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:964: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/lie_group.py:965: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/nonhomogeneous.py:156: raise NotImplementedError("Cannot find " + str(order) +
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/nonhomogeneous.py:160: raise NotImplementedError("Cannot find " + str(order) +
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/nonhomogeneous.py:191: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/nonhomogeneous.py:374: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/nonhomogeneous.py:450: raise NotImplementedError("Cannot find " + str(order) +
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/nonhomogeneous.py:477: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:37: class ODEMatchError(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:39: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:204: # TODO: Add methods that can be used by many ODE solvers:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:287: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:291: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:334: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:338: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:406: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:898: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:907: raise NotImplementedError("The given ODE " + str(eq) + " cannot be solved by"
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:2092: raise NotImplementedError("The given ODE " + str(eq) + " cannot be solved by"
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:2428: independence.  Also, ``assert len(sollist) == order`` will need to pass.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:2931: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:2941: raise NotImplementedError("The given ODE " + str(eq) + " cannot be solved by"
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:62: If a sequence of solutions is passed, the same sort of container will be
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:127: 'must pass func arg to checkodesol for this case.')
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:178: # First pass, try substituting a solved solution directly into the
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:197: # Second pass. If we cannot substitute f, try seeing if the nth
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:208: # Third pass. Try solving for df/dx and substituting that into the
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:235: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:236: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:285: raise NotImplementedError("Unable to test if " + str(sol) +
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:295: equations and solutions passed can be any iterable.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:303: When a sequence of equations is passed, the same sequence is used to return
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/subscheck.py:373: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:160: pass it to your function using the `match` dict to access it.  You can access
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:163: to solve the ODE, you find that you cannot, raise ``NotImplementedError``.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:178: :py:meth:`~sympy.core.expr.Expr.integrate`.  This allows the user to bypass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:420: that you can pass to :py:meth:`~sympy.solvers.ode.dsolve`:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:432: ``NotImplementedError``, value of that hint's key will be the
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:561: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:562: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:575: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:589: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:618: except NotImplementedError as detail:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:786: raise NotImplementedError("Unrecognized initial condition")
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:798: # TODO: Use solveset here
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:801: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:807: # we use NotImplementedError in this case.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:815: raise NotImplementedError("Initial conditions produced too many solutions for constants")
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1072: # TODO: Hint first order series should match only if d/e is analytic.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1328: # of equations is greater than 2, then NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1668: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1669: except (NotImplementedError, PolynomialError):
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1683: # least in this setup all tests pass).
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1716: - ``sol`` is not solved for ``func``, but can be if passed to solve (e.g.,
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1760: This function is designed to be passed to ``min`` as the key argument,
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1783: # TODO: if two solutions are solved for f(x), we still want to be
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1813: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1814: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1815: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:2024: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:2703: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:2838: raise NotImplementedError("Lie groups solver has been implemented "
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:2851: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:2852: raise NotImplementedError("Infinitesimals for the "
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:2903: raise NotImplementedError("Only homogeneous problems are supported" +
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:187: if result['xpass_msg'] != "":
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:188: print(result['xpass_msg'])
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:221: result = {'msg': '', 'xpass_msg': ''}
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:226: xpass = True
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:252: xpass = False
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:282: xpass = False
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:290: if xpass and xfail:
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:291: result['xpass_msg'] = example + "is now passing for the hint" + our_hint
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:313: # print(result.get('xpass_msg',''))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:322: # Test that not implemented methods give NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:326: raises(NotImplementedError, lambda: solver.matches())
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:327: raises(NotImplementedError, lambda: solver.get_general_solution())
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:328: raises(NotImplementedError, lambda: solver._matches())
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:329: raises(NotImplementedError, lambda: solver._get_general_solution())
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:1242: 'XFAIL': ['nth_algebraic']  # It passes only when prep=False is set in dsolve.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_single.py:1248: 'XFAIL': ['nth_algebraic']  # It passes only when prep=False is set in dsolve.
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2014: raises(NotImplementedError, lambda: linodesolve(A1, t))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2065: raises(NotImplementedError, lambda: linodesolve(A1, t, b=b1))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2067: # non-homogeneous term not passed
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2290: raises(NotImplementedError, lambda: dsolve_system(eq) == ([], []))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2292: raises(NotImplementedError, lambda: dsolve_system(eq, funcs=[f(x), g(x)]) == ([], []))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2293: raises(NotImplementedError, lambda: dsolve_system(eq, funcs=[f(x), g(x)], t=x) == ([], []))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2294: raises(NotImplementedError, lambda: dsolve_system(eq, funcs=[f(x), g(x)], t=x, ics={f(0): 1, g(0): 1}) == ([], []))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2295: raises(NotImplementedError, lambda: dsolve_system(eq, t=x, ics={f(0): 1, g(0): 1}) == ([], []))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2296: raises(NotImplementedError, lambda: dsolve_system(eq, ics={f(0): 1, g(0): 1}) == ([], []))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2297: raises(NotImplementedError, lambda: dsolve_system(eq, funcs=[f(x), g(x)], ics={f(0): 1, g(0): 1}) == ([], []))
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2360: assert dsolve(eqs) # NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:93: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:635: # If this passes, lines numbered 3878-3882 (at the time of this commit)
- .venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:644: # If this test passes, lines 1306-1311 (at the time of this commit)
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:211: raise NotImplementedError('No solver has been written for %s.' % self.name)
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:628: pass
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:1265: directly, one must be careful to pass an equation in the correct
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:1447: except (TypeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:1477: raise NotImplementedError('unhandled type: %s' % eq_type)
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:1630: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:1655: #  * it should be passed to that handler in diop_solve
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:1656: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:2566: # TODO: pre-simplification: Not necessary but may simplify
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:3893: # TODO: Fall back to diop_DN when k = 2
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:62: raises(NotImplementedError, lambda: classify_diop(w*x*y*z - 1))
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:63: raises(NotImplementedError, lambda: classify_diop(x**3 + y**3 + z**4 - 90))
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:557: raises(NotImplementedError, lambda: diophantine(x*y**2 + 1))
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:623: raises(NotImplementedError, lambda: classify_diop(-eq))
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:831: # it's ok if these pass some day when the solvers are implemented
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:832: raises(NotImplementedError, lambda: diophantine(x**2 + y**2 + x*y + 2*y*z - 12))
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:833: raises(NotImplementedError, lambda: diophantine(x**3 + y**2))
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:879: raises(NotImplementedError, lambda: diop_general_sum_of_even_powers(-eq, 2))
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:1058: def test_quadratic_parameter_passing():
- .venv/lib/python3.12/site-packages/sympy/solvers/diophantine/tests/test_diophantine.py:1061: # test that parameters are passed all the way to the final solution
- .venv/lib/python3.12/site-packages/sympy/parsing/sym_expr.py:112: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/parsing/sym_expr.py:172: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/parsing/sympy_parser.py:88: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/sympy_parser.py:587: is passed because that is a syntax error.
- .venv/lib/python3.12/site-packages/sympy/parsing/sympy_parser.py:791: passed_float = False
- .venv/lib/python3.12/site-packages/sympy/parsing/sympy_parser.py:795: passed_float = True
- .venv/lib/python3.12/site-packages/sympy/parsing/sympy_parser.py:798: elif passed_float == True and toknum == NUMBER:
- .venv/lib/python3.12/site-packages/sympy/parsing/sympy_parser.py:799: passed_float = False
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:99: NotImplementedError() when called for Numeric assignments or Arrays
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:102: # TODO: Arithmetic Assignment
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:123: raise NotImplementedError("Numeric assignments not supported")
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:125: raise NotImplementedError("Arrays not supported")
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:148: NotImplementedError() when called for Numeric assignments
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:151: # TODO: Integer Binary Operations
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:163: raise NotImplementedError("Numbers Currently not supported")
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:172: raise NotImplementedError("Numbers Currently not supported")
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:200: NotImplementedError() when called for unsupported data types
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:210: raise NotImplementedError("Data type not supported")
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:239: # TODO:Numbers when the LFortran ASR is updated
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:241: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:257: # TODO: Return statement, variable declaration
- .venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:285: raise NotImplementedError("Data type not supported")
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:136: Arguments to be passed to Clang while parsing the C code
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:172: Arguments to be passed to Clang while parsing the C code
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:205: NotImplementedError : if the transformation for the provided node
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:237: NotImplementedError : if called for data types not currently
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:269: raise NotImplementedError("Only bool, int "
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:326: raise NotImplementedError("Given "
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:366: raise NotImplementedError("Only void, bool, int "
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:422: raise NotImplementedError("Only bool, int "
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:443: raise NotImplementedError("Only bool, int "
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:463: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:520: #TODO: No string type in AST
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:529: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:576: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:599: # Ignore unexposed nodes; pass whatever is the first
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:611: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:705: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:711: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:735: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:754: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:796: raise NotImplementedError("Dereferencing operator, "
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:812: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:852: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:873: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:889: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:896: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:900: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:920: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:927: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:990: combined variable passed.Combined variable contains
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_c_parser.py:3324: raises(NotImplementedError, lambda: SymPyExpression(c_src_raise1, 'c'))
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_c_parser.py:3325: raises(NotImplementedError, lambda: SymPyExpression(c_src_raise2, 'c'))
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_c_parser.py:3326: raises(NotImplementedError, lambda: SymPyExpression(c_src_raise3, 'c'))
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_c_parser.py:3327: raises(NotImplementedError, lambda: SymPyExpression(c_src_raise4, 'c'))
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_c_parser.py:3328: raises(NotImplementedError, lambda: SymPyExpression(c_src_raise5, 'c'))
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_c_parser.py:4766: raises(NotImplementedError, lambda: SymPyExpression(c_src_raise1, 'c'))
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_c_parser.py:4767: raises(NotImplementedError, lambda: SymPyExpression(c_src_raise2, 'c'))
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_c_parser.py:5007: raises(NotImplementedError, lambda: SymPyExpression(c_src_raise1, 'c'))
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_c_parser.py:5008: raises(NotImplementedError, lambda: SymPyExpression(c_src_raise2, 'c'))
- .venv/lib/python3.12/site-packages/sympy/parsing/tests/test_sym_expr.py:204: raises(NotImplementedError, lambda: SymPyExpression(src, mode = 'd'))
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/errors.py:2: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/__init__.py:203: raise NotImplementedError(f"Using the '{backend}' backend in the LaTeX" \
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_parse_latex_antlr.py:21: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:928: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:945: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1012: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1028: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1177: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1182: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1233: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1238: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1245: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1303: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1308: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1368: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1373: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1462: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1470: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1570: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1578: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1652: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1658: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1664: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1670: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1676: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1682: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1739: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1745: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1751: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1757: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1763: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1832: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1841: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1850: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:1859: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2094: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2113: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2116: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2121: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2126: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2131: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2136: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2141: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2146: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2151: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2423: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2431: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2441: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2449: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2879: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2898: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2911: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2916: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2919: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2949: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2968: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2977: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2990: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2996: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:2998: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3000: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3015: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3020: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3025: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3028: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3051: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3062: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3080: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3086: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3092: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3101: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3151: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3157: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3262: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3266: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3270: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3320: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3330: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3420: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3428: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3485: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/_antlr/latexparser.py:3493: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:14: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:18: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:22: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:28: passed to the ``.transform()`` function.
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:36: the required modifications are made, the name of the new class should be passed to
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:288: # we will pass this information upwards
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:377: # We pass the integrand, along with information about the variable of integration, upw
- .venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:660: # TODO: ANTLR refers to ISO 80000-2:2019. should we keep base 10 or base 2?
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:419: # Simple list used as a store to pass around variables between the 'process' and 'write'
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:577: "exec", "finally", "for", "from", "global", "if", "import", "in", "is", "lambda", "not", "or", "pass", "print",\
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:624: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:667: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:796: # TODO: Currently only works with symbols. Make it work for dynamicsymbols.
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:916: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:977: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:983: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1037: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1269: # TODO** Parse block matrices
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1607: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1668: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1687: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1791: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:2017: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:421: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:427: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:433: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:439: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:445: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:451: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:457: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:584: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:601: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:620: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:862: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:896: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1037: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1042: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1047: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1052: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1057: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1062: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1067: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1072: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1087: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1102: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1655: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1660: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1665: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1731: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1736: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1741: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1746: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:1751: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2327: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2346: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2409: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2414: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2419: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2791: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2801: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2809: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2817: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2836: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2844: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2870: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2878: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2886: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2898: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2925: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2951: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2969: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:2987: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:3000: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py:3013: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:17: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:21: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:26: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:30: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:35: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:39: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:44: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:48: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:53: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:57: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:62: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:66: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:71: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:75: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:80: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:84: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:89: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:93: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:98: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:102: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:107: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:111: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:116: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:120: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:125: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:129: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:134: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:138: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:143: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:147: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:152: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:156: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:161: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:165: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:170: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:174: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:179: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:183: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:188: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:192: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:197: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:201: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:206: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:210: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:215: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:219: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:224: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:228: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:233: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:237: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:242: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:246: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:251: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:255: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:260: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:264: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:269: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:273: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:278: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:282: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:287: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:291: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:296: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:300: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:305: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:309: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:314: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:318: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:323: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:327: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:332: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:336: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:341: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:345: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:350: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:354: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:359: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:363: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:368: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:372: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:377: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:381: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:386: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:390: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:395: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:399: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:404: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:408: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:413: pass
- .venv/lib/python3.12/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py:417: pass
- .venv/lib/python3.12/site-packages/sympy/simplify/fu.py:759: rv = do(rv)  # final pass to resolve any new inducible pairs
- .venv/lib/python3.12/site-packages/sympy/simplify/fu.py:886: # in den_args and pass this half-angle to TR11
- .venv/lib/python3.12/site-packages/sympy/simplify/fu.py:2003: raise NotImplementedError('unhandled %s' % rv.func)
- .venv/lib/python3.12/site-packages/sympy/simplify/fu.py:2042: raise NotImplementedError('unhandled %s' % rv.func)
- .venv/lib/python3.12/site-packages/sympy/simplify/powsimp.py:349: last = True  # we are going to be done after this next pass
- .venv/lib/python3.12/site-packages/sympy/simplify/combsimp.py:34: with non-integer argument, it is automatically passed to gammasimp.
- .venv/lib/python3.12/site-packages/sympy/simplify/epathtools.py:42: raise NotImplementedError("non-root EPath")
- .venv/lib/python3.12/site-packages/sympy/simplify/epathtools.py:81: pass
- .venv/lib/python3.12/site-packages/sympy/simplify/cse_main.py:542: pass
- .venv/lib/python3.12/site-packages/sympy/simplify/cse_main.py:744: functions. Optionally 'basic' can be passed for a set of predefined
- .venv/lib/python3.12/site-packages/sympy/simplify/cse_main.py:816: # Handle the case if just one expression was passed.
- .venv/lib/python3.12/site-packages/sympy/simplify/cse_main.py:843: # In case we get passed an iterable with an __iter__ method instead of
- .venv/lib/python3.12/site-packages/sympy/simplify/radsimp.py:243: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/simplify/radsimp.py:250: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/simplify/radsimp.py:870: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:50: #   TODO work this out in detail.
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:86: # TODO see if this can work as Mod(x, 1); this will require
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:253: # TODO branching
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:736: # TODO with symbolic parameters, it could be advantageous
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:913: This uses the _matcher passed on init.
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1496: """ Create a derivative operator, to be passed to Operator.apply. """
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1793: raise NotImplementedError('Need partial fraction decomposition'
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1808: raise NotImplementedError('unrecognised form %s' % dep)
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1812: raise NotImplementedError('unrecognised form of partial fraction')
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1947: # TODO tons of more formulae
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1991: # TODO
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2116: # TODO for now, we use the following simple heuristic: inverse-shift
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2192: raise NotImplementedError('Could not devise plan.')
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2245: # TODO the following would be possible:
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2250: # TODO Also, we tend to create combinations of gamma functions that can be
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2266: # We pass it to _hyperexpand to improve performance.
- .venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2443: # TODO it would be helpful to give conditions under which the integral
- .venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:572: expression. You can avoid this behavior by passing ``doit=False`` as
- .venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:646: # TODO: Apply different strategies, considering expression pattern:
- .venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:720: # automatically passed to gammasimp
- .venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:834: keywords are passed to ``factor_terms``.
- .venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1087: # TODO: see if x*log(a)+x*log(a)*log(b) -> x*log(a)*(1+log(b))?
- .venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1247: # TODO
- .venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1344: max_len : maximum number of surds passed as constants to ``nsimplify``
- .venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1452: pass
- .venv/lib/python3.12/site-packages/sympy/simplify/sqrtdenest.py:217: pass
- .venv/lib/python3.12/site-packages/sympy/simplify/sqrtdenest.py:232: pass
- .venv/lib/python3.12/site-packages/sympy/simplify/gammasimp.py:155: for ipass in range(2):
- .venv/lib/python3.12/site-packages/sympy/simplify/gammasimp.py:166: if ipass ==  0 and not gamma_factor(nd):
- .venv/lib/python3.12/site-packages/sympy/simplify/gammasimp.py:393: # TODO is there a better heuristic?
- .venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:84: ``2*x`` by passing ``hints=[2]``:
- .venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:102: Note how no hints had to be passed, since the expression already involved
- .venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:105: The tangent function is also supported. You can either pass ``tan`` in the
- .venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:107: or you can pass a specific generator:
- .venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:121: # TODO
- .venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:496: Optional keyword arguments passed to the method. See each method's
- .venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:1121: pass
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_cse.py:98: # Simple substitution, test for being able to pass the expression directly
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_cse.py:193: def test_bypass_non_commutatives():
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_cse.py:683: @XFAIL  # Multiple simplification passed not supported in CSE
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_cse.py:698: @XFAIL  # Multiple simplification passed not supported in CSE
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_rewrite.py:30: # This next test currently passes... not clear whether it should or not?
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_epathtools.py:90: raises(NotImplementedError, lambda: EPath("Symbol"))
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:116: # TODO [a+1, aRational(-1, 2)], [2*a]
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:130: # TODO hyperexpand(hyper([a], [2*a + 1], z))
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:131: # TODO [S.Half, a], [Rational(3, 2), a+1]
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:135: # TODO [a], [a - S.Half, 2*a]
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:949: # TODO polys
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1011: # TODO LOTS more
- .venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1039: # TODO LOTS more
- .venv/lib/python3.12/site-packages/sympy/unify/core.py:134: pass
- .venv/lib/python3.12/site-packages/sympy/geometry/exceptions.py:5: pass
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:115: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:118: """Returns a tuple that will be passed to __new__ on unpickling."""
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:178: except (NotImplementedError, TypeError):
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:227: except (NotImplementedError, TypeError):
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:251: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:259: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:268: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:317: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:341: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:364: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:411: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/geometry/entity.py:586: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/geometry/plane.py:412: # TODO: Replace solve with solveset, when this line is tested
- .venv/lib/python3.12/site-packages/sympy/geometry/plane.py:581: Plane parallel to the given plane and passing through the point pt.
- .venv/lib/python3.12/site-packages/sympy/geometry/plane.py:632: Return a perpendicular passing through the given points. If the
- .venv/lib/python3.12/site-packages/sympy/geometry/plane.py:733: raise NotImplementedError('Enter a linear entity only')
- .venv/lib/python3.12/site-packages/sympy/geometry/point.py:10: can be passed as a sequence of coordinates or Points:
- .venv/lib/python3.12/site-packages/sympy/geometry/point.py:144: pass
- .venv/lib/python3.12/site-packages/sympy/geometry/point.py:195: When sequences of coordinates are passed to Point methods, they
- .venv/lib/python3.12/site-packages/sympy/geometry/point.py:299: By default `on_morph='warn'` is passed to the
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:509: raise NotImplementedError('Evolute of arbitrary Ellipse is not supported.')
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:666: # TODO: Replace solve with nonlinsolve, when nonlinsolve will be able to solve in real domain
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:709: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:886: passing in the desired value:
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:919: # TODO: Replace solve with solveset, when this line is tested
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:926: except (DomainError, PolynomialError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:927: # TODO: Replace solve with solveset, when these lines are tested
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:931: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1148: NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1174: raise NotImplementedError(filldedent(
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1201: raise NotImplementedError('Only rotations of pi/2 are currently supported for Ellipse.')
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1244: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1290: # TODO: Replace solve with solveset, when this line is tested
- .venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1339: If "point=None" it will be calculated about the axis passing through the
- .venv/lib/python3.12/site-packages/sympy/geometry/util.py:420: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/geometry/util.py:429: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/geometry/util.py:608: pass
- .venv/lib/python3.12/site-packages/sympy/geometry/util.py:649: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:205: raise TypeError('Must pass only LinearEntity objects')
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:240: raise TypeError('Must pass only LinearEntity objects')
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:355: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:617: raise TypeError('Must pass only LinearEntity objects')
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:665: raise TypeError('Must pass only LinearEntity objects')
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:745: """Create a new Line parallel to this linear entity which passes
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:788: """Create a new Line perpendicular to this linear entity which passes
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:818: through which the perpendicular was required to pass; the
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:945: of L and the line perpendicular to L that passes through P.
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:1047: raise NotImplementedError('unhandled line type')
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:1051: """Returns the perpendicular lines which pass through the intersections
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:1280: NotImplementedError is raised if `other` is not a Point
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:1484: NotImplementedError is raised if `other` is not a Point
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:1711: NotImplementedError is raised if `other` is not a Point
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:1745: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:1908: """Create a new Line perpendicular to this linear entity which passes
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:1938: point through which was required to pass; the second
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:2040: except (NotImplementedError, TypeError, ValueError):
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:2212: except (NotImplementedError, TypeError, ValueError):
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:2617: NotImplementedError is raised if `other` is not an instance of one
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:2645: pass
- .venv/lib/python3.12/site-packages/sympy/geometry/line.py:2667: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/geometry/parabola.py:50: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/geometry/parabola.py:103: perpendicular to the directrix passing through the focus.
- .venv/lib/python3.12/site-packages/sympy/geometry/polygon.py:401: If "point=None" it will be calculated about the axis passing through the
- .venv/lib/python3.12/site-packages/sympy/geometry/polygon.py:859: raise NotImplementedError('non-numeric coordinates')
- .venv/lib/python3.12/site-packages/sympy/geometry/polygon.py:1091: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/geometry/polygon.py:2463: """The circle which passes through the three vertices of the triangle.
- .venv/lib/python3.12/site-packages/sympy/geometry/polygon.py:2800: passes through the feet of altitudes and the middle points of segments
- .venv/lib/python3.12/site-packages/sympy/geometry/polygon.py:2831: The line which passes through circumcenter, centroid and orthocenter.
- .venv/lib/python3.12/site-packages/sympy/geometry/tests/test_entity.py:15: raises(NotImplementedError, lambda: Point(0, 0) in GeometryEntity(x, y))
- .venv/lib/python3.12/site-packages/sympy/geometry/tests/test_curve.py:33: # now t has the same assumptions so the test passes
- .venv/lib/python3.12/site-packages/sympy/geometry/tests/test_ellipse.py:213: raises(NotImplementedError, lambda: e.normal_lines((x + 1, 1)))
- .venv/lib/python3.12/site-packages/sympy/geometry/tests/test_ellipse.py:336: raises(NotImplementedError, lambda: e.rotate(pi/3))
- .venv/lib/python3.12/site-packages/sympy/geometry/tests/test_ellipse.py:436: raises(NotImplementedError, lambda: e.reflect(Line((1, 0), slope=m)))
- .venv/lib/python3.12/site-packages/sympy/calculus/singularities.py:53: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/calculus/singularities.py:99: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/calculus/singularities.py:109: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/calculus/singularities.py:110: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/calculus/singularities.py:158: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/calculus/singularities.py:370: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/calculus/singularities.py:399: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/calculus/finite_diff.py:323: respectively. We can change the step size by passing a symbol
- .venv/lib/python3.12/site-packages/sympy/calculus/finite_diff.py:360: pass
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:73: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:81: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:91: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:114: pass    # 0**negative handled by singularities()
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:206: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:240: raise NotImplementedError("Unable to find range for the given domain.")
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:263: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:266: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:283: raise NotImplementedError("Unable to find range for the given domain.")
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:305: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:327: # TODO: handle piecewise defined functions
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:328: # TODO: handle transcendental functions
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:329: # TODO: handle multivariate functions
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:355: raise NotImplementedError('more than one variables %s not handled' %
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:425: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:459: raise NotImplementedError("Cannot use symbol of kind %s" % symbol.kind)
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:470: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:494: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:495: pass
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:513: except NotImplementedError as err:
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:515: raise NotImplementedError(err)
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:568: pass  # not handling Piecewise yet as the return type is not favorable
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:675: pass
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:680: r"""Determines the  convexity of the function passed in the argument.
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:703: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:709: To determine concavity of a function pass `-f` as the concerned function.
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:710: To determine logarithmic convexity of a function pass `\log(f)` as
- .venv/lib/python3.12/site-packages/sympy/calculus/util.py:712: To determine logarithmic concavity of a function pass `-\log(f)` as
- .venv/lib/python3.12/site-packages/sympy/calculus/accumulationbounds.py:561: pass
- .venv/lib/python3.12/site-packages/sympy/calculus/accumulationbounds.py:688: # TODO : Devise a better method for Union of AccumBounds
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_singularities.py:49: raises(NotImplementedError, lambda: singularities(x**-oo, x))
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_singularities.py:116: raises(NotImplementedError, lambda: is_monotonic(x**2 + y + 1))
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:59: raises(NotImplementedError, lambda : function_range(
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:61: raises(NotImplementedError, lambda : function_range(
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:63: raises(NotImplementedError, lambda : function_range(
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:65: raises(NotImplementedError, lambda : function_range(
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:131: raises(NotImplementedError, lambda : continuous_domain(
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:133: raises(NotImplementedError, lambda : continuous_domain(
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:181: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:251: raises(NotImplementedError, lambda: periodicity(sin(m), m))
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:252: raises(NotImplementedError, lambda: periodicity(sin(m[0, 0]), m))
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:253: raises(NotImplementedError, lambda: periodicity(sin(m), m[0, 0]))
- .venv/lib/python3.12/site-packages/sympy/calculus/tests/test_util.py:254: raises(NotImplementedError, lambda: periodicity(sin(m[0, 0]), m[0, 0]))
- .venv/lib/python3.12/site-packages/sympy/stats/crv.py:45: raise NotImplementedError("Not Implemented for generic Domains")
- .venv/lib/python3.12/site-packages/sympy/stats/crv.py:109: raise NotImplementedError("Or not implemented here")
- .venv/lib/python3.12/site-packages/sympy/stats/crv.py:117: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/stats/crv.py:148: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/stats/crv.py:184: pass
- .venv/lib/python3.12/site-packages/sympy/stats/crv.py:364: raise NotImplementedError("Characteristic function of multivariate expressions not implemented")
- .venv/lib/python3.12/site-packages/sympy/stats/crv.py:374: raise NotImplementedError("Moment generating function of multivariate expressions not implemented")
- .venv/lib/python3.12/site-packages/sympy/stats/crv.py:419: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/stats/crv.py:439: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/stats/drv_types.py:630: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:55: pass
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:152: # TODO: support discrete sets with non integer stepsizes
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:202: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:221: raise NotImplementedError(filldedent('''Multivariate discrete
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:239: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:315: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:324: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:329: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:336: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:343: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/drv.py:350: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:337: raise NotImplementedError('The moment generating function of the '
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:563: of the sum for general x, before the argument 2 is passed.
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:736: raise NotImplementedError("The moment generating function for the "
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:1599: raise NotImplementedError('The moment generating function for the '
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:1694: .. TODO - What is the difference between these degrees of freedom?
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:1958: raise NotImplementedError('The moment generating function for the '
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:2398: raise NotImplementedError('The moment generating function of Levy distribution does not exist.')
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:2471: raise NotImplementedError("The characteristic function for the "
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:2475: raise NotImplementedError("The moment generating function for the "
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:2812: raise NotImplementedError('Moment generating function of the log-normal distribution is not defined.')
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:2986: .. TODO - what does the parameter mean?
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:4021: raise NotImplementedError('The moment generating function for the Student-T distribution is undefined.')
- .venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:4493: of the sum for general n, before the argument 2 is passed.
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:93: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:96: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:175: raise NotImplementedError("Set of Conditional Domain not Implemented")
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:221: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:224: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:227: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:230: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:233: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:386: pass
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:460: raise NotImplementedError("Density not available for ProductSpaces")
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:604: # All subevents passed
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:985: # Otherwise pass work off to the ProbabilitySpace
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1065: # Otherwise pass work off to the ProbabilitySpace
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1323: # TODO : Remove when lambdify accepts 'pymc' as module
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1340: # TODO: Replace the try-except block with only given_fn(*args)
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1366: # TODO: Replace the try-except block with only given_fn(*args)
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1383: # TODO: Replace the try-except block with only fn(*args)
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1610: # TODO: do this for drv.py and frv.py if necessary.
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1611: # TODO: add more distributions here if there are more
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1650: raise NotImplementedError("Sampling from %s is not supported yet."
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1655: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1692: checked by passing them as an iterable:
- .venv/lib/python3.12/site-packages/sympy/stats/rv.py:1702: The following are equivalent to the above but do not pass
- .venv/lib/python3.12/site-packages/sympy/stats/frv.py:186: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/stats/frv.py:200: pass
- .venv/lib/python3.12/site-packages/sympy/stats/frv.py:210: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/frv.py:214: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/frv.py:416: raise NotImplementedError("Computing quantile for random variables "
- .venv/lib/python3.12/site-packages/sympy/stats/frv.py:460: #TODO: Implement the mechanism for handling queries for symbolic sized distributions.
- .venv/lib/python3.12/site-packages/sympy/stats/frv.py:461: raise NotImplementedError("Currently, probability queries are not "
- .venv/lib/python3.12/site-packages/sympy/stats/compound_rv.py:80: raise NotImplementedError(message)
- .venv/lib/python3.12/site-packages/sympy/stats/compound_rv.py:163: raise NotImplementedError(message)
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv_types.py:134: #TODO: Add support for sets provided by the user
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv_types.py:491: _value_check(len(alpha) >= 2, "At least two categories should be passed.")
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv_types.py:725: If you want to pass the matrix omega instead of the constant delta, then use
- .venv/lib/python3.12/site-packages/sympy/stats/matrix_distributions.py:50: raise NotImplementedError("Currently, no algorithm has been "
- .venv/lib/python3.12/site-packages/sympy/stats/matrix_distributions.py:114: ### TODO: Add tests after adding matrix distributions in numpy_rv_map
- .venv/lib/python3.12/site-packages/sympy/stats/matrix_distributions.py:204: pass
- .venv/lib/python3.12/site-packages/sympy/stats/matrix_distributions.py:220: raise NotImplementedError("Sampling from %s is not supported yet."
- .venv/lib/python3.12/site-packages/sympy/stats/matrix_distributions.py:229: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:123: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:131: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:134: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:146: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:321: raise NotImplementedError("Sampling from %s is not supported yet."
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:330: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:374: pass
- .venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:415: #TODO: Modify to support integration
- .venv/lib/python3.12/site-packages/sympy/stats/random_matrix_models.py:249: # TODO : Add support for Lie groups(as extensions of sympy.diffgeom)
- .venv/lib/python3.12/site-packages/sympy/stats/random_matrix_models.py:251: raise NotImplementedError("Support for Haar measure hasn't been "
- .venv/lib/python3.12/site-packages/sympy/stats/rv_interface.py:452: raise NotImplementedError("The median of %s is not implemented."%str(pspace(X)))
- .venv/lib/python3.12/site-packages/sympy/stats/random_matrix.py:27: raise NotImplementedError("Currently, no algorithm has been "
- .venv/lib/python3.12/site-packages/sympy/stats/symbolic_probability.py:117: # Otherwise pass work off to the ProbabilitySpace
- .venv/lib/python3.12/site-packages/sympy/stats/symbolic_probability.py:287: # Otherwise case is simple, pass work off to the ProbabilitySpace
- .venv/lib/python3.12/site-packages/sympy/stats/symbolic_probability.py:298: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/symbolic_probability.py:316: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process.py:20: parameter should not be passed.
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:136: it returns the Symbol of argument if the string type argument is passed.
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:227: raise NotImplementedError("Use [] for indexing discrete time stochastic process.")
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:233: raise NotImplementedError("Use () for indexing continuous time stochastic process.")
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:236: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:260: ValueError: When the arguments passed are not of type RandomIndexSymbol
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:281: raise NotImplementedError("Abstract method for expectation queries.")
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:284: raise NotImplementedError("Abstract method for sampling queries.")
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:550: Any information passed at the time of query overrides
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:551: any information passed at the time of object creation like
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:726: raise NotImplementedError("Mechanism for handling (%s, %s) queries hasn't been "
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:785: Any information passed at the time of query overrides
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:786: any information passed at the time of object creation like
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:821: raise NotImplementedError("Mechanism for handling (%s, %s) queries hasn't been "
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:1031: raise NotImplementedError("Cannot perform the operation with a symbolic matrix.")
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:2130: raise ValueError("If given condition is passed with `Contains`, then "
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:2131: "please pass the evaluated condition with its corresponding information "
- .venv/lib/python3.12/site-packages/sympy/stats/stochastic_process_types.py:2132: "in terms of intervals of each time stamp to be passed in given condition.")
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_matrix_distributions.py:47: raises(NotImplementedError, lambda: density(M3 + M)(Z))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_matrix_distributions.py:150: raises(NotImplementedError, lambda: sample(M, size=3))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_matrix_distributions.py:167: raises(NotImplementedError, lambda: sample(M, size=3))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_matrix_distributions.py:185: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_rv.py:324: pass
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:61: raises (NotImplementedError, lambda: median(m))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:324: raises(NotImplementedError, lambda: sample(N_c, library='numpy'))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:348: raises(NotImplementedError, lambda: sample(N_c))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:367: raises(NotImplementedError, lambda: sample(N_c, library='pymc'))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:386: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:390: # XXX: This fails for pymc. Previously the test appeared to pass but that is
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:391: # just because the library argument was not passed so the test always used
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:410: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:415: # When this passes the pymc part can be uncommented in test_issue_21057 above
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_joint_rv.py:435: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_finite_rv.py:68: # TODO: Make iid method!
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_finite_rv.py:308: raises(NotImplementedError, lambda: P(B > 2))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_mix.py:80: with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:41: # pass only the name
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:50: raises(NotImplementedError, lambda: X(t))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:51: raises(NotImplementedError, lambda: X.communication_classes())
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:52: raises(NotImplementedError, lambda: X.canonical_form())
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:53: raises(NotImplementedError, lambda: X.decompose())
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:63: # pass name and state_space
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:77: with ignore_warnings(UserWarning):  # TODO: Restore tests once warnings are removed
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:87: # pass name and transition_probabilities
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:95: # pass name, state_space and transition_probabilities
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:109: with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:408: with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:478: raises(NotImplementedError, lambda: B(t))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:548: raises(NotImplementedError, lambda: X[t])
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:664: raises(NotImplementedError, lambda: X[t])
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:709: raises(NotImplementedError, lambda: X[t])
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_compound_rv.py:90: with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_compound_rv.py:120: raises(NotImplementedError, lambda: CompoundDistribution(M))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:392: raises(NotImplementedError, lambda: moment_generating_function(X))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:503: raises(NotImplementedError, lambda: moment_generating_function(X))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:677: with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:714: raises(NotImplementedError, lambda: moment_generating_function(X))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:785: raises(NotImplementedError, lambda: moment_generating_function(X))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:848: raises(NotImplementedError, lambda: moment_generating_function(X))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:928: raises(NotImplementedError, lambda: moment_generating_function(X))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1165: raises(NotImplementedError, lambda: moment_generating_function(X))
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1348: with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
- .venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1358: with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_discrete_rv.py:33: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_discrete_rv.py:35: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_discrete_rv.py:83: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_discrete_rv.py:108: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_continuous_rv.py:38: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_continuous_rv.py:40: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_continuous_rv.py:98: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_continuous_rv.py:180: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_finite_rv.py:29: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_finite_rv.py:31: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_finite_rv.py:76: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/stats/sampling/tests/test_sample_finite_rv.py:93: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/printing/fortran.py:252: raise NotImplementedError("Using Piecewise as an expression using "
- .venv/lib/python3.12/site-packages/sympy/printing/fortran.py:317: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/printing/fortran.py:424: raise NotImplementedError("Only iterable currently supported is Range")
- .venv/lib/python3.12/site-packages/sympy/printing/fortran.py:462: raise NotImplementedError("Pointers are not available by default in Fortran.")
- .venv/lib/python3.12/site-packages/sympy/printing/fortran.py:476: raise NotImplementedError("F77 init./parameter statem. req. multiple lines.")
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:35: pass
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:37: class PrintMethodNotImplementedError(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:41: pass
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:242: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:307: pass
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:317: raise NotImplementedError("This function must be implemented by "
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:322: raise NotImplementedError("This function must be implemented by "
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:327: raise NotImplementedError("This function must be implemented by "
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:332: raise NotImplementedError("This function must be implemented by "
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:339: raise NotImplementedError("This function must be implemented by "
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:345: raise NotImplementedError("This function must be implemented by "
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:477: raise PrintMethodNotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:610: raise PrintMethodNotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:618: pass
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:678: expression. These would be values passed by address to the function.
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:709: Simple custom printing can be defined for certain types by passing a
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:843: Custom printing can be defined for certain types by passing a dictionary of
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:943: expression. These would be values passed by address to the function.
- .venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:968: Simple custom printing can be defined for certain types by passing a
- .venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:107: # TODO: a better class structure would avoid this mess:
- .venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:131: raise NotImplementedError("derivation by multiple variables is not supported")
- .venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:202: # TODO: is this necessary?
- .venv/lib/python3.12/site-packages/sympy/printing/pytorch.py:171: if not isinstance(order, Integer): raise NotImplementedError("Only integer orders are supported")
- .venv/lib/python3.12/site-packages/sympy/printing/pytorch.py:286: raise NotImplementedError("PyTorch only supports digamma (0th order polygamma)")
- .venv/lib/python3.12/site-packages/sympy/printing/preview.py:10: pass
- .venv/lib/python3.12/site-packages/sympy/printing/preview.py:33: done. For this reason, we ensure the passed file will not be deleted under
- .venv/lib/python3.12/site-packages/sympy/printing/preview.py:107: pass
- .venv/lib/python3.12/site-packages/sympy/printing/preview.py:213: needs to be passed to the ``outputbuffer`` argument.
- .venv/lib/python3.12/site-packages/sympy/printing/preview.py:240: Additional keyword args will be passed to the :func:`~sympy.printing.latex.latex` call,
- .venv/lib/python3.12/site-packages/sympy/printing/preview.py:247: passing the desired filename to the 'outputTexFile' keyword
- .venv/lib/python3.12/site-packages/sympy/printing/preview.py:261: pass
- .venv/lib/python3.12/site-packages/sympy/printing/str.py:962: #TODO : Handle indices
- .venv/lib/python3.12/site-packages/sympy/printing/pycode.py:16: 'is', 'lambda', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while',
- .venv/lib/python3.12/site-packages/sympy/printing/pycode.py:747: raise NotImplementedError("Only definite integrals are supported")
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:238: # TODO: merge this with the above, which requires a lot of test changes
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:292: passed as an argument to a function, False otherwise. This is a more
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:295: not need them when passed to a function. Such an example is a*b.
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:396: pass
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:968: pass
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:1176: # TODO should exp_polar be printed differently?
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:2585: # TODO incorporate order
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:2588: pass
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:2777: # TODO: This expression is potentially confusing,
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:2785: # TODO nicer fractions for few generators...
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:2802: # TODO nicer fractions for few generators...
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:2850: # TODO: Handle indices
- .venv/lib/python3.12/site-packages/sympy/printing/latex.py:2944: Let everything else pass as given.
- .venv/lib/python3.12/site-packages/sympy/printing/c.py:403: raise NotImplementedError("Only iterable currently supported is Range")
- .venv/lib/python3.12/site-packages/sympy/printing/c.py:508: raise NotImplementedError("Unknown type of var: %s" % type(var))
- .venv/lib/python3.12/site-packages/sympy/printing/aesaracode.py:96: global state pass an empty dictionary. Note: the dictionary is not
- .venv/lib/python3.12/site-packages/sympy/printing/aesaracode.py:187: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/printing/aesaracode.py:211: raise NotImplementedError('''Only non-negative integer
- .venv/lib/python3.12/site-packages/sympy/printing/aesaracode.py:426: :func:`.aesara_code` and then passed to ``aesara.function``.
- .venv/lib/python3.12/site-packages/sympy/printing/aesaracode.py:472: argument above for the behavior when a single output is passed in a list.
- .venv/lib/python3.12/site-packages/sympy/printing/jscode.py:261: Custom printing can be defined for certain types by passing a dictionary of
- .venv/lib/python3.12/site-packages/sympy/printing/printer.py:4: passed to a designated Printer who then is responsible to return an
- .venv/lib/python3.12/site-packages/sympy/printing/printer.py:169: This fails when the ``mode`` argument is passed to the printer:
- .venv/lib/python3.12/site-packages/sympy/printing/printer.py:248: # must be initialized to pass tests and cannot be set to '| None' to pass mypy
- .venv/lib/python3.12/site-packages/sympy/printing/smtlib.py:264: raise NotImplementedError(f'Cannot convert `{repr(expr)}` of type `{type(expr)}` to SMT.')
- .venv/lib/python3.12/site-packages/sympy/printing/smtlib.py:338: Custom printing can be defined for certain types by passing a dictionary of
- .venv/lib/python3.12/site-packages/sympy/printing/julia.py:595: Alternatively, you can pass "inline=False" to use if-else conditionals.
- .venv/lib/python3.12/site-packages/sympy/printing/julia.py:612: Custom printing can be defined for certain types by passing a dictionary of
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:95: # TODO - assumes all called functions take one double precision argument.
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:112: # Used when parameters are passed by array.  Often used in callbacks to
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:254: raise NotImplementedError("Return of multiple expressions not supported for this callback")
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:268: pmb = llvm.create_pass_manager_builder()
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:270: pass_manager = llvm.create_module_pass_manager()
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:271: pmb.populate(pass_manager)
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:273: pass_manager.run(llmod)
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:419: The first ('scipy.integrate') is the function to be passed to the
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:420: integration routine, and will pass the signature checks.
- .venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:422: the function using ctypes variables. It will not pass the signature checks
- .venv/lib/python3.12/site-packages/sympy/printing/glsl.py:351: can also be passed.
- .venv/lib/python3.12/site-packages/sympy/printing/glsl.py:473: Custom printing can be defined for certain types by passing a dictionary of
- .venv/lib/python3.12/site-packages/sympy/printing/glsl.py:488: functions.  This is done by passing ``use_operators = False``:
- .venv/lib/python3.12/site-packages/sympy/printing/python.py:43: """Return Python interpretation of passed expression
- .venv/lib/python3.12/site-packages/sympy/printing/python.py:44: (can be passed to the exec() function without any modifications)"""
- .venv/lib/python3.12/site-packages/sympy/printing/rcode.py:255: raise NotImplementedError("Only iterable currently supported is Range")
- .venv/lib/python3.12/site-packages/sympy/printing/rcode.py:334: Simple custom printing can be defined for certain types by passing a
- .venv/lib/python3.12/site-packages/sympy/printing/octave.py:654: Alternatively, you can pass "inline=False" to use if-else conditionals.
- .venv/lib/python3.12/site-packages/sympy/printing/octave.py:671: Custom printing can be defined for certain types by passing a dictionary of
- .venv/lib/python3.12/site-packages/sympy/printing/numpy.py:49: `settings` is passed to CodePrinter.__init__()
- .venv/lib/python3.12/site-packages/sympy/printing/numpy.py:169: #     it will behave the same as passing the 'default' kwarg to select()
- .venv/lib/python3.12/site-packages/sympy/printing/numpy.py:222: raise NotImplementedError(f"Need at least one argument for {op}")
- .venv/lib/python3.12/site-packages/sympy/printing/numpy.py:279: raise NotImplementedError("Symbolic matrix dimensions are not yet supported for identity matrices")
- .venv/lib/python3.12/site-packages/sympy/printing/theanocode.py:94: global state pass an empty dictionary. Note: the dictionary is not
- .venv/lib/python3.12/site-packages/sympy/printing/theanocode.py:185: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/printing/theanocode.py:209: raise NotImplementedError('''Only non-negative integer
- .venv/lib/python3.12/site-packages/sympy/printing/theanocode.py:436: :func:`.theano_code` and then passed to ``theano.function``.
- .venv/lib/python3.12/site-packages/sympy/printing/theanocode.py:482: argument above for the behavior when a single output is passed in a list.
- .venv/lib/python3.12/site-packages/sympy/printing/lambdarepr.py:73: # numexpr works by altering the string passed to numexpr.evaluate
- .venv/lib/python3.12/site-packages/sympy/printing/lambdarepr.py:138: #     it will behave the same as passing the 'default' kwarg to select()
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_latex.py:99: pass   # testing notation inheritance by a subclass with same name
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_latex.py:807: # test that notation passes to subclasses of the same name only
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_latex.py:810: pass
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_latex.py:2079: #TODO: Handle indices
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_rust.py:362: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:63: raises(NotImplementedError, lambda: fcode(sign(x)))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:107: raises(NotImplementedError, lambda: fcode(Mod(x, y), standard=66))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:108: raises(NotImplementedError, lambda: fcode(x % y, standard=66))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:109: raises(NotImplementedError, lambda: fcode(Mod(x, y), standard=77))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:110: raises(NotImplementedError, lambda: fcode(x % y, standard=77))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:208: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:211: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:440: raises(NotImplementedError, lambda: fcode(expr))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:657: pass
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:842: raises(NotImplementedError, lambda: fcode(fp1))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_fortran.py:854: raises(NotImplementedError, lambda: fcode(fd1))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_cupy.py:25: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_julia.py:316: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_jax.py:332: raises(NotImplementedError, lambda: lambdify(N, N + Identity(n), 'jax'))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_numpy.py:318: raises(NotImplementedError, lambda: lambdify(N, N + Identity(n)))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:101: to stdout and returns an empty string. This can lead to tests passing where
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:172: @SKIP  # TODO - this is currently not checked but should be implemented
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:226: # TODO - matrix broadcasting?
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:322: Test passing additional kwargs from theano_function() to theano.function().
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:599: # assert theq(theano_code_(sy.Ne(x, y)), tt.neq(xt, yt))  # TODO - implement
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:111: to stdout and returns an empty string. This can lead to tests passing where
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:182: @SKIP  # TODO - this is currently not checked but should be implemented
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:236: # TODO - matrix broadcasting?
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:333: Test passing additional kwargs from aesara_function() to aesara.function().
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:611: # assert theq(aesara_code_(sy.Ne(x, y)), aet.neq(xt, yt))  # TODO - implement
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:381: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:393: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:399: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:509: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_c.py:15: from sympy.printing.codeprinter import PrintMethodNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_c.py:143: with raises(PrintMethodNotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_c.py:145: with raises(PrintMethodNotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_c.py:573: with raises(PrintMethodNotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_tableform.py:164: pass  # use default print
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_codeprinter.py:1: from sympy.printing.codeprinter import CodePrinter, PrintMethodNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_codeprinter.py:64: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_codeprinter.py:74: with raises(PrintMethodNotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_codeprinter.py:76: with raises(PrintMethodNotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_repr.py:93: # TODO more tests
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_llvmjit.py:177: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_pycode.py:15: from sympy.printing.codeprinter import PrintMethodNotImplementedError
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_pycode.py:322: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_pycode.py:339: raises(NotImplementedError, lambda: prntr.doprint(indefinite))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_pycode.py:340: raises(NotImplementedError, lambda: prntr.doprint(evaluateat))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_pycode.py:345: raises(NotImplementedError, lambda: prntr.doprint(indefinite))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_pycode.py:346: raises(NotImplementedError, lambda: prntr.doprint(evaluateat))
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_pycode.py:363: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_pycode.py:365: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_pycode.py:483: except PrintMethodNotImplementedError as e:
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_preview.py:17: pass  # latex not installed on CI server
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_preview.py:27: pass  # latex not installed on CI server
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_preview.py:38: pass  # latex not installed on CI server
- .venv/lib/python3.12/site-packages/sympy/printing/tests/test_maple.py:306: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:200: # TODO: Make brackets adjust to height of contents
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:333: # TODO robustify when no unicodedat available
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:359: pass
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/stringpict.py:10: TODO:
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/stringpict.py:382: argument (the first positional argument) should be passed.
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/stringpict.py:423: raise NotImplementedError("Can't do slashed fraction yet")
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1121: raise NotImplementedError("ASCII pretty printing of BasisDependent is not implemented")
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1574: # TODO should exp_polar be printed differently?
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1910: #TODO: Move this code to prettyForm
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2215: raise NotImplementedError("ASCII pretty printing of SymmetricDifference is not implemented")
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2239: # TODO: the stuff to the left of the | and the stuff to the right of
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2336: raise NotImplementedError("Pretty printing of sequences with symbolic bound not implemented")
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2602: # TODO: copy-pasted from _print_Function: can we do better?
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2671: # TODO incorporate order
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2674: pass
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2808: #TODO: Handle indices
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2930: pass ``num_columns=None`` to auto-detect the width of the terminal.
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:87: pass   # testing notation inheritance by a subclass with same name
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:4575: # TODO: The "x in N" parts below should be centered independently of the
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:4832: raises(NotImplementedError, lambda: pretty(s7))
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:4833: raises(NotImplementedError, lambda: upretty(s7))
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:5309: pass   # C has no .__class__ and this was causing problems
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:5312: pass
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:5969: # test that notation passes to subclasses of the same name only
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:5972: pass
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:6921: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7256: # TODO: add support for ASCII pretty.
- .venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7620: # TODO: TBD polylog(s - 1, z)
- .venv/lib/python3.12/site-packages/sympy/matrices/inverse.py:72: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/matrices/exceptions.py:7: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/exceptions.py:12: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/exceptions.py:16: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/exceptions.py:21: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/exceptions.py:26: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/determinant.py:183: # Caller did not pass in a simplification function that might
- .venv/lib/python3.12/site-packages/sympy/matrices/determinant.py:375: Whether you pass a symbol or not, the generator can be obtained
- .venv/lib/python3.12/site-packages/sympy/matrices/determinant.py:377: that was passed:
- .venv/lib/python3.12/site-packages/sympy/matrices/determinant.py:731: TODO: Implement algorithm for sparse matrices (SFF),
- .venv/lib/python3.12/site-packages/sympy/matrices/determinant.py:804: The keyword arguments iszerofunc and simpfunc are passed to
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:166: raise NotImplementedError("Subclasses must implement this.")
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:169: raise NotImplementedError("Subclasses must implement this.")
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:176: raise NotImplementedError("Subclasses must implement this.")
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:180: raise NotImplementedError("Subclasses must implement this.")
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:184: raise NotImplementedError("Subclasses must implement this.")
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:938: If matrices are passed, a block-diagonal matrix
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:975: When more than one element is passed, each is interpreted as
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:1514: pass an equality test, the matrix is still reported as
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:2746: # Matrix-like objects can be passed to CommonMatrix routines directly.
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:2828: # Matrix-like objects can be passed to CommonMatrix routines directly.
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:2837: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:3014: # Matrix-like objects can be passed to CommonMatrix routines directly.
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:3023: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:3068: # if we passed in a function, use that to populate the indices
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:3074: # if we passed in a list of lists, flatten it and set the size
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:3081: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:3085: raise NotImplementedError("Cannot initialize matrix with given parameters")
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:3186: `mat` is passed through without modification."""
- .venv/lib/python3.12/site-packages/sympy/matrices/common.py:3251: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/solvers.py:231: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/matrices/solvers.py:289: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/matrices/solvers.py:345: raise NotImplementedError("Underdetermined systems not supported.")
- .venv/lib/python3.12/site-packages/sympy/matrices/solvers.py:727: The default is ``'laplace'``.  If a callable is passed, it should take a
- .venv/lib/python3.12/site-packages/sympy/matrices/solvers.py:875: of equations that is passed to ``solve`` along with the hint
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:124: raise NotImplementedError("Subclasses must implement this.")
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:127: raise NotImplementedError("Subclasses must implement this.")
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:134: raise NotImplementedError("Subclasses must implement this.")
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:907: If matrices are passed, a block-diagonal matrix
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:944: When more than one element is passed, each is interpreted as
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:1478: pass an equality test, the matrix is still reported as
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:3427: be passed to the ``integrate`` function.
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:3512: ``args`` will be passed to the ``limit`` function.
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:3614: TODO: Implement algorithm for sparse matrices (SFF),
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:3793: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:4433: # If it so happens that only conjugate_convention is passed
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:4435: # is true but no conjugate_convention is not passed then
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:4651: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:4767: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:4973: except (NotImplementedError, TypeError):
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:5001: raise NotImplementedError("Matrix Norms under development")
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:5135: raise NotImplementedError('This function is implemented in DenseMatrix or SparseMatrix')
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:5138: raise NotImplementedError('This function is implemented in DenseMatrix or SparseMatrix')
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:5166: raise NotImplementedError('This function is implemented in DenseMatrix or SparseMatrix')
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:5169: raise NotImplementedError('This function is implemented in DenseMatrix or SparseMatrix')
- .venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:5360: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/eigen.py:101: If a function is passed to, it will attempt to apply
- .venv/lib/python3.12/site-packages/sympy/matrices/eigen.py:224: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/matrices/eigen.py:265: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/matrices/eigen.py:294: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/matrices/eigen.py:362: being evaluated with evalf. The ``chop`` flag is passed to ``evalf``.
- .venv/lib/python3.12/site-packages/sympy/matrices/eigen.py:382: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/matrices/eigen.py:1279: eigenvects(), i.e. the ``**flags`` arguments gets passed directly to
- .venv/lib/python3.12/site-packages/sympy/matrices/sparse.py:72: To autosize the matrix, pass None for rows:
- .venv/lib/python3.12/site-packages/sympy/matrices/dense.py:645: keyword arguments passed on to Symbol
- .venv/lib/python3.12/site-packages/sympy/matrices/repmatrix.py:83: are passed to :func:`construct_domain`:
- .venv/lib/python3.12/site-packages/sympy/matrices/repmatrix.py:117: # bypass calling construct_domain or performing any conversions. Some
- .venv/lib/python3.12/site-packages/sympy/matrices/repmatrix.py:128: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/repmatrix.py:999: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/repmatrix.py:1005: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/decompositions.py:939: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/decompositions.py:957: # Future versions of LUdecomposition_simple can pass iszerofunc and simpfunc
- .venv/lib/python3.12/site-packages/sympy/matrices/decompositions.py:959: # In pass 3 of _find_reasonable_pivot(), the predicate in ``if x.equals(S.Zero):``
- .venv/lib/python3.12/site-packages/sympy/matrices/decompositions.py:960: # calls sympy.simplify(), and not the simplification function passed in via
- .venv/lib/python3.12/site-packages/sympy/matrices/decompositions.py:1035: # NotImplementedError: Cannot add Zero to MutableSparseMatrix
- .venv/lib/python3.12/site-packages/sympy/matrices/matrices.py:452: be passed to the ``integrate`` function.
- .venv/lib/python3.12/site-packages/sympy/matrices/matrices.py:536: ``args`` will be passed to the ``limit`` function.
- .venv/lib/python3.12/site-packages/sympy/matrices/matrices.py:655: TODO: Implement algorithm for sparse matrices (SFF),
- .venv/lib/python3.12/site-packages/sympy/matrices/normalforms.py:124: The basic assumption is that, if you pass a value for *D*, then
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_solvers.py:117: raises(NotImplementedError, lambda: A.LUsolve(b))
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_solvers.py:241: raises(NotImplementedError, lambda: A.LDLsolve(b))
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:106: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:119: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:132: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:145: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:158: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:163: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:827: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:866: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:896: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:898: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:904: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:906: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:1167: # TODO: currently not working as ``_MinimalMatrix`` cannot be sympified:
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_sparse.py:101: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrixbase.py:364: if(int(version('numpy').split('.')[0]) >= 2): #run this test only if numpy is new enough that copy variable is passed pr
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrixbase.py:508: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrixbase.py:510: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrixbase.py:516: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrixbase.py:518: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrixbase.py:3459: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrixbase.py:3628: """ When doing numerical computations, all elements that pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_eigen.py:163: raises(NotImplementedError, lambda: m.is_diagonalizable(True))
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_eigen.py:385: # make sure we use floats out if floats are passed in
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrices.py:72: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrices.py:77: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrices.py:211: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrices.py:250: pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrices.py:2632: # when this passes, delete this and change the [1:2]
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrices.py:2777: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_matrices.py:2948: """ When doing numerical computations, all elements that pass
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_decompositions.py:294: # Test if callable passed to matrices.LUdecomposition_Simple() as iszerofunc keyword argument is used inside
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_decompositions.py:296: magic_string = "I got passed in!"
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_decompositions.py:309: # Test if callable passed to matrices.LUdecomposition() as iszerofunc keyword argument is used inside
- .venv/lib/python3.12/site-packages/sympy/matrices/tests/test_decompositions.py:311: magic_string = "I got passed in!"
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/blockmatrix.py:67: these arguments, pass them directly to Matrix.
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/blockmatrix.py:119: from these arguments, pass them directly to
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/hadamard.py:165: # TODO Implement algorithm for rewriting Hadamard product as diagonal matrix
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/factorizations.py:17: class LofCholesky(LofLU): pass
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/factorizations.py:18: class UofCholesky(UofLU): pass
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/matmul.py:130: raise NotImplementedError("noncommutative scalars in MatMul are not supported.")
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/matexpr.py:89: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/matexpr.py:103: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/matexpr.py:153: raise NotImplementedError("Matrix Power not defined")
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/matexpr.py:163: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/matexpr.py:248: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/trace.py:56: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/matpow.py:146: raise NotImplementedError("cannot evaluate %s derived by %s" % (self, x))
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/permutation.py:101: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_matpow.py:215: # if this passes, Pow.as_numer_denom should recognize
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_matpow.py:217: raises(NotImplementedError, lambda: 3**(-2*C))
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_matexpr.py:139: raises(NotImplementedError, lambda: 2/B)
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_matexpr.py:383: if(int(version('numpy').split('.')[0]) >= 2): #run this test only if numpy is new enough that copy variable is passed pr
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:52: # TODO: this is commented because it slows down the tests.
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:105: # TODO: find a way to represent a four-dimensional zero-array:
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:225: # TODO: TensorProduct is not supported
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:292: # TODO: no support for TensorProduct.
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:407: # TODO: restore this result (currently returning the transpose):
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:416: # TODO: restore (currently returning the transpose):
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:435: # TODO: not implemented
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:444: # TODO: wrong
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:448: # TODO: wrong
- .venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_blockmatrix.py:97: # block_collapse passes down into container objects, transposes, and inverse
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:10: class MDNotImplementedError(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:11: """ A NotImplementedError for multiple dispatch """
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:33: class RaiseNotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:34: """Raise ``NotImplementedError`` when called."""
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:41: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:49: Else, register instance of ``RaiseNotImplementedError`` for ambiguous types.
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:67: signature, RaiseNotImplementedError(dispatcher),
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:191: NotImplementedError: Could not find signature for add: <int, float>
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:238: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:245: except MDNotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:251: except MDNotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:252: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:253: raise NotImplementedError("Matching functions for "
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/dispatcher.py:388: raise NotImplementedError('Could not find signature for %s: <%s>' %
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/conflict.py:4: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/__init__.py:3: MDNotImplementedError)
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/__init__.py:10: 'Dispatcher', 'halt_ordering', 'restart_ordering', 'MDNotImplementedError',
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:1: from sympy.multipledispatch.dispatcher import (Dispatcher, MDNotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:185: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:201: assert raises(NotImplementedError, lambda: f('hello'))
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:215: assert raises(NotImplementedError, lambda: f('hello'))
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:231: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:250: raise MDNotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:255: assert raises(NotImplementedError, lambda: f(1, 2))
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:263: raise MDNotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:265: assert raises(NotImplementedError, lambda: f(1.0))
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:271: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:273: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:275: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:283: # raises error if ambiguous signal is passed
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_dispatcher.py:284: assert raises(NotImplementedError, lambda: f(B(), C()))
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_conflict.py:5: class A: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_conflict.py:6: class B(A): pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_conflict.py:7: class C: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_core.py:32: assert raises(NotImplementedError, lambda: f('hello'))
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_core.py:48: class A: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_core.py:49: class B: pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_core.py:50: class C(A): pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_core.py:51: class D(C): pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_core.py:52: class E(C): pass
- .venv/lib/python3.12/site-packages/sympy/multipledispatch/tests/test_core.py:82: assert raises(NotImplementedError, lambda: f(B(), B()))
- .venv/lib/python3.12/site-packages/sympy/integrals/singularityfunctions.py:9: instance of SingularityFunction is passed as argument.
- .venv/lib/python3.12/site-packages/sympy/integrals/trigonometry.py:5: # TODO sin(a*x)*cos(b*x) -> sin((a+b)x) + sin((a-b)x) ?
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:119: # TODO this needs more polar_lift (c/f entry for exp)
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:164: # TODO can do sin^n, sinh^n by expansion ... where?
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:170: # TODO can do t + a. but can also do by expansion... (XXX not really)
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:187: # TODO these only hold for positive p, and can be made more general
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:189: # TODO also it would be nice to derive them recursively ...
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:202: # TODO log(x)/(x+a) and log(x)/(x-1) can also be done. should they
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:204: # TODO further formulae in this section seem obscure
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:207: # TODO
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:230: # TODO exp(-x)*erf(I*x) does not work
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:256: # TODO all of the following should be derivable
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:282: # TODO many more formulas. should all be derivable
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:286: # TODO many more formulas. should all be derivable
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:317: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:524: # TODO should this be a method of meijerg?
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:852: # TODO altered cases 4-7
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:876: # TODO This leaves only one case from the three listed by Prudnikov.
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:900: # XXX TODO we should reduce order first
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:972: # TODO should we try both?
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:988: # XXX TODO this is a testing *nightmare*
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:1445: # TODO
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:1599: raise NotImplementedError('Unexpected form...')
- .venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:1719: #  can safely pass S.One for ``expr``.)
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:400: # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:466: # TODO
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:875: # TODO not implemented yet, but also not important
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:1242: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:1250: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:2179: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:2188: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:2289: argument ``plane``, but will be inferred if passed as None.
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:2351: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:2359: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:2370: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:190: If it is unsuccessful, it raises NotImplementedError.
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:246: raise NotImplementedError("Trigonometric extensions are not "
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:261: # We couldn't find a new extension on the last pass, so I guess
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:263: raise NotImplementedError("Couldn't find an elementary "
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:312: # do this at each pass (or else modify it to not do that).
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:333: # TODO: This probably doesn't need to be completely recomputed at
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:334: # each pass.
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:357: raise NotImplementedError("Algebraic extensions are "
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:366: # TODO: Would there ever be any benefit from just
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:395: # TODO: Just put it in self.Tfuncs
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:463: NotImplementedError.
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:497: # TODO: Add something to backsubs to put exp(const*p)
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:530: # TODO: give algebraic dependence in error string
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:531: raise NotImplementedError("Cannot integrate over "
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:573: NotImplementedError.
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:779: # TODO: Rewrite algorithms below to use this (?)
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:781: # TODO: Pass through information about why the integral was nonelementary,
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:783: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:798: # TODO: This should go in densetools.py.
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:855: # TODO: Use this on the final result.  That way, we can avoid answers like
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1006: # TODO: This algorithm appears to be faster in every case
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1007: # TODO: Verify this and splitfactor() for multiple extensions
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1250: # TODO also consider the complex roots which should
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1280: # TODO: Use log_to_atan() from rationaltools.py
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1350: # TODO: check what Lambda does with RootOf
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1365: # TODO: verify that this is correct for multiple extensions
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1458: # TODO: This does not do the right thing when b is False
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1621: # TODO: Integral from k?
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1622: # TODO: split out nonelementary integral
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1662: In this case, integrate() may raise NotImplementedError if it cannot make
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1691: # TODO: This is useful in and of itself, because isinstance(result,
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1696: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1714: result in raising NotImplementedError.  The unevaluated Integral will be
- .venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1832: raise NotImplementedError("Only exponential and logarithmic "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:114: # TODO: Merge this with the very similar special_denom() in rde.py
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:158: # TODO: Add test
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:549: raise NotImplementedError("prde_no_cancel_b_equal() is "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:557: raise NotImplementedError("non-linear and hypertangent "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:724: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:822: # TODO: implement this
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:823: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:868: theta over k(t), raises either NotImplementedError, in which case the
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:878: # TODO: finish writing this and write tests
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:921: # TODO: We treat this as 'no solution', until the structure
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:952: # TODO: Write the full algorithm using the structure theorems.
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:955: #    except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:957: # TODO: This could be implemented more efficiently.
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1002: recursively using this same function.  Therefore, it is required to pass
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1013: logarithm from the other.  Therefore, it is necessary to pass the arguments
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1032: raise NotImplementedError("Real version of the structure "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1035: # TODO: What should really be done in this case?
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1036: raise NotImplementedError("Nonelementary extensions not supported "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1060: raise NotImplementedError("Cannot work with non-rational "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1125: recursively using this same function.  Therefore, it is required to pass
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1135: is necessary to pass the arguments of the exponential terms in E_args.
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1157: raise NotImplementedError("Real version of the structure "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1160: # TODO: What should really be done in this case?
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1161: raise NotImplementedError("Nonelementary extensions not supported "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1185: # TODO: But maybe we can tell if they're not rational, like
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1188: raise NotImplementedError("Cannot work with non-rational "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1239: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1266: # TODO: finish writing this and write tests
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1301: # TODO: we can use more efficient residue reduction from ratint()
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1314: raise NotImplementedError("The hypertangent case is "
- .venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1318: # XXX: If these are supported by the structure theorems, change to NotImplementedError.
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:253: replacing `x` must be identified by passing `u` as a tuple:
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:286: must be identified: pass f(u) as (f(u), u)'''))
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:469: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:574: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:575: _debug('NotImplementedError '
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:671: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:720: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:772: # check for regularity conditions (TODO), see issue 4215
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:921: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:930: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:964: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:965: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:1076: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:1106: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:1107: _debug('NotImplementedError from meijerint_definite')
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:1138: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:1309: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:87: raise NotImplementedError("Integration for H-representation 3D"
- .venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:977: #  TODO : This part is quite hacky. Should be made more robust with
- .venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:978: #  TODO : respect to symbol names and scalable w.r.t higher dimensions.
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:160: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:161: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:170: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:171: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:283: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:495: # TODO: caching is significant factor for why permutations work at all. Change this.
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:700: # TODO: Currently it's better to use symbolic expressions here instead
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:718: pass # ignore trivial numbers
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:720: pass # ignore variables
- .venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:726: # TODO: Non-polynomial expression. This should have been
- .venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:79: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:83: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:209: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:256: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:417: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:1072: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:2040: # TODO: This is for future development, as currently
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:40: class IntegralTransformError(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:108: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:111: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:195: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:201: # TODO handle derivatives etc
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:457: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:684: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:745: # TODO
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:794: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:890: One of `a` or `b` may be passed as ``None``; a suitable `c` will be
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:968: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:972: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:1144: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:1148: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:38: # TODO: Add messages to NonElementaryIntegralException errors
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:205: # TODO: finish writing this and write tests
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:286: # TODO: finish writing this and write tests
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:326: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:350: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:510: # TODO: better name for this function
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:579: raise NotImplementedError("is_deriv_in_field() is required to "
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:631: raise NotImplementedError("is_deriv_in_field() is required to "
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:653: # TODO: Write a dummy function that does this idiom
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:713: # TODO: Is this check necessary, and if so, what should it do if it fails?
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:719: raise NotImplementedError("prde_no_cancel_b_equal() is not yet "
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:735: raise NotImplementedError("Remaining cases for Poly (P)RDE are "
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:740: raise NotImplementedError("Parametric RDE cancellation "
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:746: raise NotImplementedError("Parametric RDE cancellation "
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:751: raise NotImplementedError("Other Poly (P)RDE cancellation "
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:755: raise NotImplementedError("Remaining cases for Poly PRDE not yet "
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:757: raise NotImplementedError("Remaining cases for Poly RDE not yet "
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:772: NotImplementedError, in which case, the algorithms necessary to
- .venv/lib/python3.12/site-packages/sympy/integrals/rde.py:787: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:105: # TODO: when bound_degree() can handle this, test degree bound from that too
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:147: # TODO: Add test for deg(b) <= 0 with b small
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:262: # TODO: Add more tests
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:280: # TODO: Add more tests, including ones with exponentials
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_trigonometry.py:32: # TODO: remove conds='none' below. For this to work we would have to rule
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:110: # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:698: # TODO sinh/cosh shifted come out a mess. also delayed trig is a mess
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:699: # TODO should this simplify further?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:714: # TODO can we make erf(t) work?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:756: # TODO LT of Si, Shi, Chi is a mess ...
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:235: # TODO: Skip or make faster
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:250: # TODO: Add tests for integrate_hyperexponential() from the book
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:374: # TODO: Add a test where two different parts of the extension use a
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:589: raises(NotImplementedError, lambda: DifferentialExtension(sin(x), x))
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:620: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:657: pass
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:71: # TODO: add more tests here
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:114: # TODO: Add test for when the degree bound becomes larger after limited_integrate
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:115: # TODO: Add test for db == da - 1 case
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:118: # TODO: Add tests
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:119: # TODO: Add test for when the degree becomes larger after parametric_log_deriv()
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:179: # TODO: Add more exp tests, including tests that require is_deriv_in_field()
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:193: # TODO: Add more primitive tests, including tests that require is_deriv_in_field()
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:197: # TODO: Add more tests for rischDE, including ones from the text
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:149: # TODO what simplifications should be done automatically?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:165: # TODO it would be nice to test the condition
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:245: # TODO more orthogonality integrals
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:257: # TODO can do higher powers, but come out as high order ... should they be
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:262: # TODO more besseli when tables are extended or recursive mellin works
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:273: # TODO how does besselj(0, a*x)*besselj(0, b*x) work?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:274: # TODO how does besselj(0, x)**2*besselj(1, x)**2 work?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:275: # TODO sin(x)*besselj(0, x) etc come out a mess
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:276: # TODO can x*log(x)*besselj(0, x) be done?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:277: # TODO how does besselj(1, x)*besselj(0, x+a) work?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:278: # TODO more indefinite integrals when struve functions etc are implemented
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:374: # TODO gammasimp cannot prove that the factor is unity
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:517: # TODO conditions are a mess
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:523: # TODO gamma, rayleigh
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:579: # TODO are there other distributions supported on (-oo, oo) that we can do?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:658: # TODO maybe simplify the inequalities? when the simplification
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:668: # TODO FT(besselj(0,x)) - conditions are messy (but for acceptable reasons)
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:312: # when passed to risch_norman, this will be a CPU hog, so this really
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:328: # TODO: Remove conds='none' below, let the assumption take care of it.
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:836: raises(NotImplementedError, lambda: e.as_sum(4))
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1140: # TODO: Remove conds='none' below, let the assumption take care of it.
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1284: # Note: this used to raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1329: # TODO: How to test risch=False?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_failing_integrals.py:259: # Not slow when bypassing heurish
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:80: # TODO does not work with bneg, argument wrong. Needs changes to matching.
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:164: # TODO we cannot currently do these (needs summation of 3F2(-1))
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:244: # TODO we can't do any of these (delicate cancellation)
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:253: # TODO bessely(a, x)*besselk(a, x) is a mess
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:264: # TODO products of besselk are a mess
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:271: # TODO exp(x/2)*besselk(a, x/2) [etc] cannot currently be done
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:272: # TODO various strange products of special orders
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:323: # test passing "None"
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:386: # TODO
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:399: # test passing cot
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:420: # TODO this comes out as an amazing mess, but simplifies nicely
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:436: # TODO this can be further simplified!
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:444: # TODO more
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:466: # TODO for this to work with real a, need to expand abs(a*x) to abs(a)*abs(x)
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:479: # TODO IFT is a *mess*
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:481: # TODO IFT
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:492: # TODO IFT without factoring comes out as meijer g
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:502: # TODO IFT (comes out as meijer G)
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:504: # TODO besselj(n, x), n an integer > 0 actually can be done...
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:506: # TODO are there other common transforms (no distributions!)?
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:221: # TODO: it looks like this used to work just by coincindence and
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:254: # TODO: heurisch() is off by a constant: -3/4. Possibly different permutation
- .venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:343: # TODO: convert the rest of PMINT tests:
- .venv/lib/python3.12/site-packages/sympy/categories/baseclasses.py:64: raise(NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/categories/baseclasses.py:555: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/categories/baseclasses.py:559: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/categories/diagram_drawing.py:2494: # prop is a Symbol.  TODO: Find out why.
- .venv/lib/python3.12/site-packages/sympy/categories/diagram_drawing.py:2516: set of logical groups.  The ``hints`` will be passed directly to
- .venv/lib/python3.12/site-packages/sympy/categories/diagram_drawing.py:2555: ``diagram_format``, ``groups``, and ``hints`` are passed to
- .venv/lib/python3.12/site-packages/sympy/categories/diagram_drawing.py:2557: are passed to ``preview``.
- .venv/lib/python3.12/site-packages/sympy/categories/tests/test_baseclasses.py:84: raises(NotImplementedError, lambda: Morphism(A, B))
- .venv/lib/python3.12/site-packages/sympy/external/importtools.py:43: pass
- .venv/lib/python3.12/site-packages/sympy/external/importtools.py:87: This function uses __import__() to import the module.  To pass additional
- .venv/lib/python3.12/site-packages/sympy/external/importtools.py:89: example, to import a submodule A.B, you must pass a nonempty fromlist option
- .venv/lib/python3.12/site-packages/sympy/external/importtools.py:93: catch additional errors, pass them as a tuple to the catch keyword
- .venv/lib/python3.12/site-packages/sympy/external/importtools.py:115: >>> # To import a submodule, you must pass a nonempty fromlist to
- .venv/lib/python3.12/site-packages/sympy/external/tests/test_codegen.py:135: generated code. The test passes when the compilation and the validation
- .venv/lib/python3.12/site-packages/sympy/external/tests/test_codegen.py:183: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/external/tests/test_autowrap.py:154: # if there was only a single helper it did not need to be passed via an
- .venv/lib/python3.12/site-packages/sympy/external/tests/test_pythonmpq.py:26: pass
- .venv/lib/python3.12/site-packages/sympy/ntheory/continued_fraction.py:243: pass
- .venv/lib/python3.12/site-packages/sympy/ntheory/residue_ntheory.py:1431: pass
- .venv/lib/python3.12/site-packages/sympy/ntheory/residue_ntheory.py:1636: # Compute the order and its factoring in one pass
- .venv/lib/python3.12/site-packages/sympy/ntheory/primetest.py:659: integer there are errors that may "pass silently" if this is
- .venv/lib/python3.12/site-packages/sympy/ntheory/elliptic_curve.py:251: raise NotImplementedError("Still not implemented")
- .venv/lib/python3.12/site-packages/sympy/ntheory/elliptic_curve.py:263: raise NotImplementedError("Still not implemented")
- .venv/lib/python3.12/site-packages/sympy/ntheory/elliptic_curve.py:364: pass
- .venv/lib/python3.12/site-packages/sympy/ntheory/factor_.py:1725: Additional keyword arguments to be passed to ``factorint``.
- .venv/lib/python3.12/site-packages/sympy/ntheory/tests/test_primetest.py:179: # passes the base set [2, 3, 7, 61, 24251]
- .venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:49: (symbolic or numerical) dimensions.  This can be done by passing an
- .venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:89: #   TODO:  (some ideas for improvement)
- .venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:121: pass
- .venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:375: broadcasting.  (TODO)
- .venv/lib/python3.12/site-packages/sympy/tensor/functions.py:85: NoShapeError : Raised when object with wrong kind is passed.
- .venv/lib/python3.12/site-packages/sympy/tensor/functions.py:109: ...     pass
- .venv/lib/python3.12/site-packages/sympy/tensor/functions.py:116: If unsuitable expression is passed, ``NoShapeError()`` will be raised.
- .venv/lib/python3.12/site-packages/sympy/tensor/functions.py:154: pass
- .venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:23: pass
- .venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:294: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:393: ...             pass
- .venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:468: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:1583: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2015: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2086: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2091: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2096: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2100: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2104: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2108: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2139: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2208: # TODO: add possibility of metric after (spinors)
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2292: original index order will be used if no value is passed.
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2590: # TODO: what is the part which is not a coeff?
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3023: return NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3064: # TODO: this could be optimized by only swapping the indices
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3203: # TODO: put this into TensExpr?
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3209: # TODO: put this into TensExpr?
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3225: # TODO: inefficient, this should be done at root level only:
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3236: raise NotImplementedError("%s with contractions is not implemented" % other)
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3268: # TODO: check data compatibility with properties of tensor.
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3321: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3344: # TODO: replace .args[0] with .name:
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3359: # TODO: if there is no metric present, the derivative should be zero?
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3661: # TODO: this method should be private
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3662: # TODO: should this method be renamed _from_components_free_dum ?
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4008: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4232: ``exclude_for_gen`` is to be passed to ``_IndexStructure._get_generator_for_dummy_indices()``.
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4375: raise NotImplementedError(f"Found something that we do not know to handle: {query_sifted['coeff']}")
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4378: raise NotImplementedError(f"Found something that we do not know to handle: {expr_sifted['coeff']}")
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4486: raise NotImplementedError("Tensor matching not implemented for non-commuting tensors")
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4540: # TODO: inherit dummies from expr
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4563: # TODO: can be improved:
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4601: The ``TensorIndexType`` is automatically detected from the index that is passed
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4615: If you want to ignore the order of indices while matching, pass ``unordered_indices=True``.
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4651: raise NotImplementedError("Wild matching based on symmetry is not implemented.")
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4772: #If no indices were passed to the WildTensor, it may match tensors with any number of indices.
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4934: WildTensor by a TensExpr (passed when initializing this object).
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4960: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4979: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4982: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4985: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4988: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4991: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4994: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:5136: # TODO: add a dum_to_components_map ?
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:5152: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:5240: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:497: # TODO: add check for *get_symmetric_group_sgs(0)
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:515: #raises(NotImplementedError, lambda: TensExpr.__mul__(t, 'a'))
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:516: #raises(NotImplementedError, lambda: TensExpr.__add__(t, 'a'))
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:517: #raises(NotImplementedError, lambda: TensExpr.__radd__(t, 'a'))
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:518: #raises(NotImplementedError, lambda: TensExpr.__sub__(t, 'a'))
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:519: #raises(NotImplementedError, lambda: TensExpr.__rsub__(t, 'a'))
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:520: #raises(NotImplementedError, lambda: TensExpr.__truediv__(t, 'a'))
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:521: #raises(NotImplementedError, lambda: TensExpr.__rtruediv__(t, 'a'))
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:525: raises(NotImplementedError, lambda: 2**A(a, b))
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:526: raises(NotImplementedError, lambda: abs(A(a, b)))
- .venv/lib/python3.12/site-packages/sympy/tensor/tests/test_indexed.py:251: pass
- .venv/lib/python3.12/site-packages/sympy/tensor/array/array_derivatives.py:91: # TODO: this could be done with multiple-dispatching:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/mutable_ndim_array.py:7: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/sympy/tensor/array/ndim_array.py:147: raise NotImplementedError("A subclass of NDimArray should implement __getitem__")
- .venv/lib/python3.12/site-packages/sympy/tensor/array/ndim_array.py:194: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/array/ndim_array.py:470: raise NotImplementedError('unsupported operation on NDimArray')
- .venv/lib/python3.12/site-packages/sympy/tensor/array/ndim_array.py:567: # TODO: add checks for dimensions for `value`?
- .venv/lib/python3.12/site-packages/sympy/tensor/array/ndim_array.py:601: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/sympy/tensor/array/__init__.py:36: Otherwise one could pass a 1-dim array followed by a shape tuple:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/arrayop.py:398: lines involves passing the *old* and *new* indices, either as a list or as
- .venv/lib/python3.12/site-packages/sympy/tensor/array/arrayop.py:485: raise NotImplementedError("Data type not yet supported")
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/arrayexpr_derivatives.py:26: raise NotImplementedError(f"not implemented for type {type(expr)}")
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/arrayexpr_derivatives.py:152: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:359: raise NotImplementedError("cannot handle addition of ZeroMatrix/ZeroArray and undefined shape object")
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:605: # TODO: swap args positions in order to simplify the expression:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:606: # TODO: this should be in a function
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:641: # TODO: function in order to permute the args:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:842: # TODO: add API for total rank and cumulative rank:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1040: raise NotImplementedError("Product of N-dim arrays is not uniquely defined. Use another method.")
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1046: raise NotImplementedError("Product of N-dim arrays is not uniquely defined. Use another method.")
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1076: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1263: # TODO: add API for total rank and cumulative rank:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1390: # TODO: check that `expr` has `.subranks`:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1414: raise NotImplementedError("only for contractions of tensor products")
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1674: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:124: # TODO: is this break necessary?
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:290: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:297: # TODO: this assumes that all arguments are matrices, it may not be the case:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:448: # TODO: check if subremoved should be permuted as well...
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:542: # TODO: move this to ElementwiseApplyFunction
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:847: pass
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:852: pass
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_indexed_to_array.py:113: # TODO: check that Kronecker delta is only contracted to one other element:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_indexed_to_array.py:144: pass
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_indexed_to_array.py:223: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_convert_array_to_matrix.py:189: # TODO: this is returning a wrong result:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:50: # TODO: not yet supported:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:54: # TODO: not yet supported:
- .venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:445: # TODO: reverse operation starting with `PermuteDims` and getting down to `bb`...
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomicerrors.py:6: raise NotImplementedError("abstract base class")
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:732: # TODO: Implement this case
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:734: raise NotImplementedError("logarithmic terms in the series are not supported")
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:740: raise NotImplementedError("Definite integration for singular initial conditions")
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:868: # TODO: support for singular initial condition
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:911: raise NotImplementedError(" Can't multiply a HolonomicFunction and expressions/functions.")
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:1749: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:1898: raise NotImplementedError("Can't compute sufficient Initial Conditions")
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:2287: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:2333: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/backend.py:26: if ``strict=True`` and the argument passed to the parameter ``a`` is a
- .venv/lib/python3.12/site-packages/sympy/core/traversal.py:88: be passed along to ordered() as the only key(s) to use to sort the
- .venv/lib/python3.12/site-packages/sympy/core/traversal.py:104: is given; simply passing key=True will guarantee that the traversal is
- .venv/lib/python3.12/site-packages/sympy/core/traversal.py:245: pass
- .venv/lib/python3.12/site-packages/sympy/core/traversal.py:266: be passed along to ordered() as the only key(s) to use to sort the
- .venv/lib/python3.12/site-packages/sympy/core/traversal.py:282: is given; simply passing key=True will guarantee that the traversal is
- .venv/lib/python3.12/site-packages/sympy/core/sorting.py:22: The ``order`` argument is passed along to the sort_key routine and is
- .venv/lib/python3.12/site-packages/sympy/core/sorting.py:154: pass
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:108: ``Mul()`` evaluates the argument unless ``evaluate=False`` is passed.
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:137: If ``evaluate=False`` is passed, result is not evaluated.
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:435: # TODO: Make non-commutative exponents not combine automatically
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:1049: # TODO: Should these be self.func?
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:1190: # TODO: Should this be self.func?
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:1216: # the 0 to pass, we use __add__ directly.
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:1661: pass
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:1853: failed = []  # failed terms will need subs if other terms pass
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:1997: except (ValueError, NotImplementedError, TypeError, PoleError):
- .venv/lib/python3.12/site-packages/sympy/core/mul.py:2041: pass
- .venv/lib/python3.12/site-packages/sympy/core/mod.py:90: pass
- .venv/lib/python3.12/site-packages/sympy/core/parameters.py:15: Every global parameters must be passed as keyword argument when generating
- .venv/lib/python3.12/site-packages/sympy/core/function.py:104: pass
- .venv/lib/python3.12/site-packages/sympy/core/function.py:115: pass
- .venv/lib/python3.12/site-packages/sympy/core/function.py:120: pass
- .venv/lib/python3.12/site-packages/sympy/core/function.py:212: # TODO: Look at nargs
- .venv/lib/python3.12/site-packages/sympy/core/function.py:319: # things passing through here:
- .venv/lib/python3.12/site-packages/sympy/core/function.py:331: # things passing through here:
- .venv/lib/python3.12/site-packages/sympy/core/function.py:396: To create an undefined function, pass a string of the function name to
- .venv/lib/python3.12/site-packages/sympy/core/function.py:414: Assumptions can be passed to ``Function`` the same as with a
- .venv/lib/python3.12/site-packages/sympy/core/function.py:580: # pass
- .venv/lib/python3.12/site-packages/sympy/core/function.py:705: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/function.py:812: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/core/function.py:1416: #TODO: check if assumption of discontinuous derivatives exist
- .venv/lib/python3.12/site-packages/sympy/core/function.py:1641: @_sympifyit('z0', NotImplementedError)
- .venv/lib/python3.12/site-packages/sympy/core/function.py:1650: raise NotImplementedError('partials and higher order derivatives')
- .venv/lib/python3.12/site-packages/sympy/core/function.py:1673: # TODO: deprecate?  YES, make this 'enumerated_variables' and
- .venv/lib/python3.12/site-packages/sympy/core/function.py:1675: # TODO: support for `d^n`?
- .venv/lib/python3.12/site-packages/sympy/core/function.py:1863: passing a symbol as a parameter:
- .venv/lib/python3.12/site-packages/sympy/core/function.py:2459: You can pass evaluate=False to get an unevaluated Derivative class.  Note
- .venv/lib/python3.12/site-packages/sympy/core/function.py:2786: Expand methods are passed ``**hints`` so that expand hints may use
- .venv/lib/python3.12/site-packages/sympy/core/function.py:2791: passed to ``_eval_expand_hint()`` methods.
- .venv/lib/python3.12/site-packages/sympy/core/function.py:3389: pass  # pure_complex(rv) is likely True
- .venv/lib/python3.12/site-packages/sympy/core/assumptions.py:333: By default, all assumptions are tested; pass an iterable of the
- .venv/lib/python3.12/site-packages/sympy/core/assumptions.py:359: matching those of the passed assumptions.
- .venv/lib/python3.12/site-packages/sympy/core/assumptions.py:420: pass the expression or variable as ``against``.
- .venv/lib/python3.12/site-packages/sympy/core/assumptions.py:425: To see if a number matches the assumptions of an expression, pass
- .venv/lib/python3.12/site-packages/sympy/core/operations.py:19: str_signature, RaiseNotImplementedError)
- .venv/lib/python3.12/site-packages/sympy/core/operations.py:53: Evaluate the operation. If not passed, refer to ``global_parameters.evaluate``.
- .venv/lib/python3.12/site-packages/sympy/core/operations.py:64: # Allow faster processing by passing ``_sympify=False``, if all arguments
- .venv/lib/python3.12/site-packages/sympy/core/operations.py:176: passed.
- .venv/lib/python3.12/site-packages/sympy/core/operations.py:484: pass
- .venv/lib/python3.12/site-packages/sympy/core/operations.py:545: # passed along, but the expectation here is for _args
- .venv/lib/python3.12/site-packages/sympy/core/operations.py:586: If arguments of different types are passed, the classes which handle the operation for each type
- .venv/lib/python3.12/site-packages/sympy/core/operations.py:605: ...     pass
- .venv/lib/python3.12/site-packages/sympy/core/operations.py:724: if isinstance(typ, RaiseNotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/core/singleton.py:175: ...     pass
- .venv/lib/python3.12/site-packages/sympy/core/_print_helpers.py:58: To change the behavior of this (e.g., pass in some settings to LaTeX),
- .venv/lib/python3.12/site-packages/sympy/core/facts.py:139: TODO: write about
- .venv/lib/python3.12/site-packages/sympy/core/facts.py:254: pass
- .venv/lib/python3.12/site-packages/sympy/core/facts.py:310: """process a -> b rule"""   # TODO write more?
- .venv/lib/python3.12/site-packages/sympy/core/facts.py:324: pass
- .venv/lib/python3.12/site-packages/sympy/core/facts.py:398: # TODO b | c
- .venv/lib/python3.12/site-packages/sympy/core/logic.py:125: and you want the fuzzy_and logic applied, passing an
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:312: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:1057: evaluation, it is better to pass the substitution to
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:1097: When a single argument is passed to subs
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:1205: pass the z*(x + y) arg to Mul where the change will take place and the
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:1494: # but don't encourage mixed passing patterns
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:1582: result of passing its argument(s) to ``newtype``.
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:1708: pass
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:1712: pass
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:1738: # from them and are then passed as keywords to the callable;
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:1995: that will be transformed. If it is not passed, all possible expressions
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:2145: raise NotImplementedError('conversion to SageMath is not implemented')
- .venv/lib/python3.12/site-packages/sympy/core/basic.py:2332: pass
- .venv/lib/python3.12/site-packages/sympy/core/power.py:285: pass
- .venv/lib/python3.12/site-packages/sympy/core/power.py:740: pass
- .venv/lib/python3.12/site-packages/sympy/core/power.py:944: pass
- .venv/lib/python3.12/site-packages/sympy/core/power.py:1521: except (ValueError, NotImplementedError, PoleError):
- .venv/lib/python3.12/site-packages/sympy/core/power.py:1524: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/core/power.py:1542: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/core/power.py:1580: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/core/power.py:1585: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/core/power.py:1589: # to a NotImplementedError being returned from the block below.
- .venv/lib/python3.12/site-packages/sympy/core/power.py:1601: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/core/power.py:1646: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:180: # TODO: we should use the warnings module
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:278: # TODO caching with decorator, but not to degrade performance
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:398: raise NotImplementedError('%s needs ._as_mpf_val() method' %
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:412: raise NotImplementedError('%s needs .floor() method' %
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:416: raise NotImplementedError('%s needs .ceiling() method' %
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:447: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:509: raise NotImplementedError('%s needs .__eq__() method' %
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:513: raise NotImplementedError('%s needs .__ne__() method' %
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:521: raise NotImplementedError('%s needs .__lt__() method' %
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:529: raise NotImplementedError('%s needs .__le__() method' %
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:678: can be passed to Float or evalf to obtain an arbitrary precision with
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:832: pass
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:845: 'the number to Float is passed as a string or an integer.')
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1221: Rational is unprejudiced in accepting input. If a float is passed, the
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1240: passed:
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1313: pass
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1322: pass  # error will raise below
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1336: pass  # error will raise below
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1407: pass unvalidated or invalid arguments to this function.
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1456: #TODO: this can probably be optimized more
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1645: # if you want self < other, pass self, other, __gt__
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1780: If a float or a rational is passed to Integer, the fractional part
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:1885: # TODO make it decorator + bytecodehacks?
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:2286: is passed as *expr*.
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:2421: Note that we needed to use ``a5.to_root()``, since passing ``a5`` as
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:2736: be passed in order to save time.
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:3596: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:3657: pass
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:3883: pass
- .venv/lib/python3.12/site-packages/sympy/core/numbers.py:3956: pass
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:198: # passed to a binary special method (__mul__, etc.) will handle the
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:352: # non-integer self should pass one of these tests
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:630: If flag simplify=False is passed, self will not be simplified;
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:871: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:872: pass
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:882: except (NotAlgebraic, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:883: pass
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:931: except (NotAlgebraic, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:932: pass
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:976: raise NotImplementedError("Could not compute limit")
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:999: # if singularities is a ConditionSet (not iterable), catch the exception and pass
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:1017: pass
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:1229: pass
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:1317: raise NotImplementedError('not sure of order of %s' % o)
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:1599: # find the parts that pass the commutative terms
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:3135: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:3141: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:3477: raise NotImplementedError(filldedent("""
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:3525: raise NotImplementedError('as_leading_term(%s, %s)' % (self, x))
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:3692: # TODO: Smarter heuristics
- .venv/lib/python3.12/site-packages/sympy/core/expr.py:3959: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/core/relational.py:157: # If called by a subclass, do nothing special and pass on to Basic.
- .venv/lib/python3.12/site-packages/sympy/core/relational.py:473: pass
- .venv/lib/python3.12/site-packages/sympy/core/relational.py:501: pass
- .venv/lib/python3.12/site-packages/sympy/core/relational.py:534: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/relational.py:535: # solve_univariate_inequality raises NotImplementedError for
- .venv/lib/python3.12/site-packages/sympy/core/relational.py:645: the result set pass `evaluate=True` to give L - R;
- .venv/lib/python3.12/site-packages/sympy/core/relational.py:727: pass
- .venv/lib/python3.12/site-packages/sympy/core/relational.py:1356: Assumptions can be passed to evaluate the quality which is otherwise
- .venv/lib/python3.12/site-packages/sympy/core/relational.py:1470: Assumptions can be passed to evaluate the equality which is otherwise
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:136: *xname* and symbol names in *exprs* are passed to *compare* to be
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:138: it is recursively passed to *modify* until unique name is acquired.
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:171: Name generation can be controlled by passing *modify* parameter.
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:242: passing in greek letters:
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:389: # what was passed to the constructor modulo changes made by _sanitize).
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:476: # `name` and `dummy_index` should be passed.  This is used by `srepr` for
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:637: # TODO add check against another Wild
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:899: arguments can be passed to :func:`var`.
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:932: Return a Tuple containing the passed expressions with symbols
- .venv/lib/python3.12/site-packages/sympy/core/symbol.py:961: To make your own mapping of symbols to use, pass only the free symbols
- .venv/lib/python3.12/site-packages/sympy/core/add.py:110: ``Add()`` evaluates the argument unless ``evaluate=False`` is passed.
- .venv/lib/python3.12/site-packages/sympy/core/add.py:125: If no argument is passed, identity element 0 is returned. If single
- .venv/lib/python3.12/site-packages/sympy/core/add.py:126: element is passed, that element is returned.
- .venv/lib/python3.12/site-packages/sympy/core/add.py:149: If ``evaluate=False`` is passed, result is not evaluated.
- .venv/lib/python3.12/site-packages/sympy/core/add.py:292: seq.extend(o_args)  # TODO zerocopy?
- .venv/lib/python3.12/site-packages/sympy/core/add.py:667: pass
- .venv/lib/python3.12/site-packages/sympy/core/add.py:1069: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:57: # passing these to mpmath functions or returning them in final results.
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:66: pass
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:415: # was passed to calc_part
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:815: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:910: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:928: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1020: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1049: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1174: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1250: raise NotImplementedError('does not support inf prec')
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1256: raise NotImplementedError("a hypergeometric series is required")
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1269: raise NotImplementedError("Non rational term functionality is not implemented.")
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1334: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1341: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1348: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1357: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1496: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1499: raise NotImplementedError # e.g. FiniteSet(-1.0, 1.0).evalf()
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1502: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1510: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1518: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1548: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1655: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1668: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/evalf.py:1710: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/core/exprtools.py:128: except (PolynomialError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/core/exprtools.py:320: Although a dictionary can be passed, only minimal checking is
- .venv/lib/python3.12/site-packages/sympy/core/exprtools.py:1551: # XXX TODO there should be a way to inspect what order the terms
- .venv/lib/python3.12/site-packages/sympy/core/sympify.py:60: ...     pass
- .venv/lib/python3.12/site-packages/sympy/core/sympify.py:66: ...     pass
- .venv/lib/python3.12/site-packages/sympy/core/sympify.py:206: namespace dictionary and passed as locals:
- .venv/lib/python3.12/site-packages/sympy/core/sympify.py:267: before being passed to sympify, so adding ``evaluate=False`` will still
- .venv/lib/python3.12/site-packages/sympy/core/sympify.py:374: into a namespace dictionary and passed as locals.
- .venv/lib/python3.12/site-packages/sympy/core/sympify.py:395: # was used for a long time we allow it to pass. However if strict=True as
- .venv/lib/python3.12/site-packages/sympy/core/sympify.py:471: pass
- .venv/lib/python3.12/site-packages/sympy/core/sympify.py:488: pass
- .venv/lib/python3.12/site-packages/sympy/core/sympify.py:564: If use of the hack fails, the un-hacked string will be passed to sympify...
- .venv/lib/python3.12/site-packages/sympy/core/containers.py:283: raise NotImplementedError("SymPy Dicts are Immutable")
- .venv/lib/python3.12/site-packages/sympy/core/kind.py:33: str_signature, RaiseNotImplementedError)
- .venv/lib/python3.12/site-packages/sympy/core/kind.py:368: if isinstance(func, RaiseNotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_singleton.py:8: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_singleton.py:16: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_singleton.py:24: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_singleton.py:29: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_assumptions.py:410: # TODO Change to x.is_nonzero is None
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_power.py:623: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_power.py:625: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:184: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:186: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:190: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:192: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:196: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:198: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:202: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:219: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:965: # pass along kwargs
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:1035: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:1061: # from Integral when it passes doit to the expression
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:1447: # TODO: Disable string inputs (https://github.com/sympy/sympy/issues/11003)
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:1454: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:266: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:279: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:525: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:528: raises(NotImplementedError, lambda: foo(x).as_leading_term(x))
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:917: # TODO UndefinedFunction does not subclass Expr
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:1243: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:1818: raises(NotImplementedError, lambda: a._eval_interval(x, S.Zero, oo)._eval_interval(y, oo, S.Zero))
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:1819: raises(NotImplementedError, lambda: a._eval_interval(x, S.Zero, oo)._eval_interval(y, S.Zero, oo))
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:1821: raises(NotImplementedError, lambda: a._eval_interval(x, S.One, oo)._eval_interval(y, oo, S.One))
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:2039: #      The previous version of the tests above is this but they only pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_containers.py:184: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_basic.py:208: # TODO UndefinedFunction does not subclass Expr
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_basic.py:322: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_basic.py:333: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_basic.py:336: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_facts.py:70: # TODO move me to appropriate place
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_diff.py:138: # TODO: assert diff(x**2, (x, n)) == x**(2-n)*ff(2, n)
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_constructor_postprocessor.py:9: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_constructor_postprocessor.py:28: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_constructor_postprocessor.py:35: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_constructor_postprocessor.py:38: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_numbers.py:363: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_numbers.py:668: # We still have to pass the precision because Float doesn't know what
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_operations.py:80: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_operations.py:100: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:96: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:193: # args are only sympified without the flags being passed
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:202: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:302: # Function f is not Basic and can't sympify to Basic. We allow it to pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:508: # when 1497 is fixed, this no longer should pass: the expression
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:625: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:682: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:692: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:694: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:696: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:706: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_sympify.py:742: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_cache.py:9: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_equal.py:49: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_equal.py:60: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:617: # FIXME: could replace with random selection after test passes
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:643: # FIXME: could replace with random selection after test passes
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:117: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:133: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:690: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:774: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:819: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:829: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:834: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:859: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1124: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1128: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1198: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1202: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1206: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1242: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1254: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1405: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1409: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:1969: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2206: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2226: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2231: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2236: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2299: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2334: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2354: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2358: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2362: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2435: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2440: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2445: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2499: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2594: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2629: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2708: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2733: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2738: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2753: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2817: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2942: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2967: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:2982: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3007: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3068: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3077: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3142: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3147: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3234: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3431: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3462: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3958: @SKIP("TODO: sympy.physics.quantum.shor: Cmod Not Implemented")
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4216: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4233: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4254: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4336: # Series, Parallel and TransferFunctionMatrix) should pass.
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4337: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4342: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4347: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4486: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4511: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4523: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4567: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4591: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4624: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4715: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4737: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4842: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4861: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4881: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:4926: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:5030: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:5293: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:5300: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:5307: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:5314: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:5351: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:5371: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:5451: pass
- .venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:5457: pass
- .venv/lib/python3.12/site-packages/sympy/series/residues.py:70: raise NotImplementedError('term of unexpected form: %s' % m)
- .venv/lib/python3.12/site-packages/sympy/series/formal.py:1496: pass
- .venv/lib/python3.12/site-packages/sympy/series/formal.py:1516: raise NotImplementedError("No infinite version for an object of"
- .venv/lib/python3.12/site-packages/sympy/series/formal.py:1520: raise NotImplementedError("(%s)._eval_terms()" % self)
- .venv/lib/python3.12/site-packages/sympy/series/formal.py:1523: raise NotImplementedError("By the current logic, one can get terms"
- .venv/lib/python3.12/site-packages/sympy/series/formal.py:1537: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/series/formal.py:1540: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/series/formal.py:1856: raise NotImplementedError("multivariate formal power series")
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:311: raise NotImplementedError("MRV set computation for functions in"
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:317: raise NotImplementedError("MRV set computation for derivatives"
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:319: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:449: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:521: except (NotImplementedError, PoleError, ValueError):
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:531: except (NotImplementedError, PoleError, ValueError):
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:611: raise NotImplementedError('Result depends on the sign of %s' % sig)
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:633: # TODO this should not be necessary
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:679: raise NotImplementedError("Second argument must be a Symbol")
- .venv/lib/python3.12/site-packages/sympy/series/gruntz.py:693: raise NotImplementedError("dir must be '+' or '-'")
- .venv/lib/python3.12/site-packages/sympy/series/sequences.py:40: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/series/sequences.py:55: raise NotImplementedError("(%s).gen" % self)
- .venv/lib/python3.12/site-packages/sympy/series/sequences.py:60: raise NotImplementedError("(%s).interval" % self)
- .venv/lib/python3.12/site-packages/sympy/series/sequences.py:65: raise NotImplementedError("(%s).start" % self)
- .venv/lib/python3.12/site-packages/sympy/series/sequences.py:70: raise NotImplementedError("(%s).stop" % self)
- .venv/lib/python3.12/site-packages/sympy/series/sequences.py:75: raise NotImplementedError("(%s).length" % self)
- .venv/lib/python3.12/site-packages/sympy/series/sequences.py:107: raise NotImplementedError("The _eval_coeff method should be added to"
- .venv/lib/python3.12/site-packages/sympy/series/limitseq.py:120: except (NotImplementedError, PoleError):
- .venv/lib/python3.12/site-packages/sympy/series/series_class.py:17: raise NotImplementedError("(%s).interval" % self)
- .venv/lib/python3.12/site-packages/sympy/series/series_class.py:22: raise NotImplementedError("(%s).start" % self)
- .venv/lib/python3.12/site-packages/sympy/series/series_class.py:27: raise NotImplementedError("(%s).stop" % self)
- .venv/lib/python3.12/site-packages/sympy/series/series_class.py:32: raise NotImplementedError("(%s).length" % self)
- .venv/lib/python3.12/site-packages/sympy/series/series_class.py:56: raise NotImplementedError("The _eval_term method should be added to"
- .venv/lib/python3.12/site-packages/sympy/series/series_class.py:70: TODO
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:158: raise NotImplementedError("Limits approaching a variable point are"
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:212: To be passed to ``doit`` methods; only used if deep is True.
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:232: raise NotImplementedError("Limits at complex "
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:282: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:314: pass
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:340: except (ValueError, NotImplementedError, PoleError):
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:341: # The NotImplementedError catching is for custom functions
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:352: except (ValueError, NotImplementedError, PoleError):
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:353: pass
- .venv/lib/python3.12/site-packages/sympy/series/limits.py:372: raise NotImplementedError("Not sure of sign of %s" % ex)
- .venv/lib/python3.12/site-packages/sympy/series/order.py:121: If no symbols are passed then all symbols in the expression are used
- .venv/lib/python3.12/site-packages/sympy/series/order.py:166: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/series/order.py:184: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/series/order.py:237: pass
- .venv/lib/python3.12/site-packages/sympy/series/order.py:356: raise NotImplementedError('Order at points other than 0 '
- .venv/lib/python3.12/site-packages/sympy/series/order.py:359: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_series.py:157: pass
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:162: # TODO : A better output for Order(log(x) + 1/log(x))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:276: raises(NotImplementedError, lambda: (O(x) + O(y)).getn())
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:290: raises(NotImplementedError, lambda: (O(x) + O(y)).getn())
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:402: raises(NotImplementedError, lambda: Order(x, (x, 0))*Order(x, (x, oo)))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:403: raises(NotImplementedError, lambda: Order(x, (x, oo))*Order(x, (x, 0)))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:404: raises(NotImplementedError, lambda: Order(Order(x, (x, oo)), y))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:405: raises(NotImplementedError, lambda: Order(Order(x), (x, oo)))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:442: raises(NotImplementedError, lambda: O(x).subs(x, O(1/x))) # mixing of order at different points
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:470: raises(NotImplementedError, lambda: O(x**3).contains(x**w))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_residues.py:68: raises(NotImplementedError, lambda: residue(exp(1/z), z, 0))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:535: raises(NotImplementedError, lambda: limit(exp(x*y), x, oo))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:536: raises(NotImplementedError, lambda: limit(exp(-x*y), x, oo))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:591: raises(NotImplementedError, lambda: limit(expr, n, oo))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:689: # limit should depend on the continuity of the expression at the point passed
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:745: raises(NotImplementedError, lambda: limit((log(n))**(n/log(n)) / c**n, n, oo))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:848: raises(NotImplementedError, lambda: Limit(exp(x), x, zoo).doit())
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:849: raises(NotImplementedError, lambda: Limit(x**2/(x+1), x, zoo).doit())
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:913: raises(NotImplementedError, lambda: limit(exp(I*x)*sin(pi*x), x, oo))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:1077: raises(NotImplementedError, lambda: limit(exp((2 - n) * x), x, oo))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:1326: raises(NotImplementedError, lambda: limit(Mod(x, a), x, a))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_limits.py:1420: raises (NotImplementedError, lambda: limit((-x/(x+1))**x, x, oo))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:148: # TODO zeta function series
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:152: # TODO 8.35 - 8.37 (bessel, max-min)
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:481: # limit should depend on the continuity of the expression at the point passed
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:196: raises(NotImplementedError, lambda: fps(y*x))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:441: f = x*exp(x)*sin(2*x)  # TODO: rsolve needs improvement
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:545: raises(NotImplementedError, lambda: fprod._eval_term(5))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:546: raises(NotImplementedError, lambda: fprod.infinite)
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:547: raises(NotImplementedError, lambda: fprod._eval_derivative(x))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:548: raises(NotImplementedError, lambda: fprod.integrate(x))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:576: raises(NotImplementedError, lambda: fcomp._eval_term(5))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:577: raises(NotImplementedError, lambda: fcomp.infinite)
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:578: raises(NotImplementedError, lambda: fcomp._eval_derivative(x))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:579: raises(NotImplementedError, lambda: fcomp.integrate(x))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:608: raises(NotImplementedError, lambda: finv._eval_term(5))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:610: raises(NotImplementedError, lambda: finv.infinite)
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:611: raises(NotImplementedError, lambda: finv._eval_derivative(x))
- .venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:612: raises(NotImplementedError, lambda: finv.integrate(x))
- .venv/lib/python3.12/site-packages/sympy/interactive/session.py:153: pass
- .venv/lib/python3.12/site-packages/sympy/interactive/session.py:217: pass
- .venv/lib/python3.12/site-packages/sympy/interactive/session.py:279: pass
- .venv/lib/python3.12/site-packages/sympy/interactive/session.py:293: pass
- .venv/lib/python3.12/site-packages/sympy/interactive/session.py:437: pass
- .venv/lib/python3.12/site-packages/sympy/interactive/printing.py:41: pass
- .venv/lib/python3.12/site-packages/sympy/interactive/printing.py:369: A font size to pass to the LaTeX documentclass function in the
- .venv/lib/python3.12/site-packages/sympy/interactive/printing.py:474: # Even if ip is not passed, double check that not in IPython shell
- .venv/lib/python3.12/site-packages/sympy/interactive/printing.py:480: pass
- .venv/lib/python3.12/site-packages/sympy/interactive/printing.py:492: pass
- .venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:10: # TODO: The code below could be made more granular with something like:
- .venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:74: # TODO: How can we test that the output of a SyntaxError is the original
- .venv/lib/python3.12/site-packages/sympy/algebras/quaternion.py:1188: which represents rotation about the origin if ``v`` is not passed.
- .venv/lib/python3.12/site-packages/sympy/algebras/quaternion.py:1206: which represents rotation about the origin if v is not passed.
- .venv/lib/python3.12/site-packages/sympy/algebras/quaternion.py:1222: other than the origin) if the point(v) is passed as an argument.
- .venv/lib/python3.12/site-packages/sympy/polys/orderings.py:24: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/orderings.py:74: ProductOrder is constructed by passing a list of pairs
- .venv/lib/python3.12/site-packages/sympy/polys/orderings.py:76: Upon comparison, the Li are passed the total monomial, and should filter
- .venv/lib/python3.12/site-packages/sympy/polys/orderings.py:77: out the part of the monomial to pass to Oi.
- .venv/lib/python3.12/site-packages/sympy/polys/orderings.py:215: attribute, then it will pass through with an assumption that the
- .venv/lib/python3.12/site-packages/sympy/polys/orderings.py:261: should be a string or monomial order (will be passed to monomial_key),
- .venv/lib/python3.12/site-packages/sympy/polys/heuristicgcd.py:124: # TODO: don't expose poly repr implementation details
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:41: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:49: raise NotImplementedError("could not compute root with precision")
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:86: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:98: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:103: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:110: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:153: """Support for passing generators as `*gens` and `[gens]`. """
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:378: # TODO: Integrate this into expand() itself
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:536: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:564: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:568: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:572: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:250: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:261: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:274: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:316: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:324: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:346: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:349: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:368: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:409: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:413: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:417: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:421: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:443: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:465: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:469: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:473: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:477: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:565: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:568: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:571: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:574: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:577: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:580: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:583: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:586: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:589: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:592: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:595: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:598: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:601: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:604: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:607: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:610: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:613: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:616: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:626: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:630: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:634: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:673: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:677: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:687: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:691: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:695: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:699: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:703: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:716: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:729: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:744: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:747: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:759: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:774: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:786: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:796: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:804: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:815: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:819: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:827: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:835: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:843: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:855: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:858: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:865: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:869: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:873: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:877: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:885: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:895: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:910: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:924: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:934: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:944: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:954: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:964: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:974: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:978: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:982: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:986: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:990: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:994: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:998: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1002: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1019: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1022: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1025: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1028: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1044: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1048: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1052: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1057: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1062: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1067: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1072: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1077: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1082: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1087: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1092: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1097: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1102: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1107: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1112: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1205: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1839: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1858: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1876: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1881: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1886: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1891: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2051: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2081: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2268: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2273: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2741: except (TypeError, CoercionFailed, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2753: except (TypeError, CoercionFailed, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2765: except (TypeError, CoercionFailed, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2780: except (TypeError, CoercionFailed, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2799: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2816: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2852: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:2863: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rootoftools.py:359: raise NotImplementedError("CRootOf is not supported over %s" % dom)
- .venv/lib/python3.12/site-packages/sympy/polys/rootoftools.py:376: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rootoftools.py:746: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/polys/rootoftools.py:788: # this makes the tests pass alright but has to be a better way?
- .venv/lib/python3.12/site-packages/sympy/polys/rootoftools.py:961: pass
- .venv/lib/python3.12/site-packages/sympy/polys/euclidtools.py:1525: pass
- .venv/lib/python3.12/site-packages/sympy/polys/euclidtools.py:1533: pass
- .venv/lib/python3.12/site-packages/sympy/polys/euclidtools.py:1561: pass
- .venv/lib/python3.12/site-packages/sympy/polys/euclidtools.py:1569: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:214: raise NotImplementedError("conversion")
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:233: raise NotImplementedError("parsing")
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:395: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:421: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:428: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:465: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:472: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:511: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:518: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:550: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:557: pass
- .venv/lib/python3.12/site-packages/sympy/polys/fields.py:639: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/polyoptions.py:41: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyoptions.py:524: raise NotImplementedError("'split' option is not implemented yet")
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:11: raise NotImplementedError("abstract base class")
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:69: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:72: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:76: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:80: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:84: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:88: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:92: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:96: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:100: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:104: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:108: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:112: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:116: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:120: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:130: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:134: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:149: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:153: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:179: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polyerrors.py:183: pass
- .venv/lib/python3.12/site-packages/sympy/polys/solvers.py:20: pass
- .venv/lib/python3.12/site-packages/sympy/polys/solvers.py:173: With the equations in this form they can be passed to ``solve_lin_sys``:
- .venv/lib/python3.12/site-packages/sympy/polys/solvers.py:312: the system into connected components and pass those to
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:175: raise NotImplementedError("'order' keyword is not implemented yet")
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:192: # Poly does not pass its args to Basic.__new__ to be stored in _args so we
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:612: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:1239: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:1727: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:1766: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:1803: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:1845: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:2140: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:3879: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:5297: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:5336: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:5390: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:5526: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:5665: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:5794: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:6194: raise NotImplementedError('symbolic falling factorial')
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:6818: # passes an Expr instead of Poly they may not expect
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:6852: # passes an Expr instead of Poly they may not expect
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:6892: :py:class:`~.ComplexRootOf` bypasses limitations on the availability of
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:6915: NotImplementedError: sorted roots not supported over EX
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:6978: If ``multiple=False`` is passed then a list of root/multiplicity pairs is
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:6981: If ``radicals=False`` is passed then all roots will be represented as
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7019: # passes an Expr instead of Poly they may not expect
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7067: ``radicals=False`` is passed). All other roots will be expressed as
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7116: NotImplementedError: sorted roots not supported over EX
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7168: If ``multiple=False`` is passed then a list of root/multiplicity pairs is
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7171: If ``radicals=False`` is passed then all roots will be represented as
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7209: # passes an Expr instead of Poly they may not expect
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7240: # passes an Expr instead of Poly they may not expect
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7271: # passes an Expr instead of Poly they may not expect
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7310: # passes an Expr instead of Poly they may not expect
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7406: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7407: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7474: pass
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7716: raise NotImplementedError("Cannot convert Groebner bases of ideals with positive dimension")
- .venv/lib/python3.12/site-packages/sympy/polys/polytools.py:7813: pass
- .venv/lib/python3.12/site-packages/sympy/polys/sqfreetools.py:403: raise NotImplementedError('multivariate polynomials over finite fields')
- .venv/lib/python3.12/site-packages/sympy/polys/sqfreetools.py:497: raise NotImplementedError('multivariate polynomials over finite fields')
- .venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:796: # TODO: to improve performance, choose the main variable here
- .venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:2129: # TODO: add support for algebraic function fields
- .venv/lib/python3.12/site-packages/sympy/polys/polyfuncs.py:173: value of interest can be passed instead of passing a symbol:
- .venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:351: according to monomial order ``O``. Named arguments are passed on to the
- .venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:376: of the module is guessed, or passed via ``n``. The ground field is assumed
- .venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:515: # TODO better data structure!!!
- .venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:675: # TODO apply the product criterion?
- .venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:683: # TODO mergesort?
- .venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:726: # (TODO again, better data structures)
- .venv/lib/python3.12/site-packages/sympy/polys/partfrac.py:103: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/partfrac.py:114: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/partfrac.py:115: pass
- .venv/lib/python3.12/site-packages/sympy/polys/partfrac.py:123: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/polys/partfrac.py:329: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/polys/polyroots.py:761: # TODO: This is fragile. Figure out how to make this independent of construct_domain().
- .venv/lib/python3.12/site-packages/sympy/polys/rootisolation.py:1234: raise NotImplementedError("3 element rule (corner): " + str(qq))
- .venv/lib/python3.12/site-packages/sympy/polys/rootisolation.py:1249: raise NotImplementedError("2 element rule (inside): " + str(qq))
- .venv/lib/python3.12/site-packages/sympy/polys/rootisolation.py:1256: raise NotImplementedError("3 element rule (edge): " + str(qq))
- .venv/lib/python3.12/site-packages/sympy/polys/rootisolation.py:1726: raise NotImplementedError( "only trivial square-free polynomials are supported")
- .venv/lib/python3.12/site-packages/sympy/polys/compatibility.py:250: pass
- .venv/lib/python3.12/site-packages/sympy/polys/compatibility.py:253: pass
- .venv/lib/python3.12/site-packages/sympy/polys/compatibility.py:256: pass
- .venv/lib/python3.12/site-packages/sympy/polys/compatibility.py:259: pass
- .venv/lib/python3.12/site-packages/sympy/polys/compatibility.py:262: pass
- .venv/lib/python3.12/site-packages/sympy/polys/compatibility.py:265: pass
- .venv/lib/python3.12/site-packages/sympy/polys/compatibility.py:273: raise NotImplementedError("domain conversions")
- .venv/lib/python3.12/site-packages/sympy/polys/factortools.py:1011: The parameter ``seed`` is passed to _randint and can be used to seed randint
- .venv/lib/python3.12/site-packages/sympy/polys/factortools.py:1050: pass
- .venv/lib/python3.12/site-packages/sympy/polys/factortools.py:1456: raise NotImplementedError('multivariate polynomials over finite fields')
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:163: # TODO: rewrite this so that it doesn't use expand() (see poly()).
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:350: raise NotImplementedError("conversion")
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:352: raise NotImplementedError("parsing")
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:428: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:467: # TODO: should AlgebraicField be a Composite domain?
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:995: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:1071: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:1155: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:1251: elif len(self) <= 5: # TODO: use an actual density measure
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:1347: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:1378: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:1409: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:1440: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:2275: else: # TODO: don't use dense representation (port PRS algorithms)
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:2349: pass
- .venv/lib/python3.12/site-packages/sympy/polys/rings.py:3044: # TODO: following methods should point to polynomial
- .venv/lib/python3.12/site-packages/sympy/polys/monomials.py:123: # Force to list in case of passed tuple or other incompatible collection
- .venv/lib/python3.12/site-packages/sympy/polys/monomials.py:579: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/monomials.py:589: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:553: raise NotImplementedError("No constant term in series")
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:556: raise NotImplementedError("p - p[0] must not have a constant term in "
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:629: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:897: raise NotImplementedError('No constant term in series')
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1024: pass
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1039: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1066: raise NotImplementedError("Polynomial must not have constant term in "
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1078: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1224: raise NotImplementedError("Polynomial must not have constant term in "
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1243: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1890: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1977: # TODO Use _parallel_dict_from_expr instead of sring as sring is
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1992: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:2059: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_heuristicgcd.py:53: # TODO: assert heugcd(f, f.diff(x))[0] == g
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_factortools.py:769: raises(NotImplementedError, lambda: R.dmp_factor_list(x**2 + y**2))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polyoptions.py:243: raises(NotImplementedError, lambda: Split.postprocess({'split': True}))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_sqfreetools.py:142: raises(NotImplementedError, lambda: R.dmp_sqf_list(y**2 + 1))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_fields.py:343: pass
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_fields.py:353: pass
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_distributedmodules.py:50: # TODO test to_dict?
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polyroots.py:235: # it's ok if the solution is not Piecewise, but the tests below should pass
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_rootisolation.py:823: raises(NotImplementedError, lambda: R.dup_isolate_all_roots(f))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:391: raises(NotImplementedError, lambda: Poly(x + 1, x, modulus=3, order='grlex'))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:392: raises(NotImplementedError, lambda: Poly(x + 1, x, order='grlex'))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:1267: raises(NotImplementedError, lambda: Poly(x*y, x, y, z).eject(y))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:1451: raises(NotImplementedError, lambda: p.coeff(x))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:2460: raises(NotImplementedError, lambda: gff(f))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:2468: raises(NotImplementedError, lambda: gff(f))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:3089: raises(NotImplementedError, lambda: real_roots(f))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:3090: raises(NotImplementedError, lambda: real_roots(Poly(f, x)))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:3121: raises(NotImplementedError, lambda: all_roots(f))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_polytools.py:3122: raises(NotImplementedError, lambda : all_roots(Poly(f, x)))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_partfrac.py:61: raises(NotImplementedError, lambda: apart(1/(x + 1)/(y + 2)))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_monomials.py:265: raises(NotImplementedError, lambda: m*1)
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_monomials.py:266: raises(NotImplementedError, lambda: m/1)
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_ring_series.py:115: raises(NotImplementedError, lambda: rs_series_inversion(p, x, 4))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_rootoftools.py:94: raises(NotImplementedError, lambda: rootof(x**3 - x + sqrt(2), 0))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_rootoftools.py:95: raises(NotImplementedError, lambda: rootof(x**3 - x + I, 0))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_rootoftools.py:111: raises(NotImplementedError, lambda: rootof(x**3 + x + 2*y, x, 0))
- .venv/lib/python3.12/site-packages/sympy/polys/tests/test_rootoftools.py:124: raises(NotImplementedError, lambda: rootof(Poly(x**3 + y*x + 1, x), 0))
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:15: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:20: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:25: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:30: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:35: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:40: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:45: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:50: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:55: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:59: """The value passed is invalid"""
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/exceptions.py:60: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/sdm.py:117: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:223: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:294: or tuple of args, that would be passed to the domain constructor
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:491: Keyword arguments are passed to :func:`~.construct_domain`.
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:514: Alternatively, ``None`` may be passed, in which case this method
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:939: reconstructed by passing these to :meth:`from_flat_nz`. The idea is to
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:1662: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:1687: raise NotImplementedError('Negative powers')
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:2277: ``keep_domain=False`` is passed in which case the result will be
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:2286: unless ``keep_domain=False`` is passed in which case the result
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/domainmatrix.py:3838: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:23: # TODO:
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:149: raise NotImplementedError("Only ZZ and QQ are supported by DFM")
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:177: raise NotImplementedError("Only ZZ and QQ are supported by DFM")
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:322: raise NotImplementedError("Only ZZ and QQ are supported by DFM")
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:660: # TODO: Implement similar algorithms for DDM and SDM.
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:690: raise NotImplementedError("DFM.inv() is not implemented for %s" % K)
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:856: # XXX: There are tests that pass e.g. QQ(5,6) for delta. That fails
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/rref.py:171: pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/rref.py:256: # TODO: Add partial pivot support to the sparse implementations.
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/dfm.py:5: is a placeholder class that raises NotImplementedError when instantiated.
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/dfm.py:23: raise NotImplementedError("DFM requires GROUND_TYPES=flint.")
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/dfm.py:31: raise NotImplementedError("DFM requires GROUND_TYPES=flint.")
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:126: For inexact numeric domains like :ref:`RR` and :ref:`CC` pass
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:173: # TODO: Use a nontrivial pivoting strategy to control intermediate
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:321: # TODO: Use a non-trivial pivoting strategy. Even just row swapping makes a
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:721: raise NotImplementedError("Underdetermined")
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/normalforms.py:11: # TODO (future work):
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/normalforms.py:505: The basic assumption is that, if you pass a value for *D*, then
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_dense.py:317: raises(NotImplementedError, lambda: ddm_ilu_solve(x, L, U, swaps, b))
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_ddm.py:395: raises(NotImplementedError, lambda: A.lu_solve(b))
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_domainmatrix.py:579: raises(NotImplementedError, lambda: A ** -1)
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_domainmatrix.py:580: raises(NotImplementedError, lambda: A.pow(-1))
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_domainmatrix.py:1079: raises(NotImplementedError, lambda: A.lu_solve(b))
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_domainmatrix.py:1360: raises(NotImplementedError, lambda: setitem(slice(1, 2), 2, ZZ(1)))
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_xxm.py:201: raises(NotImplementedError, lambda: A.to_dfm())
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_xxm.py:212: raises(NotImplementedError, lambda: A.convert_to(K))
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_xxm.py:220: raises(NotImplementedError, lambda: A_K.to_dfm())
- .venv/lib/python3.12/site-packages/sympy/polys/matrices/tests/test_xxm.py:263: raises(NotImplementedError, lambda: DFM._get_flint_func(domain))
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:116: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:120: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:124: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:128: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:132: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:136: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:280: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:293: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:297: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/homomorphisms.py:304: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:44: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:48: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:52: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:56: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:60: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:64: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:72: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:76: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:80: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:84: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:88: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:92: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:96: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:100: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:102: # TODO more
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:196: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:300: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:305: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:310: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:315: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:375: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:32: # TODO
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:86: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:90: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:133: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:137: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:143: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:149: except (CoercionFailed, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:157: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:478: raise NotImplementedError('This implementation only works over '
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:481: raise NotImplementedError('Ground domain must be a field, '
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:528: raise NotImplementedError('This implementation only works over '
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:643: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:647: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:651: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:679: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:684: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:699: Some implementation allow further options to be passed. Currently, to
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:739: Some implementations allow further options to be passed. Currently, the
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:740: only one implemented is ``relations=True``, which may only be passed
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:1129: raise NotImplementedError('This implementation is for submodules of '
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:1222: This applies the normal form ``NF`` to ``x``. If ``NF`` is passed
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:1256: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:1281: # TODO this can be done more efficiently
- .venv/lib/python3.12/site-packages/sympy/polys/agca/extensions.py:103: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/sympy/polys/agca/extensions.py:176: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/agca/tests/test_extensions.py:32: raises(NotImplementedError, lambda: A(2).inverse())
- .venv/lib/python3.12/site-packages/sympy/polys/agca/tests/test_extensions.py:92: raises(NotImplementedError, lambda: (xf**2 - 1) % (xf - 1))
- .venv/lib/python3.12/site-packages/sympy/polys/agca/tests/test_extensions.py:151: raises(NotImplementedError, lambda: xK / xK)
- .venv/lib/python3.12/site-packages/sympy/polys/agca/tests/test_extensions.py:152: raises(NotImplementedError, lambda: xK // xK)
- .venv/lib/python3.12/site-packages/sympy/polys/agca/tests/test_extensions.py:153: raises(NotImplementedError, lambda: xK % xK)
- .venv/lib/python3.12/site-packages/sympy/polys/agca/tests/test_modules.py:80: raises(NotImplementedError, lambda: ZZ.old_poly_ring(x).free_module(2))
- .venv/lib/python3.12/site-packages/sympy/polys/agca/tests/test_modules.py:81: raises(NotImplementedError, lambda: FreeModulePolyRing(ZZ, 2))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/primes.py:678: # TODO (future work):
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/exceptions.py:36: pass
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/exceptions.py:44: pass
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/exceptions.py:49: pass
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/minpoly.py:85: raise NotImplementedError("multiple candidates for the minimal polynomial of %s" % v)
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/minpoly.py:133: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/minpoly.py:271: raise NotImplementedError('option not available')
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/minpoly.py:711: raise NotImplementedError("groebner method only works for QQ")
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:13: The :py:class:`~.PowerBasis` is constructed by passing either the minimal
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:223: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:267: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:380: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:516: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:570: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:1209: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:1224: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:1839: # TODO:
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:2016: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:2064: If desired, pass an empty list. The powers of *alpha* (as
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/subfield.py:85: raise NotImplementedError("PSLQ doesn't support complex coefficients")
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/subfield.py:236: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/subfield.py:237: pass
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/subfield.py:335: ``reps`` is present if and only if argument ``ex=True`` was passed,
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/subfield.py:427: As an additional convenience, this function allows you to pass a list of
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/basis.py:106: Alternatively, you may pass an :py:class:`~.AlgebraicField` instance, in
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/basis.py:161: reference. If desired, pass an empty dictionary. If the algorithm
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/basis.py:216: # TODO:
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/basis.py:235: # passed it to `_second_enlargement`, then we can't trust the nilradical
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/galoisgroups.py:569: For converting *f* to Poly, and will be passed on to the
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/galoisgroups.py:582: For converting *f* to Poly, and will be passed on to the
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/utilities.py:140: # First pass: just make d squarefree, and a/d a perfect square.
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/utilities.py:152: # Second pass: if d is cong. to 2 or 3 mod 4, then we must steal away
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/utilities.py:424: which isolates complex roots when you pass ``all=True``.
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/utilities.py:426: Precision to be passed to :py:meth:`.Poly.refine_root`
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/utilities.py:429: (Will be passed to :py:meth:`.Poly.refine_root`.)
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/utilities.py:448: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_minpoly.py:366: raises(NotImplementedError, lambda: _choose_factor(bad_factors, x, sqrt(3)))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_minpoly.py:403: raises(NotImplementedError, lambda: minimal_polynomial(sqrt(x), y, compose=False))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_minpoly.py:474: raises(NotImplementedError, lambda: _separate_sq(x**(S(1)/3) + x))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_minpoly.py:478: raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_utilities.py:113: raises(NotImplementedError, lambda: isolate(I))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_subfield.py:30: raises(NotImplementedError, lambda: field_isomorphism_pslq(a, b))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_modules.py:27: raises(NotImplementedError, lambda: M.n)
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_modules.py:28: raises(NotImplementedError, lambda: M.mult_tab())
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_modules.py:29: raises(NotImplementedError, lambda: M.represent(None))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_modules.py:30: raises(NotImplementedError, lambda: M.starts_with_unity())
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_modules.py:31: raises(NotImplementedError, lambda: M.element_from_rational(QQ(2, 3)))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_modules.py:424: raises(NotImplementedError, lambda: C.reduce_element(a))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_modules.py:736: raises(NotImplementedError, lambda: R.represent(3.14))
- .venv/lib/python3.12/site-packages/sympy/polys/numberfields/tests/test_modules.py:747: # powers list need not be passed
- .venv/lib/python3.12/site-packages/sympy/polys/domains/groundtypes.py:23: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/groundtypes.py:27: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/rationalfield.py:46: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/polynomialring.py:40: # TODO: remove this
- .venv/lib/python3.12/site-packages/sympy/polys/domains/ring.py:78: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/pythonrationalfield.py:23: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:360: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:450: # TODO: implement this in from_ methods
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:458: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:459: else: # TODO: remove this branch
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:466: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:576: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:604: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:996: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1002: raise NotImplementedError  # pragma: no cover
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1151: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1166: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1181: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1267: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1271: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1275: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1279: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1283: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1292: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1303: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1307: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1311: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1326: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1342: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1359: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:1379: raise NotImplementedError('characteristic()')
- .venv/lib/python3.12/site-packages/sympy/polys/domains/expressionrawdomain.py:29: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/old_polynomialring.py:146: raise NotImplementedError('nested domains not allowed')
- .venv/lib/python3.12/site-packages/sympy/polys/domains/old_polynomialring.py:150: raise NotImplementedError('nested domains not allowed')
- .venv/lib/python3.12/site-packages/sympy/polys/domains/old_polynomialring.py:181: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/polys/domains/old_fractionfield.py:156: raise NotImplementedError('nested domains not allowed')
- .venv/lib/python3.12/site-packages/sympy/polys/domains/old_fractionfield.py:160: raise NotImplementedError('nested domains not allowed')
- .venv/lib/python3.12/site-packages/sympy/polys/domains/gmpyrationalfield.py:27: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/algebraicfield.py:189: of :py:class:`~.Expr` or :py:class:`~.AlgebraicNumber` by passing a ``fmt``
- .venv/lib/python3.12/site-packages/sympy/polys/domains/algebraicfield.py:364: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:9: # TODO
- .venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:43: except (NotImplementedError, CoercionFailed):
- .venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:62: except (NotImplementedError, CoercionFailed):
- .venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:75: except (NotImplementedError, CoercionFailed):
- .venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:142: # TODO optionally disable reduction?
- .venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:174: raise NotImplementedError('nested domains not allowed')
- .venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:178: raise NotImplementedError('nested domains not allowed')
- .venv/lib/python3.12/site-packages/sympy/polys/domains/expressiondomain.py:164: pass
- .venv/lib/python3.12/site-packages/sympy/polys/domains/fractionfield.py:34: # TODO: remove this
- .venv/lib/python3.12/site-packages/sympy/polys/domains/domainelement.py:38: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/sympy/polys/domains/tests/test_domains.py:1369: # Alias is passed to constructed field elements:
- .venv/lib/python3.12/site-packages/sympy/concrete/gosper.py:219: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:427: and false if divergent and NotImplementedError if it cannot be checked.
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:462: raise NotImplementedError("convergence checking for more than one symbol "
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:499: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:500: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:506: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:507: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:536: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:537: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:551: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:566: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:567: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:578: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:579: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:603: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:604: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:607: # TODO
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:637: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:638: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:649: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:650: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:669: raise NotImplementedError("The algorithm to find the Sum convergence of %s "
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:1002: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:1104: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:1166: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/summations.py:1252: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/products.py:469: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/products.py:472: raise NotImplementedError("The algorithm to find the product convergence of %s "
- .venv/lib/python3.12/site-packages/sympy/concrete/expr_with_limits.py:149: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/concrete/expr_with_limits.py:179: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/expr_with_limits.py:184: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/expr_with_intlimits.py:5: class ReorderError(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/concrete/delta.py:160: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/concrete/delta.py:161: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/tests/test_sums_products.py:618: pass
- .venv/lib/python3.12/site-packages/sympy/concrete/tests/test_sums_products.py:1043: # TODO Implement matrix geometric series summation.
- .venv/lib/python3.12/site-packages/sympy/concrete/tests/test_sums_products.py:1282: raises(NotImplementedError, lambda: S.is_convergent())
- .venv/lib/python3.12/site-packages/sympy/concrete/tests/test_sums_products.py:1660: raises(NotImplementedError, lambda: D(x, (x, union)))
- .venv/lib/python3.12/site-packages/sympy/crypto/crypto.py:58: one string is passed, each of them will be processed and a list
- .venv/lib/python3.12/site-packages/sympy/crypto/crypto.py:1517: Flag to bypass warning for multipower RSA.
- .venv/lib/python3.12/site-packages/sympy/crypto/crypto.py:1562: 'the reduced residue system Z*[{}]. You can pass '
- .venv/lib/python3.12/site-packages/sympy/crypto/crypto.py:1632: If you pass a non-prime integer to the arguments
- .venv/lib/python3.12/site-packages/sympy/crypto/crypto.py:1690: you pass ``True`` to this keyword.
- .venv/lib/python3.12/site-packages/sympy/crypto/crypto.py:3182: The three necessary checks for p and q to pass
- .venv/lib/python3.12/site-packages/sympy/crypto/crypto.py:3205: If p and q do not pass the above conditions.
- .venv/lib/python3.12/site-packages/sympy/crypto/crypto.py:3228: private keys passed as arguments and
- .venv/lib/python3.12/site-packages/sympy/sets/ordinals.py:258: pass
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:134: except (NotImplementedError,
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:318: raise NotImplementedError("(%s)._inf" % self)
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:339: raise NotImplementedError("(%s)._sup" % self)
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:417: raise NotImplementedError(f"{type(self).__name__}._contains")
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:800: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:804: raise NotImplementedError("(%s)._measure" % self)
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:1088: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:1574: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:1578: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:2016: # other cases that need splitting will first pass through
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:2023: pass  # drop non-reals
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:2477: pass
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:2482: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:2486: know its dimensions. TODO
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:2555: # TODO: check subsets (`func` in `setv`)
- .venv/lib/python3.12/site-packages/sympy/sets/sets.py:2558: # TODO: support more
- .venv/lib/python3.12/site-packages/sympy/sets/conditionset.py:238: pass  # no change of bound symbols via subs
- .venv/lib/python3.12/site-packages/sympy/sets/conditionset.py:242: pass  # let error about the symbol raise from __new__
- .venv/lib/python3.12/site-packages/sympy/sets/setexpr.py:84: # TODO: this could be implemented straight into `imageset`:
- .venv/lib/python3.12/site-packages/sympy/sets/fancysets.py:329: `x` value is in ``base_set`` or not before passing it as args)
- .venv/lib/python3.12/site-packages/sympy/sets/fancysets.py:1036: NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/sets/fancysets.py:1078: raise NotImplementedError("Normalizing theta without pi as coefficient is "
- .venv/lib/python3.12/site-packages/sympy/sets/fancysets.py:1094: raise NotImplementedError('Normalizing theta without pi as '
- .venv/lib/python3.12/site-packages/sympy/sets/fancysets.py:1104: raise NotImplementedError("Normalizing theta when, it is of type %s is not "
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_sets.py:146: raises(NotImplementedError, lambda: Interval(0, 1, And(x, y)))
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_sets.py:147: raises(NotImplementedError, lambda: Interval(0, 1, False, And(x, y)))
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_sets.py:148: raises(NotImplementedError, lambda: Interval(0, 1, z, And(x, y)))
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:318: raises(NotImplementedError, lambda: empty.inf)
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:319: raises(NotImplementedError, lambda: empty.sup)
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:833: # NotImplementedError raised by diophantine (no solver for cubic_thue)
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:1118: # NotImplementedError for subset of reals
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:1119: raises(NotImplementedError, lambda: normalize_theta_set(Interval(0, 1)))
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:1121: # NotImplementedError without pi as coefficient
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:1122: raises(NotImplementedError, lambda: normalize_theta_set(Interval(1, 2*pi)))
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:1123: raises(NotImplementedError, lambda: normalize_theta_set(Interval(2*pi, 10)))
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:1124: raises(NotImplementedError, lambda: normalize_theta_set(FiniteSet(0, 3, 3*pi)))
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:29: # TODO: add support for more functions in the future:
- .venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:206: # TODO: some expressions cannot be calculated due to bugs (currently
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:38: # TODO: handle functions with infinitely many solutions (eg, sin, tan)
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:39: # TODO: handle multivariate functions
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:79: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:34: # TODO: some intervals containing 0 and oo will fail as 0*oo returns nan.
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:41: # TODO: handle symbolic intervals
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:46: # TODO: handle unevaluated condition.
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:49: # TODO: `s2 > s1` could be unevaluated.
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:85: # TODO: add logic for open intervals?
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/issubset.py:98: pass
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/intersection.py:187: pass
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/intersection.py:276: except (TypeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/intersection.py:278: # NotImplementedError if correct format but no solver.
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/intersection.py:331: pass
- .venv/lib/python3.12/site-packages/sympy/sets/handlers/intersection.py:371: # TODO: Design a technique to handle multiple-inverse
- .venv/lib/python3.12/site-packages/sympy/codegen/fnodes.py:344: not an ``Attribute``, then it is passed to :func:`dimension` as ``*dim``
- .venv/lib/python3.12/site-packages/sympy/codegen/fnodes.py:589: raise NotImplementedError("%s requires Fortran %d or newer" %
- .venv/lib/python3.12/site-packages/sympy/codegen/rewriting.py:86: First argument passed to replace.
- .venv/lib/python3.12/site-packages/sympy/codegen/rewriting.py:88: Second argument passed to replace.
- .venv/lib/python3.12/site-packages/sympy/codegen/rewriting.py:238: """ passed as second argument to Basic.replace(...) """
- .venv/lib/python3.12/site-packages/sympy/codegen/rewriting.py:330: # TODO: We should be able to support more than 2 elements
- .venv/lib/python3.12/site-packages/sympy/codegen/pynodes.py:6: pass
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:182: attribute to process the value passed to ``__new__()``. Attributes listed
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:183: in the class attribute ``not_in_args`` are not passed to :class:`~.Basic`.
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:203: """ Construct an attribute value from argument passed to ``__new__()``. """
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:701: raise NotImplementedError("CodeBlock.topological_sort only supports Assignments")
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:704: raise NotImplementedError("CodeBlock.topological_sort does not yet work with AugmentedAssignments")
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:784: raise NotImplementedError("CodeBlock.cse only supports Assignments")
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:787: raise NotImplementedError("CodeBlock.cse does not yet work with AugmentedAssignments")
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:791: raise NotImplementedError("Duplicate assignments to the same "
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:823: !        When passed an iterable it is used to instantiate a CodeBlock.
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:1070: pass
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:1521: variable keyword arguments may be passed (overriding e.g.
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:1649: When passed an iterable it is used to instantiate a CodeBlock.
- .venv/lib/python3.12/site-packages/sympy/codegen/ast.py:1682: When passed an iterable it is used to instantiate a CodeBlock.
- .venv/lib/python3.12/site-packages/sympy/codegen/algorithms.py:138: Attribute instances passed as ``attrs`` to ``FunctionDefinition``.
- .venv/lib/python3.12/site-packages/sympy/codegen/algorithms.py:140: Keyword arguments passed to :func:`sympy.codegen.algorithms.newtons_method`.
- .venv/lib/python3.12/site-packages/sympy/codegen/tests/test_ast.py:214: raises(NotImplementedError, lambda: CodeBlock(
- .venv/lib/python3.12/site-packages/sympy/codegen/tests/test_ast.py:256: pass
- .venv/lib/python3.12/site-packages/sympy/codegen/tests/test_ast.py:274: pass
- .venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:409: @XFAIL  # room for improvement, ideally this test case should pass.
- .venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:410: def test_optims_numpy_TODO():
- .venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:442: NUMBER_OF_DIGITS = 25   # TODO: this should ideally be automatically handled.
- .venv/lib/python3.12/site-packages/sympy/plotting/plot.py:128: # TODO: _process_piecewise check goes here
- .venv/lib/python3.12/site-packages/sympy/plotting/plot.py:204: # TODO: Add color arrays for plots.
- .venv/lib/python3.12/site-packages/sympy/plotting/plot.py:205: # TODO: Add more plotting options for 3d plots.
- .venv/lib/python3.12/site-packages/sympy/plotting/plot.py:206: # TODO: Adaptive sampling for 3D plots.
- .venv/lib/python3.12/site-packages/sympy/plotting/plot_implicit.py:195: raise NotImplementedError("Implicit plotting is not implemented for "
- .venv/lib/python3.12/site-packages/sympy/plotting/utils.py:55: """This function recursively loop over the arguments passed to the plot
- .venv/lib/python3.12/site-packages/sympy/plotting/utils.py:159: # TODO: prange check goes here
- .venv/lib/python3.12/site-packages/sympy/plotting/utils.py:228: keyword arguments passed to the plotting function. It will be used to
- .venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:78: #TODO debugging output
- .venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:403: #TODO
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:245: # contains keyword arguments that will be passed to the rendering
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:381: # TODO: set cse=True once this issue is solved:
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:493: """Create a list of arguments to be passed to the lambda function,
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:753: Arguments to be passed to the coloring function. Can be coordinates
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:817: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:969: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:1146: # TODO: for now, I assume that numpy functions are going to succeed
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:1156: # TODO: what if points[k][idx]==e or points[k][idx+1]==e?
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:1482: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:1507: label passed in by the pre-processor or the user
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:1774: # TODO: remove this
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:1790: # TODO: remove this
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:1871: # TODO: remove this
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:1972: # TODO: remove this
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:2094: # TODO: remove this
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:2199: raise NotImplementedError("Interactive plot with `adaptive=True` "
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:2420: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:2490: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/plotting/series.py:2560: Dictionary of keyword arguments passed into a plotting function.
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:40: This backend is meant to raise NotImplementedError for methods `show`,
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:49: This backend is meant to pass all tests.
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:55: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:58: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:61: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:410: # passing an array of values as the integration limit.
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:573: raises(NotImplementedError, lambda: p.show())
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:785: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:787: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/plotting/tests/test_plot.py:789: with raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:17: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:30: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:52: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:73: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:87: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:116: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:147: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:175: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:182: return NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:203: return NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:230: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:249: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:261: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:326: return NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:347: return NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:371: return NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:385: return NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/intervalmath/lib_interval.py:409: return NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/backends/base_backend.py:26: "argument should be passed to a plotting function, which generates "
- .venv/lib/python3.12/site-packages/sympy/plotting/backends/base_backend.py:359: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/backends/base_backend.py:362: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/backends/base_backend.py:365: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:205: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:240: # TODO The 3D stuff
- .venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:251: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:304: #TODO after fixing https://github.com/ipython/ipython/issues/1255
- .venv/lib/python3.12/site-packages/sympy/plotting/backends/textbackend/text.py:24: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_mode.py:38: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_mode.py:127: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_interval.py:153: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_window.py:114: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/color_scheme.py:223: pass  # color function probably not valid at 0,0,0,0,0
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_axes.py:46: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_axes.py:138: pass  # optional
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_axes.py:141: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_axes.py:248: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_axes.py:251: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot.py:212: The following named arguments are passed as
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_mode_base.py:70: for arguments passed to PlotMode() containing
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_mode_base.py:120: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_mode_base.py:123: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_mode_base.py:126: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_mode_base.py:129: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_object.py:17: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/managed_window.py:86: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/managed_window.py:95: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/managed_window.py:103: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/util.py:4: pass
- .venv/lib/python3.12/site-packages/sympy/plotting/pygletplot/plot_rotation.py:4: pass
- .venv/lib/python3.12/site-packages/sympy/combinatorics/free_groups.py:165: """Return a tuple of arguments that must be passed to __new__ in order to support pickling this object."""
- .venv/lib/python3.12/site-packages/sympy/combinatorics/free_groups.py:965: pass
- .venv/lib/python3.12/site-packages/sympy/combinatorics/homomorphisms.py:122: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/combinatorics/homomorphisms.py:492: raise NotImplementedError("Isomorphism methods are not implemented for infinite groups.")
- .venv/lib/python3.12/site-packages/sympy/combinatorics/homomorphisms.py:496: raise NotImplementedError("Isomorphism methods are not implemented for infinite groups.")
- .venv/lib/python3.12/site-packages/sympy/combinatorics/coset_table.py:978: An instance of `CosetTable` for `fp_grp` can be passed as the keyword
- .venv/lib/python3.12/site-packages/sympy/combinatorics/coset_table.py:985: # TODO: complete the docstring
- .venv/lib/python3.12/site-packages/sympy/combinatorics/tensor_can.py:1015: TODO: use baseswap in the case in which if it fails in finding a
- .venv/lib/python3.12/site-packages/sympy/combinatorics/polyhedron.py:188: an axis passing through a vertex and face and another axis passing
- .venv/lib/python3.12/site-packages/sympy/combinatorics/polyhedron.py:189: through a different vertex or from an axis passing through the
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:41: """Parse the passed relators."""
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:169: An instance of `CosetTable` for `fp_grp` can be passed as the keyword
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:353: # TODO: use |G:H| = |G|/|H| (currently H can't be made into a group)
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:385: raise NotImplementedError("Permutation presentation of infinite "
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:523: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:524: raise NotImplementedError("Check for infinite Cyclic group "
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:534: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:535: raise NotImplementedError("abelian invariants is not implemented"
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:545: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:546: raise NotImplementedError("composition series is not implemented"
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:870: # TODO:: Sims points out in [Sim94] that performance can be improved by
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:875: # stored and passed through to the descendants of C. Of course this would
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:903: # TODO: this should support input of a list of general words
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:951: a list of generators and relators can be passed in which case the
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:1080: pass
- .venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:1121: pass
- .venv/lib/python3.12/site-packages/sympy/combinatorics/permutations.py:269: method (or passing it to the list function) and all elements from
- .venv/lib/python3.12/site-packages/sympy/combinatorics/permutations.py:1425: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/combinatorics/permutations.py:1444: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/combinatorics/permutations.py:1511: to ``p^(q*r)`` rather than ``p^(r*q)``. To obtain r*p*~r, pass ~r to
- .venv/lib/python3.12/site-packages/sympy/combinatorics/permutations.py:1722: raise NotImplementedError("{} should be an integer.".format(i))
- .venv/lib/python3.12/site-packages/sympy/combinatorics/permutations.py:1726: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/sympy/combinatorics/partitions.py:35: This method also verifies if the arguments passed are
- .venv/lib/python3.12/site-packages/sympy/combinatorics/perm_groups.py:50: These are passed as permutations to PermutationGroup:
- .venv/lib/python3.12/site-packages/sympy/combinatorics/perm_groups.py:777: raise NotImplementedError('Group should be solvable')
- .venv/lib/python3.12/site-packages/sympy/combinatorics/perm_groups.py:1545: raise NotImplementedError('No generation defined for %s' % method)
- .venv/lib/python3.12/site-packages/sympy/combinatorics/perm_groups.py:3796: sifts to pass. This makes sure that the current ``base`` and ``gens``
- .venv/lib/python3.12/site-packages/sympy/combinatorics/perm_groups.py:4021: known in advance, it can be passed to the function as this
- .venv/lib/python3.12/site-packages/sympy/combinatorics/perm_groups.py:5371: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/combinatorics/perm_groups.py:5375: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/combinatorics/perm_groups.py:5380: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/combinatorics/tests/test_group_numbers.py:79: pass
- .venv/lib/python3.12/site-packages/sympy/combinatorics/tests/test_permutations.py:239: pass
- .venv/lib/python3.12/site-packages/sympy/combinatorics/tests/test_permutations.py:553: raises(NotImplementedError, lambda: p.apply(x))
- .venv/lib/python3.12/site-packages/sympy/combinatorics/tests/test_permutations.py:555: raises(NotImplementedError, lambda: p.apply(x))
- .venv/lib/python3.12/site-packages/sympy/benchmarks/bench_symbench.py:41: pass
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:47: # TODO should __new__ accept **options?
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:48: # TODO should constructors should check if parameters are sensible?
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:86: except (ArgumentIndexError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:133: The parameters $a_p$ and $b_q$ can be passed as arbitrary
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:210: # TODO should we check convergence conditions?
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:442: You can pass the parameters either as four separate vectors:
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:458: As with the hypergeometric function, the parameters may be passed as
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:460: passed as iterables. The parameters need not be constants, but if they
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:543: # TODO should we check convergence conditions?
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:611: raise NotImplementedError('Derivative not expressible '
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:822: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:827: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:832: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:837: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:980: # TODO this can be nicer
- .venv/lib/python3.12/site-packages/sympy/functions/special/singularity_functions.py:117: on the argument passed by the object.
- .venv/lib/python3.12/site-packages/sympy/functions/special/singularity_functions.py:125: depending on the argument passed. In other words, ``eval()`` method is
- .venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:150: # TODO should something be polarified here?
- .venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:179: # TODO use minpoly instead of ad-hoc methods when issue 5888 is fixed
- .venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:181: # TODO reference?
- .venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:371: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:420: If no value is passed for $a$ a default value of $a = 1$ is assumed,
- .venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:575: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:579: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:155: argument passed by the DiracDelta object.
- .venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:162: instance or the unevaluated instance depending on the argument passed.
- .venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:205: arg : argument passed to DiracDelta
- .venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:295: pass
- .venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:499: argument passed by the Heaviside object.
- .venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:506: instance or the unevaluated instance depending on the argument passed.
- .venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:543: arg : argument passed by Heaviside object
- .venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:656: # TODO
- .venv/lib/python3.12/site-packages/sympy/functions/special/gamma_functions.py:44: The ``gamma`` function implements the function which passes through the
- .venv/lib/python3.12/site-packages/sympy/functions/special/gamma_functions.py:687: # TODO n == 1 also can do some rational z
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:25: # TODO
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:228: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:260: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:362: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:398: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:545: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:572: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:696: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:708: raise NotImplementedError(f"Cannot proceed without knowing if {nu} is zero or not.")
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:723: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:782: raise NotImplementedError("besselk expansion is only implemented for real order")
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:915: raise NotImplementedError('expansion')
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:1326: raise NotImplementedError("Unknown method.")
- .venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:1332: raise NotImplementedError("Unknown method.")
- .venv/lib/python3.12/site-packages/sympy/functions/special/bsplines.py:258: Return spline of degree *d*, passing through the given *X*
- .venv/lib/python3.12/site-packages/sympy/functions/special/bsplines.py:291: list of X coordinates through which the spline passes
- .venv/lib/python3.12/site-packages/sympy/functions/special/bsplines.py:294: list of corresponding Y coordinates through which the spline passes
- .venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:24: # TODO series expansions
- .venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:25: # TODO see the "Note:" in Ei
- .venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:273: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:1220: # TODO:
- .venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:2738: # TODO: is the series really correct?
- .venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:150: # TODO Add more simplififcation here
- .venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:179: # TODO: Make sure n \in N
- .venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:180: # TODO: Assert |m| <= n ortherwise we should return 0
- .venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:189: # TODO: Make sure n \in N
- .venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:190: # TODO: Assert |m| <= n ortherwise we should return 0
- .venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:197: # TODO: Make sure theta \in R and phi \in R
- .venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:202: # TODO: Handle deep and hints
- .venv/lib/python3.12/site-packages/sympy/functions/combinatorial/numbers.py:76: If a number passes the Fermat test several times, then it is prime with a
- .venv/lib/python3.12/site-packages/sympy/functions/combinatorial/numbers.py:79: Unfortunately, certain composite numbers (non-primes) still pass the Fermat
- .venv/lib/python3.12/site-packages/sympy/functions/combinatorial/numbers.py:83: A Carmichael number will pass a Fermat primality test to every base $b$
- .venv/lib/python3.12/site-packages/sympy/functions/combinatorial/numbers.py:2758: # TODO: make this a class like bell()
- .venv/lib/python3.12/site-packages/sympy/functions/combinatorial/factorials.py:23: # automatically passed to gammasimp
- .venv/lib/python3.12/site-packages/sympy/functions/combinatorial/factorials.py:282: pass
- .venv/lib/python3.12/site-packages/sympy/functions/combinatorial/factorials.py:423: # TODO: extend this to complex numbers?
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:283: if arg.is_Add: # TODO, implement more if deep stuff here
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:480: if arg.is_Add: # TODO, implement more if deep stuff here
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:1203: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/complexes.py:340: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/complexes.py:454: values.  If you pass a SymPy expression to the built-in ``abs()``, it will
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/complexes.py:455: pass it automatically to ``Abs()``.
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/miscellaneous.py:619: x, y = y, x  # run next pass with reversed order relative to start
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/exponential.py:507: except (NotImplementedError, PoleError):
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/exponential.py:683: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/exponential.py:985: # TODO new and probably slow
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/exponential.py:988: except (ValueError, NotImplementedError, PoleError):
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/integers.py:70: except (PrecisionExhausted, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/integers.py:71: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/integers.py:85: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/integers.py:193: raise NotImplementedError("Not sure of sign of %s" % ndir)
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/integers.py:218: raise NotImplementedError("Not sure of sign of %s" % ndir)
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/integers.py:393: raise NotImplementedError("Not sure of sign of %s" % ndir)
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/integers.py:418: raise NotImplementedError("Not sure of sign of %s" % ndir)
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/_trigonometric_special.py:3: TODO
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:110: raise NotImplementedError("Use the periodicity function instead.")
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:498: if arg.is_Add:  # TODO, implement more if deep stuff here
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:499: # TODO: Do this more efficiently for more than two terms
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:867: if arg.is_Add:  # TODO: Do this more efficiently for more than two terms
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:1579: # TODO refactor into TrigonometricFunction common parts of
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:301: was passed) are paired with the governing x-independent relationals,
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:332: except (ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:489: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:578: # TODO simplify hi <= upto
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:616: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:838: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:874: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:907: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:909: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:946: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:1130: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:1134: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:1141: pass
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:1178: except NotImplementedError:
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:1179: pass # continue with the given `a`
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:1448: can be prevented by passing ``skip_nan=True``.
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_complexes.py:938: # TODO XXX why does abs(x)._eval_evalf() not fall back to global evalf?
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:345: def test_meijer_bypass():
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:346: # totally bypass meijerg machinery when dealing
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:603: raises(NotImplementedError, lambda: solve(f, x))
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:1223: # TODO raise error if function is discontinuous at limit of
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:1334: raises(NotImplementedError, lambda: _ITE((x, x < y), (y, x >= a)))
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:1563: raises(NotImplementedError, lambda: Piecewise((x, x<0), (0, y>1)).as_expr_set_pairs())
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_exponential.py:209: # raises(NotImplementedError, lambda: exp(1/x).as_leading_term(x))
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_exponential.py:210: # raises(NotImplementedError, lambda: exp((x + 1) / x**2).as_leading_term(x))
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_exponential.py:211: # raises(NotImplementedError, lambda: exp(x + 1/x).as_leading_term(x))
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_integers.py:679: raises(NotImplementedError, lambda: floor(x/a).as_leading_term(x, cdir = 1))
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_integers.py:680: raises(NotImplementedError, lambda: ceiling(x/a).as_leading_term(x, cdir = 1))
- .venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_trigonometric.py:2105: raises(NotImplementedError, lambda: sin(x**2).period(x))
- .venv/lib/python3.12/site-packages/sympy/vector/orienters.py:68: pass
- .venv/lib/python3.12/site-packages/sympy/vector/orienters.py:236: pass
- .venv/lib/python3.12/site-packages/sympy/vector/orienters.py:299: pass
- .venv/lib/python3.12/site-packages/sympy/vector/orienters.py:372: pass
- .venv/lib/python3.12/site-packages/sympy/vector/functions.py:158: # TODO: This gets a random coordinate system in case of multiple ones:
- .venv/lib/python3.12/site-packages/sympy/vector/functions.py:503: # TODO : The following line introduces a performance issue
- .venv/lib/python3.12/site-packages/sympy/vector/coordsysrect.py:91: pass
- .venv/lib/python3.12/site-packages/sympy/vector/coordsysrect.py:702: # TODO: trigsimp is needed here so that the matrix becomes
- .venv/lib/python3.12/site-packages/sympy/vector/coordsysrect.py:1002: pass
- .venv/lib/python3.12/site-packages/sympy/vector/implicitregion.py:131: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/vector/implicitregion.py:376: to determine a point on the region and pass it using reg_point.
- .venv/lib/python3.12/site-packages/sympy/vector/implicitregion.py:401: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/vector/implicitregion.py:432: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/vector/implicitregion.py:491: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/sympy/vector/operators.py:214: # TODO: is case of many coord systems, this gets a random one:
- .venv/lib/python3.12/site-packages/sympy/vector/tests/test_implicitregion.py:88: raises(NotImplementedError, lambda: r1.rational_parametrization())
- .venv/lib/python3.12/site-packages/sympy/vector/tests/test_implicitregion.py:90: raises(NotImplementedError, lambda: r2.rational_parametrization())
- .venv/lib/python3.12/site-packages/sympy/logic/boolalg.py:156: raise NotImplementedError('handling of relationals')
- .venv/lib/python3.12/site-packages/sympy/logic/boolalg.py:197: raise NotImplementedError(filldedent('''
- .venv/lib/python3.12/site-packages/sympy/logic/boolalg.py:209: raise NotImplementedError("Sorry, as_set has not yet been"
- .venv/lib/python3.12/site-packages/sympy/logic/boolalg.py:567: pass
- .venv/lib/python3.12/site-packages/sympy/logic/boolalg.py:700: pass
- .venv/lib/python3.12/site-packages/sympy/logic/boolalg.py:2383: be ignored, pass them as a list, too.
- .venv/lib/python3.12/site-packages/sympy/logic/boolalg.py:2464: be ignored, pass them as a list, too.
- .venv/lib/python3.12/site-packages/sympy/logic/boolalg.py:2969: NotImplementedError: unexpected level of nesting
- .venv/lib/python3.12/site-packages/sympy/logic/boolalg.py:2989: raise NotImplementedError('unexpected level of nesting')
- .venv/lib/python3.12/site-packages/sympy/logic/inference.py:119: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/logic/inference.py:260: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/logic/inference.py:263: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/logic/inference.py:266: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/logic/tests/test_boolalg.py:241: raises(NotImplementedError, lambda: (A & B).equals(A > B))
- .venv/lib/python3.12/site-packages/sympy/logic/tests/test_boolalg.py:878: raises(NotImplementedError, lambda: (sin(x) < 1).as_set())
- .venv/lib/python3.12/site-packages/sympy/logic/algorithms/dpll2.py:119: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/logic/algorithms/dpll2.py:129: raise NotImplementedError
- .venv/lib/python3.12/site-packages/sympy/logic/algorithms/dpll2.py:322: ...     pass
- .venv/lib/python3.12/site-packages/sympy/logic/algorithms/dpll2.py:379: ...     pass
- .venv/lib/python3.12/site-packages/sympy/logic/algorithms/dpll2.py:565: pass
- .venv/lib/python3.12/site-packages/sympy/logic/algorithms/dpll2.py:676: pass
- .venv/lib/python3.12/site-packages/sympy/logic/algorithms/lra_theory.py:44: and an lra object has been initialized, we can pass `f`
- .venv/lib/python3.12/site-packages/sympy/logic/algorithms/lra_theory.py:56: Next you would pass this assignment to the LRASolver
- .venv/lib/python3.12/site-packages/sympy/logic/algorithms/lra_theory.py:103: TODO:
- .venv/lib/python3.12/site-packages/sympy/strategies/tests/test_tools.py:22: pass
- .venv/lib/python3.12/site-packages/sympy/strategies/tests/test_tools.py:25: pass
- .venv/lib/python3.12/site-packages/sympy/strategies/tests/test_rl.py:51: pass
- .venv/lib/python3.12/site-packages/sympy/strategies/tests/test_rl.py:54: pass
- .venv/lib/python3.12/site-packages/sympy/strategies/tests/test_traverse.py:56: pass
- .venv/lib/python3.12/site-packages/sympy/strategies/branch/core.py:61: pass
- .venv/lib/python3.12/site-packages/charset_normalizer/md.py:43: raise NotImplementedError  # pragma: nocover
- .venv/lib/python3.12/site-packages/charset_normalizer/md.py:50: raise NotImplementedError  # pragma: nocover
- .venv/lib/python3.12/site-packages/charset_normalizer/md.py:56: raise NotImplementedError
- .venv/lib/python3.12/site-packages/charset_normalizer/md.py:64: raise NotImplementedError  # pragma: nocover
- .venv/lib/python3.12/site-packages/charset_normalizer/api.py:340: # Only if initial MD tests passes
- .venv/lib/python3.12/site-packages/charset_normalizer/api.py:395: "%s passed initial chaos probing. Mean measured chaos is %f %%",
- .venv/lib/python3.12/site-packages/charset_normalizer/legacy.py:9: # TODO: remove this check when dropping Python 3.7 support
- .venv/lib/python3.12/site-packages/charset_normalizer/cli/__main__.py:53: Instances of FileType are typically passed as type= arguments to the
- .venv/lib/python3.12/site-packages/torchgen/native_function_generation.py:400: #     a simple functional variant that the functionalization pass can consume.
- .venv/lib/python3.12/site-packages/torchgen/native_function_generation.py:405: # Don't bother generating functions trio's for native functions that bypass the dispatcher.
- .venv/lib/python3.12/site-packages/torchgen/native_function_generation.py:554: # We can't just directly pass all of the arguments from the functional op into the mutating op.
- .venv/lib/python3.12/site-packages/torchgen/model.py:514: # TODO: figure out what this does
- .venv/lib/python3.12/site-packages/torchgen/model.py:568: # are returned by the meta function in one struct and passed to the impl
- .venv/lib/python3.12/site-packages/torchgen/model.py:728: # TODO: verify that the tag is valid and has an entry in tags.yaml
- .venv/lib/python3.12/site-packages/torchgen/model.py:812: # TODO: maybe it's better to test the return
- .venv/lib/python3.12/site-packages/torchgen/model.py:975: # TODO: probably better to accumulate these errors and report them all
- .venv/lib/python3.12/site-packages/torchgen/model.py:1340: # TODO: This discrepancy isn't required; we could also generated
- .venv/lib/python3.12/site-packages/torchgen/model.py:1406: # TODO: Need to handle collisions with argument names at some point
- .venv/lib/python3.12/site-packages/torchgen/model.py:1793: # TODO: implement a proper parser if this gets more ugly
- .venv/lib/python3.12/site-packages/torchgen/model.py:1870: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torchgen/model.py:1878: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torchgen/model.py:1890: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torchgen/model.py:1893: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torchgen/model.py:2065: # TODO: deduplicate annotation matching with Return
- .venv/lib/python3.12/site-packages/torchgen/model.py:2356: # TODO: Use a real parser here; this will get bamboozled
- .venv/lib/python3.12/site-packages/torchgen/model.py:2376: pass  # do nothing
- .venv/lib/python3.12/site-packages/torchgen/model.py:2475: # TODO: These invariants are weirdly asymmetric?
- .venv/lib/python3.12/site-packages/torchgen/model.py:2476: # TODO: Fancier types?
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:37: BaseTy.bool: "int32_t",  # Use int to pass bool
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:40: BaseTy.Scalar: "double",  # Use double to pass both integer and floating point
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:41: BaseTy.float: "double",  # TODO: how about other floating point types?
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:91: # results in an rvalue tensor, which can't be passed to at::Tensor&.
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:117: # TODO: BaseTy.Dimname, etc.
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:118: raise NotImplementedError(f"TODO: add support for arg type {repr(typ)}")
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:130: # ArrayRef is passed as pointer + size, but no need to add "*" to the size argument
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:138: # Device is passed as device_type + device_index
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:162: # Need to explicitly pass the list as pointer + length
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:198: raise NotImplementedError(f"Argument type {repr(typ)} not supported!")
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:225: # Return values are passed out as pointer arguments because all the C shim functions
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:236: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:237: f"TODO: add support for return type {repr(ret.type)}"
- .venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:492: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torchgen/utils.py:54: # TODO: Use a real parser here; this will get bamboozled
- .venv/lib/python3.12/site-packages/torchgen/utils.py:92: # TODO: this does the wrong thing with KeyError
- .venv/lib/python3.12/site-packages/torchgen/utils.py:103: # TODO: put this somewhere else, maybe
- .venv/lib/python3.12/site-packages/torchgen/utils.py:145: pass
- .venv/lib/python3.12/site-packages/torchgen/gen_backend_stubs.py:145: # TODO: allow structured external backends later.
- .venv/lib/python3.12/site-packages/torchgen/gen.py:378: # TODO: for ops with structured_delegate it should check the dispatch table of
- .venv/lib/python3.12/site-packages/torchgen/gen.py:818: # TODO: This was historically used to help some JIT interop code
- .venv/lib/python3.12/site-packages/torchgen/gen.py:1073: # TODO: Get rid of dynamic_type, after getting tools/autograd
- .venv/lib/python3.12/site-packages/torchgen/gen.py:1340: # TODO: What exactly is the semantics of the 'dispatch' field?
- .venv/lib/python3.12/site-packages/torchgen/gen.py:1456: # TODO: how come ValuesView isn't a Sequence lol
- .venv/lib/python3.12/site-packages/torchgen/gen.py:2253: # TODO: this condition is a bit questionable
- .venv/lib/python3.12/site-packages/torchgen/gen.py:2610: #     These are never explicitly invoked by the functionalization pass,
- .venv/lib/python3.12/site-packages/torchgen/gen.py:2744: # TODO: --op-registration-whitelist will be removed when all call-sites
- .venv/lib/python3.12/site-packages/torchgen/gen.py:2845: # TODO: stop generating CUDA kernels for non-CUDA builds
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:76: # This file contains codegen that relates to the functionalization pass.
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:79: #     Generates dispatcher kernel definitions for the functionalization pass.
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:81: #     Generates dispatcher kernel registrations for the functionalization pass.
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:222: # for tensor inputs, we want to unwrap them before passing them into the redispatch calls.
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:246: # for non-tensor inputs, we want to pass them directly into the redispatch calls.
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:260: # for tensor inputs, we want to unwrap them before passing them into the redispatch calls.
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:266: # for non-tensor inputs, we want to pass them directly into the redispatch calls.
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:370: # Sometimes the functionalization pass needs to no-op (e.g. if it was passed non-functional tensors)
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:407: // functionalization is re-entrant, but will no-op if it wasn't passed a FunctionalTensorWrapper.
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:446: // See  Note [Propagating strides in the functionalization pass]
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:463: // functionalization is re-entrant, but will no-op if it wasn't passed a FunctionalTensorWrapper.
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:508: // See  Note [Propagating strides in the functionalization pass]
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:754: # These files provide the kernels that run the functionalization pass, which can be opted into
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:849: # Case 1: emit view -> view_copy kernels for the functionalization pass
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:862: # TODO: The below ops all have "problematic" schemas that prevent them from
- .venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:874: # Case 2: emit inplace -> out-of-place kernels for the functionalization pass
- .venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:129: # TODO(whc) add a check for shape inference functions that have meta kernels implement and should be retired.
- .venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:348: TODO(alanwaketan): Remove this sorting hack once all ops are grouped properly.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:15: #   pass named arguments directly for everything, otherwise it's much too
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:165: "replace_",  # only used by the functionalization pass, doesn't need to be exposed to python
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:166: "copy",  # only used by the functionalization pass
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:167: "fill.Tensor",  # only used by the functionalization pass
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:168: "fill.Scalar",  # only used by the functionalization pass
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:170: "normal_functional",  # only used by the functionalization pass
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:612: # HACK: these are fixed constants used to pass the aten function.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1023: switches on the presence/absence of passed output args.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1260: # TODO: should use some canonical form instead of 'str(arg.type)' - see comments
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1346: # TODO: Checking `ps.method and ('requires_grad' in parser_outputs)` is a hacky
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_autograd_functions.py:92: # and unpacking saved variables to pass to MulBackward0_apply_functional.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_autograd_functions.py:516: # TODO: This is probably not exhaustive, but it's a start
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:256: # TODO: Should handle optional here?
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:261: # TODO: Should handle optional here?
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:338: return f.func.name.name.base  # TODO: should be str(f.func.name.name)?
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:355: # TODO: Clean this logic up if we get rid of reverse view funcs or reify them.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_factories.py:23: # TODO: maybe update the cpp argument API to take optional namespace argument?
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_factories.py:101: # instead of passing it through to the kernel.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:662: # values temporarily and pass the values to the return variables outside of the
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:968: # TODO: it would be nice to not have these special cases
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1106: # TODO: `cpp_type` is only to keep it byte-for-byte compatible with the old codegen, should remove.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1127: # TODO(crcrpar): Make it simpler.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1217: # but their derivatives don't use it, so let them bypass this check.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1248: # TODO: process all derivative formulas!!!
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1372: # TODO: should be `arg.type.is_tensor_like()`?
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1629: base_name = f.func.name.name.base  # TODO: should be str(f.func.name.name)?
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1689: # the baseType operations still dispatch to non-Variable type, even if the arguments passed
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1753: # TODO: flatten allocates a std::vector, which could be expensive
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1881: # TODO update this when inplace namings are unified
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1991: # TODO(crcrpar): Should this (= the foreach specific logic) be refactored somehow?
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:59: # of proper scopes, where subsequent compilation passes can ask for the unfolding
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:116: # TODO: byte-for-byte compatible with old codegen behavior - should clean up
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:306: # TODO: clean up old codegen behavior
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:460: # the key argument should not be passed.
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:182: # TODO: Why is this going through CppSignatureGroup, that doesn't make sense...
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:403: # TODO we are trolling
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:597: # TODO: do we need eagerly calculate and save it here? Can it be derived
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:658: # TODO: maybe the logic to handle the legacy schema is no longer necessary?
- .venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:967: # converted to std::optional<std::string_view> before being passed into
- .venv/lib/python3.12/site-packages/torchgen/api/autograd.py:119: # TODO: maybe the logic to search for all variants is no longer necessary?
- .venv/lib/python3.12/site-packages/torchgen/api/autograd.py:238: # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
- .venv/lib/python3.12/site-packages/torchgen/api/autograd.py:246: #   TODO: some cpp naming logic (e.g. resolving name conflict) might be irrelevant?
- .venv/lib/python3.12/site-packages/torchgen/api/autograd.py:255: # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
- .venv/lib/python3.12/site-packages/torchgen/api/autograd.py:266: # TODO: Update comment below since it is out of date.
- .venv/lib/python3.12/site-packages/torchgen/api/autograd.py:369: # TODO(crcrpar): Avoid hard coding "Default" ideally.
- .venv/lib/python3.12/site-packages/torchgen/api/autograd.py:653: # TODO(crcrpar): Avoid hard coding "Default" ideally.
- .venv/lib/python3.12/site-packages/torchgen/api/structured.py:77: # TODO: delete these special cases; see torchgen.api.cpp--these
- .venv/lib/python3.12/site-packages/torchgen/api/unboxing.py:43: #                                                   Will be passed to unboxed kernel.
- .venv/lib/python3.12/site-packages/torchgen/api/native.py:53: # TODO: delete this!
- .venv/lib/python3.12/site-packages/torchgen/api/native.py:120: # TODO: Not sure why the arguments assigned here are for
- .venv/lib/python3.12/site-packages/torchgen/api/functionalization.py:26: # when creating view lambdas that are used by the functionalization pass.
- .venv/lib/python3.12/site-packages/torchgen/api/functionalization.py:35: # The lambdas generated for each view op in the functionalization pass are of the form
- .venv/lib/python3.12/site-packages/torchgen/api/translate.py:83: pass
- .venv/lib/python3.12/site-packages/torchgen/api/translate.py:156: # TODO: My kingdom for a pattern matcher
- .venv/lib/python3.12/site-packages/torchgen/api/translate.py:159: # TODO: This could get us in recomputation trouble if b.expr is nontrivial.
- .venv/lib/python3.12/site-packages/torchgen/api/translate.py:251: pass
- .venv/lib/python3.12/site-packages/torchgen/api/translate.py:258: pass
- .venv/lib/python3.12/site-packages/torchgen/api/translate.py:260: # TODO: These are referentially equal, shouldn't have to do this;
- .venv/lib/python3.12/site-packages/torchgen/api/translate.py:375: # TODO: You might also want to solve this from longSymVec_ctype or
- .venv/lib/python3.12/site-packages/torchgen/api/cpp.py:166: )  # TODO: fix this discrepancy
- .venv/lib/python3.12/site-packages/torchgen/api/cpp.py:183: # TODO: remove these special cases, ArrayRef fallthrough works fine
- .venv/lib/python3.12/site-packages/torchgen/api/cpp.py:287: # TODO: Consider incorporating this into the data model
- .venv/lib/python3.12/site-packages/torchgen/api/cpp.py:305: # If there is no explicit name and no fallback name was passed in, we just name the output result,
- .venv/lib/python3.12/site-packages/torchgen/api/cpp.py:424: default = "at::kLong"  # TODO: this is wrong
- .venv/lib/python3.12/site-packages/torchgen/api/ufunc.py:38: # passed along  (technically, we can pass tensors along too, it just wastes
- .venv/lib/python3.12/site-packages/torchgen/api/ufunc.py:59: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torchgen/api/ufunc.py:80: # Only Tensors ever get passed directly to operator()
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:53: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:121: raise AssertionError(f"TODO add support for type {repr(typ)}")
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:126: # TODO(whc) is this actually correct? or should it use a Vector like above
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:132: # TODO: return a value type.  The problem here is analogous to
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:147: # TODO: Determining this based off of CType is bad; this should be computed
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:150: # Invariant: passed typ should be an *owning* CType (e.g., we will report
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:167: # TODO: report True for this
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:193: # TODO: dedupe with Type.is_generator_like
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:210: # TODO: this is lies, it is false for symint list
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:232: # TODO: lists of symints are not currently treated as value types
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:309: # TODO: This is not idiomatic with how other torchgen APIs transform on schema.
- .venv/lib/python3.12/site-packages/torchgen/api/lazy.py:317: # TODO: Need to handle collisions with argument names at some point
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:258: # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:282: # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:332: # TODO: maybe don't need keep scattered out fields for python signature?
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:354: # TODO: shouldn't this be OptionalType[ListType[...]], since it defaults to None?
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:369: # TODO: create a dedicated SelfArgument type for 'self'?
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:386: # TODO: maybe create a PythonTensorOptionsArgument?
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:493: # C++ signature expects. We need store the constant default values to pass in.
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:603: # To pass PyObjects arguments to C++ function (via the lambda wrapper),
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:628: # To pass PythonArgParser output to the lambda wrapper, we need bind
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:752: # TODO: directly translate a.default to python default
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:804: # [old codegen] TODO: because these aren't guaranteed to be 100% faithful
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:976: # TODO: this doesn't seem right...
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:1116: # to 'Tensor'. It's because when calling the lambda it passes in the
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:1118: # and needs to pass by value. Also see comments in 'dispatch_lambda_return_str()'.
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:1131: # TODO: This is to keep same byte-for-byte result as the old codegen - maybe unnecessary?
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:1163: # TODO: avoid this special handling?
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:1446: # TODO: why this needs to be special case?
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:1467: # TODO: make this part of something more general, or get rid of it.
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:1482: # method's self is passed directly to python binding, rather than parsed
- .venv/lib/python3.12/site-packages/torchgen/api/python.py:1519: # TODO: maybe move to the generator side as it's not related to binding.
- .venv/lib/python3.12/site-packages/torchgen/api/types/types.py:138: # Do not pass `strip_ref` recursively.
- .venv/lib/python3.12/site-packages/torchgen/api/types/types.py:150: # Do not pass `strip_ref` recursively.
- .venv/lib/python3.12/site-packages/torchgen/api/types/types.py:162: # Do not pass `strip_ref` recursively.
- .venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:72: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:108: # Do not pass `strip_ref` recursively.
- .venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:121: # Do not pass `strip_ref` recursively.
- .venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:133: # Do not pass `strip_ref` recursively.
- .venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:188: # TODO: maybe don't represent default here
- .venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:47: # TODO: use BackendIndex
- .venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:83: # TODO: don't hardcode; return type will be inferred based on tags on
- .venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:509: # TODO: don't hardcode ufunc:: namespace here, should be centralized smh
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:174: // TODO: avoid the redispatch here
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:235: #     cpp API bindings which can be used to bypass dispatcher
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:444: # TODO: dedupe this with the structured codegen
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:469: # TODO: handle in place on tensor list
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:679: # TODO: Make sure out argument is guaranteed to be self
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:727: # TODO: Move to OptionalMPSGuard.
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:743: f"      return {output_value};\n",  # type: ignore[possibly-undefined]  # TODO: audit
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:745: # type: ignore[possibly-undefined]  # TODO: audit
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:747: f"{textwrap.indent(proxy_field, indent)}",  # type: ignore[possibly-undefined]  # TODO: audit
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:763: # TODO: Now, there is something interesting going on here.  In the code below,
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:786: # (e.g., at::cpu::add).  We don't generate methods (TODO: do this
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:839: # TODO: dedup this branch
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:917: # TODO: Stop hardcoding that the output type is a Tensor.  Note
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:932: # TODO: https://github.com/pytorch/pytorch/issues/53023
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:942: # TODO: I think this means structured won't work with method
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:971: # TODO: Do this in translate instead
- .venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:989: sig_body.append(f"return {ret_expr};")  # type: ignore[possibly-undefined]  # TODO: audit
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:46: generate a c++ string for materializing an rvalue of that arg for passing into
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:50: # TODO: Matching on CType seems wrong; should be matching on Type
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:62: # TODO: I don't understand when you should put lazy_ in the name
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:74: f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:104: Produce a formatted string with the arguments as passed into the constructor of a node class.
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:448: # TODO(alanwaketan): Maybe we want to apply GetLtcTensorOrCreateForWrappedNumber here, but hold it
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:456: f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:523: # (We can't pass in the input tensors directly, because they are "functional wrappers".
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:541: # TODO: this is trolling
- .venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:582: # TODO(whc) remove this if XLA switches to using static method for creation
- .venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:81: # TODO: these ones got added recently and need manual inspection
- .venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:269: # TODO: stop doing type tests by converting to C++ and then testing
- .venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:295: # TODO: stop type testing by converting to C++
- .venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:270: # TODO: remove the skip after these two operators schemas are fixed
- .venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:324: # TODO: remove the skip after these two operators schemas are fixed
- .venv/lib/python3.12/site-packages/idna/codec.py:101: pass
- .venv/lib/python3.12/site-packages/idna/codec.py:105: pass
- .venv/lib/python3.12/site-packages/idna/core.py:17: pass
- .venv/lib/python3.12/site-packages/idna/core.py:23: pass
- .venv/lib/python3.12/site-packages/idna/core.py:29: pass
- .venv/lib/python3.12/site-packages/idna/core.py:35: pass
- .venv/lib/python3.12/site-packages/idna/core.py:292: pass
- .venv/lib/python3.12/site-packages/idna/core.py:377: raise IDNAError("should pass a unicode string to the function rather than a byte string.")
- .venv/lib/python3.12/site-packages/idna/compat.py:15: raise NotImplementedError("IDNA 2008 does not utilise nameprep protocol")
- .venv/lib/python3.12/site-packages/setuptools/_shutil.py:17: pass
- .venv/lib/python3.12/site-packages/setuptools/unicode_utils.py:18: pass  # Not UTF-8
- .venv/lib/python3.12/site-packages/setuptools/unicode_utils.py:99: # TODO: Add a deadline?
- .venv/lib/python3.12/site-packages/setuptools/_scripts.py:33: those passed to Popen.
- .venv/lib/python3.12/site-packages/setuptools/archive_util.py:42: (which may be the same as the one passed in), or else ``None`` to skip
- .venv/lib/python3.12/site-packages/setuptools/archive_util.py:214: pass
- .venv/lib/python3.12/site-packages/setuptools/dist.py:129: # TODO: define due_date, it may break old packages that are no longer
- .venv/lib/python3.12/site-packages/setuptools/dist.py:174: # TODO: should there be a `due_date` here?
- .venv/lib/python3.12/site-packages/setuptools/dist.py:443: # TODO: Should we add a due date? It may affect old/unmaintained
- .venv/lib/python3.12/site-packages/setuptools/dist.py:876: the value passed to 'include()'.  So, 'dist.include(foo={"bar":"baz"})'
- .venv/lib/python3.12/site-packages/setuptools/dist.py:969: the value passed to 'exclude()'.  So, 'dist.exclude(foo={"bar":"baz"})'
- .venv/lib/python3.12/site-packages/setuptools/installer.py:116: # If requirement is a PEP 508 direct URL, directly pass
- .venv/lib/python3.12/site-packages/setuptools/extension.py:47: In the case ``.pyx`` files are passed as ``sources and`` ``Cython`` is **not**
- .venv/lib/python3.12/site-packages/setuptools/extension.py:113: any extra options to pass to SWIG if a source file has the .i
- .venv/lib/python3.12/site-packages/setuptools/msvc.py:344: pass
- .venv/lib/python3.12/site-packages/setuptools/_normalization.py:124: TODO: replace this with filename_component after pip 24 is
- .venv/lib/python3.12/site-packages/setuptools/_normalization.py:148: # TODO: Replace with only safe_version in the future (no need for best effort)
- .venv/lib/python3.12/site-packages/setuptools/build_meta.py:154: - pip will pass both key and value as strings and overwriting repeated keys
- .venv/lib/python3.12/site-packages/setuptools/build_meta.py:158: This means that an option passed by build can be ``str | list[str] | None``.
- .venv/lib/python3.12/site-packages/setuptools/build_meta.py:268: Users may expect to pass arbitrary lists of arguments to a command
- .venv/lib/python3.12/site-packages/setuptools/__init__.py:198: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/__init__.py:207: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/__init__.py:216: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/discovery.py:129: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/discovery.py:144: All the packages found in 'where' that pass the 'include' filter, but
- .venv/lib/python3.12/site-packages/setuptools/_entry_points.py:5: from jaraco.functools import pass_none
- .venv/lib/python3.12/site-packages/setuptools/_entry_points.py:85: @pass_none
- .venv/lib/python3.12/site-packages/setuptools/_static.py:24: _mutated_: bool = False  # TODO: Remove after deprecation warning is solved
- .venv/lib/python3.12/site-packages/setuptools/_static.py:41: # TODO: After deprecation period raise NotImplementedError instead of warning
- .venv/lib/python3.12/site-packages/setuptools/_static.py:62: pass
- .venv/lib/python3.12/site-packages/setuptools/_static.py:66: pass
- .venv/lib/python3.12/site-packages/setuptools/_core_metadata.py:122: # TODO: Replace with `raise ValueError("newlines not allowed")`
- .venv/lib/python3.12/site-packages/setuptools/config/expand.py:283: If the ``fill_package_dir`` argument is passed, this function will consider it as a
- .venv/lib/python3.12/site-packages/setuptools/config/_apply_pyprojecttoml.py:344: # TODO: remove check when `bdist_wheel` has been fully removed from pypa/wheel
- .venv/lib/python3.12/site-packages/setuptools/config/_apply_pyprojecttoml.py:520: # TODO: Consider removing this check in the future?
- .venv/lib/python3.12/site-packages/setuptools/config/setupcfg.py:104: # TODO: Temporary cast until mypy 1.12 is released with upstream fixes from typeshed
- .venv/lib/python3.12/site-packages/setuptools/config/setupcfg.py:274: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/setuptools/config/setupcfg.py:651: # TODO: define due date, see setuptools.dist:check_nsp.
- .venv/lib/python3.12/site-packages/setuptools/config/setupcfg.py:770: # TODO: should we include due_date here? Initially introduced in 6 Aug 2022.
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:35: raise JsonSchemaValueException("" + (name_prefix or "data") + " must be object", value=data, name="" + (name_prefix or "
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:43: raise JsonSchemaValueException("" + (name_prefix or "data") + ".build-system must be object", value=data__buildsystem, n
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:48: raise JsonSchemaValueException("" + (name_prefix or "data") + ".build-system must contain " + (str(sorted(data__buildsys
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:73: raise JsonSchemaValueException("" + (name_prefix or "data") + ".build-system.backend-path must be array", value=data__bu
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:79: raise JsonSchemaValueException("" + (name_prefix or "data") + ".build-system.backend-path[{data__buildsystem__backendpat
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:81: raise JsonSchemaValueException("" + (name_prefix or "data") + ".build-system must not contain "+str(data__buildsystem_ke
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:90: raise JsonSchemaValueException("" + (name_prefix or "data") + ".tool must be object", value=data__tool, name="" + (name_
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:129: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:148: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:154: raise JsonSchemaValueException("" + (name_prefix or "data") + " must not contain "+str(data_keys)+" properties", value=d
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:159: raise JsonSchemaValueException("" + (name_prefix or "data") + " must be object", value=data, name="" + (name_prefix or "
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:211: raise JsonSchemaValueException("" + (name_prefix or "data") + ".script-files must be array", value=data__scriptfiles, na
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:243: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:248: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:278: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:283: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:326: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:332: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:380: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:386: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:411: raise JsonSchemaValueException("" + (name_prefix or "data") + ".py-modules must be array", value=data__pymodules, name="
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:472: raise JsonSchemaValueException("" + (name_prefix or "data") + ".license-files must be array", value=data__licensefiles, 
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:495: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:500: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:558: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:578: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:589: raise JsonSchemaValueException("" + (name_prefix or "data") + " must not contain "+str(data_keys)+" properties", value=d
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:599: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:611: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:638: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:650: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:743: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:749: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:953: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:962: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:969: raise JsonSchemaValueException("" + (name_prefix or "data") + " must be object", value=data, name="" + (name_prefix or "
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:988: raise JsonSchemaValueException("" + (name_prefix or "data") + " must be object", value=data, name="" + (name_prefix or "
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1009: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1012: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1016: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1030: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1044: raise JsonSchemaValueException("" + (name_prefix or "data") + " must contain " + (str(sorted(data__missing_keys)) + " pr
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1076: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1080: raise JsonSchemaValueException("" + (name_prefix or "data") + ".readme must be object", value=data__readme, name="" + (n
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1096: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1111: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1118: raise JsonSchemaValueException("" + (name_prefix or "data") + ".readme must contain " + (str(sorted(data__readme__missin
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1124: raise JsonSchemaValueException("" + (name_prefix or "data") + ".readme.content-type must be string", value=data__readme_
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1126: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1128: raise JsonSchemaValueException("" + (name_prefix or "data") + ".readme must be valid exactly by one definition" + (" (" 
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1149: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1166: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1183: except JsonSchemaValueException: pass
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/fastjsonschema_validations.py:1349: raise JsonSchemaValueException("" + (name_prefix or "data") + " must not contain "+str(data_keys)+" properties", value=d
- .venv/lib/python3.12/site-packages/setuptools/config/_validate_pyproject/extra_validations.py:78: # TODO: check for `include-group` cycles (can be conditional to graphlib)
- .venv/lib/python3.12/site-packages/setuptools/command/install.py:109: msg = "For best results, pass -X:Frames to enable call stack."
- .venv/lib/python3.12/site-packages/setuptools/command/build_py.py:237: pass  # Lazily compute data files in _get_data_files() function.
- .venv/lib/python3.12/site-packages/setuptools/command/build_py.py:244: pass
- .venv/lib/python3.12/site-packages/setuptools/command/build_clib.py:21: * cflags   - specify a list of additional flags to pass to
- .venv/lib/python3.12/site-packages/setuptools/command/sdist.py:95: pass
- .venv/lib/python3.12/site-packages/setuptools/command/sdist.py:101: pass
- .venv/lib/python3.12/site-packages/setuptools/command/egg_info.py:200: pass
- .venv/lib/python3.12/site-packages/setuptools/command/egg_info.py:204: pass
- .venv/lib/python3.12/site-packages/setuptools/command/egg_info.py:537: pass
- .venv/lib/python3.12/site-packages/setuptools/command/egg_info.py:673: TODO: Remove this function in a version sufficiently > 68.
- .venv/lib/python3.12/site-packages/setuptools/command/egg_info.py:718: """Deprecated behavior warning for EggInfo, bypassing suppression."""
- .venv/lib/python3.12/site-packages/setuptools/command/dist_info.py:101: # TODO: if bdist_wheel if merged into setuptools, just add "keep_egg_info" there
- .venv/lib/python3.12/site-packages/setuptools/command/build_ext.py:75: pass
- .venv/lib/python3.12/site-packages/setuptools/command/build_ext.py:462: assert output_dir is None  # distutils build_ext doesn't pass this
- .venv/lib/python3.12/site-packages/setuptools/command/editable_wheel.py:62: COMPAT = "compat"  # TODO: Remove `compat` after Dec/2022.
- .venv/lib/python3.12/site-packages/setuptools/command/editable_wheel.py:83: # TODO: define due_date
- .venv/lib/python3.12/site-packages/setuptools/command/editable_wheel.py:290: # TODO: Once plugins/customizations had the chance to catch up, replace
- .venv/lib/python3.12/site-packages/setuptools/command/editable_wheel.py:323: # TODO: define due_date
- .venv/lib/python3.12/site-packages/setuptools/command/editable_wheel.py:428: pass
- .venv/lib/python3.12/site-packages/setuptools/command/editable_wheel.py:584: # TODO: Python 3.13 replace the whole function with `bytes(content, "utf-8")`
- .venv/lib/python3.12/site-packages/setuptools/command/editable_wheel.py:595: with suppress(AttributeError, NotImplementedError, OSError):
- .venv/lib/python3.12/site-packages/setuptools/command/test.py:39: pass
- .venv/lib/python3.12/site-packages/setuptools/command/test.py:42: pass
- .venv/lib/python3.12/site-packages/setuptools/command/develop.py:45: pass
- .venv/lib/python3.12/site-packages/setuptools/command/install_lib.py:62: # TODO: is it necessary to short-circuit here? i.e. what's the cost
- .venv/lib/python3.12/site-packages/setuptools/command/bdist_egg.py:268: pass
- .venv/lib/python3.12/site-packages/setuptools/command/bdist_wheel.py:72: # TODO armv8l, packaging pull request #690 => this did not land
- .venv/lib/python3.12/site-packages/setuptools/command/bdist_wheel.py:327: # TODO armv8l, packaging pull request #690 => this did not land
- .venv/lib/python3.12/site-packages/setuptools/tests/script-with-bom.py:1: result = 'passed'
- .venv/lib/python3.12/site-packages/setuptools/tests/environment.py:14: # when upgrading Setuptools. Bypass this behavior by avoiding the
- .venv/lib/python3.12/site-packages/setuptools/tests/environment.py:27: # Unless the test sets its own special env, pass a copy of the existing
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_meta.py:545: Some users might pass metadata_directory pre-populated with `.tox` or `.venv`.
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_meta.py:809: # attributes passed to MinimalDistribution
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_meta.py:867: _sys_argv_0_passthrough = {
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_meta.py:885: def test_sys_argv_passthrough(self, tmpdir_cwd):
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_meta.py:886: path.build(self._sys_argv_0_passthrough)
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_meta.py:926: # This must fail in build_meta, but must pass in build_meta_legacy
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_meta.py:932: def test_sys_argv_passthrough(self, tmpdir_cwd):
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_meta.py:933: path.build(self._sys_argv_0_passthrough)
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_ext.py:72: # Mock value needed to pass tests
- .venv/lib/python3.12/site-packages/setuptools/tests/test_sdist.py:81: pass  # Not UTF-8
- .venv/lib/python3.12/site-packages/setuptools/tests/test_sdist.py:123: except (OSError, NotImplementedError):
- .venv/lib/python3.12/site-packages/setuptools/tests/test_bdist_wheel.py:299: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/test_bdist_wheel.py:668: # TODO: Remove this test after deprecation period is over
- .venv/lib/python3.12/site-packages/setuptools/tests/test_core_metadata.py:162: 'Bypass normalized version',
- .venv/lib/python3.12/site-packages/setuptools/tests/test_core_metadata.py:596: # TODO: Handle lack of PEP 643 implementation in pypa/wheel?
- .venv/lib/python3.12/site-packages/setuptools/tests/test_editable_install.py:1039: # TODO: Remove `compat` after Dec/2022.
- .venv/lib/python3.12/site-packages/setuptools/tests/test_editable_install.py:1099: # TODO: Remove tests after _run_build_steps is removed.
- .venv/lib/python3.12/site-packages/setuptools/tests/test_editable_install.py:1164: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_py.py:169: # TODO: To fix #3260 we need some transition period to deprecate the
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build_py.py:199: # TODO: Enforce the following assertion once #3260 is fixed
- .venv/lib/python3.12/site-packages/setuptools/tests/test_setuptools.py:119: # TODO: Evaluate if this code is needed at all.
- .venv/lib/python3.12/site-packages/setuptools/tests/test_setuptools.py:255: except (OSError, NotImplementedError, AttributeError):
- .venv/lib/python3.12/site-packages/setuptools/tests/test_egg_info.py:25: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/test_egg_info.py:485: Packages that pass unordered install_requires sequences
- .venv/lib/python3.12/site-packages/setuptools/tests/fixtures.py:137: # TODO: Use `--no-wheel` when setuptools implements its own bdist_wheel
- .venv/lib/python3.12/site-packages/setuptools/tests/contexts.py:82: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build.py:27: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build.py:30: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/test_build.py:33: raise NotImplementedError("just to check if the command runs")
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_apply_pyprojecttoml.py:166: def main_cli(): pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_apply_pyprojecttoml.py:167: def main_gui(): pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_apply_pyprojecttoml.py:168: def main_tomatoes(): pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_setupcfg.py:75: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_setupcfg.py:390: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_setupcfg.py:395: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_setupcfg.py:400: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_setupcfg.py:422: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_setupcfg.py:712: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_setupcfg.py:731: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_setupcfg.py:753: pass
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_setupcfg.py:908: "from distutils.core import Command\nclass CustomCmd(Command): pass\n",
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_pyprojecttoml.py:96: "mod.py": "class CustomSdist: pass",
- .venv/lib/python3.12/site-packages/setuptools/tests/config/test_expand.py:154: ``read_attr`` should bypass these limitations by resolving modules statically
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:251: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:304: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:383: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:581: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:795: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:804: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:813: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:822: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:830: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:841: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:852: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:948: # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1088: deprecated_thing = "Failing to pass a value for the 'fields' parameter"
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1096: "using the functional syntax, pass an empty dictionary, e.g. "
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1218: - If no dict arguments are passed, an attempt is made to use the
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1223: - If one dict argument is passed, it is used for both globals and
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1226: - If two dict arguments are passed, they specify globals and
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1512: # PEP 695 implemented (3.12+), can pass infer_variance to typing.TypeVar
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1620: # PEP 695 implemented, can pass infer_variance to typing.TypeVar
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1756: # Hack to get typing._type_check to pass.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1758: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1785: # Hack to get typing._type_check to pass in Generic.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:1787: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:2147: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:2700: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:2725: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:2744: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:2748: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:2767: The deprecation message passed to the decorator is saved in the
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:3050: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:3123: # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:3158: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:3217: deprecated_thing = "Failing to pass a value for the 'fields' parameter"
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:3223: "pass an empty list, e.g. "
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:3228: "Cannot pass `None` as the 'fields' parameter "
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:3238: "pass an empty list, e.g. "
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:3563: The string value passed is available in the attribute ``documentation``.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typing_extensions.py:3591: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:60: # os.symlink on Windows prior to 6.0 raises NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:63: symlink_exception = (AttributeError, NotImplementedError, OSError)
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:272: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:275: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:278: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:281: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:284: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:287: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:290: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:293: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:296: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:299: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:302: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:638: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:728: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:1649: # are passed to the caller as exceptions.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:2114: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:2119: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:2578: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:2583: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/backports/tarfile/__init__.py:2734: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/recipes.py:544: *key* and *reverse* are passed to :func:`sorted`.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/recipes.py:585: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/recipes.py:887: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:571: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:658: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:1768: To sort by a function of the elements of the iterable, pass a *key*
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:1795: # if key_list contains a single item, pass the item at that offset
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:1801: # tuple of items, which we pass as *args to the key function
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:2024: and pass a *keyfunc* that extracts the first element and a *valuefunc*
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3108: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3131: Use *window_size* to control the number of items passed as arguments to
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3136: >>> pred = lambda *args: args == (0, 1, 2)  # 3 items passed to pred
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3252: Yield items from *iterable* until *limit_seconds* have passed.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3330: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3490: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3513: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3662: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3771: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3989: """Yield all arguments passed to the function in the same order in which
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:3990: they were passed. If an argument itself is iterable then iterate over its
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:4305: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/more_itertools/more.py:4640: Also accepts ``*args`` and ``**kwargs`` that are passed to ``func``.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/context.py:217: ...     pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/context.py:297: def passes(self, func):
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/context.py:305: >>> passes = ExceptionTrap(ValueError).passes
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/context.py:309: >>> @passes
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:272: Use functools.partial to pass parameters to the initial call
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:314: with whatever parameters were passed, returning its result.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:394: def pass_none(func):
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:398: >>> print_text = pass_none(print)
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:507: Provide an expression to ``use`` to pass through particular parameters.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:542: def bypass_when(check, *, _op=identity):
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:546: >>> bypassed = []  # False
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:548: >>> @bypass_when(bypassed)
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:553: >>> bypassed[:] = [object()]  # True
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:568: def bypass_unless(check):
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:574: >>> @bypass_unless(enabled)
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:583: return bypass_when(check, _op=operator.not_)
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/functools/__init__.py:600: Wrap func to expect its parameters to be passed positionally in a tuple.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/text/__init__.py:139: @_unicode_trap.passes
- .venv/lib/python3.12/site-packages/setuptools/_vendor/jaraco/collections/__init__.py:146: One may supply keyword parameters to be passed to the sort function used
- .venv/lib/python3.12/site-packages/setuptools/_vendor/tomli/_parser.py:237: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/platformdirs/api.py:44: Typically, it is the owning company name. Defaults to `appname`. You may pass ``False`` to disable it.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/platformdirs/windows.py:205: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/_vendor/platformdirs/windows.py:256: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/zipp/__init__.py:352: >>> pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/zipp/__init__.py:365: separate ZipFile object or pass a filename.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/zipp/__init__.py:385: of ``pathlib.Path.open()`` by passing arguments through
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/_elffile.py:20: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/markers.py:181: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/_parser.py:26: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/tags.py:222: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/tags.py:378: # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/specifiers.py:506: :meth:`contains` with no ``prereleases`` argument passed.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/specifiers.py:693: It can be passed a single specifier (``>=3.0``), a comma-separated list of
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/specifiers.py:738: # pass that through here.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/specifiers.py:871: :meth:`contains` with no ``prereleases`` argument passed.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/requirements.py:29: # TODO: Can we test whether something is contained within a requirement?
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/requirements.py:32: # TODO: Can we normalize the name and extra name?
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/metadata.py:204: # TODO: The spec doesn't say anything about if the keys should be
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/metadata.py:512: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/metadata.py:520: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/metadata.py:806: description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/metadata.py:848: # PEP 685 lets us raise an error if an extra doesn't pass `Name` validation
- .venv/lib/python3.12/site-packages/setuptools/_vendor/packaging/licenses/__init__.py:108: # Take a final pass to check for unknown licenses/exceptions.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_checkers.py:539: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_checkers.py:586: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_checkers.py:725: # TODO: raise exception on added keyword-only arguments without defaults
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_checkers.py:736: # TODO: implement assignability checks for non-callable members
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_checkers.py:786: pass  # No-op for now
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_transformer.py:305: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_transformer.py:308: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_transformer.py:324: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_transformer.py:522: # but we've optimised it's body away, we add a `pass` statement.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_transformer.py:844: # Replace a placeholder "pass" at the end
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_transformer.py:939: # Rmove any placeholder "pass" at the end
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_importhook.py:157: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/typeguard/_importhook.py:172: pass  # already removed
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:87: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:91: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:95: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:99: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:103: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:107: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:111: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:1472: "impasses",
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:1998: ),  # TODO: isn't ue$ -> u encompassed in the following rule?
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:2254: # Probably passed a variable name.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:2255: # Or passed a single word without wrapping it in quotes as an argument
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:2558: Returns False when a singular noun is passed.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:2768: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:2773: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:2790: )  # TODO: what if 2 spaces between these words?
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:3261: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:3266: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/inflect/__init__.py:3282: )  # TODO: what if 2 spaces between these words?
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/errors.py:21: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoasync.py:54: def autoasync(coro=None, *, loop=None, forever=False, pass_loop=False):
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoasync.py:72: If `pass_loop` is True, the event loop object is passed into the coroutine
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoasync.py:91: @autoasync(forever=True, pass_loop=True)
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoasync.py:102: pass_loop=pass_loop)
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoasync.py:108: if pass_loop:
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoasync.py:122: if pass_loop:
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoasync.py:137: # Attach the updated signature. This allows 'pass_loop' to be used with
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoasync.py:139: if pass_loop:
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/__init__.py:27: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/automain.py:23: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/automain.py:31: the program is `sys.exit`ed with the return value. You can also pass `True`
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autocommand.py:23: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autocommand.py:34: pass_loop=False):
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autocommand.py:42: # event that pass_loop is True, the `loop` parameter of the original
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autocommand.py:45: if loop is not None or forever or pass_loop:
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autocommand.py:49: pass_loop=pass_loop,
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autocommand.py:53: # parsed and passed *before* entering the asyncio event loop, if it
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autocommand.py:56: # passing are still raised if `forever` is True.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoparse.py:139: # TODO: special case for list type.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoparse.py:152: # TODO: consider depluralizing metavar/name here.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/autocommand/autoparse.py:303: # TODO: attach an updated __signature__ to autoparse_wrapper, just in case.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/__init__.py:27: from ._functools import method_cache, pass_none
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/__init__.py:343: the default implementation of some properties to bypass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/__init__.py:401: Pass a ``context`` or pass keyword arguments for constructing
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/__init__.py:505: @pass_none
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/__init__.py:513: @pass_none
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/__init__.py:585: return pass_none(self._deps_from_requires_text)(source)
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/__init__.py:631: return pass_none(json.loads)(
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/__init__.py:922: pass_none(Prepared.normalize)(self._name_from_stem(stem))
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/_functools.py:89: def pass_none(func):
- .venv/lib/python3.12/site-packages/setuptools/_vendor/importlib_metadata/_functools.py:93: >>> print_text = pass_none(print)
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/macosx_libfile.py:331: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/_bdist_wheel.py:92: # TODO armv8l, packaging pull request #690 => this did not land
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/_bdist_wheel.py:344: # TODO armv8l, packaging pull request #690 => this did not land
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/wheelfile.py:155: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/metadata.py:122: extras_require is a dictionary of {extra: [requirements]} as passed to setup(),
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/_elffile.py:18: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/markers.py:115: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/_parser.py:24: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/tags.py:225: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/tags.py:382: # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/specifiers.py:504: :meth:`contains` with no ``prereleases`` argument passed.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/specifiers.py:693: It can be passed a single specifier (``>=3.0``), a comma-separated list of
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/specifiers.py:729: # pass that through here.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/specifiers.py:862: :meth:`contains` with no ``prereleases`` argument passed.
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/requirements.py:28: # TODO: Can we test whether something is contained within a requirement?
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/vendored/packaging/requirements.py:31: # TODO: Can we normalize the name and extra name?
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/cli/convert.py:111: pass
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/cli/convert.py:155: # For any other file, just pass it through
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/cli/convert.py:184: # For any other file, just pass it through
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/cli/convert.py:278: # For any other file, just pass it through
- .venv/lib/python3.12/site-packages/setuptools/_vendor/wheel/cli/__init__.py:14: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/version.py:19: if supplied, is passed to 'parse'
- .venv/lib/python3.12/site-packages/setuptools/_distutils/version.py:20: * __str__ reconstructs the string that was passed to 'parse' (or
- .venv/lib/python3.12/site-packages/setuptools/_distutils/version.py:324: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/sysconfig.py:22: from jaraco.functools import pass_none
- .venv/lib/python3.12/site-packages/setuptools/_distutils/sysconfig.py:80: @pass_none
- .venv/lib/python3.12/site-packages/setuptools/_distutils/sysconfig.py:114: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/sysconfig.py:150: @pass_none
- .venv/lib/python3.12/site-packages/setuptools/_distutils/sysconfig.py:396: optional dictionary is passed in as the second argument, it is
- .venv/lib/python3.12/site-packages/setuptools/_distutils/sysconfig.py:413: optional dictionary is passed in as the second argument, it is
- .venv/lib/python3.12/site-packages/setuptools/_distutils/sysconfig.py:590: @pass_none
- .venv/lib/python3.12/site-packages/setuptools/_distutils/fancy_getopt.py:8: * options set attributes of a passed-in object
- .venv/lib/python3.12/site-packages/setuptools/_distutils/fancy_getopt.py:43: * options set attributes of a passed-in object
- .venv/lib/python3.12/site-packages/setuptools/_distutils/fancy_getopt.py:76: # parse the command-line, since the 'option_table' passed in here
- .venv/lib/python3.12/site-packages/setuptools/_distutils/fancy_getopt.py:232: 'args' is a modified copy of the passed-in 'args' list, which
- .venv/lib/python3.12/site-packages/setuptools/_distutils/fancy_getopt.py:302: # First pass: determine maximum length of long option names
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:23: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:30: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:39: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:45: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:52: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:60: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:71: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:78: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:86: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:93: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/errors.py:100: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/dist.py:66: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/dist.py:68: # passing a tuple or an iterator perhaps, warn and convert
- .venv/lib/python3.12/site-packages/setuptools/_distutils/dist.py:85: Distribution for some specialized purpose, and then pass the subclass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/dist.py:235: self.password = ''
- .venv/lib/python3.12/site-packages/setuptools/_distutils/dist.py:294: # If attrs['script_args'] wasn't passed, assume false.
- .venv/lib/python3.12/site-packages/setuptools/_distutils/extension.py:78: any extra options to pass to SWIG if a source file has the .i
- .venv/lib/python3.12/site-packages/setuptools/_distutils/extension.py:162: # First pass over the file to gather "VAR = VALUE" assignments.
- .venv/lib/python3.12/site-packages/setuptools/_distutils/extension.py:165: # Second pass to gobble up the real content: lines of the form
- .venv/lib/python3.12/site-packages/setuptools/_distutils/extension.py:182: if _variable_rx.match(line):  # VAR=VALUE, handled in first pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/file_util.py:147: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/file_util.py:223: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/_macos_compat.py:5: def bypass_compiler_fixup(cmd, args):
- .venv/lib/python3.12/site-packages/setuptools/_distutils/_macos_compat.py:12: compiler_fixup = bypass_compiler_fixup
- .venv/lib/python3.12/site-packages/setuptools/_distutils/__init__.py:14: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/versionpredicate.py:81: If any version numbers passed in do not conform to the
- .venv/lib/python3.12/site-packages/setuptools/_distutils/core.py:224: if you need to find out the distribution meta-data (passed as
- .venv/lib/python3.12/site-packages/setuptools/_distutils/core.py:275: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/util.py:22: from jaraco.functools import pass_none
- .venv/lib/python3.12/site-packages/setuptools/_distutils/util.py:123: @pass_none
- .venv/lib/python3.12/site-packages/setuptools/_distutils/util.py:128: If None is passed, will just pass it through as
- .venv/lib/python3.12/site-packages/setuptools/_distutils/util.py:181: # password database, do nothing
- .venv/lib/python3.12/site-packages/setuptools/_distutils/util.py:182: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/text_file.py:193: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/install.py:162: # Bypass the preferred scheme, which may not
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/bdist.py:158: # passing the owner and group names for tar archiving
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/bdist_rpm.py:98: ('no-rpm-opt-flags', None, "do not pass any RPM CFLAGS to compiler"),
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/bdist_rpm.py:225: # don't pass CFLAGS to pure python distributions
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/bdist_rpm.py:428: # invocation of brp-python-bytecompile passes in __python):
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/check.py:65: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/config.py:82: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/config.py:158: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/install_lib.py:88: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/command/clean.py:77: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/msvc.py:405: # pass the full pathname to MSVC in debug mode,
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/msvc.py:482: pass  # XXX what goes here?
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:292: to the list passed to 'set_include_dirs()'.  This does not affect
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:558: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:582: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:664: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:696: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:762: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:866: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:872: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:878: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:892: The libraries argument is a list of flags to be passed to the
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:979: raise NotImplementedError
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/base.py:1369: with some compiler (depending on the two format strings passed in).
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/unix.py:332: # be told to pass the -R option through to the linker, whereas
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/unix.py:354: # For all compilers, `-Wl` is the presumed way to pass a
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/tests/test_msvc.py:46: Ensure a specified target platform is passed to _get_vcvars_spec.
- .venv/lib/python3.12/site-packages/setuptools/_distutils/compilers/C/tests/test_msvc.py:76: # This function cannot be mocked, so pass if VC is found
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/support.py:63: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/support.py:87: """Function needed to make build_ext tests pass.
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_sysconfig.py:246: # try_compile may pass or it may fail if no compiler
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_check.py:163: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_check.py:173: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_archive_util.py:256: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_dist.py:378: # should have warning about passing a non-list
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_dist.py:400: # should have warning about passing a non-list
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_dist.py:422: # should have warning about passing a non-list
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_build_clib.py:77: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_util.py:138: result = pwd.struct_passwd((
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_build_ext.py:87: # TODO: can the file be scheduled for deletion?
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_build_ext.py:249: cmd.run()  # should pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_build_ext.py:351: # ok this one should pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_build_ext.py:357: # check_extensions_list adds in ext the values passed
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_cmd.py:14: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_build_scripts.py:55: pass
- .venv/lib/python3.12/site-packages/setuptools/_distutils/tests/test_build_scripts.py:60: pass
- .venv/lib/python3.12/site-packages/urllib3/exceptions.py:121: """Raised when passing an invalid state to a timeout"""
- .venv/lib/python3.12/site-packages/urllib3/exceptions.py:306: # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:125: Host used for this HTTP Connection (e.g. "localhost"), passed into
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:129: Port used for this HTTP Connection (None is equivalent to 80), passed
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:226: # Do not pass 'self' as callback to 'finalize'.
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:228: # By just passing a reference to the pool allows the garbage collector
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:285: pass  # Oh well, we'll create a new connection then
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:314: pass
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:344: pass
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:354: # User passed us an int/float. This is for backwards compatibility,
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:364: """Is the error actually a timeout? Will raise a ReadTimeout or pass"""
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:508: pass
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:578: # TODO: Add optional support for socket.gethostbyname checking.
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:733: # passed down into the recursive call, and its value will be respected.
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:972: ``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:994: key_password: str | None = None,
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1020: self.key_password = key_password
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1073: key_password=self.key_password,
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1095: # TODO revise this, see https://github.com/urllib3/urllib3/issues/2791
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1153: # Specifically, if we include brackets but also pass the port then
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1155: # Instead, we need to make sure we never pass ``None`` as the port.
- .venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1178: pass  # Done.
- .venv/lib/python3.12/site-packages/urllib3/fields.py:69: pass
- .venv/lib/python3.12/site-packages/urllib3/poolmanager.py:48: "key_password",
- .venv/lib/python3.12/site-packages/urllib3/poolmanager.py:72: key_key_password: str | None
- .venv/lib/python3.12/site-packages/urllib3/poolmanager.py:407: pass
- .venv/lib/python3.12/site-packages/urllib3/__init__.py:32: pass
- .venv/lib/python3.12/site-packages/urllib3/_request_methods.py:64: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/urllib3/connection.py:38: pass
- .venv/lib/python3.12/site-packages/urllib3/connection.py:96: you might pass:
- .venv/lib/python3.12/site-packages/urllib3/connection.py:104: Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).
- .venv/lib/python3.12/site-packages/urllib3/connection.py:330: # TODO: Fix tunnel so it doesn't depend on self.sock state.
- .venv/lib/python3.12/site-packages/urllib3/connection.py:436: # object later. TODO: Remove this in favor of a real
- .venv/lib/python3.12/site-packages/urllib3/connection.py:559: # Save a reference to the shutdown function before ownership is passed
- .venv/lib/python3.12/site-packages/urllib3/connection.py:561: # TODO should we implement it everywhere?
- .venv/lib/python3.12/site-packages/urllib3/connection.py:599: Many of the parameters to this constructor are passed to the underlying SSL
- .venv/lib/python3.12/site-packages/urllib3/connection.py:641: key_password: str | None = None,
- .venv/lib/python3.12/site-packages/urllib3/connection.py:656: self.key_password = key_password
- .venv/lib/python3.12/site-packages/urllib3/connection.py:682: key_password: str | None = None,
- .venv/lib/python3.12/site-packages/urllib3/connection.py:711: self.key_password = key_password
- .venv/lib/python3.12/site-packages/urllib3/connection.py:801: key_password=self.key_password,
- .venv/lib/python3.12/site-packages/urllib3/connection.py:878: key_password=None,
- .venv/lib/python3.12/site-packages/urllib3/connection.py:904: key_password: str | None,
- .venv/lib/python3.12/site-packages/urllib3/connection.py:914: """Logic for constructing an SSLContext from all TLS parameters, passing
- .venv/lib/python3.12/site-packages/urllib3/connection.py:973: key_password=key_password,
- .venv/lib/python3.12/site-packages/urllib3/response.py:56: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:59: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:390: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:399: To use a custom JSON decoder pass the result of :attr:`HTTPResponse.data` to
- .venv/lib/python3.12/site-packages/urllib3/response.py:415: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:419: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:423: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:439: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:447: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:454: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:461: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:464: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:467: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:470: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:473: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/urllib3/response.py:498: Decode the data passed in and potentially flush the decoder.
- .venv/lib/python3.12/site-packages/urllib3/response.py:682: pass
- .venv/lib/python3.12/site-packages/urllib3/response.py:1005: # TODO make sure to initially read enough data to get past the headers
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:40: not_passed = auto()
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:137: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:198: passed_key, passed_val = item
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:199: if isinstance(passed_key, str) and isinstance(passed_val, str):
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:200: return self._headers._has_value_for_header(passed_key, passed_val)
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:211: Additional field-value pairs to pass in to ``dict.update``.
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:224: If multiple fields that are equal case-insensitively are passed to the
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:298: pass
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:375: self, key: str, default: _Sentinel | _DT = _Sentinel.not_passed
- .venv/lib/python3.12/site-packages/urllib3/_collections.py:382: if default is _Sentinel.not_passed:
- .venv/lib/python3.12/site-packages/urllib3/_base_connection.py:20: # TODO: Remove this in favor of a better
- .venv/lib/python3.12/site-packages/urllib3/_base_connection.py:138: key_password: str | None
- .venv/lib/python3.12/site-packages/urllib3/_base_connection.py:164: key_password: str | None = None,
- .venv/lib/python3.12/site-packages/urllib3/http2/__init__.py:38: # TODO: Offer 'http/1.1' as well, but for testing purposes this is handy.
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:94: raise NotImplementedError("Proxies aren't supported with HTTP/2")
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:99: raise NotImplementedError("Tunneling isn't supported with HTTP/2")
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:123: raise NotImplementedError("`skip_host` isn't supported")
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:125: raise NotImplementedError("`skip_accept_encoding` isn't supported")
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:144: # TODO SKIPPABLE_HEADERS from urllib3 are ignored.
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:222: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:234: # TODO: Arbitrary read value.
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:282: # TODO this is often present from upstream.
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:283: # raise NotImplementedError("`chunked` isn't supported with HTTP/2")
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:284: pass
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:314: pass
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:325: # TODO: This is a woefully incomplete response object, but works for non-streaming.
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:332: decode_content: bool = False,  # TODO: support decoding
- .venv/lib/python3.12/site-packages/urllib3/http2/connection.py:356: pass
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:14: - Usernames and passwords for the SOCKS proxy
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:31: When connecting to a SOCKS5 proxy the ``username`` and ``password`` portion
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:32: of the ``proxy_url`` will be sent as the username/password to authenticate
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:37: proxy_url="socks5h://<username>:<password>@proxy-host"
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:80: password: str | None
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:116: proxy_password=self._socks_options["password"],
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:162: pass
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:188: password: str | None = None,
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:195: if username is None and password is None and parsed.auth is not None:
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:198: username, password = split
- .venv/lib/python3.12/site-packages/urllib3/contrib/socks.py:221: "password": password,
- .venv/lib/python3.12/site-packages/urllib3/contrib/pyopenssl.py:34: pass
- .venv/lib/python3.12/site-packages/urllib3/contrib/pyopenssl.py:51: pass
- .venv/lib/python3.12/site-packages/urllib3/contrib/pyopenssl.py:484: password: str | None = None,
- .venv/lib/python3.12/site-packages/urllib3/contrib/pyopenssl.py:488: if password is not None:
- .venv/lib/python3.12/site-packages/urllib3/contrib/pyopenssl.py:489: if not isinstance(password, bytes):
- .venv/lib/python3.12/site-packages/urllib3/contrib/pyopenssl.py:490: password = password.encode("utf-8")  # type: ignore[assignment]
- .venv/lib/python3.12/site-packages/urllib3/contrib/pyopenssl.py:491: self._ctx.set_passwd_cb(lambda *_: password)
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/connection.py:79: pass
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/connection.py:82: pass
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/connection.py:169: key_password: str | None
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/connection.py:203: key_password: str | None = None,
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/connection.py:219: self.key_password = key_password
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/connection.py:242: key_password: str | None = None,
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/connection.py:249: pass
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/fetch.py:92: pass
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/fetch.py:96: pass
- .venv/lib/python3.12/site-packages/urllib3/contrib/emscripten/response.py:212: To use a custom JSON decoder pass the result of :attr:`HTTPResponse.data` to
- .venv/lib/python3.12/site-packages/urllib3/util/url.py:182: print( urllib3.util.Url("https", "username:password",
- .venv/lib/python3.12/site-packages/urllib3/util/url.py:186: # "https://username:password@host.com:80/path?query#fragment"
- .venv/lib/python3.12/site-packages/urllib3/util/url.py:245: uri_bytes = component.encode("utf-8", "surrogatepass")
- .venv/lib/python3.12/site-packages/urllib3/util/url.py:454: # TODO: Remove this when we break backwards compatibility.
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:188: Resolves the argument to a numeric constant, which can be passed to
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:195: constant which can directly be passed to wrap_socket.
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:365: pass
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:386: key_password: str | None = ...,
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:404: key_password: str | None = ...,
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:421: key_password: str | None = None,
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:442: :param key_password:
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:443: Optional password if the keyfile is encrypted.
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:446: passing as the cadata parameter to SSLContext.load_verify_locations()
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:468: # passphrase via the terminal and instead error out.
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:469: if keyfile and key_password is None and _is_key_file_encrypted(keyfile):
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:470: raise SSLError("Client private key is encrypted, password is required")
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:473: if key_password is None:
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:476: context.load_cert_chain(certfile, keyfile, key_password)
- .venv/lib/python3.12/site-packages/urllib3/util/retry.py:61: Retries can be disabled by passing ``False``:
- .venv/lib/python3.12/site-packages/urllib3/util/ssl_match_hostname.py:21: pass
- .venv/lib/python3.12/site-packages/urllib3/util/request.py:28: pass
- .venv/lib/python3.12/site-packages/urllib3/util/request.py:44: pass
- .venv/lib/python3.12/site-packages/urllib3/util/request.py:91: Colon-separated username:password string for 'authorization: basic ...'
- .venv/lib/python3.12/site-packages/urllib3/util/request.py:95: Colon-separated username:password string for 'proxy-authorization: basic ...'
- .venv/lib/python3.12/site-packages/urllib3/util/request.py:115: pass
- .venv/lib/python3.12/site-packages/urllib3/util/request.py:203: transforms them into an iterable of chunks to pass to
- .venv/lib/python3.12/site-packages/urllib3/util/request.py:229: # File-like object, TODO: use seek() and tell() for length?
- .venv/lib/python3.12/site-packages/urllib3/util/request.py:262: # Since it implements the buffer API can be passed directly to socket.sendall()
- .venv/lib/python3.12/site-packages/urllib3/util/timeout.py:15: # This value should never be passed to socket.settimeout() so for safety we use a -1.
- .venv/lib/python3.12/site-packages/urllib3/util/timeout.py:179: passed to this function.
- .venv/lib/python3.12/site-packages/urllib3/util/connection.py:130: pass
- .venv/lib/python3.12/site-packages/urllib3/util/response.py:22: pass
- .venv/lib/python3.12/site-packages/urllib3/util/response.py:28: pass
- .venv/lib/python3.12/site-packages/urllib3/util/response.py:35: pass
- .venv/lib/python3.12/site-packages/urllib3/util/response.py:53: # This will fail silently if we pass in the wrong kind of parameter.
- .venv/lib/python3.12/site-packages/platformdirs/api.py:45: Typically, it is the owning company name. Defaults to `appname`. You may pass ``False`` to disable it.
- .venv/lib/python3.12/site-packages/platformdirs/windows.py:205: raise NotImplementedError
- .venv/lib/python3.12/site-packages/platformdirs/windows.py:256: pass
- .venv/lib/python3.12/site-packages/requests/auth.py:25: def _basic_auth_str(username, password):
- .venv/lib/python3.12/site-packages/requests/auth.py:38: "3.0.0. Please convert the object you've passed in ({!r}) to "
- .venv/lib/python3.12/site-packages/requests/auth.py:45: if not isinstance(password, basestring):
- .venv/lib/python3.12/site-packages/requests/auth.py:47: "Non-string passwords will no longer be supported in Requests "
- .venv/lib/python3.12/site-packages/requests/auth.py:48: "3.0.0. Please convert the object you've passed in ({!r}) to "
- .venv/lib/python3.12/site-packages/requests/auth.py:50: "problems.".format(type(password)),
- .venv/lib/python3.12/site-packages/requests/auth.py:53: password = str(password)
- .venv/lib/python3.12/site-packages/requests/auth.py:59: if isinstance(password, str):
- .venv/lib/python3.12/site-packages/requests/auth.py:60: password = password.encode("latin1")
- .venv/lib/python3.12/site-packages/requests/auth.py:63: b64encode(b":".join((username, password))).strip()
- .venv/lib/python3.12/site-packages/requests/auth.py:73: raise NotImplementedError("Auth hooks must be callable.")
- .venv/lib/python3.12/site-packages/requests/auth.py:79: def __init__(self, username, password):
- .venv/lib/python3.12/site-packages/requests/auth.py:81: self.password = password
- .venv/lib/python3.12/site-packages/requests/auth.py:87: self.password == getattr(other, "password", None),
- .venv/lib/python3.12/site-packages/requests/auth.py:95: r.headers["Authorization"] = _basic_auth_str(self.username, self.password)
- .venv/lib/python3.12/site-packages/requests/auth.py:103: r.headers["Proxy-Authorization"] = _basic_auth_str(self.username, self.password)
- .venv/lib/python3.12/site-packages/requests/auth.py:110: def __init__(self, username, password):
- .venv/lib/python3.12/site-packages/requests/auth.py:112: self.password = password
- .venv/lib/python3.12/site-packages/requests/auth.py:189: A1 = f"{self.username}:{realm}:{self.password}"
- .venv/lib/python3.12/site-packages/requests/auth.py:309: self.password == getattr(other, "password", None),
- .venv/lib/python3.12/site-packages/requests/hooks.py:19: # TODO: response is the only one
- .venv/lib/python3.12/site-packages/requests/adapters.py:136: raise NotImplementedError
- .venv/lib/python3.12/site-packages/requests/adapters.py:140: raise NotImplementedError
- .venv/lib/python3.12/site-packages/requests/adapters.py:158: which we retry a request, import urllib3's ``Retry`` class and pass
- .venv/lib/python3.12/site-packages/requests/adapters.py:257: username, password = get_auth_from_url(proxy)
- .venv/lib/python3.12/site-packages/requests/adapters.py:261: password=password,
- .venv/lib/python3.12/site-packages/requests/adapters.py:567: pass
- .venv/lib/python3.12/site-packages/requests/adapters.py:583: username, password = get_auth_from_url(proxy)
- .venv/lib/python3.12/site-packages/requests/adapters.py:586: headers["Proxy-Authorization"] = _basic_auth_str(username, password)
- .venv/lib/python3.12/site-packages/requests/adapters.py:639: pass
- .venv/lib/python3.12/site-packages/requests/adapters.py:663: # TODO: Remove this in 3.0.0: see #2811
- .venv/lib/python3.12/site-packages/requests/models.py:110: Will successfully encode parameters when passed as a dict or a list of
- .venv/lib/python3.12/site-packages/requests/models.py:140: Will successfully encode files when passed as a dict or a list of
- .venv/lib/python3.12/site-packages/requests/models.py:246: :param auth: Auth handler or (user, pass) tuple.
- .venv/lib/python3.12/site-packages/requests/models.py:544: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/requests/models.py:632: # hooks can be passed as None to the prepare method and to this
- .venv/lib/python3.12/site-packages/requests/models.py:971: pass
- .venv/lib/python3.12/site-packages/requests/cookies.py:80: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/requests/cookies.py:404: # if there are multiple cookies that meet passed in criteria
- .venv/lib/python3.12/site-packages/requests/__init__.py:140: pass
- .venv/lib/python3.12/site-packages/requests/compat.py:38: pass
- .venv/lib/python3.12/site-packages/requests/compat.py:97: proxy_bypass,
- .venv/lib/python3.12/site-packages/requests/compat.py:98: proxy_bypass_environment,
- .venv/lib/python3.12/site-packages/requests/utils.py:45: proxy_bypass,
- .venv/lib/python3.12/site-packages/requests/utils.py:46: proxy_bypass_environment,
- .venv/lib/python3.12/site-packages/requests/utils.py:75: # provide a proxy_bypass version on Windows without DNS lookups
- .venv/lib/python3.12/site-packages/requests/utils.py:77: def proxy_bypass_registry(host):
- .venv/lib/python3.12/site-packages/requests/utils.py:115: def proxy_bypass(host):  # noqa
- .venv/lib/python3.12/site-packages/requests/utils.py:116: """Return True, if the host should be bypassed.
- .venv/lib/python3.12/site-packages/requests/utils.py:122: return proxy_bypass_environment(host)
- .venv/lib/python3.12/site-packages/requests/utils.py:124: return proxy_bypass_registry(host)
- .venv/lib/python3.12/site-packages/requests/utils.py:158: pass
- .venv/lib/python3.12/site-packages/requests/utils.py:237: # Return with login / password
- .venv/lib/python3.12/site-packages/requests/utils.py:248: pass
- .venv/lib/python3.12/site-packages/requests/utils.py:653: This function passes the given URI through an unquote/quote cycle to
- .venv/lib/python3.12/site-packages/requests/utils.py:755: def should_bypass_proxies(url, no_proxy):
- .venv/lib/python3.12/site-packages/requests/utils.py:757: Returns whether we should bypass proxies or not.
- .venv/lib/python3.12/site-packages/requests/utils.py:806: bypass = proxy_bypass(parsed.hostname)
- .venv/lib/python3.12/site-packages/requests/utils.py:808: bypass = False
- .venv/lib/python3.12/site-packages/requests/utils.py:810: if bypass:
- .venv/lib/python3.12/site-packages/requests/utils.py:822: if should_bypass_proxies(url, no_proxy=no_proxy):
- .venv/lib/python3.12/site-packages/requests/utils.py:871: if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):
- .venv/lib/python3.12/site-packages/requests/utils.py:1010: username,password.
- .venv/lib/python3.12/site-packages/requests/utils.py:1017: auth = (unquote(parsed.username), unquote(parsed.password))
- .venv/lib/python3.12/site-packages/requests/sessions.py:50: should_bypass_proxies,
- .venv/lib/python3.12/site-packages/requests/sessions.py:73: # Bypass if not a dictionary (e.g. verify)
- .venv/lib/python3.12/site-packages/requests/sessions.py:322: username, password = get_auth_from_url(new_proxies[scheme])
- .venv/lib/python3.12/site-packages/requests/sessions.py:324: username, password = None, None
- .venv/lib/python3.12/site-packages/requests/sessions.py:328: if not scheme.startswith("https") and username and password:
- .venv/lib/python3.12/site-packages/requests/sessions.py:329: headers["Proxy-Authorization"] = _basic_auth_str(username, password)
- .venv/lib/python3.12/site-packages/requests/sessions.py:743: pass
- .venv/lib/python3.12/site-packages/mpmath/ctx_base.py:22: pass
- .venv/lib/python3.12/site-packages/mpmath/ctx_base.py:57: pass
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:198: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:211: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:245: pass
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:306: # TODO: add more of these, make consistent, write docstrings, ...
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:844: You can specify a custom precision in bits by passing the *prec* keyword
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:847: *exact=True* is passed, an exact addition with no rounding is performed.
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:1293: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/function_docs.py:1529: *primitive=True* is passed, only the primitive roots are returned.
- .venv/lib/python3.12/site-packages/mpmath/function_docs.py:2947: This optimization can be disabled by passing ``eliminate=False``.
- .venv/lib/python3.12/site-packages/mpmath/function_docs.py:8898: as such by passing an integer tuple `(p, q)`. Evaluation is supported for
- .venv/lib/python3.12/site-packages/mpmath/function_docs.py:9370: instead of `m` by passing ``q=<value>``, or you can directly
- .venv/lib/python3.12/site-packages/mpmath/rational.py:103: return NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/rational.py:240: pass
- .venv/lib/python3.12/site-packages/mpmath/usertools.py:5: *input* with every input (*args*, *kwargs*) passed to *f* and
- .venv/lib/python3.12/site-packages/mpmath/usertools.py:21: pass *None* as argument.
- .venv/lib/python3.12/site-packages/mpmath/usertools.py:66: may be passed to time the execution of ``f(*args, **kwargs)``.
- .venv/lib/python3.12/site-packages/mpmath/identification.py:14: pass
- .venv/lib/python3.12/site-packages/mpmath/identification.py:273: # slowly (e.g. a factor 1-10) with each step TODO: we could
- .venv/lib/python3.12/site-packages/mpmath/visualization.py:167: Alternatively, you can select a builtin color function by passing
- .venv/lib/python3.12/site-packages/mpmath/math2.py:207: # TODO: sinpi
- .venv/lib/python3.12/site-packages/mpmath/math2.py:221: # TODO: sinpi
- .venv/lib/python3.12/site-packages/mpmath/math2.py:359: # TODO: could implement complex erf and erfc here. Need
- .venv/lib/python3.12/site-packages/mpmath/math2.py:653: pass
- .venv/lib/python3.12/site-packages/mpmath/math2.py:654: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp_python.py:37: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp_python.py:317: 'raise NotImplementedError("complex modulo")')
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp_python.py:653: except: pass
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp_python.py:663: pass
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp_python.py:670: except: pass
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp_python.py:864: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp_python.py:971: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp_python.py:1008: raise NotImplementedError("%s of a %s" % (name, type(x)))
- .venv/lib/python3.12/site-packages/mpmath/ctx_mp_python.py:1149: pass
- .venv/lib/python3.12/site-packages/mpmath/ctx_iv.py:35: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/ctx_iv.py:551: pass
- .venv/lib/python3.12/site-packages/mpmath/calculus/quadrature.py:14: passing it as the *method* argument.
- .venv/lib/python3.12/site-packages/mpmath/calculus/quadrature.py:41: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/calculus/quadrature.py:127: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/calculus/quadrature.py:524: passing the classes *method=TanhSinh*, *method=GaussLegendre*.
- .venv/lib/python3.12/site-packages/mpmath/calculus/quadrature.py:760: raise NotImplementedError("quadrature must have dim 1, 2 or 3")
- .venv/lib/python3.12/site-packages/mpmath/calculus/quadrature.py:862: passed to :func:`~mpmath.nsum` becomes an *alternating series* and this
- .venv/lib/python3.12/site-packages/mpmath/calculus/approximation.py:156: is to pass it to :func:`~mpmath.fourierval`.
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:9: pass
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:264: # TODO: maybe refactoring with function for divided differences
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:289: # TODO: consider raising a ValueError when there's no sign change in a and b
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:418: # TODO: better condition (when f is very flat)
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:457: # TODO: check whether it's possible to combine it with Illinois stuff
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:503: # TODO: better condition (when f is very flat)
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:560: # TODO: decide not to use convergence acceleration
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:573: # TODO: add Brent
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:601: # TODO: test with user-specified jacobian matrix
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:665: # damping step size TODO: better strategy (hard task)
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:774: The secant method can also be used as an optimization algorithm, by passing
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:984: if verify and norm(f(*xl))**2 > tol: # TODO: better condition?
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:1053: ...             pass
- .venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:1057: ...             pass
- .venv/lib/python3.12/site-packages/mpmath/calculus/inverselaplace.py:13: :func:`~mpmath.invertlaplace` by passing it as the *method*
- .venv/lib/python3.12/site-packages/mpmath/calculus/inverselaplace.py:24: Hoog is default), the algorithm-specific parameters passed (or
- .venv/lib/python3.12/site-packages/mpmath/calculus/inverselaplace.py:27: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/calculus/inverselaplace.py:36: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/calculus/inverselaplace.py:45: does not. The `r` parameter could be passed in as a parameter,
- .venv/lib/python3.12/site-packages/mpmath/calculus/inverselaplace.py:775: *method='cohen'* or by passing the classes *method=FixedTalbot*,
- .venv/lib/python3.12/site-packages/mpmath/calculus/differentiation.py:178: pass
- .venv/lib/python3.12/site-packages/mpmath/calculus/differentiation.py:364: TODO: most exponents are zero, so maybe a sparse representation
- .venv/lib/python3.12/site-packages/mpmath/calculus/odes.py:5: pass
- .venv/lib/python3.12/site-packages/mpmath/calculus/odes.py:219: **TODO**
- .venv/lib/python3.12/site-packages/mpmath/calculus/calculus.py:2: pass
- .venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:129: Optionally, an existing table can be passed to :func:`~mpmath.shanks`.
- .venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:171: (TODO: find a better solution to this problem.)
- .venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:1007: are known, it is more efficient to pass the value of the
- .venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:1161: pass
- .venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:1969: # TODO: we are evaluating log(1+eps) -> eps, which is
- .venv/lib/python3.12/site-packages/mpmath/tests/test_gammazeta.py:599: # TODO: more tests for polyexp
- .venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:273: # TODO: many more tests
- .venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:404: # TODO: need many more tests
- .venv/lib/python3.12/site-packages/mpmath/tests/torture.py:27: TODO:
- .venv/lib/python3.12/site-packages/mpmath/tests/test_hp.py:195: # abs_eps should be 0, but has to be set to 1e-205 to pass the
- .venv/lib/python3.12/site-packages/mpmath/tests/test_hp.py:224: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/tests/test_convert.py:128: pass
- .venv/lib/python3.12/site-packages/mpmath/tests/test_matrices.py:57: # TODO remove exec() wrapper as soon as we drop support for Python <= 3.5
- .venv/lib/python3.12/site-packages/mpmath/tests/test_visualization.py:3: sure that passing custom Axes works.
- .venv/lib/python3.12/site-packages/mpmath/tests/test_linalg.py:1: # TODO: don't use round
- .venv/lib/python3.12/site-packages/mpmath/tests/test_rootfinding.py:75: pass
- .venv/lib/python3.12/site-packages/mpmath/tests/runtests.py:57: # TODO: add a flag for this
- .venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:99: # TODO:
- .venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:136: if current > biggest: # TODO: what if equal?
- .venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:218: # TODO: necessary to check also b?
- .venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:239: raise RuntimeError("need n*n matrix") # TODO: really?
- .venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:372: # TODO: implement this
- .venv/lib/python3.12/site-packages/mpmath/matrices/eigen.py:39: pass
- .venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:3: # TODO: should use diagonalization-based algorithms
- .venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:14: TODO:
- .venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:4: # TODO: interpret list as vectors (for multiplication)
- .venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:208: COMMENT: TODO: the above "doctest:+SKIP" may be removed as soon as we
- .venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:1001: raise NotImplementedError("matrix p-norm for arbitrary p")
- .venv/lib/python3.12/site-packages/mpmath/libmp/backend.py:80: pass
- .venv/lib/python3.12/site-packages/mpmath/libmp/backend.py:92: pass
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:498: # TODO: handle cancellation when c ~=  -1 and ch ~= 1
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:584: # TODO: avoid loss of accuracy
- .venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:342: # TODO: handle rnd direction of the logarithm carefully
- .venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:711: # TODO: if close enough to 1, we could use Taylor series
- .venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:876: # TODO: cleanup the special cases
- .venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1158: # TODO: the best cutoff depends on both x and the precision.
- .venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1249: # TODO: optimize division precision
- .venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:4: TODO: rename, cleanup, perhaps move the gmpy wrapper code
- .venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:129: # TODO: speed up for bases 2, 4, 8, 16, ...
- .venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:458: TODO: speed up using factorization
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:124: # TODO: optimize
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:367: # TODO: combine evaluation code to avoid duplicate modulo
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:388: pass
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:631: # TODO: optimize for real/imag cases
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:643: # TODO: optimize for real/imag cases
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:670: # TODO: accuracy for small x
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:759: # TODO: recognize/speed up real cases, integer y
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:848: # TODO: reflection formula
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:885: # TODO: reflection formula
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:179: # formula to the tail. TODO: choose more intelligently
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:626: TODO: the current estimation of N for m > 0 is *very suboptimal*.
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:628: TODO: implement the reflection formula for m > 0, Re(z) << 0.
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:633: TODO: maybe use exact algorithms to compute psi for integral
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1055: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1160: # TODO: optimize / cleanup interface / unify with list_primes
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1383: TODO: this is currently only used for gamma, but could
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1546: # pass very close to 0, so do floating-point multiply
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1942: # a fixed-point value. TODO: determine a precise cutoff of validity
- .venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1956: pass
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:44: pass
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:54: TODO:
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:199: # TODO: when there are several real parameters and just a few complex
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:332: # TODO: mpf_erf should call mpf_erfc when appropriate (currently
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:355: # TODO: interval rounding
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:574: pass
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:617: # TODO: could return finite imaginary value at -inf
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:635: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:702: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:742: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:911: # TODO: for extremely large x, we could use an asymptotic
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:914: # TODO: recompute at higher precision if the fixed-point mantissa
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1046: TODO:
- .venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1081: # TODO: for |x| << 1/2, one could use fall back to
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:44: pass
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:386: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1175: # TODO: account for precision when doing this
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1320: TODO: the rounding does not work properly for large exponents.
- .venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1414: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:18: # TODO:
- .venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:313: # TODO: something else is required here
- .venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:316: raise NotImplementedError("Gegenbauer function with two limits")
- .venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:373: # TODO: correct evaluation at singularities
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:11: # Avoid division by zero in leading factors (TODO:
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:54: infinite; try passing zeroprec=N or infprec=M to bound finite values between
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:284: # TODO: handle the all-real case more efficiently!
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:285: # TODO: figure out how much precision is needed (exponential growth)
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:306: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:339: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:404: # TODO: the following logic can be simplified
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:432: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:544: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:578: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:697: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:760: # TODO: much of the following could be shared with 2F3 instead of
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:805: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:832: # TODO: much of the following could be shared with 2F3 instead of
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:886: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:971: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:989: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1071: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1073: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1091: # TODO: continuation
- .venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1107: # TODO: continuation
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:68: def _besselj(ctx, n, z): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:69: def _erf(ctx, z): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:70: def _erfc(ctx, z): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:71: def _gamma_upper_int(ctx, z, a): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:72: def _expint_int(ctx, n, z): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:73: def _zeta(ctx, s): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:74: def _zetasum_fast(ctx, s, a, n, derivatives, reflect): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:75: def _ei(ctx, z): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:76: def _e1(ctx, z): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:77: def _ci(ctx, z): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:78: def _si(ctx, z): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:79: def _altzeta(ctx, s): raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:174: # TODO: tests; improve implementation
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:182: # TODO: accurately eval the smaller of the real/imag parts
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:212: # TODO: accurately eval the smaller of the real/imag part
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:257: # TODO: this can be done *much* faster
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:604: # TODO: the following could be generalized into a perfect
- .venv/lib/python3.12/site-packages/mpmath/functions/functions.py:620: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:99: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:100: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:205: raise NotImplementedError("n too large for zetazeros")
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:238: # TODO: fix the interface wrt contexts
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:287: # TODO: for bernpoly and eulerpoly, ensure that all exact zeros are covered
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:385: # TODO: this should be implemented low-level
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:519: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:534: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:535: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:550: #    except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:553: #        pass
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:561: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:564: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:596: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:597: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:620: # TODO: implement for derivatives
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:622: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:631: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:697: # TODO: the following could perhaps be tidied a bit
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:742: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:743: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:793: raise NotImplementedError("arbitrary order derivatives")
- .venv/lib/python3.12/site-packages/mpmath/functions/theta.py:926: # TODO: write _jacobi_theta2a and _jacobi_theta3a using fixed-point
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:28: # TODO: the integer special-casing shouldn't be necessary.
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:54: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:55: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:147: # TODO: avoid cancellation for imaginary arguments
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:232: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:384: # TODO: do this more generically?
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:423: # TODO: could be expressed more elegantly using triple factorials
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:444: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:468: # TODO: limits
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:521: # TODO: asymptotic series for derivatives
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:562: # TODO: limits
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:664: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:678: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:718: # TODO: check that chop=True chops when and only when it should
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:757: # TODO: check that chop=True chops when and only when it should
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:833: TODO: this can be optimized, e.g. by reusing evaluation points.
- .venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:878: # TODO: use v <= j'_{v,1} < y_{v,1}?
- .venv/lib/python3.12/site-packages/mpmath/functions/factorials.py:112: # TODO: fixme, obviously
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:30: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:31: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:35: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:36: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:45: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:46: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:50: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:51: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:203: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:204: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:249: raise NotImplementedError
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:256: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:257: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:265: # TODO: reasonable sign of infinity
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:291: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:314: pass
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:326: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:333: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:360: except NotImplementedError:
- .venv/lib/python3.12/site-packages/mpmath/functions/rszeta.py:326: raise NotImplementedError("Riemann-Siegel can not compute with such precision")
- .venv/lib/python3.12/site-packages/mpmath/functions/rszeta.py:404: # cache.  The bulk of the computation is passed to
- .venv/lib/python3.12/site-packages/mpmath/functions/rszeta.py:835: raise NotImplementedError("Riemann-Siegel can not compute with such precision")
- .venv/lib/python3.12/site-packages/mpmath/functions/rszeta.py:908: # cache.  The bulk of the computation is passed to
- .venv/lib/python3.12/site-packages/mpmath/functions/rszeta.py:1381: raise NotImplementedError
- .venv/lib/python3.12/site-packages/networkx/conftest.py:102: # TODO: The warnings below need to be dealt with, but for now we silence them.
- .venv/lib/python3.12/site-packages/networkx/convert.py:114: pass
- .venv/lib/python3.12/site-packages/networkx/convert.py:143: pass
- .venv/lib/python3.12/site-packages/networkx/convert.py:157: pass
- .venv/lib/python3.12/site-packages/networkx/convert.py:171: pass
- .venv/lib/python3.12/site-packages/networkx/relabel.py:120: # you can pass any callable e.g. f(old_label) -> new_label or
- .venv/lib/python3.12/site-packages/networkx/lazy_imports.py:163: pass
- .venv/lib/python3.12/site-packages/networkx/classes/multigraph.py:175: ...                 pass
- .venv/lib/python3.12/site-packages/networkx/classes/multigraph.py:182: ...         pass
- .venv/lib/python3.12/site-packages/networkx/classes/multigraph.py:571: object, e.g. by using `list(iterator_of_edges)`, and pass this
- .venv/lib/python3.12/site-packages/networkx/classes/multigraph.py:759: pass
- .venv/lib/python3.12/site-packages/networkx/classes/function.py:658: pass
- .venv/lib/python3.12/site-packages/networkx/classes/function.py:667: pass
- .venv/lib/python3.12/site-packages/networkx/classes/function.py:742: pass
- .venv/lib/python3.12/site-packages/networkx/classes/function.py:856: pass
- .venv/lib/python3.12/site-packages/networkx/classes/function.py:862: pass
- .venv/lib/python3.12/site-packages/networkx/classes/function.py:874: pass
- .venv/lib/python3.12/site-packages/networkx/classes/function.py:880: pass
- .venv/lib/python3.12/site-packages/networkx/classes/function.py:960: pass
- .venv/lib/python3.12/site-packages/networkx/classes/graph.py:209: ...             pass
- .venv/lib/python3.12/site-packages/networkx/classes/graph.py:216: ...         pass
- .venv/lib/python3.12/site-packages/networkx/classes/graph.py:599: object, e.g. by using `list(iterator_of_nodes)`, and pass this
- .venv/lib/python3.12/site-packages/networkx/classes/graph.py:713: object, e.g. by using `list(iterator_of_nodes)`, and pass this
- .venv/lib/python3.12/site-packages/networkx/classes/graph.py:742: pass
- .venv/lib/python3.12/site-packages/networkx/classes/graph.py:1006: object, e.g. by using `list(iterator_of_edges)`, and pass this
- .venv/lib/python3.12/site-packages/networkx/classes/graph.py:1086: object, e.g. by using `list(iterator_of_edges)`, and pass this
- .venv/lib/python3.12/site-packages/networkx/classes/graph.py:1094: Evaluate an iterator over edges before passing it
- .venv/lib/python3.12/site-packages/networkx/classes/digraph.py:226: ...             pass
- .venv/lib/python3.12/site-packages/networkx/classes/digraph.py:233: ...         pass
- .venv/lib/python3.12/site-packages/networkx/classes/digraph.py:515: object, e.g. by using `list(iterator_of_nodes)`, and pass this
- .venv/lib/python3.12/site-packages/networkx/classes/digraph.py:631: object, e.g. by using `list(iterator_of_nodes)`, and pass this
- .venv/lib/python3.12/site-packages/networkx/classes/digraph.py:663: pass  # silent failure on remove
- .venv/lib/python3.12/site-packages/networkx/classes/digraph.py:768: object, e.g. by using `list(iterator_of_edges)`, and pass this
- .venv/lib/python3.12/site-packages/networkx/classes/reportviews.py:439: pass
- .venv/lib/python3.12/site-packages/networkx/classes/reportviews.py:743: pass
- .venv/lib/python3.12/site-packages/networkx/classes/multidigraph.py:183: ...                 pass
- .venv/lib/python3.12/site-packages/networkx/classes/multidigraph.py:190: ...         pass
- .venv/lib/python3.12/site-packages/networkx/classes/multidigraph.py:819: for a bunch of nodes or if nothing is passed as argument.
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_subgraphviews.py:330: # Revert the change, so tests pass with pytest-randomly
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_subgraphviews.py:346: # Revert the change, so tests pass with pytest-randomly
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:307: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:311: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:337: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:619: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:817: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:828: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:832: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:869: # test that the keyword arguments are passed correctly
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:1041: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_reportviews.py:1050: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_graph.py:88: # NOTE: even if this safeguard is deemed unnecessary to pass NetworkX tests,
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_graph.py:105: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_multidigraph.py:420: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_digraph.py:126: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_multigraph.py:491: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_special.py:13: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_special.py:16: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_special.py:19: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_special.py:22: pass
- .venv/lib/python3.12/site-packages/networkx/classes/tests/test_special.py:25: pass
- .venv/lib/python3.12/site-packages/networkx/utils/configs.py:26: Another way is to simply pass the initial configuration as keyword arguments to
- .venv/lib/python3.12/site-packages/networkx/utils/configs.py:60: configurations, then pass ``strict=False`` when defining the subclass:
- .venv/lib/python3.12/site-packages/networkx/utils/configs.py:253: pass
- .venv/lib/python3.12/site-packages/networkx/utils/configs.py:309: backend graph is passed to a dispatchable function, the default behavior is to
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:343: raise TypeError("'name' and 'graphs' must be passed by keyword") from None
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:417: pass
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:530: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:632: f"'{backend_name}' backend raised NotImplementedError when calling "
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:645: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:683: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:739: except NotImplementedError as exc:
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:769: raise NotImplementedError(msg_template % extra)
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:798: # instead of raising NotImplementedError.
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:810: # simply passing objects from one backend directly to another backend;
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:961: except NotImplementedError as exc:
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:994: except NotImplementedError as exc:
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1021: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1156: pass
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1186: pass
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1218: pass
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1248: pass
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1386: # NotImplementedError is reasonable to use since the backend doesn't
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1389: # Using NotImplementedError allows the next backend to be attempted.
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1390: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1473: except NotImplementedError as exc:
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1481: raise NotImplementedError(extra_message) from exc
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1503: Additional message to log if NotImplementedError is raised by backend.
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1530: except NotImplementedError as exc:
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1542: raise NotImplementedError(extra_message) from exc
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1553: except NotImplementedError as exc:
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1561: raise NotImplementedError(extra_message) from exc
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1673: except NotImplementedError as exc:
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1710: except NotImplementedError as exc:
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1773: raise NotImplementedError
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:1793: pass
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:2030: pass
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:2034: pass
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:2040: pass  # Cache works for edge data!
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:2044: pass  # Cache works for node data!
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:2094: pass
- .venv/lib/python3.12/site-packages/networkx/utils/backends.py:2098: pass
- .venv/lib/python3.12/site-packages/networkx/utils/heaps.py:50: raise NotImplementedError
- .venv/lib/python3.12/site-packages/networkx/utils/heaps.py:65: raise NotImplementedError
- .venv/lib/python3.12/site-packages/networkx/utils/heaps.py:84: raise NotImplementedError
- .venv/lib/python3.12/site-packages/networkx/utils/heaps.py:107: raise NotImplementedError
- .venv/lib/python3.12/site-packages/networkx/utils/heaps.py:229: """Merge the subtrees of the root using the standard two-pass method.
- .venv/lib/python3.12/site-packages/networkx/utils/heaps.py:237: # At the end of the pass, only the prev pointers of the resulting
- .venv/lib/python3.12/site-packages/networkx/utils/heaps.py:239: # in pass 2.
- .venv/lib/python3.12/site-packages/networkx/utils/heaps.py:253: # Pass 2: Successively merge the subtrees produced by pass 1 from
- .venv/lib/python3.12/site-packages/networkx/utils/misc.py:125: pass
- .venv/lib/python3.12/site-packages/networkx/utils/misc.py:329: raise NotImplementedError("seed() not implemented in PythonRandomViaNumpyBits")
- .venv/lib/python3.12/site-packages/networkx/utils/misc.py:457: wrapper as well. We use it only used if passed a (non-default) `np.RandomState`
- .venv/lib/python3.12/site-packages/networkx/utils/misc.py:470: pass
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:53: pass
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:59: pass
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:66: pass
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:126: pass
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:131: pass
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:136: pass
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:141: pass
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:147: pass
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:1216: argmap._indent(*["try:", "try:", "pass#", "finally:", "pass#", "#",
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:1217: "finally:", "pass#"])
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:1223: pass#
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:1225: pass#
- .venv/lib/python3.12/site-packages/networkx/utils/decorators.py:1228: pass#'''
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_misc.py:54: _result = copy(result)  # because pytest passes parameters as is
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_backends.py:13: raise NotImplementedError("_stub_func is a stub")
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_backends.py:158: # It would be nice to test passing graphs from *different* backends,
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_backends.py:186: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:22: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:30: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:38: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:46: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:55: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:67: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:89: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:99: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:313: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:323: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:333: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:343: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:350: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:468: "pass#",
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:470: "pass#",
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:473: "pass#",
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:481: pass#
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:483: pass#
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_decorators.py:486: pass#"""
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_config.py:26: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_config.py:167: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_config.py:170: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_config.py:243: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_config.py:262: pass
- .venv/lib/python3.12/site-packages/networkx/utils/tests/test_mapped_queue.py:51: pass
- .venv/lib/python3.12/site-packages/networkx/generators/nonisomorphic_trees.py:128: # if left does not encompass more vertices
- .venv/lib/python3.12/site-packages/networkx/generators/expanders.py:347: In the case where $\epsilon = 0$ then if the graph successfully passes the test
- .venv/lib/python3.12/site-packages/networkx/generators/degree_seq.py:671: # TODO Does this need to be sorted in reverse order?
- .venv/lib/python3.12/site-packages/networkx/generators/degree_seq.py:752: pass
- .venv/lib/python3.12/site-packages/networkx/generators/community.py:1034: # TODO The original code incremented the number of iterations each
- .venv/lib/python3.12/site-packages/networkx/generators/geometric.py:190: # TODO Is this function just a special case of the geographical
- .venv/lib/python3.12/site-packages/networkx/generators/geometric.py:251: tools for custom probability distribution definitions [2], and passing
- .venv/lib/python3.12/site-packages/networkx/generators/geometric.py:401: probability density definitions, and passing the ``.pdf`` method of
- .venv/lib/python3.12/site-packages/networkx/generators/spectral_graph_forge.py:63: pass filtering common in telecommunications.
- .venv/lib/python3.12/site-packages/networkx/generators/classic.py:588: This is used when passing an unknown `create_using` value
- .venv/lib/python3.12/site-packages/networkx/generators/classic.py:624: Secondly, one can pass an existing graph (digraph, multigraph,
- .venv/lib/python3.12/site-packages/networkx/generators/classic.py:631: you can use empty_graph to construct the graph by passing a user
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_classic.py:296: pass
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_classic.py:299: pass
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_expanders.py:37: # TODO The second largest eigenvalue should be smaller than a constant,
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_line.py:151: # so long as we get one of them the test should pass
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_duplication.py:42: pass
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_duplication.py:45: pass
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_duplication.py:95: pass
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_duplication.py:98: pass
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_random_graphs.py:386: pass
- .venv/lib/python3.12/site-packages/networkx/generators/tests/test_random_graphs.py:389: pass
- .venv/lib/python3.12/site-packages/networkx/tests/test_lazy_imports.py:20: pass
- .venv/lib/python3.12/site-packages/networkx/tests/test_lazy_imports.py:27: pass
- .venv/lib/python3.12/site-packages/networkx/tests/test_lazy_imports.py:59: pass
- .venv/lib/python3.12/site-packages/networkx/tests/test_lazy_imports.py:65: pass
- .venv/lib/python3.12/site-packages/networkx/tests/test_convert.py:266: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/edgelist.py:122: pass  # missing data for this edge, should warn?
- .venv/lib/python3.12/site-packages/networkx/readwrite/text.py:683: # Do an initial pass over the lines to determine what type of graph it is.
- .venv/lib/python3.12/site-packages/networkx/readwrite/text.py:685: # parsing pass.
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:227: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:328: # first pass through G collecting edge ids
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:362: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:368: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:374: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:421: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:426: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:431: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:437: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gexf.py:443: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/pajek.py:202: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/pajek.py:227: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/pajek.py:257: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gml.py:25: `GML website <https://web.archive.org/web/20190207140002/http://www.fim.uni-passau.de/index.php?id=17297&L=1>`_.
- .venv/lib/python3.12/site-packages/networkx/readwrite/gml.py:159: `GML url <https://web.archive.org/web/20190207140002/http://www.fim.uni-passau.de/index.php?id=17297&L=1>`_.
- .venv/lib/python3.12/site-packages/networkx/readwrite/gml.py:244: `GML url <https://web.archive.org/web/20190207140002/http://www.fim.uni-passau.de/index.php?id=17297&L=1>`_.
- .venv/lib/python3.12/site-packages/networkx/readwrite/gml.py:391: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gml.py:410: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/gml.py:670: `GML url <https://web.archive.org/web/20190207140002/http://www.fim.uni-passau.de/index.php?id=17297&L=1>`_.
- .venv/lib/python3.12/site-packages/networkx/readwrite/gml.py:865: `GML url <https://web.archive.org/web/20190207140002/http://www.fim.uni-passau.de/index.php?id=17297&L=1>`_.
- .venv/lib/python3.12/site-packages/networkx/readwrite/graphml.py:412: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/graphml.py:768: # Then pass through attributes to create key_id for each.
- .venv/lib/python3.12/site-packages/networkx/readwrite/graphml.py:949: pass
- .venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:12: All other non-list inputs are passed through unmodified. This function is
- .venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:94: A graph can also be serialized by passing `node_link_data` as an encoder function.
- .venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:129: # TODO: Remove between the lines when `link` deprecation expires
- .venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:274: # TODO: Remove between the lines when `link` deprecation expires
- .venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/tests/test_node_link.py:27: # TODO: To be removed when signature change complete
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pydot.py:59: dot file with the passed path.
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pydot.py:177: pass  # N.graph['node']={}
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pydot.py:181: pass  # N.graph['edge']={}
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pydot.py:222: pass
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pydot.py:226: pass
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pydot.py:328: # from the passed graph with the passed external GraphViz command.
- .venv/lib/python3.12/site-packages/networkx/drawing/layout.py:792: Ai = A.getrowview(i).toarray()  # TODO: revisit w/ sparse 1D container
- .venv/lib/python3.12/site-packages/networkx/drawing/layout.py:1152: # TODO: Rm csr_array wrapper in favor of spdiags array constructor when available
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_agraph.py:338: Additional arguments to pass to the Graphviz layout program.
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_agraph.py:422: # If the user passed in an edgelabel, we update the labels for all edges.
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_agraph.py:452: pass
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:214: # TODO allow pos to be None and use a nice TikZ default
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:277: # TODO -- handle bending of multiedges
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:470: # If `attr` is not a graph attr and was explicitly passed as an argument
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:804: #    be passed in as the sole string, not part of a list of strings.
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:1148: width. A list of values can be passed in to assign a different size for arrow head's length and width.
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:1829: turned off with keyword arrows=False or by passing an arrowstyle without
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:2499: # TODO should this be list or array (as in a numpy array)?
- .venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:2505: # Don't need to pass in an edge because these are lists, not dicts
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_latex.py:244: # check that passes with 2 values
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_latex.py:277: # all pass
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_pydot.py:18: Validate :mod:`pydot`-based usage of the passed NetworkX graph with the
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_pydot.py:19: passed basename of an external GraphViz command (e.g., `dot`, `neato`).
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_pydot.py:26: # Add arbitrary nodes and edges to the passed empty graph.
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_pydot.py:30: # Validate layout of this graph with the passed GraphViz command.
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_pylab.py:545: # While we can pass in dicts for edge label defaults without errors,
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_pylab.py:750: pass
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_pylab.py:755: pass
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_pylab.py:767: pass
- .venv/lib/python3.12/site-packages/networkx/drawing/tests/test_pylab.py:779: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/vitality.py:26: The name of the edge attribute used as weight. This is passed
- .venv/lib/python3.12/site-packages/networkx/algorithms/cycles.py:841: if thisnode not in B[nextnode]:  # TODO: use set for speedup?
- .venv/lib/python3.12/site-packages/networkx/algorithms/cycles.py:1147: # two passes: flag which edges get kept, then build it
- .venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:19: # TODO STILL NEED TO UPDATE ALL THE DOCUMENTATION!
- .venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:322: # TODO What is the generalization to two arguments, S and T? Does the
- .venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:362: # TODO What is the generalization to two arguments, S and T? Does the
- .venv/lib/python3.12/site-packages/networkx/algorithms/distance_measures.py:49: this error will always raise if a non-tree is passed.
- .venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:94: # TODO: csr_array
- .venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:173: # TODO: csr_array
- .venv/lib/python3.12/site-packages/networkx/algorithms/walks.py:72: # TODO: Use matrix_power from scipy.sparse when available
- .venv/lib/python3.12/site-packages/networkx/algorithms/distance_regular.py:184: # TODO There is a definition for directed strongly regular graphs.
- .venv/lib/python3.12/site-packages/networkx/algorithms/chains.py:120: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/d_separation.py:627: def _pass(e, v, f, n):
- .venv/lib/python3.12/site-packages/networkx/algorithms/d_separation.py:628: """Whether a ball entering node `v` along edge `e` passes to `n` along `f`.
- .venv/lib/python3.12/site-packages/networkx/algorithms/d_separation.py:641: Checking whether the ball passes to this node.
- .venv/lib/python3.12/site-packages/networkx/algorithms/d_separation.py:646: Whether the ball passes or not.
- .venv/lib/python3.12/site-packages/networkx/algorithms/d_separation.py:673: if (f, n) not in processed and _pass(e, v, f, n):
- .venv/lib/python3.12/site-packages/networkx/algorithms/planarity.py:871: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/networkx/algorithms/planarity.py:977: object, e.g. by using `list(iterator_of_nodes)`, and pass this
- .venv/lib/python3.12/site-packages/networkx/algorithms/planarity.py:1028: Omit or pass `None` if adding the first out-half-edge of `start_node`.
- .venv/lib/python3.12/site-packages/networkx/algorithms/planarity.py:1247: will be removed from the graph. The nodes can be passed as:
- .venv/lib/python3.12/site-packages/networkx/algorithms/planarity.py:1346: Optionally it is possible to pass a set to which all encountered half
- .venv/lib/python3.12/site-packages/networkx/algorithms/efficiency_measures.py:118: # TODO This can be made more efficient by computing all pairs shortest
- .venv/lib/python3.12/site-packages/networkx/algorithms/triads.py:135: triads are present in a directed graph. If a list of nodes is passed, then
- .venv/lib/python3.12/site-packages/networkx/algorithms/graphical.py:152: # Accept if sequence has no non-zero degrees or passes the ZZ condition
- .venv/lib/python3.12/site-packages/networkx/algorithms/graphical.py:254: # Accept if sequence has no non-zero degrees or passes the ZZ condition
- .venv/lib/python3.12/site-packages/networkx/algorithms/non_randomness.py:65: If a weight field is passed, this algorithm will use the eigenvalues
- .venv/lib/python3.12/site-packages/networkx/algorithms/core.py:126: """Returns the subgraph induced by nodes passing filter `k_filter`.
- .venv/lib/python3.12/site-packages/networkx/algorithms/similarity.py:686: # TODO: support DiGraph
- .venv/lib/python3.12/site-packages/networkx/algorithms/similarity.py:880: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/similarity.py:1092: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/similarity.py:1138: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/similarity.py:1699: By passing a dictionary into `index_map`, it will build an
- .venv/lib/python3.12/site-packages/networkx/algorithms/threshold.py:215: # pass through twice--first backwards
- .venv/lib/python3.12/site-packages/networkx/algorithms/threshold.py:226: wseq.reverse()  # now pass through forwards
- .venv/lib/python3.12/site-packages/networkx/algorithms/simple_paths.py:214: directed acyclic graph passing all leaves together to avoid unnecessary
- .venv/lib/python3.12/site-packages/networkx/algorithms/simple_paths.py:543: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/dag.py:1175: # TODO In Python 3, this would be better as `yield from ...`.
- .venv/lib/python3.12/site-packages/networkx/algorithms/clique.py:297: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/clique.py:300: # TODO Should this also be not implemented for directed graphs?
- .venv/lib/python3.12/site-packages/networkx/algorithms/minors/contraction.py:26: `relation` function returns `True` when passed any two objects from that
- .venv/lib/python3.12/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:463: # TODO: csr_array
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/group.py:28: fraction of all-pairs shortest paths that pass through any vertex in $C$
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/group.py:36: those paths passing through some node in group $C$. Note that
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/group.py:248: fraction of all-pairs shortest paths that pass through any vertex in $C$
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/group.py:256: those paths passing through some node in group $C$. Note that
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/load.py:15: paths that pass through that node.
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/betweenness.py:24: fraction of all-pairs shortest paths that pass through $v$
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/betweenness.py:32: those paths  passing through some  node $v$ other than $s, t$.
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/betweenness.py:168: fraction of all-pairs shortest paths that pass through $e$
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/betweenness.py:176: those paths passing through edge $e$ [2]_.
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/betweenness.py:364: # could have a path pass through v. If endpoints is False, then v must
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:111: # TODO This can be trivially parallelized.
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:206: # TODO This can be trivially parallelized.
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/flow_matrix.py:53: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/betweenness_subset.py:31: passing through some  node $v$ other than $s, t$.
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/betweenness_subset.py:131: passing through edge $e$ [2]_.
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality_subset.py:88: #     pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality.py:144: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/centrality/tests/test_current_flow_closeness.py:43: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/assortativity/connectivity.py:55: If either `source` or `target` is passed for an undirected graph.
- .venv/lib/python3.12/site-packages/networkx/algorithms/assortativity/neighbor_degree.py:66: If either `source` or `target` is passed for an undirected graph.
- .venv/lib/python3.12/site-packages/networkx/algorithms/assortativity/tests/test_connectivity.py:138: # TODO Is this really the intended behavior for providing a
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/vf2pp.py:273: # Feasibility rules pass, so extend the mapping and update the parameters
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/vf2pp.py:792: True if the pair passes all the consistency checks successfully. False otherwise.
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/vf2pp.py:836: This function should be called right after the feasibility checks are passed,
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:135: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:139: raise NotImplementedError(message) from None
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:292: # TODO: graph and subgraph setter methods that invalidate the caches.
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:293: # TODO: allow for precomputed partitions and colors
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:529: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:932: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:217: # TODO:
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/vf2userfunc.py:13: n1 and n2, the algorithm passes their node attribute dictionaries to
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/vf2userfunc.py:25: dictionaries are passed to edge_match, and if it returns False, then
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/vf2userfunc.py:30: So, all of the edge attribute dictionaries are passed to edge_match, and
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/isomorph.py:102: # All checked conditions passed
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/tests/test_vf2pp_helpers.py:1068: # Delete one uncovered neighbor of u. Notice how it still passes the test.
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/tests/test_vf2pp_helpers.py:1759: # Delete one uncovered neighbor of u. Notice how it still passes the test.
- .venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/tests/test_vf2pp_helpers.py:2412: # Delete one uncovered neighbor of u. Notice how it still passes the
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_summarization.py:236: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_summarization.py:239: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_dag.py:60: # this will raise NotImplementedError when nodes need to be ordered
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_dag.py:140: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_distance_measures.py:29: and `networkx.center` when passing `usebounds=True`. Expectation is that method
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_distance_measures.py:30: returns the same result whether we pass usebounds=True or not.
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_cluster.py:212: # Relaxed comparisons to allow graphblas-algorithms to pass tests
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_d_separation.py:199: Test that graphs that have invalid nodes passed in raise errors.
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_d_separation.py:261: # the minimal separating set should also pass the test for minimality
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_d_separation.py:273: # the minimal separating set should pass the test for minimality
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_planarity.py:541: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_planarity.py:543: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_planarity.py:545: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_reciprocity.py:7: # test overall reciprocity by passing whole graph
- .venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_swap.py:40: # TODO: Rewrite function to explicitly check for impossible swaps and raise error
- .venv/lib/python3.12/site-packages/networkx/algorithms/coloring/equitable_coloring.py:163: # TODO: Checking whether a color has been visited can be made faster by
- .venv/lib/python3.12/site-packages/networkx/algorithms/coloring/equitable_coloring.py:227: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/centrality.py:86: fraction of all-pairs shortest paths that pass through `v`.
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/cluster.py:193: The container of nodes passed to this function must contain all of the nodes
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/link_analysis.py:299: # If both error thresholds pass, return a single dictionary mapping
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/link_analysis.py:311: handle case where None is passed, ensure values are non-negative."""
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/edgelist.py:146: pass  # missing data for this edge, should warn?
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:276: # TODO - The lines between --- were unused and were thus commented
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:282: #     # TODO Why is extra inner loop necessary?
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:287: # TODO Originally, this function returned a three-tuple:
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/__init__.py:40: colorations. This is the reason why we require the user to pass a container
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/basic.py:254: The container of nodes passed as argument must contain all nodes
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/basic.py:310: The container of nodes passed as argument must contain all nodes
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/redundancy.py:93: # TODO This can be trivially parallelized.
- .venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/tests/test_matching.py:110: # TODO Assert that the vertices are the correct ones.
- .venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/astar.py:54: the evaluation function surpasses this value for a node n, the node will not
- .venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/astar.py:216: the evaluation function surpasses this value for a node n, the node will not
- .venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:181: # TODO This can be trivially parallelized.
- .venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:475: # TODO This can be trivially parallelized.
- .venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/weighted.py:833: the caller through the original pred and paths objects passed
- .venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/weighted.py:881: # by the caller via the pred and paths objects passed as arguments.
- .venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/weighted.py:1135: # TODO This can be trivially parallelized.
- .venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/tests/test_dense.py:9: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/flow/maxflow.py:54: kwargs : Any other keyword parameter is passed to the function that
- .venv/lib/python3.12/site-packages/networkx/algorithms/flow/maxflow.py:158: " you need to pass parameters via kwargs."
- .venv/lib/python3.12/site-packages/networkx/algorithms/flow/maxflow.py:205: kwargs : Any other keyword parameter is passed to the function that
- .venv/lib/python3.12/site-packages/networkx/algorithms/flow/maxflow.py:299: " you need to pass parameters via kwargs."
- .venv/lib/python3.12/site-packages/networkx/algorithms/flow/maxflow.py:348: kwargs : Any other keyword parameter is passed to the function that
- .venv/lib/python3.12/site-packages/networkx/algorithms/flow/maxflow.py:448: " you need to pass parameters via kwargs."
- .venv/lib/python3.12/site-packages/networkx/algorithms/flow/maxflow.py:511: kwargs : Any other keyword parameter is passed to the function that
- .venv/lib/python3.12/site-packages/networkx/algorithms/flow/maxflow.py:599: " you need to pass parameters via kwargs."
- .venv/lib/python3.12/site-packages/networkx/algorithms/flow/networksimplex.py:84: self._spanning_tree_initialized = True  # True only if all the assignments pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/branchings.py:11: # TODO: Implement method from Gabow, Galil, Spence and Tarjan:
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/branchings.py:661: passed to `attr`)
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/branchings.py:776: passed to `attr`)
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/branchings.py:996: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:124: # TODO This can be parallelized, both in the outer loop over
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:132: # TODO This loop can be parallelized, to an extent (the union
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:848: # delete the second node it is passed so the resulting graph would be
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/tests/test_mst.py:617: # to randomly sample the same sample each time. However, if we pass in a
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/tests/test_mst.py:620: # and pass those into sample_spanning_tree.
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/tests/test_mst.py:742: # to randomly sample the same sample each time. However, if we pass in a
- .venv/lib/python3.12/site-packages/networkx/algorithms/tree/tests/test_mst.py:745: # and pass those into sample_spanning_tree.
- .venv/lib/python3.12/site-packages/networkx/algorithms/community/leiden.py:159: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/networkx/algorithms/community/asyn_fluid.py:105: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/community/asyn_fluid.py:126: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/community/asyn_fluid.py:140: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/community/tests/test_leiden.py:19: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/networkx/algorithms/community/tests/test_leiden.py:21: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/treewidth.py:185: """Returns a treewidth decomposition using the passed heuristic.
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/dominating_set.py:22: # TODO Why doesn't this algorithm work for directed graphs?
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/kcomponents.py:333: Degree of the node, if a single node is passed as argument.
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/traveling_salesman.py:166: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/traveling_salesman.py:266: Other keyword arguments to be passed to the `method` function passed in.
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/traveling_salesman.py:300: Otherwise, pass other keyword arguments directly into the tsp function.
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/traveling_salesman.py:805: # TODO: this branch does not restore original_edge_weights of G!
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/traveling_salesman.py:1017: be passed as a parameter to an iterative improvement algorithm such
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/tests/test_treewidth.py:125: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/tests/test_treewidth.py:230: pass
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/tests/test_traveling_salesman.py:789: # For the second condition it is possible to have the tour pass through the
- .venv/lib/python3.12/site-packages/networkx/algorithms/approximation/tests/test_traveling_salesman.py:959: will return a graph rather than a dict, bypassing most of the asadpour
- .venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/cuts.py:121: >>> # Reuse the auxiliary digraph and the residual network by passing them
- .venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/cuts.py:246: >>> # Reuse the auxiliary digraph and the residual network by passing them
- .venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/connectivity.py:125: >>> # Reuse the auxiliary digraph and the residual network by passing them
- .venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/connectivity.py:576: >>> # Reuse the auxiliary digraph and the residual network by passing them
- .venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:97: # TODO: investigate https://arxiv.org/abs/1412.6466 for k=2
- .venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:314: # @not_implemented_for('multigraph')  # TODO: fix decor for classmethods
- .venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_augmentation.py:265: # raise NotImplementedError(f'not implemented for k>2. k={k}')
- .venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/disjoint_paths.py:126: >>> # Reuse the auxiliary digraph and the residual network by passing them
- .venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/disjoint_paths.py:325: >>> # Reuse the auxiliary digraph and the residual network by passing them
- .venv/lib/python3.12/site-packages/networkx/algorithms/traversal/beamsearch.py:77: # TODO The Python documentation states that for small values, it
- .venv/lib/python3.12/site-packages/networkx/algorithms/traversal/breadth_first_search.py:515: # thus somewhat faster than a python-defined def nop(x): pass
- .venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:75: # TODO: Rm csr_array wrapper when spdiags array creation becomes available
- .venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:77: # TODO: Rm csr_array wrapper when eye array creation becomes available
- .venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:128: # TODO: rm csr_array wrapper when spdiags can produce arrays
- .venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:238: # TODO: rm csr_array wrapper when spdiags can produce arrays
- .venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:244: # TODO: rm csr_array wrapper when spdiags can produce arrays
- .venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:341: # TODO: rm csr_array wrapper when spdiags creates arrays
- .venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:344: # TODO: rm csr_array wrapper when spdiags creates arrays
- .venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:436: # TODO: Rm csr_array wrapper when spdiags array creation becomes available
- .venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:498: # TODO: Rm csr_array wrapper when spdiags array creation becomes available
- .venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:503: # TODO: Rm csr_array wrapper when identity array creation becomes available
- .venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:192: # TODO: rm csr_array wrapper when spdiags array creation becomes available
- .venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:279: # TODO: rm csc_array wrapping when spdiags array becomes available
- .venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:296: # TODO: rm csr_array wrapping when spdiags array becomes available
- .venv/lib/python3.12/site-packages/networkx/linalg/attrmatrix.py:158: If only `G` is passed in, then the adjacency matrix is constructed.
- .venv/lib/python3.12/site-packages/networkx/linalg/attrmatrix.py:201: The parameter is passed to numpy.zeros(). If unspecified, the NumPy
- .venv/lib/python3.12/site-packages/networkx/linalg/attrmatrix.py:206: (row- or column-wise) order in memory. This parameter is passed to
- .venv/lib/python3.12/site-packages/networkx/linalg/attrmatrix.py:317: If only `G` is passed in, then the adjacency matrix is constructed.
- .venv/lib/python3.12/site-packages/networkx/linalg/attrmatrix.py:359: The parameter is passed to numpy.zeros(). If unspecified, the NumPy
- .venv/lib/python3.12/site-packages/_distutils_hack/__init__.py:138: pass
- .venv/lib/python3.12/site-packages/_distutils_hack/__init__.py:234: pass
- .venv/lib/python3.12/site-packages/packaging/_elffile.py:20: pass
- .venv/lib/python3.12/site-packages/packaging/markers.py:185: pass
- .venv/lib/python3.12/site-packages/packaging/_parser.py:26: raise NotImplementedError
- .venv/lib/python3.12/site-packages/packaging/tags.py:222: pass
- .venv/lib/python3.12/site-packages/packaging/tags.py:378: # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
- .venv/lib/python3.12/site-packages/packaging/specifiers.py:506: :meth:`contains` with no ``prereleases`` argument passed.
- .venv/lib/python3.12/site-packages/packaging/specifiers.py:693: It can be passed a single specifier (``>=3.0``), a comma-separated list of
- .venv/lib/python3.12/site-packages/packaging/specifiers.py:738: # pass that through here.
- .venv/lib/python3.12/site-packages/packaging/specifiers.py:870: :meth:`contains` with no ``prereleases`` argument passed.
- .venv/lib/python3.12/site-packages/packaging/requirements.py:29: # TODO: Can we test whether something is contained within a requirement?
- .venv/lib/python3.12/site-packages/packaging/requirements.py:32: # TODO: Can we normalize the name and extra name?
- .venv/lib/python3.12/site-packages/packaging/metadata.py:204: # TODO: The spec doesn't say anything about if the keys should be
- .venv/lib/python3.12/site-packages/packaging/metadata.py:512: pass
- .venv/lib/python3.12/site-packages/packaging/metadata.py:520: pass
- .venv/lib/python3.12/site-packages/packaging/metadata.py:805: description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
- .venv/lib/python3.12/site-packages/packaging/metadata.py:847: # PEP 685 lets us raise an error if an extra doesn't pass `Name` validation
- .venv/lib/python3.12/site-packages/packaging/licenses/__init__.py:108: # Take a final pass to check for unknown licenses/exceptions.
- .venv/lib/python3.12/site-packages/virtualenv/info.py:45: except (OSError, NotImplementedError):
- .venv/lib/python3.12/site-packages/virtualenv/info.py:46: pass  # symlink is not supported
- .venv/lib/python3.12/site-packages/virtualenv/config/cli/parser.py:98: msg = "can only pass in parser.options"
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:20: """Called when the user passes in the reset app data."""
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:24: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:28: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:32: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:36: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:40: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:44: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:48: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:62: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:67: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:73: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:77: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:81: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:85: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/base.py:90: pass
- .venv/lib/python3.12/site-packages/virtualenv/app_data/via_tempdir.py:29: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/na.py:15: pass
- .venv/lib/python3.12/site-packages/virtualenv/app_data/read_only.py:25: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/read_only.py:31: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/app_data/via_disk_folder.py:130: pass
- .venv/lib/python3.12/site-packages/virtualenv/discovery/builtin.py:105: pass
- .venv/lib/python3.12/site-packages/virtualenv/discovery/builtin.py:120: pass
- .venv/lib/python3.12/site-packages/virtualenv/discovery/builtin.py:134: pass
- .venv/lib/python3.12/site-packages/virtualenv/discovery/builtin.py:227: pass
- .venv/lib/python3.12/site-packages/virtualenv/discovery/discover.py:16: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/discovery/discover.py:35: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/discovery/py_info.py:150: pass
- .venv/lib/python3.12/site-packages/virtualenv/discovery/py_info.py:160: pass  # We found it directly
- .venv/lib/python3.12/site-packages/virtualenv/discovery/py_info.py:188: pass
- .venv/lib/python3.12/site-packages/virtualenv/discovery/py_spec.py:67: pass
- .venv/lib/python3.12/site-packages/virtualenv/discovery/cached_py_info.py:129: # generated by something else. The right way to deal with it is to create an anonymous pipe and pass its descriptor
- .venv/lib/python3.12/site-packages/virtualenv/discovery/windows/pep514.py:47: pass
- .venv/lib/python3.12/site-packages/virtualenv/create/describe.py:81: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/create/debug.py:57: pass
- .venv/lib/python3.12/site-packages/virtualenv/create/creator.py:104: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/create/via_global_ref/_virtualenv.py:83: pass  # C-Extension loaders are r/o such as zipimporter with <3.7
- .venv/lib/python3.12/site-packages/virtualenv/create/via_global_ref/builtin/via_global_self_do.py:74: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/create/via_global_ref/builtin/ref.py:84: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/create/via_global_ref/builtin/cpython/mac_os.py:56: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/create/via_global_ref/builtin/cpython/mac_os.py:60: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/create/via_global_ref/builtin/pypy/common.py:48: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/create/via_global_ref/builtin/graalpy/__init__.py:53: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/run/__init__.py:25: :param options: passing in a ``VirtualEnvOptions`` object allows return of the parsed options
- .venv/lib/python3.12/site-packages/virtualenv/run/__init__.py:43: :param options: passing in a ``VirtualEnvOptions`` object allows return of the parsed options
- .venv/lib/python3.12/site-packages/virtualenv/run/plugin/base.py:43: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/activation/activator.py:45: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/activation/via_template.py:23: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/activation/powershell/__init__.py:14: string is passed directly to Windows native commands [2].
- .venv/lib/python3.12/site-packages/virtualenv/activation/powershell/__init__.py:17: [2]: https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_parsing#passing-arguments
- .venv/lib/python3.12/site-packages/virtualenv/cache/cache.py:30: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/cache/cache.py:40: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/cache/cache.py:49: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/cache/cache.py:54: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/util/lock.py:67: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/util/lock.py:71: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/util/lock.py:76: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/util/lock.py:81: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/util/lock.py:156: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/util/lock.py:159: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/seed/seeder.py:28: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/seed/seeder.py:38: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/seed/embed/base_embed.py:71: help=f"pass to disable download of the latest {'/'.join(cls.distributions())} from PyPI",
- .venv/lib/python3.12/site-packages/virtualenv/seed/embed/base_embed.py:78: help=f"pass to enable download of the latest {'/'.join(cls.distributions())} from PyPI",
- .venv/lib/python3.12/site-packages/virtualenv/seed/embed/via_app_data/pip_install/symlink.py:36: pass
- .venv/lib/python3.12/site-packages/virtualenv/seed/embed/via_app_data/pip_install/base.py:31: raise NotImplementedError
- .venv/lib/python3.12/site-packages/virtualenv/seed/embed/via_app_data/pip_install/base.py:117: raise NotImplementedError
- .venv/lib/python3.12/site-packages/yaml/scanner.py:33: pass
- .venv/lib/python3.12/site-packages/yaml/scanner.py:187: # TODO: support for BOM within a stream.
- .venv/lib/python3.12/site-packages/yaml/scanner.py:503: pass
- .venv/lib/python3.12/site-packages/yaml/scanner.py:761: # TODO: We need to make tab handling rules more sane. A good rule is
- .venv/lib/python3.12/site-packages/yaml/error.py:46: pass
- .venv/lib/python3.12/site-packages/yaml/composer.py:9: pass
- .venv/lib/python3.12/site-packages/yaml/parser.py:70: pass
- .venv/lib/python3.12/site-packages/yaml/serializer.py:9: pass
- .venv/lib/python3.12/site-packages/yaml/constructor.py:17: pass
- .venv/lib/python3.12/site-packages/yaml/constructor.py:61: pass
- .venv/lib/python3.12/site-packages/yaml/constructor.py:108: pass
- .venv/lib/python3.12/site-packages/yaml/constructor.py:748: pass
- .venv/lib/python3.12/site-packages/yaml/events.py:32: pass
- .venv/lib/python3.12/site-packages/yaml/events.py:43: pass
- .venv/lib/python3.12/site-packages/yaml/events.py:62: pass
- .venv/lib/python3.12/site-packages/yaml/events.py:76: pass
- .venv/lib/python3.12/site-packages/yaml/events.py:79: pass
- .venv/lib/python3.12/site-packages/yaml/events.py:82: pass
- .venv/lib/python3.12/site-packages/yaml/events.py:85: pass
- .venv/lib/python3.12/site-packages/yaml/resolver.py:10: pass
- .venv/lib/python3.12/site-packages/yaml/resolver.py:168: pass
- .venv/lib/python3.12/site-packages/yaml/representer.py:11: pass
- .venv/lib/python3.12/site-packages/yaml/representer.py:115: pass
- .venv/lib/python3.12/site-packages/yaml/emitter.py:15: pass
- .venv/lib/python3.12/site-packages/fsspec/generic.py:326: # TODO: special case for one FS being local, which can use get/put
- .venv/lib/python3.12/site-packages/fsspec/generic.py:327: # TODO: special case for one being memFS, which can use cat/pipe
- .venv/lib/python3.12/site-packages/fsspec/generic.py:329: raise NotImplementedError("Please use fsspec.generic.rsync")
- .venv/lib/python3.12/site-packages/fsspec/conftest.py:44: [sys.executable, "-m", "pyftpdlib", "-d", d, "-u", "user", "-P", "pass", "-w"]
- .venv/lib/python3.12/site-packages/fsspec/conftest.py:48: yield "localhost", 2121, "user", "pass"
- .venv/lib/python3.12/site-packages/fsspec/conftest.py:55: pass
- .venv/lib/python3.12/site-packages/fsspec/registry.py:312: passed directly to the class.
- .venv/lib/python3.12/site-packages/fsspec/caching.py:93: # TODO: use rich for better formatting
- .venv/lib/python3.12/site-packages/fsspec/caching.py:501: # TODO: only set start/end after fetch, in case it fails?
- .venv/lib/python3.12/site-packages/fsspec/caching.py:553: pass
- .venv/lib/python3.12/site-packages/fsspec/compression.py:13: # TODO: files should also be available as contexts
- .venv/lib/python3.12/site-packages/fsspec/compression.py:73: pass
- .venv/lib/python3.12/site-packages/fsspec/compression.py:97: pass
- .venv/lib/python3.12/site-packages/fsspec/compression.py:105: pass
- .venv/lib/python3.12/site-packages/fsspec/compression.py:128: raise NotImplementedError("SnappyFile is not seekable")
- .venv/lib/python3.12/site-packages/fsspec/compression.py:148: pass
- .venv/lib/python3.12/site-packages/fsspec/compression.py:155: pass
- .venv/lib/python3.12/site-packages/fsspec/compression.py:177: pass
- .venv/lib/python3.12/site-packages/fsspec/spec.py:45: * The arguments passed to ``__init__``.
- .venv/lib/python3.12/site-packages/fsspec/spec.py:137: passed to ``DirCache``, if the implementation supports
- .venv/lib/python3.12/site-packages/fsspec/spec.py:141: If this is a cachable implementation, pass True here to force
- .venv/lib/python3.12/site-packages/fsspec/spec.py:169: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/spec.py:296: pass  # not necessary to implement, may not have directories
- .venv/lib/python3.12/site-packages/fsspec/spec.py:312: pass  # not necessary to implement, may not have directories
- .venv/lib/python3.12/site-packages/fsspec/spec.py:316: pass  # not necessary to implement, may not have directories
- .venv/lib/python3.12/site-packages/fsspec/spec.py:357: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/spec.py:369: pass
- .venv/lib/python3.12/site-packages/fsspec/spec.py:382: pass
- .venv/lib/python3.12/site-packages/fsspec/spec.py:415: kwargs: passed to ``ls``
- .venv/lib/python3.12/site-packages/fsspec/spec.py:491: kwargs are passed to ``ls``.
- .venv/lib/python3.12/site-packages/fsspec/spec.py:493: # TODO: allow equivalent of -name parameter
- .venv/lib/python3.12/site-packages/fsspec/spec.py:530: kwargs: passed to ``find``
- .venv/lib/python3.12/site-packages/fsspec/spec.py:563: Additional arguments passed to ``find`` (e.g., detail=True)
- .venv/lib/python3.12/site-packages/fsspec/spec.py:678: shortcut. kwargs are passed on to ```ls()``.
- .venv/lib/python3.12/site-packages/fsspec/spec.py:794: kwargs: passed to ``open()``.
- .venv/lib/python3.12/site-packages/fsspec/spec.py:854: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/spec.py:888: kwargs: passed to cat_file
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1108: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1168: kwargs are passed to ``glob`` or ``find``, which may in turn call ``ls``
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1230: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1243: Depth to pass to walk for finding files to delete, if recursive.
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1307: Extra arguments to pass through to the cache.
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1312: encoding, errors, newline: passed on to TextIOWrapper for text mode
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1371: pass
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1373: raise NotImplementedError  # update timestamp, if possible
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1424: def to_json(self, *, include_password: bool = True) -> str:
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1430: include_password: bool, default True
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1431: Whether to include the password (if any) in the output.
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1443: passed to the constructor, such as passwords and tokens. Make sure you
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1453: {"include_password": include_password},
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1482: def to_dict(self, *, include_password: bool = True) -> dict[str, Any]:
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1488: include_password: bool, default True
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1489: Whether to include the password (if any) in the output.
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1501: passed to the constructor, such as passwords and tokens. Make sure you
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1512: if not include_password:
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1513: storage_options.pop("password", None)
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1601: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1605: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1640: >>> fs = filesystem('ftp', host='test.rebex.net', user='demo', password='password')
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1817: NotImplementedError : if method is not implemented for a filesystem
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1819: raise NotImplementedError("Sign is not implemented for this filesystem")
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1872: Additional options passed to the constructor for the cache specified
- .venv/lib/python3.12/site-packages/fsspec/spec.py:1907: raise NotImplementedError("File mode not supported")
- .venv/lib/python3.12/site-packages/fsspec/spec.py:2086: pass
- .venv/lib/python3.12/site-packages/fsspec/gui.py:19: """Signal-slot mixin, for Panel event passing
- .venv/lib/python3.12/site-packages/fsspec/gui.py:98: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/fsspec/gui.py:142: This method can be used in tests to simulate message passing without
- .venv/lib/python3.12/site-packages/fsspec/gui.py:242: To pass to file system instance
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:46: that has to be passed to the child method, e.g., put_file,
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:67: A callback instance to be passed to the child method
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:70: # mutate kwargs so that we can force the caller to pass "callback=" explicitly
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:75: Wraps a coroutine, and pass a new child callback to it.
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:129: Each function is passed the internal size and current value
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:135: kwargs: passed on to (all) hook(s)
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:166: trigger transfers that can also be monitored. The passed kwargs are
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:177: arguments passed to child method, e.g., put_file.
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:186: pass
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:248: subclass of `tqdm.tqdm`. If not passed, it will default to `tqdm.tqdm`.
- .venv/lib/python3.12/site-packages/fsspec/callbacks.py:272: You can also customize the progress bar by passing a subclass of `tqdm`.
- .venv/lib/python3.12/site-packages/fsspec/__init__.py:47: pass  # importlib-metadata < 0.8
- .venv/lib/python3.12/site-packages/fsspec/core.py:110: "to pass expand=True in fsspec.open() or the storage_options of \n"
- .venv/lib/python3.12/site-packages/fsspec/core.py:242: can pass a globstring or a list of paths, with the caveat that they
- .venv/lib/python3.12/site-packages/fsspec/core.py:258: if writing mode, number of files we expect to create (passed to
- .venv/lib/python3.12/site-packages/fsspec/core.py:271: host, port, username, password, etc.
- .venv/lib/python3.12/site-packages/fsspec/core.py:312: pass
- .venv/lib/python3.12/site-packages/fsspec/core.py:379: host, port, username, password, etc.
- .venv/lib/python3.12/site-packages/fsspec/core.py:464: host, port, username, password, etc.
- .venv/lib/python3.12/site-packages/fsspec/core.py:523: passed on to FS for or used by open_files (e.g., compression)
- .venv/lib/python3.12/site-packages/fsspec/core.py:640: Additional keywords to pass to the filesystem class.
- .venv/lib/python3.12/site-packages/fsspec/config.py:102: Augments the passed kwargs, by finding entries in the config dict
- .venv/lib/python3.12/site-packages/fsspec/utils.py:62: {"protocol": "hdfs", "username": "username", "password": "pwd",
- .venv/lib/python3.12/site-packages/fsspec/utils.py:107: if parsed_path.password:
- .venv/lib/python3.12/site-packages/fsspec/utils.py:108: options["password"] = parsed_path.password
- .venv/lib/python3.12/site-packages/fsspec/utils.py:228: pass
- .venv/lib/python3.12/site-packages/fsspec/utils.py:300: # TODO: allow length to be None and read to the end of the file?
- .venv/lib/python3.12/site-packages/fsspec/utils.py:346: Any other object is passed through unchanged, which includes bytes,
- .venv/lib/python3.12/site-packages/fsspec/utils.py:468: pass
- .venv/lib/python3.12/site-packages/fsspec/utils.py:541: sorted, passing `sort=False` will skip the re-ordering.
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:80: raise NotImplementedError("Calling sync() from within a running loop")
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:81: except NotImplementedError:
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:84: pass
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:331: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:334: # TODO: implement on_error
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:344: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:411: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:450: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:498: # TODO: on_error
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:501: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:520: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:541: The default can be set for this instance by passing "batch_size" in the
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:597: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:618: The default can be set for this instance by passing "batch_size" in the
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:701: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:704: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:903: pass  # not necessary to implement, may not have directories
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:906: pass  # not necessary to implement, may not have directories
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:911: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:947: pass
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:979: pass
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:985: # TODO: readahead might still be useful here, but needs async version
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:1091: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:1094: pass
- .venv/lib/python3.12/site-packages/fsspec/asyn.py:1097: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/mapping.py:80: pass
- .venv/lib/python3.12/site-packages/fsspec/mapping.py:168: pass
- .venv/lib/python3.12/site-packages/fsspec/fuse.py:114: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/fuse.py:139: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/fuse.py:201: pass
- .venv/lib/python3.12/site-packages/fsspec/fuse.py:229: -o 'ftp-password=xieyanbo'
- .venv/lib/python3.12/site-packages/fsspec/fuse.py:302: pass
- .venv/lib/python3.12/site-packages/fsspec/json.py:17: include_password: ClassVar[bool] = True
- .venv/lib/python3.12/site-packages/fsspec/json.py:21: return o.to_dict(include_password=self.include_password)
- .venv/lib/python3.12/site-packages/fsspec/parquet.py:49: Mode option to be passed through to `fs.open`. Default is "rb".
- .venv/lib/python3.12/site-packages/fsspec/parquet.py:93: Optional key-word arguments to pass to `fs.open`
- .venv/lib/python3.12/site-packages/fsspec/parquet.py:354: "Please pass 'fastparquet', 'pyarrow', or 'auto'"
- .venv/lib/python3.12/site-packages/fsspec/parquet.py:370: pass
- .venv/lib/python3.12/site-packages/fsspec/parquet.py:480: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/tests/abstract/get.py:426: pass
- .venv/lib/python3.12/site-packages/fsspec/tests/abstract/copy.py:423: pass
- .venv/lib/python3.12/site-packages/fsspec/tests/abstract/put.py:434: pass
- .venv/lib/python3.12/site-packages/fsspec/tests/abstract/__init__.py:246: raise NotImplementedError("This function must be overridden in derived classes")
- .venv/lib/python3.12/site-packages/fsspec/tests/abstract/__init__.py:260: raise NotImplementedError("This function must be overridden in derived classes")
- .venv/lib/python3.12/site-packages/fsspec/implementations/dask.py:144: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/dask.py:148: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/git.py:31: Same as ``path``, but passed as part of a chained URL. This one
- .venv/lib/python3.12/site-packages/fsspec/implementations/zip.py:43: Kwargs passed when instantiating the target FS, if ``fo`` is
- .venv/lib/python3.12/site-packages/fsspec/implementations/zip.py:45: compression, allowZip64, compresslevel: passed to ZipFile
- .venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:78: # TODO: tarfile already implements compression with modes like "'r:gz'",
- .venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:92: # TODO: load and set saved index, if exists
- .venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:101: # TODO: save index to self.index_store here, if set
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:32: specified principal/password; parameters are passed with ``kerb_kwargs``
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:37: basic-auth: used when both parameter ``user`` and parameter ``password``
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:52: password=None,
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:76: password: str or None
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:77: If given, assert the password to use for basic auth. If password
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:91: URLs are passed, and function must conform to
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:113: "If passing a delegation token, must not set "
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:119: self.password = password
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:121: if password is not None:
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:124: "If passing a password, the user must also be"
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:163: if self.user is not None and self.password is not None:
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:166: self.session.auth = HTTPBasicAuth(self.user, self.password)
- .venv/lib/python3.12/site-packages/fsspec/implementations/webhdfs.py:188: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/libarchive.py:115: Kwargs passed when instantiating the target FS, if ``fo`` is
- .venv/lib/python3.12/site-packages/fsspec/implementations/libarchive.py:196: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/github.py:212: out = {"org": opts["username"], "repo": opts["password"]}
- .venv/lib/python3.12/site-packages/fsspec/implementations/github.py:227: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:25: ``smb://workgroup;user:password@server:port/share/folder/file.csv``.
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:31: ...     'smb://myuser:mypassword@myserver.com/' 'share/folder/file.csv'
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:35: Note that you need to pass in a valid hostname or IP address for the host
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:42: The URL components ``workgroup`` , ``user``, ``password`` and ``port`` may be
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:68: password=None,
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:82: Authentication will be anonymous or integrated if username/password are not
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:93: password: str or None
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:94: User's password on the server, if using username
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:132: self.password = password
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:183: password=self.password,
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:224: # smb://workgroup;user:password@host:port/share/folder/file.csv
- .venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:394: # TODO: use transaction support in SMB protocol
- .venv/lib/python3.12/site-packages/fsspec/implementations/memory.py:117: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/memory.py:304: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/memory.py:307: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/sftp.py:38: Parameters passed on to connection. See details in
- .venv/lib/python3.12/site-packages/fsspec/implementations/sftp.py:40: May include port, username, password...
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:147: # TODO: derive fs from `root`
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:203: kwargs: passed to __init__
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:441: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:473: # TODO: only save needed columns
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:500: raise NotImplementedError(f"{self.engine} not supported")
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:546: # TODO: only clear those that we wrote to?
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:603: Configuration is by passing a dict of references at init, or a URL to
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:685: kwargs : passed to parent class
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:748: # TODO: warning here, since this can be very expensive?
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:881: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:883: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:884: # TODO: if references is lazy, pre-fetch all paths in batch before access
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:985: # TODO: we make dircache by iterating over all entries, but for Spec >= 1,
- .venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:1146: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/ftp.py:22: password=None,
- .venv/lib/python3.12/site-packages/fsspec/implementations/ftp.py:35: Authentication will be anonymous if username/password are not
- .venv/lib/python3.12/site-packages/fsspec/implementations/ftp.py:46: password: str of None
- .venv/lib/python3.12/site-packages/fsspec/implementations/ftp.py:47: User's password on the server, if using
- .venv/lib/python3.12/site-packages/fsspec/implementations/ftp.py:65: self.cred = username or "", password or "", acct or ""
- .venv/lib/python3.12/site-packages/fsspec/implementations/ftp.py:266: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:182: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:323: # TODO: action where partial file exists in read-only cache
- .venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:572: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:616: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:776: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:779: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/cache_metadata.py:159: # TODO: consolidate blocks here
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:81: For example, ``{'auth': aiohttp.BasicAuth('user', 'pass')}``
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:87: Any other parameters passed on to requests
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:104: # TODO: Maybe rename `self.kwargs` to `self.request_options` to make
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:126: except (TimeoutError, FSTimeoutError, NotImplementedError):
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:127: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:290: raise NotImplementedError("Exclusive write")
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:293: # Support passing arbitrary file-like objects
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:367: Any other parameters, passed to requests calls
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:370: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:407: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:548: Additional parameters to pass to the HTTP request
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:582: kwargs: all other key-values are passed to requests calls.
- .venv/lib/python3.12/site-packages/fsspec/implementations/http.py:600: raise NotImplementedError("File mode not supported")
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:105: # TODO: encoding from headers
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:145: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:234: For example, ``{'auth': aiohttp.BasicAuth('user', 'pass')}``
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:236: Any other parameters passed on to requests
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:405: # Support passing arbitrary file-like objects
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:502: Any other parameters, passed to requests calls
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:505: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:677: kwargs: all other key-values are passed to requests calls.
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:693: raise NotImplementedError("File mode not supported")
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:883: # TODO: not allowed in JS
- .venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:896: # TODO:
- .venv/lib/python3.12/site-packages/fsspec/implementations/gist.py:32: Stored on `self.request_kw` and passed to `requests.get` when fetching Gist
- .venv/lib/python3.12/site-packages/fsspec/implementations/gist.py:69: """Auth parameters passed to 'requests' if we have username/token."""
- .venv/lib/python3.12/site-packages/fsspec/implementations/gist.py:146: if "password" in so and so["password"]:
- .venv/lib/python3.12/site-packages/fsspec/implementations/gist.py:147: out["token"] = so["password"]
- .venv/lib/python3.12/site-packages/fsspec/implementations/gist.py:195: raise NotImplementedError("GitHub Gist FS is read-only (no write).")
- .venv/lib/python3.12/site-packages/fsspec/implementations/gist.py:229: pass  # skip
- .venv/lib/python3.12/site-packages/fsspec/implementations/local.py:72: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/local.py:356: # TODO: if all incoming paths were posix-compliant then separator would
- .venv/lib/python3.12/site-packages/fsspec/implementations/local.py:397: # TODO: check if path is writable?
- .venv/lib/python3.12/site-packages/fsspec/implementations/local.py:452: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/dbfs.py:149: pass
- .venv/lib/python3.12/site-packages/fsspec/implementations/dbfs.py:173: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/dbfs.py:232: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/dbfs.py:234: raise NotImplementedError
- .venv/lib/python3.12/site-packages/fsspec/implementations/dbfs.py:306: A handle has a unique identifier which needs to be passed
- .venv/lib/python3.12/site-packages/numpy/conftest.py:49: # of pytest.ini, but can be overridden by passing the
- .venv/lib/python3.12/site-packages/numpy/exceptions.py:56: pass
- .venv/lib/python3.12/site-packages/numpy/exceptions.py:70: nose tester will let pass without making tests fail.
- .venv/lib/python3.12/site-packages/numpy/exceptions.py:73: pass
- .venv/lib/python3.12/site-packages/numpy/exceptions.py:84: pass
- .venv/lib/python3.12/site-packages/numpy/exceptions.py:93: pass
- .venv/lib/python3.12/site-packages/numpy/exceptions.py:106: pass
- .venv/lib/python3.12/site-packages/numpy/exceptions.py:134: message was provided. This should be the axis as passed by
- .venv/lib/python3.12/site-packages/numpy/exceptions.py:167: Alternatively, a custom exception message can be passed:
- .venv/lib/python3.12/site-packages/numpy/exceptions.py:247: pass
- .venv/lib/python3.12/site-packages/numpy/_expired_attrs_2_0.py:68: "`numpy.result_type` and pass the Python values `0`, `0.0`, or `0j`.",
- .venv/lib/python3.12/site-packages/numpy/__init__.py:451: pass
- .venv/lib/python3.12/site-packages/numpy/__init__.py:829: "pass simple sanity checks. This can be caused for example "
- .venv/lib/python3.12/site-packages/numpy/__init__.py:849: pass
- .venv/lib/python3.12/site-packages/numpy/__init__.py:914: # TODO: Remove the environment variable entirely now that it is "weak"
- .venv/lib/python3.12/site-packages/numpy/_pytesttester.py:21: warnings are passed through.
- .venv/lib/python3.12/site-packages/numpy/_pytesttester.py:93: List with any extra arguments to pass to pytests.
- .venv/lib/python3.12/site-packages/numpy/_pytesttester.py:121: 1023 passed, 2 skipped, 6 deselected, 1 xfailed in 10.39 seconds
- .venv/lib/python3.12/site-packages/numpy/_distributor_init.py:15: pass
- .venv/lib/python3.12/site-packages/numpy/random/tests/test_generator_mt19937_regressions.py:156: pass
- .venv/lib/python3.12/site-packages/numpy/random/tests/test_randomstate_regression.py:136: pass
- .venv/lib/python3.12/site-packages/numpy/random/tests/test_direct.py:91: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/random/tests/test_direct.py:160: assert_raises(NotImplementedError, dummy.generate_state, 10)
- .venv/lib/python3.12/site-packages/numpy/random/tests/test_direct.py:567: def test_passthrough(self):
- .venv/lib/python3.12/site-packages/numpy/random/tests/test_random.py:542: pass
- .venv/lib/python3.12/site-packages/numpy/random/tests/test_random.py:1069: # TODO: Include test for randint once it can broadcast
- .venv/lib/python3.12/site-packages/numpy/random/tests/test_generator_mt19937.py:1038: assert_raises(NotImplementedError, random.shuffle, arr, 1)
- .venv/lib/python3.12/site-packages/numpy/random/tests/test_regression.py:134: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/extbuild.py:101: Where to find the libraries, ``-L`` passed to the linker
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:51: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:100: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:192: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:429: except (TypeError, ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:430: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:449: raise NotImplementedError('cannot compare to a scalar '
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:456: except (TypeError, ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:457: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:632: except (NotImplementedError, TypeError):
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:633: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:731: except (TypeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:732: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:1161: except (TypeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:1162: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:1229: The following assertion passes because each finite element of `x` is
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:1254: the assertion passes.
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:1445: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:1559: A label to identify `code_str` with. This is passed into ``compile``
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:1880: raise NotImplementedError("_nulp not implemented for complex array")
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:1978: >>> # or passing a func
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2025: Arguments passed to `func`.
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2027: Keyword arguments passed to `func`.
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2114: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2121: All arguments are passed as this to the underlying tempfile.mkdtemp
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2137: parameters are the same as for tempfile.mkstemp and are passed directly
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2262: warnings will be passed out and be matched by the outer level.
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2292: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2459: # There is no filter in place, so pass to the outside handler
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2460: # unless we should only pass it once
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2564: Arguments passed to `func`.
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2566: Keyword arguments passed to `func`.
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2677: pass
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2728: def run_threaded(func, max_workers=8, pass_count=False,
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2729: pass_barrier=False, outer_iterations=1,
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2739: if pass_barrier:
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2742: if pass_count:
- .venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:2756: if len(futures) < max_workers and pass_barrier:
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:624: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:771: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1087: pass
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1225: def test_float64_pass(self):
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1270: def test_float32_pass(self):
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1311: def test_float16_pass(self):
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1352: def test_complex128_pass(self):
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1404: def test_complex64_pass(self):
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1561: pass
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1588: pass
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1804: pass
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1820: pass
- .venv/lib/python3.12/site-packages/numpy/testing/tests/test_utils.py:1851: def test_passes(self):
- .venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:82: '-include<header>'  Writes additional headers in the C wrapper, can be passed
- .venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:113: thread safety issues before passing
- .venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:153: be passed multiple times for multiple dependencies.
- .venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:217: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:296: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:461: # TODO: Remove all this when scaninputline is replaced
- .venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:577: # and `sys.argv` is passed to the rest of `f2py` as is.
- .venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:653: # TODO: Once distutils is dropped completely, i.e. min_ver >= 3.12, unify into --fflags
- .venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:728: outmess('Using meson backend\nWill pass --lower to f2py\nSee https://numpy.org/doc/stable/f2py/buildtools/meson.html\n')
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:23: # TODO: support logical constants (Op.BOOLEAN)
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:24: # TODO: support logical operators (.AND., ...)
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:25: # TODO: support defined operators (.MYOP., ...)
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:110: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:150: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:229: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:396: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:414: raise NotImplementedError(f'tostring for op {self.op}')
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:519: # TODO: other kind not used
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:569: # TODO: implement a method for deciding when __call__ should
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:657: raise NotImplementedError(f'substitute method for {self.op}: {self!r}')
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:713: raise NotImplementedError(f'traverse method for {self.op}')
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:810: # TODO: determine correct kind
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:845: # TODO: determine correct kind
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:895: # TODO: denom kind not used
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:1107: # TODO: find common divisor of coefficients
- .venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:1350: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/f2py/_isocbind.py:55: # TODO: See gh-25229
- .venv/lib/python3.12/site-packages/numpy/f2py/func2subr.py:189: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/func2subr.py:276: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/auxfuncs.py:140: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/auxfuncs.py:614: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/auxfuncs.py:721: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/auxfuncs.py:723: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:745: /* TODO: change the type of `len` so that we can remove this */
- .venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:805: // TODO: update when numpy will support 1-byte and
- .venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:830: /* TODO: This error (and most other) error handling needs cleaning. */
- .venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:852: # TODO: These should be dynamically generated, too many mapped to int things,
- .venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:919: /*pass*/;
- .venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:968: /*pass*/;
- .venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:1018: /*pass*/;
- .venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:1094: /*pass*/;
- .venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:249: # TODO: support Fortran `len` function with optional kind parameter
- .venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:298: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:501: # TODO: Evaluate intent_flags here.
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:133: TODO:
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:440: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:840: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:919: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:1156: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:1170: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:1180: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:1960: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2036: TODO:
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2305: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2343: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2469: # TODO: test .eq., .neq., etc replacements.
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2515: outmess(f'get_parameters[TODO]: '
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2558: # TODO: use symbolic from PR #19805
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2597: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2639: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2648: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2782: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2910: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2917: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:3347: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:3471: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:3634: # `&<varname>` in argument passing
- .venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:3661: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:387: # Case I: --lower is passed
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:394: # Case II: --no-lower is passed
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:415: # TODO: Clean up to prevent passing --overwrite-signature
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:514: TODO: Test to ensure this has no effect without --latex-doc
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:658: TODO: Document this in the help string
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:682: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:683: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:691: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:692: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:696: """Check that Fortran-to-Python KIND specs can be passed
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:747: # TODO: f2py2e should not call sys.exit() after printing the version
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:821: # TODO: These should be tested separately
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:827: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:828: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:835: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:836: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:843: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:844: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:851: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:852: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:859: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:860: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:867: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:868: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:875: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:876: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:883: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:884: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:891: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:892: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:899: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:900: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:907: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:908: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:915: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:916: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:923: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:924: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:931: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:932: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:939: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:940: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:947: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:948: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:955: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:956: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:963: # TODO: populate
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:964: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_array_from_pyobj.py:411: """Test if intent(in) array can be passed without copies"""
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_crackfortran.py:327: # it's unlikely that a bad regex will pass even on fast CPUs
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_return_character.py:31: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_modules.py:23: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_modules.py:38: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/util.py:142: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/util.py:146: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_docs.py:64: # TODO: implement test methods for other example Fortran codes
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_regression.py:163: # Compile dubious file using passed flags
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_regression.py:168: # Meson will collect and dedup these to pass to fortran_args:
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_return_real.py:49: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/tests/test_return_complex.py:51: pass
- .venv/lib/python3.12/site-packages/numpy/f2py/_backends/_backend.py:44: pass
- .venv/lib/python3.12/site-packages/numpy/fft/_pocketfft.py:62: # Calculate the normalization factor, passing in the array dtype to
- .venv/lib/python3.12/site-packages/numpy/fft/_pocketfft.py:720: "`axes[i]`. To retain current behaviour, pass a sequence "
- .venv/lib/python3.12/site-packages/numpy/fft/_pocketfft.py:732: "of the corresponding 1-D transform, pass the value matching "
- .venv/lib/python3.12/site-packages/numpy/fft/_pocketfft.py:816: incompatible with passing in all but the trivial ``s``).
- .venv/lib/python3.12/site-packages/numpy/fft/_pocketfft.py:957: incompatible with passing in all but the trivial ``s``).
- .venv/lib/python3.12/site-packages/numpy/fft/_pocketfft.py:1213: incompatible with passing in all but the trivial ``s``).
- .venv/lib/python3.12/site-packages/numpy/fft/_pocketfft.py:1328: incompatible with passing in all but the trivial ``s``).
- .venv/lib/python3.12/site-packages/numpy/fft/_pocketfft.py:1440: incompatible with passing in all but the trivial ``s``).
- .venv/lib/python3.12/site-packages/numpy/fft/__init__.py:203: # TODO: `numpy.fft.helper`` was deprecated in NumPy 2.0. It should
- .venv/lib/python3.12/site-packages/numpy/fft/_helper.py:147: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/fft/_helper.py:206: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/fft/tests/test_pocketfft.py:442: # With s, shape varies, so generally one cannot pass in out.
- .venv/lib/python3.12/site-packages/numpy/polynomial/polyutils.py:82: When False, the inputs are passed through intact.
- .venv/lib/python3.12/site-packages/numpy/polynomial/polyutils.py:707: Like `operator.index`, but emits a custom exception when passed an
- .venv/lib/python3.12/site-packages/numpy/polynomial/hermite_e.py:1253: passing in a 2D-array that contains one dataset per column.
- .venv/lib/python3.12/site-packages/numpy/polynomial/chebyshev.py:1526: passing in a 2D-array that contains one dataset per column.
- .venv/lib/python3.12/site-packages/numpy/polynomial/chebyshev.py:1742: extra arguments passed in the `args` parameter.
- .venv/lib/python3.12/site-packages/numpy/polynomial/chebyshev.py:1974: extra arguments passed in the `args` parameter.
- .venv/lib/python3.12/site-packages/numpy/polynomial/laguerre.py:1311: passing in a 2D-array that contains one dataset per column.
- .venv/lib/python3.12/site-packages/numpy/polynomial/legendre.py:1268: passing in a 2D-array that contains one dataset per column.
- .venv/lib/python3.12/site-packages/numpy/polynomial/polynomial.py:1307: call to `polyfit` by passing in for `y` a 2-D array that contains
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:117: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:122: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:127: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:132: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:137: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:142: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:147: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:152: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:157: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:162: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:167: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:172: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:177: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:182: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:187: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:314: # If a user passes in something other than a string, the above
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:335: f"Unsupported format string '{fmt_str}' passed to "
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:401: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:415: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:424: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:432: # TODO: we're stuck with disabling math formatting until we handle
- .venv/lib/python3.12/site-packages/numpy/polynomial/hermite.py:1328: passing in a 2D-array that contains one dataset per column.
- .venv/lib/python3.12/site-packages/numpy/polynomial/tests/test_symbol.py:41: Values for symbol that should pass input validation.
- .venv/lib/python3.12/site-packages/numpy/polynomial/tests/test_printing.py:402: # be fixed such that tests below continue to pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/tests/test_polyutils.py:107: pass
- .venv/lib/python3.12/site-packages/numpy/polynomial/tests/test_polynomial.py:195: pass
- .venv/lib/python3.12/site-packages/numpy/tests/test_ctypeslib.py:25: pass
- .venv/lib/python3.12/site-packages/numpy/tests/test_ctypeslib.py:31: pass
- .venv/lib/python3.12/site-packages/numpy/tests/test_ctypeslib.py:377: assert_raises(NotImplementedError, np.ctypeslib.as_ctypes_type, dt)
- .venv/lib/python3.12/site-packages/numpy/tests/test_public_api.py:576: # It must be empty for the test to pass.
- .venv/lib/python3.12/site-packages/numpy/typing/__init__.py:124: During runtime numpy aggressively casts any passed 0D arrays into their
- .venv/lib/python3.12/site-packages/numpy/typing/tests/test_typing.py:40: PASS_DIR = os.path.join(DATA_DIR, "pass")
- .venv/lib/python3.12/site-packages/numpy/typing/tests/test_typing.py:142: def test_pass(path) -> None:
- .venv/lib/python3.12/site-packages/numpy/typing/tests/test_runtime.py:56: def func(a: typ) -> None: pass
- .venv/lib/python3.12/site-packages/numpy/typing/tests/test_runtime.py:68: def func(a: typ_str) -> None: pass
- .venv/lib/python3.12/site-packages/numpy/typing/tests/data/pass/array_constructors.py:12: pass
- .venv/lib/python3.12/site-packages/numpy/typing/tests/data/pass/simple.py:1: """Simple expression that should pass with mypy."""
- .venv/lib/python3.12/site-packages/numpy/typing/tests/data/pass/ufunc_config.py:57: pass
- .venv/lib/python3.12/site-packages/numpy/typing/tests/data/pass/ufunc_config.py:59: pass
- .venv/lib/python3.12/site-packages/numpy/typing/tests/data/pass/arrayterator.py:21: pass
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:127: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:190: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:276: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:344: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:433: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:545: # TODO: this works around .astype(bool) not working properly (gh-9847)
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:1406: msg = "'%s' arg requires %d <= %s < %d, but %d was passed in"
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:1467: pass
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:1900: the coordinate arrays passed to `function`.
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:1902: Data-type of the coordinate arrays passed to `function`.
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:1911: The result of the call to `function` is passed back directly.
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:1922: Keywords other than `dtype` and `like` are passed to `function`.
- .venv/lib/python3.12/site-packages/numpy/_core/numeric.py:2691: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/multiarray.py:147: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/_ufunc_config.py:356: pass
- .venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:98: pass  # OK, do nothing.
- .venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:142: To always use the full repr without summarization, pass `sys.maxsize`.
- .venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:244: If set a passed function will be used for generating arrays' repr.
- .venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:426: Should be passed a base-class ndarray, since it makes no guarantees about
- .venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:1020: # do a first pass of printing all the numbers, to determine sizes
- .venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:1379: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:1567: # TODO: Custom repr for user DTypes, logic should likely move.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:852: If True, then sub-classes will be passed-through, otherwise
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:954: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:979: asanyarray : Similar function which passes through subclasses.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:1011: Contrary to `asanyarray`, ndarray subclasses are not passed through:
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:1027: Convert the input to an ndarray, but pass ndarray subclasses through.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:1046: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:1091: Instances of `ndarray` subclasses are passed through as-is:
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:1244: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:1675: Must be ``"cpu"`` if passed which may allow importing an array
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:1755: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:2276: assignment examples; TODO).
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:3199: If True, then sub-classes will be passed-through (default), otherwise
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:3379: arguments, and this function always passes sub-classes through.)
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:3390: and will not pass sub-classes through by default.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:3847: the elements of the shape parameter to be passed in as separate arguments.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:4334: file, bypassing the file object's ``write`` method. As a result, tofile
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:4841: (these will be converted to a NumPy array before being passed on to
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:4911: If passed as a keyword argument, can be Ellipses (``out=...``) to
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5097: corresponding passed-in array, starting from the end of the shape tuple.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5173: If passed as a keyword argument, can be Ellipses (``out=...``) to
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5195: defined, one has to pass in also ``initial``.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5287: For consistency with ``ufunc.__call__``, if passed as a keyword
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5369: For consistency with ``ufunc.__call__``, if passed as a keyword
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5465: Arguments to pass on to the ufunc. Typically `dtype` or `out`.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5572: ``complex`` thus behave weak and should be passed for "untyped"
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5582: The ufunc ``dtype`` argument is equivalent to passing a tuple with
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5602: dtypes may not match the passed in ones (casting is necessary).
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5607: This API requires passing dtypes, define them for convenience:
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5613: The typical ufunc call does not pass an output dtype.  `numpy.add` has two
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5622: ``resolve_dtypes`` supports "weak" handling for Python scalars by passing
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5699: passed context as new first input and ``auxdata`` as (replaced) last.
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5904: and passing it directly to `numpy.dtype` will not accurately reconstruct
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:5934: of the tuple can be passed directly as arguments to the
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:6576: The returned tuple can be passed as the second argument of `numpy.datetime64` and
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs.py:6932: Whether or not items in an array-like passed to an array creation
- .venv/lib/python3.12/site-packages/numpy/_core/memmap.py:36: passing the object created in its 'buffer=' parameter.
- .venv/lib/python3.12/site-packages/numpy/_core/memmap.py:259: pass
- .venv/lib/python3.12/site-packages/numpy/_core/_asarray.py:33: is returned for passing to compiled code (perhaps through ctypes).
- .venv/lib/python3.12/site-packages/numpy/_core/_asarray.py:64: asanyarray : Convert to an ndarray, but pass through ndarray subclasses.
- .venv/lib/python3.12/site-packages/numpy/_core/overrides.py:18: NumPy arrays. If an array-like passed in as ``like`` supports
- .venv/lib/python3.12/site-packages/numpy/_core/overrides.py:21: compatible with that passed in via this argument."""
- .venv/lib/python3.12/site-packages/numpy/_core/overrides.py:39: All arguments are required, and can only be passed by position.
- .venv/lib/python3.12/site-packages/numpy/_core/overrides.py:52: overrides.  Arguments passed calling the ``_ArrayFunctionDispatcher``
- .venv/lib/python3.12/site-packages/numpy/_core/overrides.py:59: The original implementation passed in.
- .venv/lib/python3.12/site-packages/numpy/_core/overrides.py:121: and not passed on.  A function implementing `like=` must call its
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs_scalars.py:26: pass
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs_scalars.py:129: # TODO: These docs probably need an if to highlight the default rather than
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs_scalars.py:272: 3. When a ``dtype=`` is passed the call is roughly the same as an
- .venv/lib/python3.12/site-packages/numpy/_core/_add_newdocs_scalars.py:338: # TODO: work out how to put this on the base class, np.floating
- .venv/lib/python3.12/site-packages/numpy/_core/records.py:153: pass
- .venv/lib/python3.12/site-packages/numpy/_core/records.py:222: pass
- .venv/lib/python3.12/site-packages/numpy/_core/records.py:422: pass
- .venv/lib/python3.12/site-packages/numpy/_core/records.py:562: "the shape and suppress this warning, pass `shape=None` instead.",
- .venv/lib/python3.12/site-packages/numpy/_core/records.py:585: If `dtype` is ``None``, these arguments are passed to
- .venv/lib/python3.12/site-packages/numpy/_core/records.py:679: If `dtype` is ``None``, these arguments are passed to
- .venv/lib/python3.12/site-packages/numpy/_core/records.py:772: If `dtype` is ``None``, these arguments are passed to
- .venv/lib/python3.12/site-packages/numpy/_core/records.py:855: If `dtype` is ``None``, these arguments are passed to
- .venv/lib/python3.12/site-packages/numpy/_core/records.py:967: If `dtype` is ``None``, these arguments are passed to
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:44: # but this follows what was done before. TODO: revisit this.
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:70: passkwargs = {k: v for k, v in kwargs.items()
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:77: pass
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:82: return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:84: return reduction(axis=axis, out=out, **passkwargs)
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:86: return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:90: # Same as above function, but dtype is always bool (but never passed on)
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:91: passkwargs = {k: v for k, v in kwargs.items()
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:98: pass
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:100: return reduction(axis=axis, out=out, **passkwargs)
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:102: return ufunc.reduce(obj, axis, bool, out, **passkwargs)
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:316: "use `shape=...` or pass shape positionally instead. "
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:847: The next example shows the use of multiple values passed to `kth`.
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2272: can be passed at the same time. Default: ``None``.
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2371: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2372: passed through to the `sum` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2507: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2508: passed through to the `any` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2617: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2618: passed through to the `all` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2997: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2998: passed through to the `ptp` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3078: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3079: passed through to the ``max`` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3216: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3217: passed through to the ``min`` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3363: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3364: passed through to the `prod` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3772: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3773: passed through to the `mean` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3856: pass
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3906: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3907: passed through to the `std` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:4060: pass
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:4110: If the default value is passed, then `keepdims` will not be
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:4111: passed through to the `var` method of sub-classes of
- .venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:4264: pass
- .venv/lib/python3.12/site-packages/numpy/_core/_internal.py:202: 'is deprecated; pass either a single number or indicate '
- .venv/lib/python3.12/site-packages/numpy/_core/_internal.py:324: when passing this attribute to arbitrary C-code to avoid trouble
- .venv/lib/python3.12/site-packages/numpy/_core/_internal.py:742: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/_core/function_base.py:70: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/_core/function_base.py:361: passing through two points; the output will follow the shortest such path.)
- .venv/lib/python3.12/site-packages/numpy/_core/function_base.py:483: pass
- .venv/lib/python3.12/site-packages/numpy/_core/_dtype_ctypes.py:27: # While this module is not used unless the user passes in ctypes
- .venv/lib/python3.12/site-packages/numpy/_core/_dtype_ctypes.py:119: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/_core/numerictypes.py:369: pass
- .venv/lib/python3.12/site-packages/numpy/_core/strings.py:736: passing a non-ASCII character in ``fillchar`` when ``a`` is of dtype "S"
- .venv/lib/python3.12/site-packages/numpy/_core/strings.py:805: passing a non-ASCII character in ``fillchar`` when ``a`` is of dtype "S"
- .venv/lib/python3.12/site-packages/numpy/_core/strings.py:870: passing a non-ASCII character in ``fillchar`` when ``a`` is of dtype "S"
- .venv/lib/python3.12/site-packages/numpy/_core/_methods.py:88: # TODO: Optimize case when `where` is broadcast along a non-reduction
- .venv/lib/python3.12/site-packages/numpy/_core/shape_base.py:210: raise TypeError('arrays to stack must be passed as a "sequence" type '
- .venv/lib/python3.12/site-packages/numpy/_core/shape_base.py:574: The full index of `arrays` within the nested lists passed to
- .venv/lib/python3.12/site-packages/numpy/_core/shape_base.py:753: `arrays` is the argument passed to
- .venv/lib/python3.12/site-packages/numpy/_core/shape_base.py:801: If passed a single ndarray or scalar (a nested list of depth 0), this
- .venv/lib/python3.12/site-packages/numpy/_core/_dtype.py:71: is the object passed as the first parameter to the dtype
- .venv/lib/python3.12/site-packages/numpy/_core/_dtype.py:174: # TODO: this path can never be reached
- .venv/lib/python3.12/site-packages/numpy/_core/_dtype.py:183: # TODO: this duplicates the C metastr_to_unicode functionality
- .venv/lib/python3.12/site-packages/numpy/_core/einsumfunc.py:865: pass
- .venv/lib/python3.12/site-packages/numpy/_core/getlimits.py:374: TODO: MachAr should be retired completely ideally.  We currently only
- .venv/lib/python3.12/site-packages/numpy/_core/getlimits.py:500: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_cpu_features.py:75: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_coercion.py:32: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_coercion.py:357: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_coercion.py:452: # TODO: This discrepancy _should_ be resolved, either by relaxing the
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_coercion.py:590: # These are tests for bad objects passed into `np.array`, in general
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_coercion.py:637: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_coercion.py:705: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_coercion.py:709: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_coercion.py:712: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_coercion.py:905: # TODO: This is arguably weird/wrong, but seems old:
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_arrayprint.py:30: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_arrayprint.py:1202: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_arrayprint.py:1212: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_errstate.py:79: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_errstate.py:86: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath_complex.py:17: # TODO: branch cuts (use Pauli code)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath_complex.py:18: # TODO: conj 'symmetry'
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath_complex.py:19: # TODO: FPU exceptions
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath_complex.py:28: # TODO: replace with a check on whether platform-provided C99 funcs are used
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath_complex.py:31: # TODO This can be xfail when the generator functions are got rid of.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath_complex.py:126: # TODO This can be xfail when the generator functions are got rid of.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath_complex.py:483: # TODO This can be xfail when the generator functions are got rid of.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_half.py:561: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath.py:283: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath.py:376: # make sure np.equal.reduce raises a TypeError if an array is passed
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath.py:3138: "Bad arguments passed in ufunc call",
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath.py:3667: # While we're at it, check that default output is never passed on.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath.py:4338: reason="Older glibc versions are imprecise (maybe passes with SIMD?)"
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath.py:4601: # The value of tiny for double double is NaN, so we need to pass the
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_umath.py:4808: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_casting_unittests.py:781: # TODO: While this test is fairly thorough, right now, it does not
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:11: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:13: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:16: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:18: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:21: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:23: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:30: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:60: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:85: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarinherit.py:93: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:22: run_threaded(func, 500, pass_count=True)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:44: run_threaded(f, NUM_THREADS, pass_barrier=True)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:63: run_threaded(func, 100, pass_count=True)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:76: pass_count=True)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:135: run_threaded(closure, NUM_THREADS, pass_barrier=True)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:147: run_threaded(closure, outer_iterations=100, pass_barrier=True)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:159: run_threaded(closure, pass_barrier=True, prepare_args=prepare_args)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:170: run_threaded(closure, max_workers=10, pass_barrier=True)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:269: run_threaded(closure, 250, pass_barrier=True)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:276: # In a second pass the indices of the non-zero elements are determined, but they can have changed
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multithreading.py:292: run_threaded(func, max_workers=10, pass_count=True, outer_iterations=5)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:126: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:617: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:657: def __getitem__(self, _, /): pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:937: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:1129: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:1697: # But never when a dtype is passed in:
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:2813: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3354: # test passing in an output array
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3425: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3438: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3441: assert_raises(NotImplementedError, np.dot, A(), A())
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3442: assert_raises(NotImplementedError, np.matmul, A(), A())
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3443: assert_raises(NotImplementedError, np.inner, A(), A())
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3539: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3687: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3771: # Minimal test for the out argument being passed on correctly
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3772: # NOTE: The ability to pass `out` is currently undocumented!
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:3904: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:4114: # is passed on (latter is another regression tests for github bug 4753)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5162: # The tests that call us pass clip_min and clip_max that
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5165: # passed explicitly to avoid a warning.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5517: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5523: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5664: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5746: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5751: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5755: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5959: testpassed = False
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5963: testpassed = True
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5964: assert_(testpassed)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5968: testpassed = False
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5972: testpassed = True
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:5973: assert_(testpassed)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:6003: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:6013: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:7665: # TODO: test for multidimensional
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8132: # Native-only data types can be passed through the buffer interface
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8413: NotImplementedError,
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8627: # explicitly passing copy=None shouldn't raise a warning
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8632: # As of NumPy 2.1, explicitly passing copy=True does trigger passing
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8640: # And passing copy=False gives a deprecation warning, but also raises
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8654: self.true_passed = False
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8658: self.true_passed = True
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8665: assert arr_random.true_passed
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8670: assert not arr_random.true_passed
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8675: assert not arr_random.true_passed
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8679: assert arr_random.true_passed
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8685: assert not arr_random.true_passed
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8692: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8700: except NotImplementedError:
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8701: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:8933: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:9011: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:9013: assert_raises(NotImplementedError, bool, np.array(NotConvertible()))
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:9014: assert_raises(NotImplementedError, bool, np.array([NotConvertible()]))
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:9056: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:9057: assert_raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:9060: assert_raises(NotImplementedError,
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:9213: # pass empty where result through an assignment which reads the data of
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:9879: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_multiarray.py:10472: If a 'width' parameter is passed into ``binary_repr`` that is insufficient
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarmath.py:103: # TODO: It would be nice to resolve this issue.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarmath.py:889: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarmath.py:900: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarmath.py:910: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarmath.py:932: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarmath.py:936: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarmath.py:1051: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarmath.py:1054: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalarmath.py:1143: # TODO: Power is a bit special, but here mostly bools seem to behave oddly
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_records.py:218: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_shape_base.py:882: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_argparse.py:62: # the second argument is positional but can be passed as keyword.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_dtype.py:330: """Test if an appropriate exception is raised when passing bad values to
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_dtype.py:1220: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_dtype.py:1508: # If we only pass scalars (mainly python ones!), NEP 50 means
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_dtype.py:1587: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_dtype.py:1612: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_dtype.py:1922: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_dtype.py:1942: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_memmap.py:200: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_array_interface.py:126: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_dlpack.py:74: def test_dtype_passthrough(self, arr, dtype):
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_nditer.py:3048: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_nditer.py:3102: # passing an itershape alone is not enough, the op_axes are also needed
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_nditer.py:3131: # followup: this tests for a bug introduced in the first pass of gh-18450,
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_nditer.py:3224: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_stringdtype.py:573: # explicitly passing arr_rev.dtype
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_stringdtype.py:897: # The promoter should be able to handle things if users pass `dtype=`
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_stringdtype.py:1027: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_stringdtype.py:1558: # TODO: generalize to more ufuncs
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_arrayobject.py:42: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_arrayobject.py:53: # * NumPy returns scalars, if `return_scalar` is passed as True to allow
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_arrayobject.py:62: # (I don't think NumPy would pass `None`, but it seems clear to support)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/_locales.py:40: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_api.py:210: # subok=False passes through a non-subclassed array
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_api.py:215: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_api.py:219: # subok=True passes through a subclass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_datetime.py:1609: # TODO: Allowing unsafe casting by
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_datetime.py:2590: # TODO: add absolute (gold standard) time span limit strings
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalar_methods.py:234: # Third argument not passed, None, or True "decays" to scalar.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_scalar_methods.py:235: # (I don't think NumPy would pass `None`, but it seems clear to support)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:198: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:316: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:902: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:1135: # can pass in other types of integer (with __index__ protocol)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:1148: # should pass in indices.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:1152: # cannot pass an index unless there is only one dimension
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:1155: # or pass in generally the wrong number of axes
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:1250: # Cannot pass in both axis and axes.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:1389: # matmul mimicker passes, and returns a vector.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:1682: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:2636: # is passed.  The two paths below should differ, without `dtype=` the
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:2642: # If `dtype=` is passed, the calculation is forced to float32:
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:2738: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:2761: pass  # ok, just not implemented
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:2768: pass  # ok, just not implemented
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_ufunc.py:2775: pass  # ok, just not implemented
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_mem_policy.py:222: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_mem_policy.py:291: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_longdouble.py:358: # architecture, but should pass natively.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_cython.py:241: # These conversion passes via `__int__`, not `__index__`:
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_custom_dtypes.py:60: # implementation bypasses the object repr
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_custom_dtypes.py:123: # Addition reduction works (as of writing requires to pass initial
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_custom_dtypes.py:240: res = arr.astype(SF)  # passing the class class
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_custom_dtypes.py:245: # passing in a dtype class should return
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_indexing.py:533: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_indexing.py:718: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_indexing.py:745: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:1031: # pass the assert
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:1317: # The same type passed in twice to promote types always
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:1536: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:1745: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:1915: # result grows on the second pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:1922: # result shrinks on the second pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:1962: # assert that an exception in first pass is handled correctly
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:1966: # raise exception in second pass for 1-dimensional loop
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:1970: # raise exception in second pass for n-dimensional loop
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:2089: we pre-create arrays as we sometime want to pass the same instance
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:2482: # explicitly passing "unsafe" will silence warning
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:3514: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:4124: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_numeric.py:4132: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:754: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:1099: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:1574: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:1590: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:1892: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:2218: def passer(*args):
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:2219: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:2221: assert_raises(ValueError, np.frompyfunc, passer, 64, 1)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:2556: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_regression.py:2560: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_einsum.py:164: # Check order kwarg, asanyarray allows 1d to pass through
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_einsum.py:173: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_einsum.py:232: # pass-through
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_einsum.py:653: # all-ones array was bypassing bug (ticket #10930)
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_overrides.py:61: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_overrides.py:157: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_overrides.py:291: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_overrides.py:296: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_overrides.py:392: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_overrides.py:447: def test_bad_like_passing(self):
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_overrides.py:448: # Cover internal sanity check for passing like as first positional arg
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_overrides.py:450: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_overrides.py:473: pass
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_deprecations.py:250: def test_both_passed(self, func):
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_deprecations.py:295: pass  # OverflowErrors always happened also before and are OK.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_deprecations.py:301: pass  # OverflowErrors always happened also before and are OK.
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_deprecations.py:401: return 'pass context'
- .venv/lib/python3.12/site-packages/numpy/_core/tests/test_deprecations.py:406: return 'pass'
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:53: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:57: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:61: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:65: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:69: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:73: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:77: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:81: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:85: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:93: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:97: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py:101: pass
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_masked_matrix.py:232: # matrix, this test should either still pass, or both actual and
- .venv/lib/python3.12/site-packages/numpy/matrixlib/tests/test_interaction.py:134: # subok=True passes through a matrix
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:91: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:95: Adjust the axis passed to argsort, warning if necessary
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:116: "Explicitly pass -1 or None to silence this warning.",
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:159: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:167: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:237: # TODO: This is probably a mess, but should best preserve behavior?
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:369: An array of numeric data can also be passed.
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:421: An array of numeric data can also be passed.
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:480: # TODO: It seems better to always store a valid fill_value, the oddity
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:513: # that the passed fill_value is not compatible with the ndtype.
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:1020: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:1097: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:1238: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:2348: Tolerance parameters passed on to `isclose`
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:2842: array with the same shape as ``data`` by passing in a scalar
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:2960: # if users pass `mask=None` be forgiving here and cast it False
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:3135: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:3222: If None, then this argument is inferred from the passed `dtype`, or
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:3287: pass  # leave _fill_value as is
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:3481: raise NotImplementedError(err_msg)
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:3507: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:3628: raise NotImplementedError("Coming soon: setting the mask per records!")
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:4719: (Masked arrays currently use 'A' on the data when 'K' is passed.)
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:4750: # TODO: We don't actually support K, so use A instead.  We could
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:6416: NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:6420: raise NotImplementedError("MaskedArray.tofile() not implemented yet.")
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:6777: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:6807: "Format strings passed to MaskedConstant are ignored,"
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:6968: "Explicitly pass 0 or None to silence this warning.",
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:8230: pass
- .venv/lib/python3.12/site-packages/numpy/ma/core.py:8679: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:298: pass
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:304: argument followed by auxiliary args that are passed verbatim for
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:322: of arrays followed by auxiliary args that are passed verbatim for
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:336: arguments that are passed verbatim for both the data and mask calls.
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:363: are passed through verbatim for the data and mask calls. Arrays
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:688: # Don't pass on the keepdims argument if one wasn't given.
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:1009: raise NotImplementedError("compress_rowcols works for 2D arrays only.")
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:1048: raise NotImplementedError("compress_rows works for 2D arrays only.")
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:1089: raise NotImplementedError("compress_cols works for 2D arrays only.")
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:1123: NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:1168: raise NotImplementedError("mask_rowcols works for 2D arrays only.")
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:1228: "The axis argument has always been ignored, in future passing it "
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:1278: "The axis argument has always been ignored, in future passing it "
- .venv/lib/python3.12/site-packages/numpy/ma/extras.py:2172: raise NotImplementedError("Currently limited to at most 2D array.")
- .venv/lib/python3.12/site-packages/numpy/ma/mrecords.py:185: pass
- .venv/lib/python3.12/site-packages/numpy/ma/mrecords.py:197: raise NotImplementedError("MaskedRecords is currently limited to"
- .venv/lib/python3.12/site-packages/numpy/ma/mrecords.py:208: pass
- .venv/lib/python3.12/site-packages/numpy/ma/mrecords.py:504: to a masked array if needed. If a 2D array is passed as argument, it is
- .venv/lib/python3.12/site-packages/numpy/ma/mrecords.py:547: to a masked array if needed. If a 2D array is passed as argument, it is
- .venv/lib/python3.12/site-packages/numpy/ma/mrecords.py:656: raise NotImplementedError("Wow, binary file")
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_mrecords.py:255: except NotImplementedError:
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_mrecords.py:257: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_mrecords.py:265: except (NotImplementedError, TypeError):
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_mrecords.py:266: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:341: # passed on, i.e., that it would be "is" instead of "==".
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:720: # TODO FIXME: Find out what the following raises a warning in r8247
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_extras.py:995: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_extras.py:1378: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_extras.py:1483: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:1117: # Test case to check the NotImplementedError.
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:1120: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:1383: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:2557: # Check that code does not crash if passed an ndarray sub-class that
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:2570: # Check that fill_value gets reset if passed a dtype but not a
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:3833: # assert_equal crashes when passed np.ma.mask
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:4988: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5065: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5079: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5603: pass
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5617: # TODO: Test masked_object, masked_equal, ...
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5707: # the mask of the output should not affect the result, however it is passed
- .venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5816: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_arraypad_impl.py:781: # Make sure that no unsupported keywords were passed for the current mode
- .venv/lib/python3.12/site-packages/numpy/lib/_arraypad_impl.py:819: pass  # Do nothing as _pad_simple already returned the correct result
- .venv/lib/python3.12/site-packages/numpy/lib/_arraypad_impl.py:831: # passed, don't need to do anything more as _pad_simple already
- .venv/lib/python3.12/site-packages/numpy/lib/_polynomial_impl.py:484: passing in a 2D-array that contains one dataset per column.
- .venv/lib/python3.12/site-packages/numpy/lib/_type_check_impl.py:402: Value to be used to fill NaN values. If no value is passed
- .venv/lib/python3.12/site-packages/numpy/lib/_type_check_impl.py:406: passed then positive infinity values will be replaced with a very
- .venv/lib/python3.12/site-packages/numpy/lib/_type_check_impl.py:410: passed then negative infinity values will be replaced with a very
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:54: Convert attribute look-ups to getitems on the object passed in.
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:105: pathlib.Path objects. `args` and `kwargs` are passed to the zipfile.ZipFile
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:145: Additional keyword arguments to pass on to pickle.load.
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:150: to load securely and thus require explicitly passing a larger value.
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:152: This option is ignored when `allow_pickle` is passed.  In that case
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:319: constructed data. Consider passing ``allow_pickle=False`` to
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:355: to load securely and thus require explicitly passing a larger value.
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:357: This option is ignored when `allow_pickle` is passed.  In that case
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:436: # in. Pickle does not pass on the encoding information to
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:648: Keys passed in `kwds` are used as filenames inside the ZIP archive.
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1173: The ability to pass a single callable to be applied to all columns
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1194: that ensures you receive byte arrays as results if possible and passes
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1196: unicode arrays and pass strings as input to converters.  If set to None
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1851: when possible and passes latin1 encoded strings to converters.
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1852: Override this value to receive unicode arrays and pass strings
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:2115: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:2167: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:2236: # behavior, so encode the string again before passing
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:2382: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:2427: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/lib/_shape_base_impl.py:535: ``axis == a.ndim``, and passing ``axis < -a.ndim - 1`` will
- .venv/lib/python3.12/site-packages/numpy/lib/_shape_base_impl.py:608: # NOTE: Remove once deprecation period passes
- .venv/lib/python3.12/site-packages/numpy/lib/recfunctions.py:78: Can be passed to the dtype constructor to reconstruct the dtype, noting that
- .venv/lib/python3.12/site-packages/numpy/lib/recfunctions.py:1008: raise NotImplementedError("arr with no fields is not supported")
- .venv/lib/python3.12/site-packages/numpy/lib/recfunctions.py:1136: raise NotImplementedError("last axis with size 0 is not supported")
- .venv/lib/python3.12/site-packages/numpy/lib/mixins.py:166: # TODO: handle the optional third argument for __pow__?
- .venv/lib/python3.12/site-packages/numpy/lib/_histograms_impl.py:351: # ensure we pass in arrays with the initial dtype (related to NEP 50).
- .venv/lib/python3.12/site-packages/numpy/lib/_histograms_impl.py:551: The edges to pass into `histogram`
- .venv/lib/python3.12/site-packages/numpy/lib/_histograms_impl.py:642: passed through unmodified:
- .venv/lib/python3.12/site-packages/numpy/lib/_histograms_impl.py:785: plt.hist(a, bins='auto')  # arguments are passed to np.histogram
- .venv/lib/python3.12/site-packages/numpy/lib/_histograms_impl.py:946: The default, None, is equivalent to passing a tuple of D None values.
- .venv/lib/python3.12/site-packages/numpy/lib/_ufunclike_impl.py:63: # when no out argument is passed and no subclasses are involved, flatten
- .venv/lib/python3.12/site-packages/numpy/lib/_utils_impl.py:275: used to issue a DeprecationWarning, by passing the to-be decorated
- .venv/lib/python3.12/site-packages/numpy/lib/_utils_impl.py:517: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_utils_impl.py:764: # NOTE: Could pass (dtype.type, structure) to preserve record dtypes...
- .venv/lib/python3.12/site-packages/numpy/lib/_index_tricks_impl.py:51: corresponding dimension (equivalent to passing in
- .venv/lib/python3.12/site-packages/numpy/lib/_index_tricks_impl.py:653: The size of each dimension of the array can be passed as
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:565: # Don't pass on the keepdims argument if one wasn't given.
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:633: asanyarray : Similar function which passes through subclasses.
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:707: Any further arguments given to `piecewise` are passed to the functions
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:711: Keyword arguments used in calling `piecewise` are passed to the
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:866: # TODO: This preserves the Python int, float, complex manually to get the
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:933: If True, then sub-classes will be passed-through, otherwise the
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:1276: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:1278: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:1696: This function passes the imaginary and real parts of the argument to
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:2326: passed directly to `pyfunc` unmodified.
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:2414: passed by position or keyword.
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:2520: # `inds` to mutate `the_args` and `kwargs` to pass to the original
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3873: additional keyword arguments to pass to `func`.
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:4603: "You shall not pass both `method` and `interpolation`!\n"
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:5391: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:5397: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:5405: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:115: An object that can be passed as an argument to the `numpy.dtype`
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:259: a default name.  Instead, we construct descriptor that can be passed to
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:270: An object that can be passed to `numpy.dtype()` in order to
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:323: The object retrieved by dtype.descr. Can be passed to
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:428: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:433: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:535: to load securely and thus require explicitly passing a larger value.
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:562: to load securely and thus require explicitly passing a larger value.
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:724: Additional keyword arguments to pass to pickle.dump, excluding
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:794: Additional keyword arguments to pass to pickle.load. These are only
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:798: to load securely and thus require explicitly passing a larger value.
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:800: This option is ignored when `allow_pickle` is passed.  In that case
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:842: "You may need to pass the encoding= option "
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:926: to load securely and thus require explicitly passing a larger value.
- .venv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:1018: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_twodim_base_impl.py:199: For Array-API interoperability only, so must be ``"cpu"`` if passed.
- .venv/lib/python3.12/site-packages/numpy/lib/_twodim_base_impl.py:858: An optional argument which is passed through to `mask_func`. Functions
- .venv/lib/python3.12/site-packages/numpy/lib/_twodim_base_impl.py:891: An offset can be passed also to the masking function.  This gets us the
- .venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:279: `keepdims` will be passed through to the `min` method
- .venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:408: `keepdims` will be passed through to the `max` method
- .venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:671: `keepdims` will be passed through to the `mean` or `sum` methods
- .venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:988: `keepdims` will be passed through to the `mean` or `sum` methods
- .venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1158: If this is anything but the default value it will be passed
- .venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1300: If this is anything but the default value it will be passed
- .venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1487: If this is anything but the default value it will be passed
- .venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1689: # TODO: What to do when arr1d = [1, np.nan] and weights = [0, 1]?
- .venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1941: If this value is anything but the default it is passed through
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:71: # TODO: .zip support, .tar support?
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:109: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:115: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:124: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:204: low-level details of downloading the file, allowing you to simply pass
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:331: # TODO: Doesn't handle compressed files!
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:397: # TODO:  This should be more robust.  Handles case where path includes
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:511: # TODO: There is no support for opening a file for writing which
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:514: # TODO: Add a ``subdir`` parameter for specifying the subdirectory
- .venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:697: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/lib/_iotools.py:428: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_iotools.py:436: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_iotools.py:449: pass
- .venv/lib/python3.12/site-packages/numpy/lib/_iotools.py:511: # If a non-default dtype is passed, fall back to generic
- .venv/lib/python3.12/site-packages/numpy/lib/_stride_tricks_impl.py:150: If True, sub-classes will be passed-through, otherwise the returned
- .venv/lib/python3.12/site-packages/numpy/lib/_stride_tricks_impl.py:379: If True, then sub-classes will be passed-through, otherwise
- .venv/lib/python3.12/site-packages/numpy/lib/_stride_tricks_impl.py:492: If True, then sub-classes will be passed-through, otherwise
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_recfunctions.py:354: assert_raises(NotImplementedError, structured_to_unstructured,
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_recfunctions.py:356: assert_raises(NotImplementedError, unstructured_to_structured,
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:100: # Check that passed array is not modified.
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:176: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:232: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:251: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:275: # Check that passed array is not modified.
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:327: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:466: # Check that passed array is not modified.
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:548: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:846: # Check that passed array is not modified.
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:1047: # Check that passed array is not modified.
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_nanfunctions.py:1298: # Also check with out passed:
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_stride_tricks.py:500: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_arraysetops.py:826: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_utils.py:19: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_utils.py:23: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:100: Parameters passed to `save_func`.
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:102: Parameters passed to `numpy.load`.
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:340: sup.filter(ResourceWarning)  # TODO: specify exact message
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:353: # pass a file name to load for the test. On windows failure will
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:1455: #            pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:1717: with assert_raises_regex(NotImplementedError,
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:1724: with assert_raises_regex(NotImplementedError,
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_arraypad.py:81: def test_pass_through(self):
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_arraypad.py:82: """Test if `x` already matching desired output are passed through."""
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_arraypad.py:1372: # Test if allowed keyword arguments pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:495: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:658: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:1034: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:1945: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:2145: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:2916: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:3816: # TODO: Note that times have dubious rounding as of fixing NaTs!
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:4359: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:4532: # TODO: Median does not support Datetime, due to `mean`.
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_format.py:785: # These should pass.
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_format.py:988: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_shape_base.py:157: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_shape_base.py:242: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_shape_base.py:580: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_shape_base.py:613: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_shape_base.py:643: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test__datasource.py:330: # Test case where destpath is passed in
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_histograms.py:22: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_histograms.py:25: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_histograms.py:63: # Test that passing False works too
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_histograms.py:209: # This is a regression test that ensures that values passed to
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_histograms.py:497: Check a Value Error is thrown when an unknown string is passed in
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_loadtxt.py:315: passed to the converter. This means that the output of the converter may
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_loadtxt.py:563: match="the dtype passed requires 3 columns but 4 were"):
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_polynomial.py:259: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_type_check.py:166: def test_pass(self):
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_type_check.py:174: def test_pass(self):
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_type_check.py:213: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_regression.py:220: # Test if the oldstyle class test is bypassed in python3
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test_regression.py:223: pass
- .venv/lib/python3.12/site-packages/numpy/lib/tests/test__iotools.py:206: pass
- .venv/lib/python3.12/site-packages/numpy/ctypeslib/_ctypeslib.py:326: pass
- .venv/lib/python3.12/site-packages/numpy/ctypeslib/_ctypeslib.py:387: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/ctypeslib/_ctypeslib.py:437: raise NotImplementedError("Overlapping fields")
- .venv/lib/python3.12/site-packages/numpy/ctypeslib/_ctypeslib.py:480: NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_utils/__init__.py:24: pass
- .venv/lib/python3.12/site-packages/numpy/_utils/__init__.py:34: pass
- .venv/lib/python3.12/site-packages/numpy/_utils/__init__.py:49: If only the new parameter is passed into the function, behave as usual.
- .venv/lib/python3.12/site-packages/numpy/_utils/__init__.py:50: If only the old parameter is passed into the function (as a keyword), raise
- .venv/lib/python3.12/site-packages/numpy/_utils/__init__.py:53: If both old and new parameters are passed into the function, raise a
- .venv/lib/python3.12/site-packages/numpy/_utils/_inspect.py:115: """Get information about arguments passed into a particular frame.
- .venv/lib/python3.12/site-packages/numpy/_typing/_char_codes.py:148: # be passed to the `dtype` constructor
- .venv/lib/python3.12/site-packages/numpy/_typing/_char_codes.py:211: # TODO: add `_StringCodes` once it has a scalar type
- .venv/lib/python3.12/site-packages/numpy/_typing/_dtype_like.py:31: _DTypeLikeNested: TypeAlias = Any  # TODO: wait for support for recursive types
- .venv/lib/python3.12/site-packages/numpy/_typing/_nested_sequence.py:55: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_typing/_nested_sequence.py:59: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_typing/_nested_sequence.py:63: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_typing/_nested_sequence.py:67: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_typing/_nested_sequence.py:71: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_typing/_nested_sequence.py:75: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_typing/_nested_sequence.py:79: raise NotImplementedError
- .venv/lib/python3.12/site-packages/numpy/_typing/_nbit_base.py:69: pass
- .venv/lib/python3.12/site-packages/numpy/_typing/_nbit_base.py:74: pass
- .venv/lib/python3.12/site-packages/numpy/_typing/_nbit_base.py:79: pass
- .venv/lib/python3.12/site-packages/numpy/_typing/_nbit_base.py:84: pass
- .venv/lib/python3.12/site-packages/numpy/_typing/_nbit_base.py:89: pass
- .venv/lib/python3.12/site-packages/numpy/_typing/_nbit_base.py:94: pass
- .venv/lib/python3.12/site-packages/numpy/_typing/_array_like.py:48: # TODO: Wait until mypy supports recursive objects in combination with typevars
- .venv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:758: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:1012: be passed using only the first letter for backwards compatibility,
- .venv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:2204: is passed then the API standard default is used.
- .venv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:2273: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:3377: If a scalar value is passed in.
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:54: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:103: A bundle of arguments to be passed to a test case, with an identifying
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:496: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:513: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:547: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:581: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:614: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:657: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:836: # nans should be passed through, not converted to infs
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:889: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:903: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1201: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1279: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1568: # Using `axis=<integer>` or passing in a 1-D array implies vector
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1591: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1638: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1642: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1646: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1904: pass
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1948: # Byte order check should pass for native order
- .venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:2013: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/_oauth.py:112: State passed to the OAuth provider in the original request to the OAuth provider.
- .venv/lib/python3.12/site-packages/huggingface_hub/_oauth.py:155: # TODO: handle generic case (handling OAuth in a non-Space environment with custom dev values) (low priority)
- .venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:46: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:188: model_save_kwargs will be passed to
- .venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:284: model_kwargs will be passed to the model during initialization
- .venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:370: model_save_kwargs will be passed to
- .venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:445: >>> # Build the graph by training it or passing dummy inputs
- .venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:476: TODO - Some args above aren't used since we are calling
- .venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:494: # TODO: change this in a future PR. We are not returning a KerasModelHubMixin instance here...
- .venv/lib/python3.12/site-packages/huggingface_hub/_commit_scheduler.py:290: disturbance for the user. The object is passed to `CommitOperationAdd`.
- .venv/lib/python3.12/site-packages/huggingface_hub/_commit_scheduler.py:320: raise NotImplementedError(f"PartialFileIO does not support '{name}'.")
- .venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py:186: " io.BufferedIOBase. If you passed a file-like object, make sure it is"
- .venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py:407: token=None,  # already passed in 'headers'
- .venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py:656: is to first check if `gitignore_content` is passed, then check if the `.gitignore` file is present
- .venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py:783: raise NotImplementedError("Copying a folder is not implemented.")
- .venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py:789: # TODO: (optimization) download regular files to copy concurrently
- .venv/lib/python3.12/site-packages/huggingface_hub/_webhooks_server.py:327: "To add a secret, set `WEBHOOK_SECRET` as environment variable or pass it at initialization: "
- .venv/lib/python3.12/site-packages/huggingface_hub/errors.py:136: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/errors.py:140: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/errors.py:144: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/errors.py:148: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/errors.py:190: Invalid username or password.
- .venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:329: TODO: factorize logic with `read_download_metadata`.
- .venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:386: # TODO: can we do better?
- .venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:402: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:436: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:438: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:442: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/constants.py:138: hf_cache_home = HF_HOME  # for backward compatibility. TODO: remove this in 1.0.0
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:75: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:155: `NotImplementedError`:
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:175: raise NotImplementedError("Access to repositories lists is not implemented.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:179: raise NotImplementedError("Access to repositories lists is not implemented.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:229: raise NotImplementedError("Access to repositories lists is not implemented.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:271: raise NotImplementedError("Appending to remote files is not yet supported.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:327: # TODO: use `commit_description` to list all the deleted paths?
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:360: If True, bypass the cache and fetch the latest data. Defaults to False.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:543: If True, bypass the cache and fetch the latest data. Defaults to False.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:669: If True, bypass the cache and fetch the latest data. Defaults to False.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:696: "tree_id": None,  # TODO: tree_id of the root directory?
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:921: raise NotImplementedError("Transactional commits are not supported.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:927: raise NotImplementedError("Transactional commits are not supported.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:319: raise ValueError(f"Unable to retrieve user and repo ID from the passed HF ID: {hf_id}")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:407: is passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:411: `create_pr=True` is passed. Example: `"refs/pr/1"`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:415: `create_pr=True` is passed. Can be passed as `discussion_num` in
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1596: SHA-256 object ID of the file. This is the identifier to pass when permanently deleting the file.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1691: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1703: Headers passed here are taking precedence over the default headers.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1773: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1829: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1833: token passed, if token is invalid or if role is not returned by the server. This typically happens when the token is an 
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1899: If `gated=True` is passed, only gated models are returned.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1900: If `gated=False` is passed, only non-gated models are returned.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1942: This parameter cannot be used if `full`, `cardData` or `fetch_config` are passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1959: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1992: raise ValueError("`expand` cannot be used if `full`, `cardData` or `fetch_config` are passed.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:1995: raise ValueError("`emissions_thresholds` were passed without setting `cardData=True`.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2120: If `gated=True` is passed, only gated datasets are returned.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2121: If `gated=False` is passed, only non-gated datasets are returned.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2159: This parameter cannot be used if `full` is passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2169: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2213: raise ValueError("`expand` cannot be used if `full` is passed.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2320: The name of a specific dataset can be passed as a string.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2323: The name of a specific model can be passed as a string.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2337: This parameter cannot be used if `full` is passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2346: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2352: raise ValueError("`expand` cannot be used if `full` is passed.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2421: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2459: This list is public so token is optional. If `user` is not passed, it defaults to
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2471: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2479: If `user` is not passed and no token found (either from argument or from machine).
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2546: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2579: Model can be private if you pass an acceptable token or are logged in.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2598: This parameter cannot be used if `securityStatus` or `files_metadata` are passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2604: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2656: Dataset can be private if you pass an acceptable token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2672: This parameter cannot be used if `files_metadata` is passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2678: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2729: Space can be private if you pass an acceptable token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2745: This parameter cannot be used if `full` is passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2751: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2817: This parameter cannot be used if `files_metadata` is passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2826: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2884: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2931: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2982: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3035: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3085: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3205: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3277: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3372: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3457: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3526: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3590: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3653: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3759: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3795: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3848: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3911: To disable authentication, pass False.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3991: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4127: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4163: url, pr url, commit message,...). If `run_as_future=True` is passed, returns a Future object which will
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4186: raise ValueError("`commit_message` can't be empty, please pass a value.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4385: objects except to pass them to [`create_commit`]. If you don't want to remove the attached content from the
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4386: commit operation object, pass `free_memory=False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4402: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4419: is to first check if `gitignore_content` is passed, then check if the `.gitignore` file is present
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4607: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4639: url, pr url, commit message,...). If `run_as_future=True` is passed, returns a Future object which will
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4735: # TODO: remove this in v1.0
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4835: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4874: url, pr url, commit message,...). If `run_as_future=True` is passed, returns a Future object which will
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5008: # TODO: remove this in v1.0
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5040: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5134: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5207: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5314: - you cannot create a PR directly. Please create a PR first (from the UI or using [`create_pull_request`]) and then comm
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5387: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5389: Dictionary mapping protocol to the URL of the proxy passed to `requests.request`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5488: Dictionary mapping protocol to the URL of the proxy passed to
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5492: data before giving up which is passed to `requests.request`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5497: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5602: Dictionary mapping protocol to the URL of the proxy passed to
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5606: data before giving up which is passed to `requests.request`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5613: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5627: Note that the `tqdm_class` is not passed to each individual download.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5708: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5847: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5951: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5996: pass  # We raise the original error if the branch does not exist
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6023: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6086: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6149: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6190: If passed, the repository name will be in the organization
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6196: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6200: ({username}/{model_id}) if no organization is passed, and under the
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6250: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6345: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6428: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6519: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6606: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6685: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6758: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6833: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6892: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:6953: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7013: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7041: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7064: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7101: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7132: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7153: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7183: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7239: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7284: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7325: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7384: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7464: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7489: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7525: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7557: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7584: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7686: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:7933: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8050: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8122: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8151: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8190: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8232: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8293: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8330: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8386: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8459: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8509: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8564: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8571: or `admin` role in the organization the repo belongs to or if you passed a `read` token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8643: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8693: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8750: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8762: or `admin` role in the organization the repo belongs to or if you passed a `read` token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8816: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8828: or `admin` role in the organization the repo belongs to or if you passed a `read` token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8878: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8890: or `admin` role in the organization the repo belongs to or if you passed a `read` token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8967: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:8974: or `admin` role in the organization the repo belongs to or if you passed a `read` token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9009: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9016: or `admin` role in the organization the repo belongs to or if you passed a `read` token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9059: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9066: or `admin` role in the organization the repo belongs to or if you passed a `read` token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9097: raise ValueError("`rejection_reason` can only be passed when rejecting an access request.")
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9132: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9141: or `admin` role in the organization the repo belongs to or if you passed a `read` token.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9172: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9221: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9288: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9364: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9425: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9476: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9527: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9688: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9727: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9753: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9781: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9809: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:9843: To disable authentication, pass `False`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:10292: Arguments to pass to the script.
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard.py:304: Templates are Jinja2 templates that can be customized by passing keyword arguments.
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard.py:354: Templates are Jinja2 templates that can be customized by passing keyword arguments.
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard.py:435: Templates are Jinja2 templates that can be customized by passing keyword arguments.
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard.py:800: "You passed a new value for the existing metric"
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard.py:815: f"You passed a new value for the existing meta data field '{key}'."
- .venv/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:89: Dictionary mapping protocol to the URL of the proxy passed to
- .venv/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:93: data before giving up which is passed to `requests.request`.
- .venv/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:116: Note that the `tqdm_class` is not passed to each individual download.
- .venv/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:177: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:189: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:232: "outgoing traffic has been disabled. To enable repo look-ups and downloads online, pass "
- .venv/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:290: # if passed revision is not identical to commit_hash
- .venv/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:302: # we pass the commit_hash to hf_hub_download
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:158: Check if the file passed is tracked with git-lfs.
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:165: `bool`: `True` if the file passed is tracked with git-lfs, `False`
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:202: `bool`: `True` if the file passed is ignored by `git`, `False`
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:227: `bool`: `True` if the file passed is a binary file, `False` otherwise.
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:327: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:539: raise ValueError("If not specifying `clone_from`, you need to pass Repository a valid git clone.")
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:628: if an organization token (starts with "api_org") is passed. Use must use
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:1159: Whether creating a branch named with the `revision` passed at
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:1222: If remote is not passed, will just be updated locally
- .venv/lib/python3.12/site-packages/huggingface_hub/repository.py:1261: annotated tag if a message is passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/_upload_large_folder.py:177: " If you are using the CLI, pass it as `--repo-type=model`."
- .venv/lib/python3.12/site-packages/huggingface_hub/_upload_large_folder.py:695: # Hacks with CommitOperationAdd to bypass checks/sha256 calculation
- .venv/lib/python3.12/site-packages/huggingface_hub/dataclasses.py:134: # If validation passed, set the attribute
- .venv/lib/python3.12/site-packages/huggingface_hub/dataclasses.py:261: Additional arguments to pass to `dataclasses.field()`.
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:282: Params to pass to `requests.request`.
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:374: Dictionary mapping protocol to the URL of the proxy passed to `requests.request`.
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:696: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:748: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:808: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:897: Dictionary mapping protocol to the URL of the proxy passed to
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:901: data before giving up which is passed to `requests.request`.
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:985: "not rely on symlinks anymore. You only need to pass a destination folder "
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1089: # 1. we passed local_files_only.
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1130: # if passed revision is not identical to commit_hash
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1434: Dictionary mapping protocol to the URL of the proxy passed to
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1641: raise ValueError("Cannot pass 'force_download=True' and 'local_files_only=True' at the same time.")
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1643: raise ValueError("Cannot pass 'force_download=True' when offline mode is enabled.") from head_call_error
- .venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1787: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/inference_api.py:202: " Please install it (`pip install Pillow`) or pass"
- .venv/lib/python3.12/site-packages/huggingface_hub/inference_api.py:213: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/huggingface_hub/inference_api.py:214: f"{content_type} output type is not implemented yet. You can pass"
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:84: When inheriting from [`ModelHubMixin`], you can define class-level attributes. These attributes are not passed to
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:294: - If `config` is passed as a dataclass, set it as `self._hub_mixin_config`.
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:295: - Otherwise, build `self._hub_mixin_config` from default values and passed values.
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:303: # Infer passed values
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:304: passed_values = {
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:316: # If config passed as dataclass => set it and return early
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:317: if is_dataclass(passed_values.get("config")):
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:318: instance._hub_mixin_config = passed_values["config"]
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:321: # Otherwise, build config from default + passed values
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:325: # passed values
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:328: for key, value in passed_values.items()
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:332: passed_config = init_config.pop("config", {})
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:335: if isinstance(passed_config, dict):
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:336: init_config.update(passed_config)
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:405: Additional arguments passed to the model card template to customize the model card.
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:407: Additional key word arguments passed along to the [`~ModelHubMixin.push_to_hub`] method.
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:458: raise NotImplementedError
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:500: Additional kwargs to pass to the model during initialization.
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:543: # Check if `config` argument was passed at init
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:545: # Decode `config` argument if it was passed
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:602: args taken as input can be directly passed to those 2 methods. If needed, you can add more arguments to this
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:628: Additional keyword arguments passed along to the [`~ModelHubMixin._from_pretrained`] method.
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:630: raise NotImplementedError
- .venv/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:679: Additional arguments passed to the model card template to customize the model card.
- .venv/lib/python3.12/site-packages/huggingface_hub/_jobs_api.py:77: Arguments passed to the command
- .venv/lib/python3.12/site-packages/huggingface_hub/_tensorboard_logger.py:91: Additional keyword arguments passed to `SummaryWriter`.
- .venv/lib/python3.12/site-packages/huggingface_hub/_login.py:18: from getpass import getpass
- .venv/lib/python3.12/site-packages/huggingface_hub/_login.py:90: When the token is not passed, [`login`] will automatically detect if the script runs
- .venv/lib/python3.12/site-packages/huggingface_hub/_login.py:111: If an organization token is passed. Only personal account tokens are valid
- .venv/lib/python3.12/site-packages/huggingface_hub/_login.py:154: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/_login.py:255: This is equivalent to [`login`] without passing a token when not run in a notebook.
- .venv/lib/python3.12/site-packages/huggingface_hub/_login.py:287: token = getpass("Enter your token (input will not be visible): ")
- .venv/lib/python3.12/site-packages/huggingface_hub/_login.py:299: alt='Hugging Face'> <br> Immediately click login after typing your password or
- .venv/lib/python3.12/site-packages/huggingface_hub/_login.py:327: This is equivalent to [`login`] without passing a token when run in a notebook.
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:42: The arguments passed during `Metric.compute()`. Example for `bleu`: `{"max_order": 4}`
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:50: The arguments passed during `Metric.compute()`. Example for `bleu`: max_order: 4
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:103: # The arguments passed during `Metric.compute()`.
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:116: # The arguments passed during `Metric.compute()`.
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:196: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:466: # TODO - maybe handle this similarly to EvalResult?
- .venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:752: # TODO - Check if there cases where this list is longer than one?
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_headers.py:93: A `Dict` of headers to pass in your API call.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_headers.py:119: If organization token is passed and "write" access is required.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_headers.py:121: If "write" access is required but token is not passed and not saved locally.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:257: kwargs to pass to `requests.request`.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:274: When using `requests` it is possible to stream data by passing an iterator to the
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:83: UserWarning: Both `token` and `use_auth_token` are passed (...)
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:91: # TODO: add an argument to opt-out validation for specific argument?
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:123: avoid local inconsistencies whenever possible (example: passing `repo_type` in the
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:186: `use_auth_token` is passed to a function, the `use_auth_token` value is passed
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:188: a. Corner case: if both `use_auth_token` and `token` values are passed, a warning
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:216: "Both `token` and `use_auth_token` are passed to"
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:218: " preferred argument to pass a User Access Token."
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:222: # `token` argument is not passed and a non-None value is passed in
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_runtime.py:71: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_runtime.py:352: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_runtime.py:357: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_git_credential.py:67: A git password. In practice, the User Access Token for the Hub.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_git_credential.py:76: stdin.write(f"url={ENDPOINT}\nusername={username.lower()}\npassword={token}\n\n")
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_git_credential.py:108: """Parse the output of `git credential fill` to extract the password.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_subprocess.py:74: Keyword arguments to be passed to the `subprocess.run` underlying command.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_subprocess.py:112: Keyword arguments to be passed to the `subprocess.run` underlying command.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:25: # TODO: deprecate when adapted in transformers/datasets/gradio
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:43: # TODO: deprecate when adapted in transformers/datasets/gradio
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:58: # TODO: deprecate when adapted in transformers/datasets/gradio
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:68: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_fixes.py:71: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_fixes.py:78: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_fixes.py:114: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_fixes.py:133: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/insecure_hashlib.py:3: # DO NOT use this function for security purposes (e.g., password hashing).
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/insecure_hashlib.py:6: # environments unless `usedforsecurity=False` is explicitly passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_xet.py:146: Additional parameters to pass with the request.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_xet.py:176: Additional parameters to pass with the request.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:10: * will issue a warning when passed as a positional argument.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:39: f"Deprecated positional argument(s) used in '{f.__name__}': pass"
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:40: f" {args_msg} as keyword args. From version {version} passing these"
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:60: TODO: could be useful to be able to set a custom error message.
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:68: Warning message that is raised. If not passed, a default warning message
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:115: Warning message that is raised. If not passed, a default warning message
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/tqdm.py:35: ...    pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/tqdm.py:39: ...    pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/tqdm.py:49: ...   pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/tqdm.py:73: ...     pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/tqdm.py:77: ...     pass
- .venv/lib/python3.12/site-packages/huggingface_hub/utils/tqdm.py:222: name = kwargs.pop("name", None)  # do not pass `name` to `tqdm`
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:51: TODO: add support for `huggingface-cli delete-cache aaaaaa bbbbbb cccccc (...)` ?
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:52: TODO: add "--keep-last" arg to delete revisions that are not on `main` ref
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:53: TODO: add "--filter" arg to filter repositories by name ?
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:54: TODO: add "--limit" arg to limit to X repos ?
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:55: TODO: add "-y" arg for immediate deletion ?
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:85: # TODO: refactor this + imports in a unified pattern across codebase
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:271: The list of choices to pass to `inquirer.checkbox`.
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/repo.py:137: print(ANSI.red("You cannot pass both --organization and a repo_id with a namespace."))
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/upload.py:169: raise ValueError("Cannot set `--include` when passing a `local_path` containing a wildcard.")
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/upload.py:171: raise ValueError("Cannot set `path_in_repo` when passing a `local_path` containing a wildcard.")
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/__init__.py:23: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/huggingface_hub/commands/__init__.py:27: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:168: TODO: handle base64 as input
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:174: yield get_session().get(content).content  # TODO: retrieve as stream and pipe to post request ?
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:180: " file. To pass raw content, please encode it as bytes first."
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:25: # Some TODO:
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:134: arguments are mutually exclusive. If a URL is passed as `model` or `base_url` for chat completion, the `(/v1)/chat/compl
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:138: If model is a URL or `base_url` is passed, then `provider` is not used.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:183: " When passing a URL as `model`, the client will not append any suffix path to it."
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:193: # Legacy behavior: previously is was possible to pass `token=False` to disable authentication. This is not
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:258: # TODO: this should be handled in provider helpers directly
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:415: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:562: You can pass provider-specific parameters to the model by using the `extra_body` argument.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:572: If `model` is a model ID, it is passed to the server as the `model` parameter. If you want to define a
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:618: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:969: The maximum length of the total sentence (context + question) in tokens of each chunk passed to the
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:1050: Which side of the input should be truncated when `truncate=True` is passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:1108: When passed, the model will limit the scores to the passed targets instead of looking up in the whole
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:1112: When passed, overrides the number of predictions to return.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:1557: The maximum length of the total sentence (context + question) in tokens of each chunk passed to the
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2306: "`decoder_input_details=True` has been passed to the server but `details=False` is set meaning that"
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2371: " Please pass `stream=False` as input."
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2455: You can pass provider-specific parameters to the model by using the `extra_body` argument.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2482: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2590: You can pass provider-specific parameters to the model by using the `extra_body` argument.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2613: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2698: You can pass provider-specific parameters to the model by using the `extra_body` argument.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2755: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2972: you can use `src_lang` and `tgt_lang` arguments to pass the relevant information.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:3510: raise NotImplementedError("Model status is only available for Inference API endpoints.")
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_providers/fal_ai.py:97: # If input is a URL, pass it directly
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:122: arguments are mutually exclusive. If a URL is passed as `model` or `base_url` for chat completion, the `(/v1)/chat/compl
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:126: If model is a URL or `base_url` is passed, then `provider` is not used.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:174: " When passing a URL as `model`, the client will not append any suffix path to it."
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:184: # Legacy behavior: previously is was possible to pass `token=False` to disable authentication. This is not
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:256: # TODO: this should be handled in provider helpers directly
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:274: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:448: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:596: You can pass provider-specific parameters to the model by using the `extra_body` argument.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:606: If `model` is a model ID, it is passed to the server as the `model` parameter. If you want to define a
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:652: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:1009: The maximum length of the total sentence (context + question) in tokens of each chunk passed to the
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:1091: Which side of the input should be truncated when `truncate=True` is passed.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:1150: When passed, the model will limit the scores to the passed targets instead of looking up in the whole
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:1154: When passed, overrides the number of predictions to return.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:1606: The maximum length of the total sentence (context + question) in tokens of each chunk passed to the
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:2363: "`decoder_input_details=True` has been passed to the server but `details=False` is set meaning that"
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:2428: " Please pass `stream=False` as input."
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:2512: You can pass provider-specific parameters to the model by using the `extra_body` argument.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:2539: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:2648: You can pass provider-specific parameters to the model by using the `extra_body` argument.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:2671: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:2756: You can pass provider-specific parameters to the model by using the `extra_body` argument.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:2813: Additional provider-specific parameters to pass to the model. Refer to the provider's documentation
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:3032: you can use `src_lang` and `tgt_lang` arguments to pass the relevant information.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:3622: raise NotImplementedError("Model status is only available for Inference API endpoints.")
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/types/fill_mask.py:16: """When passed, the model will limit the scores to the passed targets instead of looking up
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/types/fill_mask.py:22: """When passed, overrides the number of predictions to return."""
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/types/document_question_answering.py:42: passed to the model. The context will be split in several chunks (using doc_stride as
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/types/question_answering.py:43: passed to the model. The context will be split in several chunks (using docStride as
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/types/sentence_similarity.py:17: sentence, or longer passage, depending on the model being used.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/cli.py:69: except (AttributeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/cli.py:218: except (AttributeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/cli.py:219: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/mcp_client.py:71: If model is a URL or `base_url` is passed, then `provider` is not used.
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/mcp_client.py:192: # ^ TODO: should be handle `get_session_id_callback`? (function to retrieve the current session ID)
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/types.py:10: password: bool
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/_cli_hacks.py:31: # Ensure we pass the creation flags for Windows
- .venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/agent.py:31: If model is a URL or `base_url` is passed, then `provider` is not used.
- .venv/lib/python3.12/site-packages/huggingface_hub/cli/upload.py:169: raise ValueError("Cannot set `--include` when passing a `local_path` containing a wildcard.")
- .venv/lib/python3.12/site-packages/huggingface_hub/cli/upload.py:171: raise ValueError("Cannot set `path_in_repo` when passing a `local_path` containing a wildcard.")
- .venv/lib/python3.12/site-packages/huggingface_hub/cli/__init__.py:23: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/huggingface_hub/cli/__init__.py:27: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/huggingface_hub/cli/jobs.py:85: "or `--secrets HF_TOKEN` to pass your Hugging Face token."
- .venv/lib/python3.12/site-packages/huggingface_hub/cli/jobs.py:467: "or `--secrets HF_TOKEN` to pass your Hugging Face token."
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_base.py:61: made to make each shard as close as possible to the maximum size passed. For example, if the limit is 10GB and we
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_tensorflow.py:38: made to make each shard as close as possible to the maximum size passed. For example, if the limit is 10GB and we
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:75: If your model is a `transformers.PreTrainedModel`, you should pass `model._tied_weights_keys` as `shared_tensors_to_disc
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:121: >>> from huggingface_hub import load_torch_model  # TODO
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:175: If your model is a `transformers.PreTrainedModel`, you should pass `model._tied_weights_keys` as `shared_tensors_to_disc
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:312: made to make each shard as close as possible to the maximum size passed. For example, if the limit is 10GB and we
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:637: f"The safetensors archive passed at {checkpoint_file} does not contain the valid metadata. Make sure "
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:716: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:728: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:772: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:783: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:791: except NotImplementedError:
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:830: pass
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:838: except NotImplementedError:
- .venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:938: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/__init__.py:35: # We can just silently allow import failures to pass here. If we
- .venv/lib/python3.12/site-packages/pip/_vendor/__init__.py:43: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1: # TODO: Add Generic type annotations to initialized collections.
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:12: names being passed into the API.
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:77: # capture these to bypass sandboxing
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:122: _ResourceStream = Any  # TODO / Incomplete: A readable file-like object
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:219: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:410: and `provider_factory` is a function that, passed a *module* object,
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:472: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:885: if not req_extras.markers_pass(req, extras):
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1111: def markers_pass(self, req: Requirement, extras: tuple[str, ...] | None = None):
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1431: _bypass_ensure_directory(target_path)
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1453: #  bypass the warning.
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1728: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1733: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1738: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1831: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1918: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2011: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2238: handler), and `distribution_finder` is a callable that, passed a path
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2353: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2742: # We could pass `env` and `installer` directly,
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2767: # then resolve them. We have to pass `extras` along when resolving so
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3308: # TODO: remove this except clause when python/cpython#103632 is fixed.
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3414: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3507: def _bypass_ensure_directory(path):
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3508: """Sandbox-bypassing version of ensure_directory()"""
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3513: _bypass_ensure_directory(dirname)
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3517: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3549: # temporarily bypass sandboxing
- .venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3598: # TODO: Add a deadline?
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/scripts.py:302: pass  # still in use - ignore error
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/__init__.py:13: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/__init__.py:23: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/__init__.py:26: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/resources.py:303: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/compat.py:53: # """splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'."""
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/compat.py:94: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/compat.py:218: # directories pass the os.access check.
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/compat.py:253: # what file suffixes are executable, so just pass on cmd as-is.
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/compat.py:553: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/compat.py:657: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/compat.py:733: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:146: Parse a requirement passed in as a string. Return a Container
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:401: # TODO check k, v for valid values
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:816: username = password = None
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:822: username, password = prefix.split(':', 1)
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:825: if password:
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:826: password = unquote(password)
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:827: return username, password, netloc
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1060: :param args: The positional arguments to pass to the event's
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1062: :param kwargs: The keyword arguments to pass to the event's
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1501: pass a connection class to do_open, but it doesn't actually check for
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1504: we *must* pass a class, we'll create an UnsafeHTTPSConnection class
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1506: choose which one to pass to do_open.
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1742: Read lines from a subprocess' output stream and either pass to a progress
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1829: ('password', None)):
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1851: 'password': config.get(server, 'password'),
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1858: def update(self, username, password):
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1866: config.set('pypi', 'password', password)
- .venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:1879: PyPIRCFile().update(index.username, index.password)
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/abc.py:29: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/syntax.py:130: raise NotImplementedError  # pragma: no cover
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/syntax.py:135: raise NotImplementedError  # pragma: no cover
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/syntax.py:402: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/syntax.py:411: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/syntax.py:442: Tries to find the lexer by name if a string was passed to the constructor.
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/text.py:562: # TODO: This is a little inefficient, it is only used by full justify
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/progress_bar.py:25: pulse (bool, optional): Enable pulse effect. Defaults to False. Will pulse if a None total was passed.
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/progress.py:393: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/progress.py:418: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/progress.py:535: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/progress.py:965: """dict: Arbitrary fields passed in via Progress.update."""
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/progress.py:1120: If the Progress instance is created without passing a columns argument,
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/progress.py:1292: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/progress.py:1308: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_null_file.py:7: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_null_file.py:40: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_null_file.py:57: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_null_file.py:63: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:37: password (bool, optional): Enable password input. Defaults to False.
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:59: password: bool = False,
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:71: self.password = password
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:85: password: bool = False,
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:102: password: bool = False,
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:117: password: bool = False,
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:133: password (bool, optional): Enable password input. Defaults to False.
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:143: password=password,
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:198: password: bool,
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:206: password (bool): Enable password entry.
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:211: return console.input(prompt, password=password, stream=stream)
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:292: value = self.get_input(self.console, prompt, self.password, stream=stream)
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:380: password = Prompt.ask(
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:381: "Please enter a password [cyan](must be at least 5 characters)",
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:382: password=True,
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:384: if len(password) >= 5:
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:386: print("[prompt.invalid]password too short")
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/prompt.py:387: print(f"password={password!r}")
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_inspect.py:96: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_emoji_codes.py:152: "japanese_passing_grade_button": "🈴",
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_emoji_codes.py:639: "compass": "🧭",
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_emoji_codes.py:1713: "passenger_ship": "🛳",
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_emoji_codes.py:1714: "passport_control": "🛂",
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/pretty.py:108: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/pretty.py:563: to craft an object that passes this check and isn't a namedtuple, but
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/pretty.py:662: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/logging.py:281: log.warning("password was rejected for admin site.")
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/_win32_console.py:30: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/console.py:10: from getpass import getpass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/console.py:80: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/console.py:1032: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/console.py:2145: password: bool = False,
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/console.py:2156: password: (bool, optional): Hide typed text. Defaults to False.
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/console.py:2164: if password:
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/console.py:2165: result = getpass("", stream=stream)
- .venv/lib/python3.12/site-packages/pip/_vendor/rich/jupyter.py:95: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/serialize.py:31: # When a body isn't passed in, we'll read the response. We
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:57: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:64: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:67: # TODO: Add some logging here...
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:101: # it's passed e.g. after we've already closed self.__buf.
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/cache.py:21: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/cache.py:26: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/cache.py:29: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/cache.py:32: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/cache.py:58: passed in (as a bytes-like object) in a separate call to ``set_body()``.
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/cache.py:69: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/cache.py:75: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:181: logger.debug('Request header has "no-cache", cache bypassed')
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:185: logger.debug('Request header has "max_age" as 0, cache bypassed')
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:227: # TODO: There is an assumption that the result will be a
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:306: # We pass in the body separately; just put a placeholder empty
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py:104: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/caches/redis_cache.py:48: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:82: You can pass options to the constructor. The basic options recognized
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:267: bypassed even if filters are defined.
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:288: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:334: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:357: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:647: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:660: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:863: TODO: clean up the code here.
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/formatter.py:42: You can pass options as keyword arguments to the constructor.
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/style.py:98: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/util.py:272: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/util.py:307: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/filter.py:51: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/filter.py:59: functions passed to it.
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:35: Options are passed to the filter initializer if wanted.
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72: highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81: ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:757: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/__init__.py:329: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:214: 'pass', 'raise', 'nonlocal', 'return', 'try', 'while', 'yield',
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:255: 'NotImplementedError', 'OSError', 'OverflowError',
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:494: 'exec', 'finally', 'for', 'global', 'if', 'lambda', 'pass',
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:523: 'NotImplementedError', 'OSError', 'OverflowError', 'OverflowWarning',
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:715: # different tokens.  TODO: DelegatingLexer should support this
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:884: 'global', 'if', 'include', 'lambda', 'nogil', 'pass', 'print',
- .venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:912: 'MemoryError', 'NameError', 'NotImplemented', 'NotImplementedError',
- .venv/lib/python3.12/site-packages/pip/_vendor/dependency_groups/_implementation.py:185: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/tomli/_parser.py:315: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/idna/codec.py:101: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/idna/codec.py:105: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/idna/core.py:17: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/idna/core.py:23: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/idna/core.py:29: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/idna/core.py:35: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/idna/core.py:292: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/idna/core.py:377: raise IDNAError("should pass a unicode string to the function rather than a byte string.")
- .venv/lib/python3.12/site-packages/pip/_vendor/idna/compat.py:15: raise NotImplementedError("IDNA 2008 does not utilise nameprep protocol")
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:11: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:17: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:47: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:61: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:67: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:105: """Raised when passing an invalid state to a timeout"""
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:107: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:117: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:123: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:131: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:137: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:143: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:149: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:155: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:188: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:194: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:200: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:206: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:212: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:218: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:227: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:233: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:242: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:283: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:289: # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:309: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:323: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:106: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:118: Host used for this HTTP Connection (e.g. "localhost"), passed into
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:122: Port used for this HTTP Connection (None is equivalent to 80), passed
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:127: as a valid HTTP/1.0 or 1.1 status line, passed into
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:231: # Do not pass 'self' as callback to 'finalize'.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:233: # By just passing a reference to the pool allows the garbage collector
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:287: pass  # Oh well, we'll create a new connection then
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:296: # attempt to bypass the proxy)
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:320: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:336: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:340: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:350: # User passed us an int/float. This is for backwards compatibility,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:355: """Is the error actually a timeout? Will raise a ReadTimeout or pass"""
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:423: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:522: # TODO: Add optional support for socket.gethostbyname checking.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:640: Additional parameters are passed to
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:672: # passed down into the recursive call, and its value will be respected.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:925: ``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:948: key_password=None,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:975: self.key_password = key_password
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:991: key_password=self.key_password,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:1047: key_password=self.key_password,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:1122: # Specifically, if we include brackets but also pass the port then
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:1124: # Instead, we need to make sure we never pass ``None`` as the port.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:1140: pass  # Done.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/fields.py:48: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/poolmanager.py:36: "key_password",
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/poolmanager.py:52: "key_key_password",  # str
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/poolmanager.py:318: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/request.py:56: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/__init__.py:29: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:25: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:34: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:43: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:91: you might pass:
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:99: Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:199: # TODO: Fix tunnel so it doesn't depend on self.sock state.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:240: # Avoid modifying the headers passed into .request()
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:288: Many of the parameters to this constructor are passed to the underlying SSL
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:308: key_password=None,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:320: self.key_password = key_password
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:333: key_password=None,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:354: self.key_password = key_password
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:423: key_password=self.key_password,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:565: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:291: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:394: Decode the data passed in and potentially flush the decoder.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:633: Remaining parameters are passed to the HTTPResponse constructor, along
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/_collections.py:13: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/_collections.py:16: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/_collections.py:88: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/_collections.py:114: Additional field-value pairs to pass in to ``dict.update``.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/_collections.py:127: If multiple fields that are equal case-insensitively are passed to the
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/_collections.py:213: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:15: - Usernames and passwords for the SOCKS proxy
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:32: When connecting to a SOCKS5 proxy the ``username`` and ``password`` portion
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:33: of the ``proxy_url`` will be sent as the username/password to authenticate
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:38: proxy_url="socks5h://<username>:<password>@proxy-host"
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:102: proxy_password=self._socks_options["password"],
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:148: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:174: password=None,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:181: if username is None and password is None and parsed.auth is not None:
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:184: username, password = split
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/socks.py:207: "password": password,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:482: client_key_passphrase,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:659: # TODO: should I do clean shutdown here? Do I have to?
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:798: self._client_key_passphrase = None
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:815: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:819: # TODO: Well, crap.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:829: # TODO: Update in line with above.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:850: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:868: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:872: def load_cert_chain(self, certfile, keyfile=None, password=None):
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:875: self._client_cert_passphrase = password
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:881: Raises a NotImplementedError if ALPN is not supported.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:884: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:917: self._client_key_passphrase,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:34: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:60: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:473: def load_cert_chain(self, certfile, keyfile=None, password=None):
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:475: if password is not None:
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:476: if not isinstance(password, six.binary_type):
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:477: password = password.encode("utf-8")
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:478: self._ctx.set_passwd_cb(lambda *_: password)
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/ntlmpool.py:38: pw is the password for the user.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/ntlmpool.py:108: raise Exception("Server rejected request: wrong username or password")
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/appengine.py:72: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/appengine.py:76: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py:215: credentials. This keychain uses a one-time password and a temporary file to
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py:227: # some random bytes to password-protect the keychain we're creating, so we
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py:231: password = base64.b16encode(random_bytes[8:])  # Must be valid UTF-8
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py:239: keychain_path, len(password), password, False, None, ctypes.byref(keychain)
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py:243: # Having created the keychain, we want to pass it off to the caller.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py:272: None,  # key params, can include passphrase in the future
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/_securetransport/bindings.py:303: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/packages/six.py:103: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/packages/six.py:206: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/packages/six.py:237: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/packages/six.py:460: MovedAttribute("proxy_bypass", "urllib", "urllib.request"),
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:146: >>> Url('http', 'username:password', 'host.com', 80,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:148: 'http://username:password@host.com:80/path?query#fragment'
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:226: uri_bytes = component.encode("utf-8", "surrogatepass")
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:402: # TODO: Remove this when we break backwards compatibility.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/wait.py:15: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:52: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:57: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:62: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:222: Resolves the argument to a numeric constant, which can be passed to
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:229: constant which can directly be passed to wrap_socket.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:375: key_password=None,
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:394: :param key_password:
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:395: Optional password if the keyfile is encrypted.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:398: passing as the cadata parameter to SSLContext.load_verify_locations()
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:421: # passphrase via the terminal and instead error out.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:422: if keyfile and key_password is None and _is_key_file_encrypted(keyfile):
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:423: raise SSLError("Client private key is encrypted, password is required")
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:426: if key_password is None:
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:429: context.load_cert_chain(certfile, keyfile, key_password)
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:434: except NotImplementedError:  # Defensive: in CI, we always have set_alpn_protocols
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_.py:435: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:31: # TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:108: Retries can be disabled by passing ``False``::
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:261: # TODO: Deprecated, remove in v2.0
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:323: # TODO: If already given in **kw we use what's given to us
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:324: # If not given we need to figure out what to pass. We decide
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:326: # and if so we pass the deprecated 'method_whitelist' otherwise
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:454: # TODO: For now favor if the Retry implementation sets its own method_whitelist
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:608: # TODO: Remove this deprecated alias in v2.0
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/ssl_match_hostname.py:22: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/request.py:45: Colon-separated username:password string for 'authorization: basic ...'
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/request.py:49: Colon-separated username:password string for 'proxy-authorization: basic ...'
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/request.py:65: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/timeout.py:175: passed to this function.
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/connection.py:142: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:22: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:28: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:35: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:53: # This will fail silently if we pass in the wrong kind of parameter.
- .venv/lib/python3.12/site-packages/pip/_vendor/platformdirs/api.py:45: Typically, it is the owning company name. Defaults to `appname`. You may pass ``False`` to disable it.
- .venv/lib/python3.12/site-packages/pip/_vendor/platformdirs/windows.py:205: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/platformdirs/windows.py:256: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:25: def _basic_auth_str(username, password):
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:38: "3.0.0. Please convert the object you've passed in ({!r}) to "
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:45: if not isinstance(password, basestring):
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:47: "Non-string passwords will no longer be supported in Requests "
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:48: "3.0.0. Please convert the object you've passed in ({!r}) to "
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:50: "problems.".format(type(password)),
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:53: password = str(password)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:59: if isinstance(password, str):
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:60: password = password.encode("latin1")
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:63: b64encode(b":".join((username, password))).strip()
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:73: raise NotImplementedError("Auth hooks must be callable.")
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:79: def __init__(self, username, password):
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:81: self.password = password
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:87: self.password == getattr(other, "password", None),
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:95: r.headers["Authorization"] = _basic_auth_str(self.username, self.password)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:103: r.headers["Proxy-Authorization"] = _basic_auth_str(self.username, self.password)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:110: def __init__(self, username, password):
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:112: self.password = password
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:189: A1 = f"{self.username}:{realm}:{self.password}"
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/auth.py:309: self.password == getattr(other, "password", None),
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/hooks.py:19: # TODO: response is the only one
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:85: # Bypass default SSLContext creation when Python
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:160: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:164: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:182: which we retry a request, import urllib3's ``Retry`` class and pass
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:281: username, password = get_auth_from_url(proxy)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:285: password=password,
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:590: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:606: username, password = get_auth_from_url(proxy)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:609: headers["Proxy-Authorization"] = _basic_auth_str(username, password)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:662: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:686: # TODO: Remove this in 3.0.0: see #2811
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/models.py:110: Will successfully encode parameters when passed as a dict or a list of
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/models.py:140: Will successfully encode files when passed as a dict or a list of
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/models.py:246: :param auth: Auth handler or (user, pass) tuple.
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/models.py:544: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/models.py:632: # hooks can be passed as None to the prepare method and to this
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/models.py:971: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/cookies.py:80: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/cookies.py:404: # if there are multiple cookies that meet passed in criteria
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/__init__.py:80: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/__init__.py:135: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/compat.py:81: proxy_bypass,
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/compat.py:82: proxy_bypass_environment,
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:45: proxy_bypass,
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:46: proxy_bypass_environment,
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:75: # provide a proxy_bypass version on Windows without DNS lookups
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:77: def proxy_bypass_registry(host):
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:115: def proxy_bypass(host):  # noqa
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:116: """Return True, if the host should be bypassed.
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:122: return proxy_bypass_environment(host)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:124: return proxy_bypass_registry(host)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:158: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:237: # Return with login / password
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:248: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:653: This function passes the given URI through an unquote/quote cycle to
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:755: def should_bypass_proxies(url, no_proxy):
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:757: Returns whether we should bypass proxies or not.
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:806: bypass = proxy_bypass(parsed.hostname)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:808: bypass = False
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:810: if bypass:
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:822: if should_bypass_proxies(url, no_proxy=no_proxy):
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:871: if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:1010: username,password.
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/utils.py:1017: auth = (unquote(parsed.username), unquote(parsed.password))
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py:50: should_bypass_proxies,
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py:73: # Bypass if not a dictionary (e.g. verify)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py:322: username, password = get_auth_from_url(new_proxies[scheme])
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py:324: username, password = None, None
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py:328: if not scheme.startswith("https") and username and password:
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py:329: headers["Proxy-Authorization"] = _basic_auth_str(username, password)
- .venv/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py:743: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/_elffile.py:20: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/markers.py:185: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/_parser.py:26: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py:222: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py:378: # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/specifiers.py:506: :meth:`contains` with no ``prereleases`` argument passed.
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/specifiers.py:693: It can be passed a single specifier (``>=3.0``), a comma-separated list of
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/specifiers.py:738: # pass that through here.
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/specifiers.py:870: :meth:`contains` with no ``prereleases`` argument passed.
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:29: # TODO: Can we test whether something is contained within a requirement?
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:32: # TODO: Can we normalize the name and extra name?
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:204: # TODO: The spec doesn't say anything about if the keys should be
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:512: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:520: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:805: description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:847: # PEP 685 lets us raise an error if an extra doesn't pass `Name` validation
- .venv/lib/python3.12/site-packages/pip/_vendor/packaging/licenses/__init__.py:108: # Take a final pass to check for unknown licenses/exceptions.
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/reporters.py:40: requirements passed in from ``Resolver.resolve()``.
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/providers.py:31: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/providers.py:90: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/providers.py:125: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/providers.py:136: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/providers.py:144: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/providers.py:182: will then be passed to the sort key `get_preference` to pick the most
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/resolvers/exceptions.py:15: bubbling pass the resolver should be treated as a bug.
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/resolvers/exceptions.py:44: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py:227: # always pass under normal circumstances, but in the case of a
- .venv/lib/python3.12/site-packages/pip/_vendor/resolvelib/resolvers/abstract.py:47: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_vendor/msgpack/exceptions.py:11: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/msgpack/exceptions.py:15: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:499: # TODO should we eliminate the recursion?
- .venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:503: # TODO check whether we need to call `list_hook`
- .venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:511: # TODO is the interaction between `list_hook` and `use_list` ok?
- .venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:516: # TODO check whether we need to call hooks
- .venv/lib/python3.12/site-packages/pip/_vendor/distro/distro.py:269: The so determined ID value then passes the following transformations,
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_api.py:44: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_api.py:61: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_api.py:72: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_api.py:160: password: _PasswordType | None = None,
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_api.py:163: certfile=certfile, keyfile=keyfile, password=password
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_api.py:187: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_api.py:204: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_api.py:328: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py:419: raise NotImplementedError("VERIFY_CRL_CHECK_LEAF not implemented for macOS")
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py:558: # TODO: Not sure if we need the SecTrustResultType for anything?
- .venv/lib/python3.12/site-packages/pip/_vendor/truststore/_openssl.py:66: pass
- .venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_impl.py:212: the metadata from it. Should be passed as a keyword argument only.
- .venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_impl.py:295: the metadata from it. Should be passed as a keyword argument only.
- .venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py:236: pass  # Touch marker file
- .venv/lib/python3.12/site-packages/pip/_internal/exceptions.py:695: "installation or OS, by passing --break-system-packages."
- .venv/lib/python3.12/site-packages/pip/_internal/exceptions.py:735: pass
- .venv/lib/python3.12/site-packages/pip/_internal/self_outdated_check.py:73: pass
- .venv/lib/python3.12/site-packages/pip/_internal/self_outdated_check.py:130: pass
- .venv/lib/python3.12/site-packages/pip/_internal/build_env.py:48: """Get a file to pass to a Python executable, to run the currently-running pip.
- .venv/lib/python3.12/site-packages/pip/_internal/build_env.py:325: pass
- .venv/lib/python3.12/site-packages/pip/_internal/build_env.py:328: pass
- .venv/lib/python3.12/site-packages/pip/_internal/build_env.py:336: pass
- .venv/lib/python3.12/site-packages/pip/_internal/build_env.py:339: pass
- .venv/lib/python3.12/site-packages/pip/_internal/build_env.py:349: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/cache.py:89: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/cache.py:98: passed link.
- .venv/lib/python3.12/site-packages/pip/_internal/cache.py:100: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/cache.py:280: # TODO: use DirectUrl.equivalent when
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/base.py:15: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/base.py:20: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:194: # TODO: Check already installed candidate, and use it if the link and
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:613: # TODO: Are there more cases this needs to return True? Editable?
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py:139: raise NotImplementedError("don't do this")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py:155: raise NotImplementedError("don't do this")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:72: raise NotImplementedError("Subclass should override")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:81: raise NotImplementedError("Subclass should override")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:87: raise NotImplementedError("Subclass should override")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:90: raise NotImplementedError("Subclass should override")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:108: raise NotImplementedError("Override in subclass")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:117: raise NotImplementedError("Override in subclass")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:121: raise NotImplementedError("Override in subclass")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:125: raise NotImplementedError("Override in subclass")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:129: raise NotImplementedError("Override in subclass")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:133: raise NotImplementedError("Override in subclass")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:136: raise NotImplementedError("Override in subclass")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:139: raise NotImplementedError("Override in subclass")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/base.py:142: raise NotImplementedError("Subclass should override")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:136: :param link: The link passed to the ``InstallRequirement``. The backing
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:211: raise NotImplementedError("Override in subclass")
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:230: # TODO performance: this means we iterate the dependencies at least twice,
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:365: # TODO: Supply reason based on force_reinstall and upgrade_strategy.
- .venv/lib/python3.12/site-packages/pip/_internal/resolution/legacy/resolver.py:376: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/subprocess.py:221: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/retry.py:21: surpassed, the last exception raised is reraised.
- .venv/lib/python3.12/site-packages/pip/_internal/utils/wheel.py:71: # and RuntimeError for password-protected files
- .venv/lib/python3.12/site-packages/pip/_internal/utils/filesystem.py:52: kwargs will be passed to tempfile.NamedTemporaryFile to control
- .venv/lib/python3.12/site-packages/pip/_internal/utils/filesystem.py:104: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py:85: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py:212: # last pass ignore/log all errors
- .venv/lib/python3.12/site-packages/pip/_internal/utils/compat.py:22: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/appdirs.py:5: The intention is to rewrite current usages gradually, keeping the tests pass,
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:4: import getpass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:114: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:134: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:168: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:175: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:238: def ask_password(message: str) -> str:
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:239: """Ask for a password interactively."""
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:241: return getpass.getpass(message)
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:349: pass
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:429: Returns: (netloc, (username, password)).
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:436: # the password attribute of urlsplit()'s return value).
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:442: # using the password attribute of the return value)
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:459: - "user:pass@example.com" returns "user:****@example.com"
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:462: netloc, (user, password) = split_auth_from_netloc(netloc)
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:465: if password is None:
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:467: password = ""
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:470: password = ":****"
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:471: return f"{user}{password}@{netloc}"
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:508: Returns: (url_without_auth, netloc, (username, password))
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:515: """Return a copy of url with 'username:password@' removed."""
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:516: # username/pass params are passed to subversion through flags
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:522: """Replace the password in a given url with ****."""
- .venv/lib/python3.12/site-packages/pip/_internal/utils/misc.py:527: """Replace the password in a given requirement url with ****."""
- .venv/lib/python3.12/site-packages/pip/_internal/utils/deprecation.py:19: pass
- .venv/lib/python3.12/site-packages/pip/_internal/models/selection_prefs.py:6: # TODO: This needs Python 3.10's improved slots support for dataclasses
- .venv/lib/python3.12/site-packages/pip/_internal/models/pylock.py:127: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/models/pylock.py:135: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/models/pylock.py:140: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/models/pylock.py:158: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/models/target_python.py:38: find packages that can be built on the platforms passed in. These
- .venv/lib/python3.12/site-packages/pip/_internal/models/target_python.py:44: :param abis: A list of strings or None. This is passed to
- .venv/lib/python3.12/site-packages/pip/_internal/models/target_python.py:46: :param implementation: A string or None. This is passed to
- .venv/lib/python3.12/site-packages/pip/_internal/models/direct_url.py:27: pass
- .venv/lib/python3.12/site-packages/pip/_internal/models/direct_url.py:170: user_pass, netloc_no_user_pass = netloc.split("@", 1)
- .venv/lib/python3.12/site-packages/pip/_internal/models/direct_url.py:174: and user_pass == "git"
- .venv/lib/python3.12/site-packages/pip/_internal/models/direct_url.py:177: if ENV_VAR_RE.match(user_pass):
- .venv/lib/python3.12/site-packages/pip/_internal/models/direct_url.py:179: return netloc_no_user_pass
- .venv/lib/python3.12/site-packages/pip/_internal/models/direct_url.py:183: """url with user:password part removed unless it is formed with
- .venv/lib/python3.12/site-packages/pip/_internal/models/installation_report.py:51: # TODO: currently, the resolver uses the default environment to evaluate
- .venv/lib/python3.12/site-packages/pip/_internal/models/link.py:422: # includes a username and password.
- .venv/lib/python3.12/site-packages/pip/_internal/models/link.py:423: netloc, user_pass = split_auth_from_netloc(self.netloc)
- .venv/lib/python3.12/site-packages/pip/_internal/locations/_distutils.py:17: pass
- .venv/lib/python3.12/site-packages/pip/_internal/distributions/sdist.py:124: # This must be done in a second pass, as the pyproject.toml
- .venv/lib/python3.12/site-packages/pip/_internal/distributions/wheel.py:44: pass
- .venv/lib/python3.12/site-packages/pip/_internal/distributions/installed.py:33: pass
- .venv/lib/python3.12/site-packages/pip/_internal/distributions/base.py:42: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/distributions/base.py:46: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/distributions/base.py:55: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/commands/configuration.py:43: If none of --user, --global and --site are passed, a virtual
- .venv/lib/python3.12/site-packages/pip/_internal/commands/inspect.py:60: # TODO tags? scheme?
- .venv/lib/python3.12/site-packages/pip/_internal/commands/completion.py:133: "ERROR: You must pass {}\n".format(" or ".join(shell_options))
- .venv/lib/python3.12/site-packages/pip/_internal/commands/search.py:174: pass
- .venv/lib/python3.12/site-packages/pip/_internal/req/req_set.py:74: TODO remove this property together with the legacy resolver, since the new
- .venv/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:233: pass
- .venv/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:565: pass
- .venv/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:628: pass
- .venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:66: # options to be passed to requirements
- .venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:104: # TODO: replace this with slots=True when dropping Python 3.9 support.
- .venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:523: # TODO: handle space after '\'.
- .venv/lib/python3.12/site-packages/pip/_internal/req/req_install.py:166: # gets stored. We need this to pass to build_wheel, so the backend
- .venv/lib/python3.12/site-packages/pip/_internal/req/constructors.py:287: # TODO: The is_installable_dir test here might not be necessary
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:30: ask_password,
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:44: password: str
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:56: def save_auth_info(self, url: str, username: str, password: str) -> None: ...
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:67: def save_auth_info(self, url: str, username: str, password: str) -> None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:89: return cred.username, cred.password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:93: logger.debug("Getting password from keyring for %s", url)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:94: password = self.keyring.get_password(url, username)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:95: if password:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:96: return username, password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:99: def save_auth_info(self, url: str, username: str, password: str) -> None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:100: self.keyring.set_password(url, username, password)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:121: password = self._get_password(url, username)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:122: if password is not None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:123: return username, password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:126: def save_auth_info(self, url: str, username: str, password: str) -> None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:127: return self._set_password(url, username, password)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:129: def _get_password(self, service_name: str, username: str) -> str | None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:130: """Mirror the implementation of keyring.get_password using cli"""
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:147: def _set_password(self, service_name: str, username: str, password: str) -> None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:148: """Mirror the implementation of keyring.set_password using cli"""
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:155: input=f"{password}{os.linesep}".encode(),
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:175: pass
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:210: pass
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:234: self.passwords: dict[str, AuthInfo] = {}
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:256: # We won't use keyring when --no-input is passed unless
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:293: The provided url should have had its username and password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:344: url, netloc, url_user_password = split_auth_netloc_from_url(
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:349: username, password = url_user_password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:350: if username is not None and password is not None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:352: return url_user_password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:360: index_url, _, index_url_user_password = index_info
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:364: if index_url and index_url_user_password[0] is not None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:365: username, password = index_url_user_password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:366: if username is not None and password is not None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:368: return index_url_user_password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:377: # If we don't have a password and keyring is available, use it.
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:390: return username, password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:400: Returns (url_without_credentials, username, password). Note
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:402: function may return a different username and password.
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:407: username, password = self._get_new_credentials(original_url)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:410: # Do this if either the username or the password is missing.
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:412: # the username in the index url, but the password comes from keyring.
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:413: if (username is None or password is None) and netloc in self.passwords:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:414: un, pw = self.passwords[netloc]
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:418: username, password = un, pw
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:420: if username is not None or password is not None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:421: # Convert the username and password if they're None, so that
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:426: password = password or ""
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:429: self.passwords[netloc] = (username, password)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:433: (username is not None and password is not None)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:435: or (username is None and password is None)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:438: return url, username, password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:442: url, username, password = self._get_url_and_credentials(req.url)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:447: if username is not None and password is not None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:449: req = HTTPBasicAuth(username, password)(req)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:457: def _prompt_for_password(self, netloc: str) -> tuple[str | None, str | None, bool]:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:465: password = ask_password("Password: ")
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:466: return username, password, True
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:469: def _should_save_password_to_keyring(self) -> bool:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:480: #   pass through the actual response
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:484: username, password = None, None
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:488: username, password = self._get_new_credentials(
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:495: if not self.prompting and not username and not password:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:500: # Prompt the user for a new username and password
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:502: if not username and not password:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:503: username, password, save = self._prompt_for_password(parsed.netloc)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:505: # Store the new username and password to use for future requests
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:507: if username is not None and password is not None:
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:508: self.passwords[parsed.netloc] = (username, password)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:510: # Prompt to save the password to keyring
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:511: if save and self._should_save_password_to_keyring():
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:515: password=password,
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:525: # Add our new username and password to the request
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:526: req = HTTPBasicAuth(username or "", password or "")(resp.request)
- .venv/lib/python3.12/site-packages/pip/_internal/network/auth.py:561: creds.url, creds.username, creds.password
- .venv/lib/python3.12/site-packages/pip/_internal/network/session.py:186: pass
- .venv/lib/python3.12/site-packages/pip/_internal/network/session.py:251: pass
- .venv/lib/python3.12/site-packages/pip/_internal/network/session.py:296: pass
- .venv/lib/python3.12/site-packages/pip/_internal/network/session.py:300: pass
- .venv/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:23: pass
- .venv/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:167: pass
- .venv/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:177: # TODO: Get range requests to be correctly cached
- .venv/lib/python3.12/site-packages/pip/_internal/network/cache.py:32: pass
- .venv/lib/python3.12/site-packages/pip/_internal/index/package_finder.py:308: pass
- .venv/lib/python3.12/site-packages/pip/_internal/index/package_finder.py:487: Function to pass as the `key` argument to a call to sorted() to sort
- .venv/lib/python3.12/site-packages/pip/_internal/index/sources.py:35: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/index/sources.py:39: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/index/sources.py:43: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/index/collector.py:87: pass
- .venv/lib/python3.12/site-packages/pip/_internal/index/collector.py:339: # TODO: In the future, it would be nice if pip supported PEP 691
- .venv/lib/python3.12/site-packages/pip/_internal/index/collector.py:421: # Make sure find_links is a list before passing to create().
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/git.py:396: # We need to pass 1 for extra_ok_returncodes since the command
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/git.py:519: url, rev, user_pass = super().get_url_rev_and_auth(url)
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/git.py:522: url, rev, user_pass = super().get_url_rev_and_auth(url)
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/git.py:524: return url, rev, user_pass
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/bazaar.py:94: url, rev, user_pass = super().get_url_rev_and_auth(url)
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/bazaar.py:97: return url, rev, user_pass
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:103: pass
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:256: # Iterable of environment variable names to pass to call_subprocess().
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:315: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:365: information can be provided via the --username and --password options
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:369: Returns: (netloc, (username, password)).
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:379: Returns: (url, rev, (username, password)).
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:390: netloc, user_pass = cls.get_netloc_and_auth(netloc, scheme)
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:401: return url, rev, user_pass
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:404: def make_rev_args(username: str | None, password: HiddenText | None) -> CommandArgs:
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:415: secret_url, rev, user_pass = self.get_url_rev_and_auth(url.secret)
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:416: username, secret_password = user_pass
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:417: password: HiddenText | None = None
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:418: if secret_password is not None:
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:419: password = hide_value(secret_password)
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:420: extra_args = self.make_rev_args(username, password)
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:452: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:467: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:482: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:493: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:604: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:611: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:79: This override allows the auth information to be passed to svn via the
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:80: --username and --password options instead of via the URL.
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:83: # The --username and --password options can't be used for
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:92: url, rev, user_pass = super().get_url_rev_and_auth(url)
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:95: return url, rev, user_pass
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:98: def make_rev_args(username: str | None, password: HiddenText | None) -> CommandArgs:
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:102: if password:
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:103: extra_args += ["--password", password]
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:160: # is being used to prompt for passwords, because passwords
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:258: :return: A list of command line arguments to pass to ``svn``.
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:268: # call_subprocess(), pip must pass --force-interactive to ensure
- .venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:269: # the user can be prompted for a password, if required.
- .venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:81: pass
- .venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:93: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:135: # Bypass our logger and write any remaining messages to
- .venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:209: # TODO: Try to get these passing down from the command?
- .venv/lib/python3.12/site-packages/pip/_internal/cli/progress_bars.py:139: return iter  # no-op, when passed an iterator
- .venv/lib/python3.12/site-packages/pip/_internal/cli/cmdoptions.py:7: pass on state. To be consistent, all options will follow this design.
- .venv/lib/python3.12/site-packages/pip/_internal/cli/cmdoptions.py:280: help="Specify a proxy in the form scheme://[user:passwd@]proxy.server:port.",
- .venv/lib/python3.12/site-packages/pip/_internal/cli/cmdoptions.py:711: # The value argument will be None if --no-cache-dir is passed via the
- .venv/lib/python3.12/site-packages/pip/_internal/cli/cmdoptions.py:829: # will be None if --no-use-pep517 is passed via the command-line.
- .venv/lib/python3.12/site-packages/pip/_internal/cli/cmdoptions.py:833: msg = """A value was passed for --no-use-pep517,
- .venv/lib/python3.12/site-packages/pip/_internal/cli/cmdoptions.py:851: # Otherwise, --no-use-pep517 was passed via the command-line.
- .venv/lib/python3.12/site-packages/pip/_internal/cli/cmdoptions.py:904: help="Configuration settings to be passed to the PEP 517 build backend. "
- .venv/lib/python3.12/site-packages/pip/_internal/cli/cmdoptions.py:906: "to pass multiple keys to the backend.",
- .venv/lib/python3.12/site-packages/pip/_internal/cli/req_command.py:73: # This kind of conflict can occur when the user passes an explicit
- .venv/lib/python3.12/site-packages/pip/_internal/cli/spinners.py:32: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/cli/spinners.py:35: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:32: from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:47: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:51: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:55: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:101: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:119: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:133: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:153: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:162: # TODO: this property is relatively costly to compute, memoize it ?
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:172: # TODO: get project location from second line of egg_link file
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:188: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:204: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:269: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:273: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:277: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:357: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:365: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:374: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:377: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:380: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:443: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:459: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:584: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:588: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:596: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:605: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:668: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/pkg_resources.py:77: pass
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/pkg_resources.py:293: # We didn't pass in any version specifiers, so this can never
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_compat.py:32: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_compat.py:36: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_dists.py:98: raise NotImplementedError
- .venv/lib/python3.12/site-packages/pip/_internal/operations/check.py:66: If should_ignore is passed, it should be a callable that takes a
- .venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:101: pass
- .venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:471: # `req.local_file_path` on the appropriate requirement after passing
- .venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:562: # TODO: separate this part out from RequirementPreparer when the v1
- .venv/lib/python3.12/site-packages/pip/_internal/operations/build/build_tracker.py:101: pass
- .venv/lib/python3.12/site-packages/pip/_internal/operations/install/wheel.py:63: pass
- .venv/lib/python3.12/site-packages/pip/_internal/operations/install/wheel.py:203: passed to this function, the size can be an integer as an int or string,
- .venv/lib/python3.12/site-packages/pip/_internal/operations/install/wheel.py:692: pass
- .venv/lib/python3.12/site-packages/pip/_internal/operations/install/editable_legacy.py:28: """Install a package in editable mode. Most arguments are pass-through
- .venv/lib/python3.12/site-packages/psutil/_common.py:475: pass
- .venv/lib/python3.12/site-packages/psutil/_common.py:489: pass
- .venv/lib/python3.12/site-packages/psutil/_common.py:787: pass
- .venv/lib/python3.12/site-packages/psutil/_pswindows.py:542: and can be passed to win_service_get() to get a new
- .venv/lib/python3.12/site-packages/psutil/_pswindows.py:572: """The process PID, if any, else None. This can be passed
- .venv/lib/python3.12/site-packages/psutil/_pswindows.py:801: # TODO: the C ext can probably be refactored in order
- .venv/lib/python3.12/site-packages/psutil/_psbsd.py:261: # Next calls will fail with NotImplementedError
- .venv/lib/python3.12/site-packages/psutil/_psbsd.py:268: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/psutil/_psbsd.py:359: except NotImplementedError:
- .venv/lib/python3.12/site-packages/psutil/_psbsd.py:467: except NotImplementedError:
- .venv/lib/python3.12/site-packages/psutil/_psbsd.py:492: except NotImplementedError:
- .venv/lib/python3.12/site-packages/psutil/_psbsd.py:493: pass
- .venv/lib/python3.12/site-packages/psutil/_psbsd.py:878: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/psutil/_psbsd.py:890: raise NotImplementedError
- .venv/lib/python3.12/site-packages/psutil/_pssunos.py:226: # TODO - the filtering logic should be better checked so that
- .venv/lib/python3.12/site-packages/psutil/_pssunos.py:273: # TODO: refactor and use _common.conn_to_ntuple.
- .venv/lib/python3.12/site-packages/psutil/_pssunos.py:433: pass  # continue and guess the exe name from the cmdline
- .venv/lib/python3.12/site-packages/psutil/_pssunos.py:620: # TODO: rewrite this in C (...but the damn netstat source code
- .venv/lib/python3.12/site-packages/psutil/__init__.py:139: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/psutil/__init__.py:263: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:355: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:359: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:409: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:442: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:576: except NotImplementedError:
- .venv/lib/python3.12/site-packages/psutil/__init__.py:603: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:680: # Just pass and return the truncated name: it's better
- .venv/lib/python3.12/site-packages/psutil/__init__.py:685: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:733: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:874: If an empty list is passed, all egible CPUs are assumed
- .venv/lib/python3.12/site-packages/psutil/__init__.py:978: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:1006: pass
- .venv/lib/python3.12/site-packages/psutil/__init__.py:1134: It does so by passing through the whole process address.
- .venv/lib/python3.12/site-packages/psutil/__init__.py:1550: terminates (a Process instance is passed as callback argument).
- .venv/lib/python3.12/site-packages/psutil/__init__.py:1580: pass
- .venv/lib/python3.12/site-packages/psutil/_psaix.py:52: cext.SSWAP: _common.STATUS_RUNNING,  # TODO what status is this?
- .venv/lib/python3.12/site-packages/psutil/_psaix.py:174: # TODO - the filtering logic should be better checked so that
- .venv/lib/python3.12/site-packages/psutil/_psaix.py:241: # TODO: rewrite this in C (entstat forks, so use truss -f to follow.
- .venv/lib/python3.12/site-packages/psutil/_psaix.py:515: # TODO rewrite without using procfiles (stat /proc/pid/fd/* and then
- .venv/lib/python3.12/site-packages/psutil/_psosx.py:217: except NotImplementedError:
- .venv/lib/python3.12/site-packages/psutil/_psosx.py:321: pass
- .venv/lib/python3.12/site-packages/psutil/_psposix.py:76: passed to *exit().
- .venv/lib/python3.12/site-packages/psutil/_psposix.py:132: # positive integer passed to *exit().
- .venv/lib/python3.12/site-packages/psutil/_psposix.py:206: pass
- .venv/lib/python3.12/site-packages/psutil/_pslinux.py:205: # bytes, not str" errors when the string is passed to other
- .venv/lib/python3.12/site-packages/psutil/_pslinux.py:641: pass
- .venv/lib/python3.12/site-packages/psutil/_pslinux.py:721: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/psutil/_pslinux.py:746: pass
- .venv/lib/python3.12/site-packages/psutil/_pslinux.py:1153: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/psutil/_pslinux.py:1593: # os.kill() can also be passed a TID. This is quite confusing.
- .venv/lib/python3.12/site-packages/psutil/_pslinux.py:1628: pass
- .venv/lib/python3.12/site-packages/psutil/_pslinux.py:2072: raise NotImplementedError(msg)
- .venv/lib/python3.12/site-packages/psutil/tests/test_posix.py:78: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_misc.py:261: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_misc.py:275: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_misc.py:429: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process_all.py:202: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process_all.py:283: # TODO: check ntuple fields
- .venv/lib/python3.12/site-packages/psutil/tests/test_process_all.py:347: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process_all.py:371: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process_all.py:530: # On Linux a TID (thread ID) can be passed to the
- .venv/lib/python3.12/site-packages/psutil/tests/test_aix.py:60: # TODO maybe try to use "swap -l" to check "used" too, but its units
- .venv/lib/python3.12/site-packages/psutil/tests/test_osx.py:117: # TODO: remove this once 1892 is fixed
- .venv/lib/python3.12/site-packages/psutil/tests/test_osx.py:182: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_testutils.py:152: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_testutils.py:171: # TODO: test for timeout
- .venv/lib/python3.12/site-packages/psutil/tests/test_testutils.py:437: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_testutils.py:516: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_testutils.py:522: def test_passed(self):
- .venv/lib/python3.12/site-packages/psutil/tests/test_testutils.py:523: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_testutils.py:542: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_testutils.py:555: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_contracts.py:228: # TODO: remove this once 1892 is fixed
- .venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:995: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:1018: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:1103: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:1319: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:1969: # TODO: re-enable this test.
- .venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:1973: #             NotImplementedError,
- .venv/lib/python3.12/site-packages/psutil/tests/test_bsd.py:7: # TODO: (FreeBSD) add test for comparing connections with 'sockstat' cmd.
- .venv/lib/python3.12/site-packages/psutil/tests/test_bsd.py:149: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:523: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:539: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:542: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:550: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:629: raise NotImplementedError("not POSIX")
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:652: raise NotImplementedError("not WINDOWS")
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:783: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:801: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:809: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:950: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:1273: import getpass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:1334: info['user'] = getpass.getuser()
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:1573: pass
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:1645: """Decorator to Ignore NotImplementedError exceptions."""
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:1652: except NotImplementedError:
- .venv/lib/python3.12/site-packages/psutil/tests/__init__.py:1658: " NotImplementedError"
- .venv/lib/python3.12/site-packages/psutil/tests/test_windows.py:56: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_windows.py:68: "powershell.exe -ExecutionPolicy Bypass -NoLogo -NonInteractive "
- .venv/lib/python3.12/site-packages/psutil/tests/test_windows.py:816: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:251: # TODO: UNIX sockets are temporarily implemented by parsing
- .venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:291: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:316: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:365: # TODO: remove this once 1892 is fixed
- .venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:383: # TODO: remove this skip when this gets fixed
- .venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:475: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_system.py:584: # TODO: remove this once 1892 is fixed
- .venv/lib/python3.12/site-packages/psutil/tests/test_system.py:852: # TODO: skip AF_INET6 for now because I get:
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:12: import getpass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:139: cmd = [PYTHON_EXE, "-c", "pass"]
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:233: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:397: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:427: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:664: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:730: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:867: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:889: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:926: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:937: getpass_user = getpass.getuser()
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:938: if getpass_user.endswith('$'):
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:943: assert username == getpass_user
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:947: assert username == getpass.getuser()
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1039: # TODO: #595
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1078: # TODO: #595
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1199: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1208: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1274: # By default APIs raising NotImplementedError are
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1277: 'psutil.Process.nice', create=True, side_effect=NotImplementedError
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1282: with pytest.raises(NotImplementedError):
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1355: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1480: pass
- .venv/lib/python3.12/site-packages/psutil/tests/test_scripts.py:205: pass
- .venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:64: pass
- .venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:99: You can also pass `default_to_notebook=False` to get back raw HTML
- .venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:106: pass
- .venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:238: # TODO is this the right name for the data attribute ?
- .venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:305: # TODO I think there is an edge case here where an annotation's span might not close
- .venv/lib/python3.12/site-packages/triton/knobs.py:20: pass
- .venv/lib/python3.12/site-packages/triton/knobs.py:109: raise NotImplementedError()
- .venv/lib/python3.12/site-packages/triton/knobs.py:152: # We can't pass the type directly to avoid import cycles
- .venv/lib/python3.12/site-packages/triton/knobs.py:220: pass
- .venv/lib/python3.12/site-packages/triton/knobs.py:224: pass
- .venv/lib/python3.12/site-packages/triton/knobs.py:355: # TODO: Use enum to constrain / 'typecheck' the values
- .venv/lib/python3.12/site-packages/triton/knobs.py:376: # TODO: Use tuple instead of list for better typing.
- .venv/lib/python3.12/site-packages/triton/testing.py:176: # if it contains a backward pass. So we clear the
- .venv/lib/python3.12/site-packages/triton/tools/build_extern.py:128: pass
- .venv/lib/python3.12/site-packages/triton/tools/build_extern.py:132: pass
- .venv/lib/python3.12/site-packages/triton/tools/compile.py:85: pass
- .venv/lib/python3.12/site-packages/triton/tools/compile.py:90: pass
- .venv/lib/python3.12/site-packages/triton/tools/link.py:13: pass
- .venv/lib/python3.12/site-packages/triton/tools/disasm.py:60: pass
- .venv/lib/python3.12/site-packages/triton/tools/disasm.py:110: line_idx += 2  # bypass .headerflags
- .venv/lib/python3.12/site-packages/triton/language/semantic.py:1473: pass
- .venv/lib/python3.12/site-packages/triton/language/semantic.py:1573: #TODO: validate types.
- .venv/lib/python3.12/site-packages/triton/language/random.py:131: # TODO: fix frontend issues and cleanup
- .venv/lib/python3.12/site-packages/triton/language/core.py:110: pass
- .venv/lib/python3.12/site-packages/triton/language/core.py:138: pass
- .venv/lib/python3.12/site-packages/triton/language/core.py:150: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/language/core.py:156: raise NotImplementedError("Types must implement __eq__")
- .venv/lib/python3.12/site-packages/triton/language/core.py:166: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/language/core.py:169: raise NotImplementedError(f"NYI: Type mangling for type {self.__class__}")
- .venv/lib/python3.12/site-packages/triton/language/core.py:172: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/language/core.py:1116: pass  # an unsqueeze
- .venv/lib/python3.12/site-packages/triton/language/core.py:1297: # TODO: remove
- .venv/lib/python3.12/site-packages/triton/language/core.py:1728: :code:`shape` can be passed as a tuple or as individual parameters: ::
- .venv/lib/python3.12/site-packages/triton/language/core.py:1751: :code:`dims` can be passed as a tuple or as individual parameters: ::
- .venv/lib/python3.12/site-packages/triton/language/core.py:1777: :code:`dims` can be passed as a tuple or as individual parameters: ::
- .venv/lib/python3.12/site-packages/triton/language/core.py:1898: :code:`shape` can be passed as a tuple or as individual parameters: ::
- .venv/lib/python3.12/site-packages/triton/language/core.py:1929: :code:`shape` can be passed as a tuple or as individual parameters: ::
- .venv/lib/python3.12/site-packages/triton/language/core.py:2877: pass
- .venv/lib/python3.12/site-packages/triton/language/core.py:2891: pass
- .venv/lib/python3.12/site-packages/triton/language/core.py:3049: :param args: the input tensors, whose values are passed to the asm block
- .venv/lib/python3.12/site-packages/triton/language/core.py:3169: :code:`triton.jit` functions. In addition, it allows user to pass extra attributes to the compiler.
- .venv/lib/python3.12/site-packages/triton/language/core.py:3176: Note this is subtly different than passing :code:`num_stages` as a
- .venv/lib/python3.12/site-packages/triton/runtime/cache.py:15: pass
- .venv/lib/python3.12/site-packages/triton/runtime/cache.py:19: pass
- .venv/lib/python3.12/site-packages/triton/runtime/cache.py:23: pass
- .venv/lib/python3.12/site-packages/triton/runtime/cache.py:27: pass
- .venv/lib/python3.12/site-packages/triton/runtime/cache.py:31: pass
- .venv/lib/python3.12/site-packages/triton/runtime/cache.py:129: pass
- .venv/lib/python3.12/site-packages/triton/runtime/cache.py:133: pass
- .venv/lib/python3.12/site-packages/triton/runtime/cache.py:137: pass
- .venv/lib/python3.12/site-packages/triton/runtime/interpreter.py:682: raise NotImplementedError("extern_elementwise not supported in interpreter mode")
- .venv/lib/python3.12/site-packages/triton/runtime/interpreter.py:685: raise NotImplementedError("inline_asm not supported in interpreter mode")
- .venv/lib/python3.12/site-packages/triton/runtime/interpreter.py:711: pass
- .venv/lib/python3.12/site-packages/triton/runtime/interpreter.py:1066: # can get `step` passed by keyword
- .venv/lib/python3.12/site-packages/triton/runtime/interpreter.py:1125: # TODO: wrap everything in triton tensors
- .venv/lib/python3.12/site-packages/triton/runtime/interpreter.py:1181: from .jit import _normalize_ty  # TODO: modularize
- .venv/lib/python3.12/site-packages/triton/runtime/autotuner.py:300: :ivar kwargs: a dictionary of meta-parameters to pass to the kernel as keyword arguments.
- .venv/lib/python3.12/site-packages/triton/runtime/autotuner.py:417: 'kwargs': a dict of all arguments passed to the kernel.
- .venv/lib/python3.12/site-packages/triton/runtime/autotuner.py:422: 'kwargs': a dict of all arguments passed to the kernel.
- .venv/lib/python3.12/site-packages/triton/runtime/autotuner.py:425: :param warmup: warmup time (in ms) to pass to benchmarking (deprecated).
- .venv/lib/python3.12/site-packages/triton/runtime/autotuner.py:427: :param rep: repetition time (in ms) to pass to benchmarking (deprecated).
- .venv/lib/python3.12/site-packages/triton/runtime/jit.py:208: # TODO(jlebar): I don't actually know how to hit this.  You don't
- .venv/lib/python3.12/site-packages/triton/runtime/jit.py:529: function with args and kwargs passed into the kernel
- .venv/lib/python3.12/site-packages/triton/runtime/jit.py:671: # TODO(jlebar): Remove uses of these fields outside this file, then
- .venv/lib/python3.12/site-packages/triton/runtime/jit.py:691: # TODO : hash should be attribute of `self`
- .venv/lib/python3.12/site-packages/triton/runtime/jit.py:762: Bypasses the __setattr__ restriction by calling super().__setattr__ directly.
- .venv/lib/python3.12/site-packages/triton/experimental/gluon/language/_layouts.py:22: pass
- .venv/lib/python3.12/site-packages/triton/experimental/gluon/language/_layouts.py:137: pass
- .venv/lib/python3.12/site-packages/triton/experimental/gluon/language/_core.py:17: block_type,  # TODO: block type with layout info
- .venv/lib/python3.12/site-packages/triton/experimental/gluon/language/_core.py:108: # TODO: split these
- .venv/lib/python3.12/site-packages/triton/backends/compiler.py:32: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/backends/compiler.py:37: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/backends/compiler.py:45: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/backends/compiler.py:57: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/backends/compiler.py:64: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/backends/compiler.py:71: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/backends/driver.py:8: pass
- .venv/lib/python3.12/site-packages/triton/backends/driver.py:16: pass
- .venv/lib/python3.12/site-packages/triton/backends/driver.py:20: pass
- .venv/lib/python3.12/site-packages/triton/backends/driver.py:24: pass
- .venv/lib/python3.12/site-packages/triton/backends/driver.py:31: raise NotImplementedError
- .venv/lib/python3.12/site-packages/triton/backends/driver.py:34: pass
- .venv/lib/python3.12/site-packages/triton/backends/driver.py:40: # TODO: support other frameworks than torch
- .venv/lib/python3.12/site-packages/triton/backends/driver.py:51: # TODO: remove once TMA is cleaned up
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:2: from triton._C.libtriton import ir, passes, llvm, nvidia
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:94: # TODO: Handle non-"a" sms
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:214: pm = ir.pass_manager(mod.context)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:216: passes.common.add_inliner(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:217: passes.ttir.add_rewrite_tensor_pointer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:219: passes.ttir.add_rewrite_tensor_descriptor_to_pointer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:220: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:221: passes.ttir.add_combine(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:222: passes.ttir.add_reorder_broadcast(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:223: passes.common.add_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:224: passes.common.add_symbol_dce(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:225: passes.ttir.add_loop_unroll(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:240: pm = ir.pass_manager(mod.context)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:242: passes.ttir.add_convert_to_ttgpuir(pm, f"cuda:{capability}", opt.num_warps, 32, opt.num_ctas)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:244: passes.ttgpuir.add_coalesce(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:246: passes.ttgpuir.add_f32_dot_tc(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:247: # TODO(Qingyi): Move PlanCTAPass to the front of CoalescePass
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:248: nvidia.passes.ttnvgpuir.add_plan_cta(pm, cluster_info)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:249: passes.ttgpuir.add_remove_layout_conversions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:250: passes.ttgpuir.add_optimize_thread_locality(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:251: passes.ttgpuir.add_accelerate_matmul(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:252: passes.ttgpuir.add_remove_layout_conversions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:253: passes.ttgpuir.add_optimize_dot_operands(pm, capability >= 80)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:254: nvidia.passes.ttnvgpuir.add_optimize_descriptor_encoding(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:255: passes.ttir.add_loop_aware_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:257: passes.ttgpuir.add_fuse_nested_loops(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:258: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:259: passes.ttir.add_triton_licm(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:260: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:261: passes.ttgpuir.add_combine_tensor_select_and_if(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:262: nvidia.passes.hopper.add_hopper_warpspec(pm, opt.num_stages, dump_enabled)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:263: passes.ttgpuir.add_assign_latencies(pm, opt.num_stages)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:264: passes.ttgpuir.add_schedule_loops(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:265: passes.ttgpuir.add_pipeline(pm, opt.num_stages, dump_enabled)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:267: passes.ttgpuir.add_fuse_nested_loops(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:268: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:269: passes.ttir.add_triton_licm(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:270: passes.ttgpuir.add_optimize_accumulator_init(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:271: passes.ttgpuir.add_hoist_tmem_alloc(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:272: nvidia.passes.ttnvgpuir.add_promote_lhs_to_tmem(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:273: passes.ttgpuir.add_assign_latencies(pm, opt.num_stages)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:274: passes.ttgpuir.add_schedule_loops(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:275: passes.ttgpuir.add_warp_specialize(pm, opt.num_stages)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:276: passes.ttgpuir.add_pipeline(pm, opt.num_stages, dump_enabled)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:277: passes.ttgpuir.add_combine_tensor_select_and_if(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:278: nvidia.passes.ttnvgpuir.add_remove_tmem_tokens(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:280: passes.ttir.add_triton_licm(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:281: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:282: passes.ttir.add_loop_aware_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:283: passes.ttgpuir.add_prefetch(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:284: passes.ttgpuir.add_optimize_dot_operands(pm, capability >= 80)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:285: passes.ttgpuir.add_coalesce_async_copy(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:286: nvidia.passes.ttnvgpuir.add_optimize_tmem_layouts(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:287: passes.ttgpuir.add_remove_layout_conversions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:288: nvidia.passes.ttnvgpuir.add_interleave_tmem(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:289: passes.ttgpuir.add_reduce_data_duplication(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:290: passes.ttgpuir.add_reorder_instructions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:291: passes.ttir.add_loop_aware_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:292: passes.common.add_symbol_dce(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:294: nvidia.passes.ttnvgpuir.add_tma_lowering(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:295: nvidia.passes.ttnvgpuir.add_fence_insertion(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:296: passes.common.add_sccp(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:297: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:306: pm = ir.pass_manager(mod.context)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:309: passes.ttgpuir.add_inliner(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:310: passes.common.add_sccp(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:311: passes.ttir.add_loop_aware_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:312: passes.ttgpuir.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:313: passes.ttgpuir.add_combine_tensor_select_and_if(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:324: pm = ir.pass_manager(mod.context)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:327: nvidia.passes.ttnvgpuir.add_lower_mma(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:328: passes.ttgpuir.add_combine_tensor_select_and_if(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:329: passes.ttgpuir.add_allocate_warp_groups(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:330: passes.convert.add_scf_to_cf(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:331: passes.ttgpuir.add_allocate_shared_memory(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:332: nvidia.passes.ttnvgpuir.add_allocate_tensor_memory(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:333: passes.ttgpuir.add_allocate_global_scratch_memory(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:334: nvidia.passes.ttgpuir.add_to_llvmir(pm, capability, ptx_version)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:335: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:336: passes.common.add_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:337: nvidia.passes.ttnvgpuir.add_nvgpu_to_llvm(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:338: nvidia.passes.ttnvgpuir.add_warp_specialize_to_llvm(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:339: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:340: passes.common.add_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:341: passes.common.add_symbol_dce(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/compiler.py:343: passes.llvmir.add_di_scope(pm)
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/driver.py:144: # Currently the host side tensor descriptors get passed in as a
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/driver.py:148: # we have to pass the shape and strides twice.
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/driver.py:307: // 4 attributes that we can currently pass maxmimum
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/driver.py:620: # above. Sadly this means we have to pass the shape and strides
- .venv/lib/python3.12/site-packages/triton/backends/nvidia/driver.py:715: self.utils = CudaUtils()  # TODO: make static
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:2: from triton._C.libtriton import ir, passes, llvm, amd
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:199: pm = ir.pass_manager(mod.context)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:201: passes.common.add_inliner(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:202: passes.ttir.add_rewrite_tensor_pointer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:203: passes.ttir.add_rewrite_tensor_descriptor_to_pointer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:204: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:205: passes.ttir.add_combine(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:206: passes.ttir.add_reorder_broadcast(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:207: passes.common.add_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:208: passes.ttir.add_triton_licm(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:209: passes.common.add_symbol_dce(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:210: passes.ttir.add_loop_unroll(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:216: pm = ir.pass_manager(mod.context)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:218: passes.ttir.add_convert_to_ttgpuir(pm, f"hip:{options.arch}", options.num_warps, options.warp_size,
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:221: pm = ir.pass_manager(mod.context)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:223: passes.ttgpuir.add_coalesce(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:224: passes.ttgpuir.add_remove_layout_conversions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:225: passes.ttgpuir.add_optimize_thread_locality(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:226: amd.passes.ttgpuir.add_accelerate_matmul(pm, options.arch, options.matrix_instr_nonkdim, options.kpack)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:227: passes.ttgpuir.add_remove_layout_conversions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:228: amd.passes.ttgpuir.add_optimize_epilogue(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:229: passes.ttgpuir.add_optimize_dot_operands(pm, True)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:230: amd.passes.ttgpuir.add_hoist_layout_conversions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:232: passes.ttgpuir.add_fuse_nested_loops(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:233: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:234: passes.ttir.add_triton_licm(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:235: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:245: amd.passes.ttgpuir.add_stream_pipeline(pm, options.num_stages, global_prefetch, local_prefetch, use_async_copy)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:247: amd.passes.ttgpuir.add_coalesce_async_copy(pm, options.arch)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:248: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:250: amd.passes.ttgpuir.insert_instruction_sched_hints(pm, options.schedule_hint)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:251: passes.ttgpuir.add_optimize_dot_operands(pm, True)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:252: passes.ttgpuir.add_remove_layout_conversions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:253: passes.ttgpuir.add_reduce_data_duplication(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:255: amd.passes.ttgpuir.add_in_thread_transpose(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:256: passes.ttgpuir.add_remove_layout_conversions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:257: amd.passes.ttgpuir.add_reorder_instructions(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:260: amd.passes.ttgpuir.add_block_pingpong(pm, options.num_stages)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:263: amd.passes.ttgpuir.add_canonicalize_pointers(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:264: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:265: amd.passes.ttgpuir.add_convert_to_buffer_ops(pm, options.arch)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:267: amd.passes.ttgpuir.add_fold_true_cmpi(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:268: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:269: passes.common.add_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:270: passes.common.add_symbol_dce(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:272: amd.passes.ttgpuir.add_update_async_wait_count(pm, options.arch)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:279: pm = ir.pass_manager(mod.context)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:282: passes.ttgpuir.add_inliner(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:283: passes.common.add_sccp(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:284: passes.ttir.add_loop_aware_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:285: passes.ttgpuir.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:286: passes.ttgpuir.add_combine_tensor_select_and_if(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:295: pm = ir.pass_manager(mod.context)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:300: # If custom_lds_size = 0, pass will consider all LDS is available for one threads block,
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:303: amd.passes.ttgpuir.add_optimize_lds_usage(pm, options.arch, custom_lds_size)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:304: passes.convert.add_scf_to_cf(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:305: passes.convert.add_index_to_llvmir(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:307: passes.ttgpuir.add_allocate_shared_memory(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:316: amd.passes.ttgpuir.add_to_llvmir(pm, options.arch, __HIP_FTZ)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:317: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:318: passes.common.add_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:320: passes.convert.add_cf_to_llvmir(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:321: passes.convert.add_arith_to_llvmir(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:322: passes.common.add_canonicalizer(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:323: passes.common.add_cse(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:324: passes.common.add_symbol_dce(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:326: amd.passes.ttgpuir.lower_instruction_sched_hints(pm, options.arch, options.num_stages)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:328: passes.llvmir.add_di_scope(pm)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:329: amd.passes.ttgpuir.add_builtin_func_to_llvmir(pm, __HIP_FTZ)
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:390: amd.add_scalarize_packed_fops_llvm_pass(fns[0])
- .venv/lib/python3.12/site-packages/triton/backends/amd/compiler.py:412: # into loops to avoid register spills in the MachineSinking pass, while it
- .venv/lib/python3.12/site-packages/triton/backends/amd/driver.py:206: # Currently the host side tensor descriptors get passed in as a
- .venv/lib/python3.12/site-packages/triton/backends/amd/driver.py:210: # we have to pass the shape and strides twice.
- .venv/lib/python3.12/site-packages/triton/backends/amd/driver.py:574: # above. Sadly this means we have to pass the shape and strides
- .venv/lib/python3.12/site-packages/triton/compiler/errors.py:47: pass
- .venv/lib/python3.12/site-packages/triton/compiler/errors.py:51: pass
- .venv/lib/python3.12/site-packages/triton/compiler/compiler.py:41: # TODO: Capture and support shared memory space
- .venv/lib/python3.12/site-packages/triton/compiler/compiler.py:102: # TODO - replace with a proper parser
- .venv/lib/python3.12/site-packages/triton/compiler/compiler.py:325: # when the source is an IR file, don't apply the passes related to this stage. This makes it easier to write IR level te
- .venv/lib/python3.12/site-packages/triton/compiler/compiler.py:391: # However disabling multithreading causes the code to hang if the ASAN pass is enabled
- .venv/lib/python3.12/site-packages/triton/compiler/compiler.py:393: # TODO: Reconcile the difference here between the ASAN and non-ASAN path with enabling
- .venv/lib/python3.12/site-packages/triton/compiler/compiler.py:489: # TODO: n_regs, n_spills should be metadata generated when calling `ptxas`
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:198: # TODO: optimize the following case in which we actually don't have
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:323: # TODO: we currently generate illegal names for non-kernel functions involving constexprs!
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:634: # TODO: raise something meaningful if getattr fails below, esp for reverse method
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:704: # TODO: could probably be cleaned up
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:758: # TODO: refactor
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:828: # TODO: Deal w/ more complicated return types (e.g tuple)
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:878: pass
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:1447: passed = _unwrap_if_constexpr(self.visit(node.args[0]))
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:1448: if not isinstance(passed, bool):
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:1449: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/triton/compiler/code_generator.py:1452: if not passed:
- .venv/lib/python3.12/site-packages/triton/profiler/profile.py:210: pass
- .venv/lib/python3.12/site-packages/triton/profiler/proton.py:35: def execute_as_main(script, args, instrumentation_pass=None):
- .venv/lib/python3.12/site-packages/triton/profiler/proton.py:51: if instrumentation_pass == "print-mem-spaces":
- .venv/lib/python3.12/site-packages/triton/profiler/proton.py:52: instrumentation_pass_path = str(
- .venv/lib/python3.12/site-packages/triton/profiler/proton.py:56: os.environ['LLVM_PASS_PLUGIN_PATH'] = instrumentation_pass_path
- .venv/lib/python3.12/site-packages/triton/profiler/proton.py:69: def do_setup_and_execute(target_args, instrumentation_pass=None):
- .venv/lib/python3.12/site-packages/triton/profiler/proton.py:79: execute_as_main(script, script_args, instrumentation_pass)
- .venv/lib/python3.12/site-packages/triton/profiler/specs.py:6: lambda width, **kwargs: (330.3 * 1e12) / (width / 8),  # TODO(Keren): Implement fp16 acc-> 660.6 fp8
- .venv/lib/python3.12/site-packages/triton/profiler/viewer.py:269: # TODO: generalize to support multiple metrics, not just the first one
- .venv/lib/python3.12/site-packages/triton/profiler/viewer.py:325: """Find frames that match the given regular expression and return all nodes in the paths that pass through the matching 
- .venv/lib/python3.12/site-packages/safetensors/torch.py:19: except NotImplementedError:
- .venv/lib/python3.12/site-packages/safetensors/torch.py:39: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_streambase.py:12: pass
- .venv/lib/python3.12/site-packages/torch/_streambase.py:20: pass
- .venv/lib/python3.12/site-packages/torch/library.py:70: A dummy function to pass to ``Library.impl`` in order to register a fallthrough.
- .venv/lib/python3.12/site-packages/torch/library.py:72: raise NotImplementedError("fallthrough_kernel() should never be called.")
- .venv/lib/python3.12/site-packages/torch/library.py:79: A user can optionally pass in a dispatch keyname if they only want to register
- .venv/lib/python3.12/site-packages/torch/library.py:84: To create a fragment of a possibly existing library to register operators (and bypass
- .venv/lib/python3.12/site-packages/torch/library.py:205: # TODO(rzou): We're gonna need to stage this change with torchvision,
- .venv/lib/python3.12/site-packages/torch/library.py:279: "_impl_with_aoti_compile should be passed either a name or an OpOverload object "
- .venv/lib/python3.12/site-packages/torch/library.py:285: # TODO: in future, add more info about where the existing function is registered (this info is
- .venv/lib/python3.12/site-packages/torch/library.py:312: with_keyset: flag controlling if the current dispatcher call keyset should be passed as the first argument
- .venv/lib/python3.12/site-packages/torch/library.py:347: "impl should be passed either a name or an OpOverload object as the first argument"
- .venv/lib/python3.12/site-packages/torch/library.py:352: # TODO: in future, add more info about where the existing function is registered (this info is
- .venv/lib/python3.12/site-packages/torch/library.py:401: with_keyset: flag controlling if the current dispatcher call keyset should be passed as the first argument
- .venv/lib/python3.12/site-packages/torch/library.py:523: not contain the operator name (that is passed in ``qualname``).
- .venv/lib/python3.12/site-packages/torch/library.py:620: You may pass "default" for ``types`` to register this implementation as the
- .venv/lib/python3.12/site-packages/torch/library.py:730: # We also support passing a DispatchKey to impl. Please prefer using
- .venv/lib/python3.12/site-packages/torch/library.py:731: # the higher-level torch.library APIs and only pass DispatchKey to
- .venv/lib/python3.12/site-packages/torch/library.py:997: >>>     raise NotImplementedError("Implementation goes here")
- .venv/lib/python3.12/site-packages/torch/library.py:1093: 1. You must tell us how to compute gradients during the backward pass
- .venv/lib/python3.12/site-packages/torch/library.py:1098: ``backward`` runs during the backward pass. It accepts ``(ctx, *grads)``:
- .venv/lib/python3.12/site-packages/torch/library.py:1105: ``setup_context(ctx, inputs, output)`` runs during the forward pass.
- .venv/lib/python3.12/site-packages/torch/library.py:1196: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/library.py:1320: ``info.randomness`` is the ``randomness`` option that was passed to :func:`torch.vmap`.
- .venv/lib/python3.12/site-packages/torch/library.py:1373: If your custom operator has any custom behavior in the backward pass, please
- .venv/lib/python3.12/site-packages/torch/library.py:1391: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/library.py:1508: and these APIs require that the functions you pass them satisfy certain
- .venv/lib/python3.12/site-packages/torch/library.py:1540: functionalization and that the backward pass (if it exists) also
- .venv/lib/python3.12/site-packages/torch/library.py:1559: on if each test passed or not.
- .venv/lib/python3.12/site-packages/torch/_ops.py:81: # TODO: The cache is NOT currently used by HigherOrderOperator, but it should!
- .venv/lib/python3.12/site-packages/torch/_ops.py:111: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_ops.py:136: # TODO(voz): Should we replace setting DispatchKey.Python entirely with setting mode keys?
- .venv/lib/python3.12/site-packages/torch/_ops.py:204: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_ops.py:258: raise NotImplementedError(f"could not find kernel for {op} at dispatch key {k}")
- .venv/lib/python3.12/site-packages/torch/_ops.py:415: # TODO(rzou): we should support torch_dispatch calling convention too.
- .venv/lib/python3.12/site-packages/torch/_ops.py:418: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_ops.py:448: # TODO(rzou): we should support torch_dispatch calling convention too.
- .venv/lib/python3.12/site-packages/torch/_ops.py:451: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_ops.py:493: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_ops.py:539: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_ops.py:903: # TODO: We also need to handle tensor subclasses here
- .venv/lib/python3.12/site-packages/torch/_ops.py:904: # TODO(voz): We should walk all the nodes here / turn it into a list, topmode is ok for now.
- .venv/lib/python3.12/site-packages/torch/_ops.py:966: # TODO: We could potentially have lots of debugging wrappers against
- .venv/lib/python3.12/site-packages/torch/_ops.py:1000: # TODO: add more methods to expose information about input and output arguments
- .venv/lib/python3.12/site-packages/torch/_ops.py:1009: # TODO: we should be calling the fallback for these, but a fallthrough is almost close
- .venv/lib/python3.12/site-packages/torch/_ops.py:1202: # TODO: disallow access to overloads registered by JIT
- .venv/lib/python3.12/site-packages/torch/_ops.py:1245: # TODO: use this to make a __dir__
- .venv/lib/python3.12/site-packages/torch/_utils.py:112: **kwargs (dict): the kwargs passed to the function.
- .venv/lib/python3.12/site-packages/torch/_utils.py:180: # OrderedDict(), if you pass a None you'll run afoul #12219.
- .venv/lib/python3.12/site-packages/torch/_utils.py:183: # TODO: Once we decide to break serialization FC, `storage` no longer needs to
- .venv/lib/python3.12/site-packages/torch/_utils.py:303: # TODO: Validation currently involves an expensive traversal
- .venv/lib/python3.12/site-packages/torch/_utils.py:324: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_utils.py:371: raise NotImplementedError(f"rebuilding sparse tensor for layout {layout}")
- .venv/lib/python3.12/site-packages/torch/_utils.py:425: # TODO: Once we decide to break serialization FC, `storage` no longer needs to
- .venv/lib/python3.12/site-packages/torch/_storage_docs.py:17: pass
- .venv/lib/python3.12/site-packages/torch/_storage_docs.py:38: shared (bool): whether to share memory (whether ``MAP_SHARED`` or ``MAP_PRIVATE`` is passed to the
- .venv/lib/python3.12/site-packages/torch/functional.py:106: # TODO Move this to C++ once the jit has better support for torch.Size.
- .venv/lib/python3.12/site-packages/torch/functional.py:286: To bypass this default behavior, add the following to disable opt_einsum and skip path calculation:
- .venv/lib/python3.12/site-packages/torch/functional.py:413: # the old interface of passing the operands as one list argument
- .venv/lib/python3.12/site-packages/torch/functional.py:546: # the old interface of passing the operands as one list argument
- .venv/lib/python3.12/site-packages/torch/functional.py:1243: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1255: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1264: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1273: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1282: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1640: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1652: # TODO: type dim as BroadcastingList when
- .venv/lib/python3.12/site-packages/torch/functional.py:1664: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1676: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1688: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1700: pass
- .venv/lib/python3.12/site-packages/torch/functional.py:1872: # TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed
- .venv/lib/python3.12/site-packages/torch/_tensor.py:146: # TODO: skipping storage copy is wrong for meta, as meta
- .venv/lib/python3.12/site-packages/torch/_tensor.py:199: # TODO: Once we decide to break serialization FC, no longer
- .venv/lib/python3.12/site-packages/torch/_tensor.py:272: # TODO: remove hasattr, it's a hack to support versions of torch that
- .venv/lib/python3.12/site-packages/torch/_tensor.py:414: # TODO: Once we decide to break serialization FC, no longer
- .venv/lib/python3.12/site-packages/torch/_tensor.py:437: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_tensor.py:474: # Ideally, we'd use a private API for this instead. TODO: Switch to this if
- .venv/lib/python3.12/site-packages/torch/_tensor.py:529: # TODO: Once we decide to break serialization FC, no longer
- .venv/lib/python3.12/site-packages/torch/_tensor.py:538: # TODO: remove hasattr, it's a hack to support versions of torch that
- .venv/lib/python3.12/site-packages/torch/_tensor.py:612: :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.
- .venv/lib/python3.12/site-packages/torch/_tensor.py:723: this hook runs during the backward pass, it will run in no_grad mode (unless
- .venv/lib/python3.12/site-packages/torch/_tensor.py:859: assign (bool): the assign argument passed to :meth:`nn.Module.load_state_dict`
- .venv/lib/python3.12/site-packages/torch/_tensor.py:1047: pass
- .venv/lib/python3.12/site-packages/torch/_tensor.py:1258: f"Tensor.__contains__ only supports Tensor or scalar, but you passed in a {type(element)}."
- .venv/lib/python3.12/site-packages/torch/_tensor.py:1269: # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
- .venv/lib/python3.12/site-packages/torch/_tensor.py:1683: of the library that will consume the capsule. `from_dlpack` passes the current
- .venv/lib/python3.12/site-packages/torch/_tensor.py:1691: both streams.  If None or -1 is passed then no synchronization is performed.
- .venv/lib/python3.12/site-packages/torch/overrides.py:1564: A callable that returns an iterable of Tensor-likes passed into the function.
- .venv/lib/python3.12/site-packages/torch/overrides.py:1694: Arbitrary positional arguments originally passed into ``public_api``.
- .venv/lib/python3.12/site-packages/torch/overrides.py:1696: Arbitrary keyword arguments originally passed into ``public_api``.
- .venv/lib/python3.12/site-packages/torch/overrides.py:1913: """Get a human readable string name for a function passed to
- .venv/lib/python3.12/site-packages/torch/overrides.py:1943: Returns True if the function passed in is a handler for a
- .venv/lib/python3.12/site-packages/torch/overrides.py:1944: method or property belonging to ``torch.Tensor``, as passed
- .venv/lib/python3.12/site-packages/torch/overrides.py:1948: For properties, their ``__get__`` method must be passed in.
- .venv/lib/python3.12/site-packages/torch/overrides.py:1953: 2. They require that the first passed-in argument is an instance
- .venv/lib/python3.12/site-packages/torch/overrides.py:1968: Returns ``True`` if the passed-in input is a Tensor-like.
- .venv/lib/python3.12/site-packages/torch/overrides.py:2038: pass
- .venv/lib/python3.12/site-packages/torch/overrides.py:2041: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/overrides.py:2117: pass
- .venv/lib/python3.12/site-packages/torch/types.py:85: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:88: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:97: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:100: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:103: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:106: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:109: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:112: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:115: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:123: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/types.py:130: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_vmap_internals.py:122: allow_none_pass_through: bool = False,
- .venv/lib/python3.12/site-packages/torch/_vmap_internals.py:138: if allow_none_pass_through:
- .venv/lib/python3.12/site-packages/torch/_vmap_internals.py:217: allow_none_pass_through: bool = False,
- .venv/lib/python3.12/site-packages/torch/_vmap_internals.py:219: # The `allow_none_pass_through` argument is a temporary workaround may be removed.
- .venv/lib/python3.12/site-packages/torch/_vmap_internals.py:232: if not allow_none_pass_through:
- .venv/lib/python3.12/site-packages/torch/_vmap_internals.py:240: allow_none_pass_through=allow_none_pass_through,
- .venv/lib/python3.12/site-packages/torch/_appdirs.py:83: pass False to disable it.
- .venv/lib/python3.12/site-packages/torch/_appdirs.py:138: pass False to disable it.
- .venv/lib/python3.12/site-packages/torch/_appdirs.py:207: pass False to disable it.
- .venv/lib/python3.12/site-packages/torch/_appdirs.py:251: pass False to disable it.
- .venv/lib/python3.12/site-packages/torch/_appdirs.py:308: pass False to disable it.
- .venv/lib/python3.12/site-packages/torch/_appdirs.py:365: pass False to disable it.
- .venv/lib/python3.12/site-packages/torch/_appdirs.py:407: pass False to disable it.
- .venv/lib/python3.12/site-packages/torch/_appdirs.py:544: pass
- .venv/lib/python3.12/site-packages/torch/_appdirs.py:546: pass
- .venv/lib/python3.12/site-packages/torch/_lobpcg.py:983: # TODO use torch.linalg.cholesky_solve once it is implemented
- .venv/lib/python3.12/site-packages/torch/random.py:191: # Protect against user passing us a generator; we need to traverse this
- .venv/lib/python3.12/site-packages/torch/storage.py:54: pass
- .venv/lib/python3.12/site-packages/torch/storage.py:57: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:60: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:63: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:66: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:69: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:72: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:115: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:121: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:124: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:128: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:131: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:135: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:139: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:143: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:155: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:163: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:167: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:170: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:173: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:176: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:179: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:182: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:185: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:188: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:191: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:195: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:198: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:202: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:206: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:210: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:214: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:218: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:221: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:224: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/storage.py:398: pass  # CUDA or PrivateUse1 doesn't use POSIX shared memory
- .venv/lib/python3.12/site-packages/torch/storage.py:448: pass
- .venv/lib/python3.12/site-packages/torch/storage.py:469: raise NotImplementedError("Not available for 'meta' device type")
- .venv/lib/python3.12/site-packages/torch/storage.py:512: `open(2) <https://man7.org/linux/man-pages/man2/open.2.html>`_ to open the filename passed by the user.
- .venv/lib/python3.12/site-packages/torch/storage.py:979: raise NotImplementedError("Not available for 'meta' device type")
- .venv/lib/python3.12/site-packages/torch/storage.py:1418: shared (bool): whether to share memory (whether ``MAP_SHARED`` or ``MAP_PRIVATE`` is passed to the
- .venv/lib/python3.12/site-packages/torch/_deploy.py:25: # TODO: Once we decide to break serialization FC, we can
- .venv/lib/python3.12/site-packages/torch/_deploy.py:67: # TODO: Once we decide to break serialization FC, we can
- .venv/lib/python3.12/site-packages/torch/_meta_registrations.py:144: lambda: f"linspace(): inferred dtype {default_complex_dtype} can't be safely cast to passed dtype {dtype}",
- .venv/lib/python3.12/site-packages/torch/_meta_registrations.py:667: # TODO: Ideally, we'd insert a deferred runtime assert here, but if we are
- .venv/lib/python3.12/site-packages/torch/_meta_registrations.py:893: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_meta_registrations.py:4508: # TODO: handle out
- .venv/lib/python3.12/site-packages/torch/_meta_registrations.py:5573: # TODO: Deduplicate this with canonicalize_dim
- .venv/lib/python3.12/site-packages/torch/_meta_registrations.py:6849: # TODO: Query cudnnGetRNNTrainingReserveSize (expose to python)
- .venv/lib/python3.12/site-packages/torch/_meta_registrations.py:7987: pass
- .venv/lib/python3.12/site-packages/torch/_meta_registrations.py:8000: pass
- .venv/lib/python3.12/site-packages/torch/_custom_ops.py:63: >>> # (a function that returns NotImplementedError), from which
- .venv/lib/python3.12/site-packages/torch/_custom_ops.py:67: >>>     raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_custom_ops.py:106: f"is passed to `custom_op`"
- .venv/lib/python3.12/site-packages/torch/_custom_ops.py:124: If the op is passed multiple Tensor inputs with different device
- .venv/lib/python3.12/site-packages/torch/_custom_ops.py:146: >>> # (a function that returns NotImplementedError), from which
- .venv/lib/python3.12/site-packages/torch/_custom_ops.py:150: >>>     raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_custom_ops.py:214: >>>     raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_custom_ops.py:291: During runtime, when you call the operator in a forwards pass, PyTorch
- .venv/lib/python3.12/site-packages/torch/__init__.py:63: # TODO(torch_deploy) figure out how to freeze version.py in fbcode build
- .venv/lib/python3.12/site-packages/torch/__init__.py:66: # TODO: Remove this ugly hack when deploy typing extensions are updated to 4.10+
- .venv/lib/python3.12/site-packages/torch/__init__.py:167: pass
- .venv/lib/python3.12/site-packages/torch/__init__.py:338: pass
- .venv/lib/python3.12/site-packages/torch/__init__.py:360: # TODO: Remove once CUDA 11.8 binaries are deprecated
- .venv/lib/python3.12/site-packages/torch/__init__.py:595: # TODO: Force specialization
- .venv/lib/python3.12/site-packages/torch/__init__.py:606: # TODO: A more relaxed guard is possible here, where you guard to
- .venv/lib/python3.12/site-packages/torch/__init__.py:865: # TODO: Probably can make bool work too, just lazy
- .venv/lib/python3.12/site-packages/torch/__init__.py:1032: # TODO: fix their module from C++ side
- .venv/lib/python3.12/site-packages/torch/__init__.py:1151: # TODO: Call like get_device_index() method corresponding to
- .venv/lib/python3.12/site-packages/torch/__init__.py:1178: were passed ``device`` as an argument.
- .venv/lib/python3.12/site-packages/torch/__init__.py:1776: Error type: ``NotImplementedError``
- .venv/lib/python3.12/site-packages/torch/__init__.py:1787: _check_with(NotImplementedError, cond, message)
- .venv/lib/python3.12/site-packages/torch/__init__.py:2118: # TODO: Once the undocumented FC window is passed, remove the line below
- .venv/lib/python3.12/site-packages/torch/__init__.py:2410: # only pass the args if they non-empty
- .venv/lib/python3.12/site-packages/torch/__init__.py:2540: options (dict): A dictionary of options to pass to the backend. Some notable ones to try out are
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:1255: the size of the datatype passed to the :attr:`dtype` keyword argument. (If no datatype is
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:1256: passed then the default floating point datatype is used, instead.) The returned tensor
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:3652: .. note::  To take a batch diagonal, pass in dim1=-2, dim2=-1.
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:4410: This function's behavior is undefined when passed an object implementing
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:4474: shared (bool): whether to share memory (whether ``MAP_SHARED`` or ``MAP_PRIVATE`` is passed to the
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:4498: are passed, only dimensions starting with :attr:`start_dim` and ending with :attr:`end_dim` are flattened.
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:5101: of bin edges. Bin edges may be specified explicitly by passing a sequence of 1D
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:5102: tensors. Alternatively, bin edges may be constructed automatically by passing a
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:5145: tensor is passed, each N-dimensional coordinate in input
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:5177: # TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:10846: and `V[..., :, min(m, n):]` will be ignored in the backward pass, as those vectors
- .venv/lib/python3.12/site-packages/torch/_torch_docs.py:13814: (one pass the last index of the *innermost* dimension). In other words, if False,
- .venv/lib/python3.12/site-packages/torch/_guards.py:70: # TODO: mark as kw_only=True once we drop support for <Python 3.10
- .venv/lib/python3.12/site-packages/torch/_guards.py:83: # TODO: consider also tracking the recompilation count
- .venv/lib/python3.12/site-packages/torch/_guards.py:213: pass
- .venv/lib/python3.12/site-packages/torch/_guards.py:417: pass
- .venv/lib/python3.12/site-packages/torch/_guards.py:639: directly outside of it. For passing around internal state representations of this object,
- .venv/lib/python3.12/site-packages/torch/_guards.py:653: # NB: "steals" the passed in state
- .venv/lib/python3.12/site-packages/torch/_guards.py:768: CompileContext is a more overarching context that encompasses multiple restarts.
- .venv/lib/python3.12/site-packages/torch/_guards.py:1010: This function installs the passed in tracing context as a dynamic scoped
- .venv/lib/python3.12/site-packages/torch/_guards.py:1035: # TODO(voz): Consider a toplevel torch/_source.py
- .venv/lib/python3.12/site-packages/torch/_guards.py:1045: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_guards.py:1048: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_guards.py:1051: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_guards.py:1055: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_guards.py:1093: - Fake mode associated with passed in tensors (inputs does not
- .venv/lib/python3.12/site-packages/torch/_tensor_str.py:100: can be passed as ``**kwargs`` to set_printoptions().
- .venv/lib/python3.12/site-packages/torch/_tensor_str.py:150: # TODO(#146647): extend this to other dtypes without casts defined, such
- .venv/lib/python3.12/site-packages/torch/_tensor_str.py:167: # TODO(#113663): also add the other float8 dtypes here after arithmetic
- .venv/lib/python3.12/site-packages/torch/_tensor_str.py:273: # TODO(#146647): extend this to other dtypes without casts defined, such
- .venv/lib/python3.12/site-packages/torch/_tensor_str.py:357: # TODO: Remove me when `masked_select` is implemented for FP8
- .venv/lib/python3.12/site-packages/torch/_tensor_str.py:438: # TODO(albanD) This needs to be updated when more than one level is supported
- .venv/lib/python3.12/site-packages/torch/_tensor_str.py:464: # TODO: add an API to map real -> complex dtypes
- .venv/lib/python3.12/site-packages/torch/_tensor_str.py:620: # TODO: This implies that ellipses is valid syntax for allocating
- .venv/lib/python3.12/site-packages/torch/_tensor_docs.py:59: When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,
- .venv/lib/python3.12/site-packages/torch/_tensor_docs.py:2609: is not coalesced. It is therefore advisable to pass ``mask.coalesce()``
- .venv/lib/python3.12/site-packages/torch/_tensor_docs.py:4415: The backward pass is implemented only for ``src.shape == index.shape``.
- .venv/lib/python3.12/site-packages/torch/_tensor_docs.py:4534: The backward pass is implemented only for ``src.shape == index.shape``.
- .venv/lib/python3.12/site-packages/torch/_tensor_docs.py:4592: The backward pass is implemented only for ``src.shape == index.shape``.
- .venv/lib/python3.12/site-packages/torch/_tensor_docs.py:5044: argument is passed in. Otherwise, an integer value is returned as the stride in
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:779: pass
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:782: pass
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:969: pass
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:973: pass
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:1008: def is_pass(x):
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:1018: if len(body) != 1 or not (is_pass(body[0]) or is_ellipsis(body[0])):
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:1020: "Only `pass` statement or `...` can be the body of overload declaration:\n"
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:1023: msg += " <- Expecting `pass` or `...` here!\n" + _OVERLOAD_EXAMPLE
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:1108: # TODO: __name__ not set for submodules in recursive script
- .venv/lib/python3.12/site-packages/torch/_jit_internal.py:1401: # TODO support future
- .venv/lib/python3.12/site-packages/torch/hub.py:45: pass
- .venv/lib/python3.12/site-packages/torch/hub.py:276: "You can disambiguate tags and branches by explicitly passing refs/heads/branch_name or "
- .venv/lib/python3.12/site-packages/torch/hub.py:327: # TODO: Remove `None` option in 2.0 and change the default to "check"
- .venv/lib/python3.12/site-packages/torch/_weights_only_unpickler.py:509: strval = str(read(strlen), "utf-8", "surrogatepass")
- .venv/lib/python3.12/site-packages/torch/serialization.py:110: pass
- .venv/lib/python3.12/site-packages/torch/serialization.py:259: pass
- .venv/lib/python3.12/site-packages/torch/serialization.py:302: ...     pass
- .venv/lib/python3.12/site-packages/torch/serialization.py:327: ...     pass
- .venv/lib/python3.12/site-packages/torch/serialization.py:389: will be empty space. The storage bytes can then be populated in a separate pass.
- .venv/lib/python3.12/site-packages/torch/serialization.py:735: pass
- .venv/lib/python3.12/site-packages/torch/serialization.py:947: to use the old format, pass the kwarg ``_use_new_zipfile_serialization=False``.
- .venv/lib/python3.12/site-packages/torch/serialization.py:994: # TODO: This feature could be added in the future
- .venv/lib/python3.12/site-packages/torch/serialization.py:1025: # TODO: Once we decide to break serialization FC, this case
- .venv/lib/python3.12/site-packages/torch/serialization.py:1064: # TODO: There's an issue here with FC. It might be impossible to
- .venv/lib/python3.12/site-packages/torch/serialization.py:1156: # TODO: This feature could be added in the future
- .venv/lib/python3.12/site-packages/torch/serialization.py:1167: # TODO: Once we decide to break serialization FC, this case
- .venv/lib/python3.12/site-packages/torch/serialization.py:1301: argument passed to :attr:`map_location`. The builtin location tags are ``'cpu'``
- .venv/lib/python3.12/site-packages/torch/serialization.py:1337: pickle_load_args: (Python 3 only) optional keyword arguments passed over to
- .venv/lib/python3.12/site-packages/torch/serialization.py:1458: "`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.",
- .venv/lib/python3.12/site-packages/torch/serialization.py:1501: "Cannot use ``weights_only=True`` with TorchScript archives passed to "
- .venv/lib/python3.12/site-packages/torch/serialization.py:1587: pass
- .venv/lib/python3.12/site-packages/torch/serialization.py:1674: # TODO: Once we decide to break serialization FC, we can
- .venv/lib/python3.12/site-packages/torch/serialization.py:1685: # TODO: Once we decide to break serialization FC, we can
- .venv/lib/python3.12/site-packages/torch/serialization.py:1748: # TODO: Once we decide to break serialization FC, we can
- .venv/lib/python3.12/site-packages/torch/serialization.py:1768: # TODO: Once we decide to break serialization FC, we can
- .venv/lib/python3.12/site-packages/torch/serialization.py:1921: pass
- .venv/lib/python3.12/site-packages/torch/serialization.py:2045: # TODO: Once we decide to break serialization FC, we can
- .venv/lib/python3.12/site-packages/torch/serialization.py:2106: pass
- .venv/lib/python3.12/site-packages/torch/__config__.py:12: # TODO: In principle, we could provide more structured version/config
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:62: pass
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:71: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:75: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:130: pass
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:134: pass
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:138: pass
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:142: pass
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:145: def log_cache_bypass(*args, **kwargs) -> None:
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:146: pass
- .venv/lib/python3.12/site-packages/torch/_utils_internal.py:239: return 1700  # TODO: placeholder, get actual value
- .venv/lib/python3.12/site-packages/torch/fx/traceback.py:50: pass_name: str
- .venv/lib/python3.12/site-packages/torch/fx/traceback.py:58: pass_name: str = "",
- .venv/lib/python3.12/site-packages/torch/fx/traceback.py:61: self.pass_name = pass_name
- .venv/lib/python3.12/site-packages/torch/fx/traceback.py:108: + f"(name={self.name}, pass_name={self.pass_name}, action={action_string}, graph_id={self.graph_id})\n"
- .venv/lib/python3.12/site-packages/torch/fx/traceback.py:121: "pass_name": self.pass_name,
- .venv/lib/python3.12/site-packages/torch/fx/traceback.py:199: def set_current_meta(node, pass_name=""):
- .venv/lib/python3.12/site-packages/torch/fx/traceback.py:211: NodeSource(node, pass_name, NodeSourceAction.CREATE)
- .venv/lib/python3.12/site-packages/torch/fx/node.py:86: # TODO: Either refactor this into 2 functions 1 dce for functional graphs and 1 dce for all graphs,
- .venv/lib/python3.12/site-packages/torch/fx/node.py:266: # Dictionary to store metadata passes need to do their
- .venv/lib/python3.12/site-packages/torch/fx/node.py:298: args (Tuple['Argument']): The args to be passed to ``target``
- .venv/lib/python3.12/site-packages/torch/fx/node.py:300: kwargs (Dict[str, 'Argument']): The kwargs to be passed to ``target``
- .venv/lib/python3.12/site-packages/torch/fx/node.py:587: # TODO: THIS IS BROKEN: _get_qualified_name calls `__name__`
- .venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:48: pass
- .venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:53: pass
- .venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:105: # TODO: Figure out if this is safe. It seems like when generating the type signatures for
- .venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:193: pass
- .venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:201: pass
- .venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:422: pass
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:249: pass
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:389: # Wrap string in list to pass by reference
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:593: from torch.fx.passes.shape_prop import TensorMetadata
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:704: raise NotImplementedError(f"node: {node.op} {node.target}")
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:721: # single pass statement
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:722: body.append("pass\n")
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1027: from nodes in ``g`` to nodes in ``self``. Note that ``val_map`` can be passed
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1131: Processes args so that they can be passed to the FX graph.
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1250: should be passed as this argument to specify that the parameter does _not_
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1271: name ``foo.bar.baz`` should be passed as ``qualified_name``.
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1346: qualified name ``foo.bar`` should be passed as ``module_name`` to
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1349: args (Optional[Tuple[Argument, ...]]): The positional arguments to be passed
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1352: kwargs (Optional[Dict[str, Argument]]): The keyword arguments to be passed
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1394: then to call ``relu()`` on that ``Tensor``, pass ``relu`` to ``method_name``.
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1396: args (Optional[Tuple[Argument, ...]]): The positional arguments to be passed
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1399: kwargs (Optional[Dict[str, Argument]]): The keyword arguments to be passed
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1436: args (Optional[Tuple[Argument, ...]]): The positional arguments to be passed
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1439: kwargs (Optional[Dict[str, Argument]]): The keyword arguments to be passed
- .venv/lib/python3.12/site-packages/torch/fx/graph.py:1759: bool: Whether the graph was changed as a result of the pass.
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:116: "quantization_tag",  # TODO deprecated
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:117: "_numeric_debug_handle",  # TODO deprecated
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:170: # TODO node_name_to_scope will be depreciated in favor of
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:194: # is created. During the FWD pass we store the sequence_nr
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:198: # BWD pass we retrieve the sequence_nr stored on the current
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:321: # 1) When you add a new type, all of the downstream consumers and pass writers
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:323: # passes for, so we will push back against new types.
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:328: handler = _create_arg_bypass.get(type(a))
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:379: raise NotImplementedError(f"argument of type: {type(a)}")
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:437: pass
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:620: # TODO: Define how to symbolically trace HigherOrderOperators
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:699: attribute accesses pass through to the underlying  module parameter object,
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:784: _create_arg_bypass = {
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:794: _create_arg_bypass[Proxy] = lambda self, a: a.node
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:795: _create_arg_bypass[tuple] = lambda self, a: tuple([self.create_arg(elem) for elem in a])
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:796: _create_arg_bypass[list] = lambda self, a: [self.create_arg(elem) for elem in a]
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:797: _create_arg_bypass[dict] = _create_arg_dict
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:798: _create_arg_bypass[immutable_list] = _create_arg_bypass[list]
- .venv/lib/python3.12/site-packages/torch/fx/proxy.py:799: _create_arg_bypass[immutable_dict] = _create_arg_bypass[dict]
- .venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py:74: examples regarding pattern matching fx passes in inductor:
- .venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py:75: 1. some passes will update the graph to be compiled and then call recompile on the GraphModule.
- .venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py:76: 2. some passes will trace small pattern function to search it in the graph being compiled and
- .venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py:130: # TODO: we shold handle __reduce_deploy__ the same way as __reduce_package__,
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:31: # TODO: This list is pretty pessimistic right now. What's the full list?
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:43: # BypassFxGraphCache exception. If None then all ops are allowed.
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:57: # This abomination is so we can pass external decoding state to the
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:73: # to pass to unpickle).
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:83: #      FakeTensorMode) which is passed to each value it's harder to
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:144: # This token is passed when pickling to indicate that we want to use the
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:206: raise NotImplementedError(f"Unhandled SymNode type {type(obj)}")
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:261: # TODO: make common w/ _output_from_cache_entry() in fake_tensor.py?
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:425: # TODO: raise a BypassFxGraphCache so we will just bypass this one...
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:426: raise NotImplementedError(f"TARGET: {type(op)} {op} {name}")
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:437: from torch._inductor.codecache import BypassFxGraphCache
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:439: raise BypassFxGraphCache(f"Unable to pickle non-standard op: {name}")
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:444: pass
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:512: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/fx/_graph_pickler.py:574: # TODO: Do we really need all of this?
- .venv/lib/python3.12/site-packages/torch/fx/interpreter.py:32: transformations as well as analysis passes.
- .venv/lib/python3.12/site-packages/torch/fx/interpreter.py:83: graph (Optional[Graph]): If passed, the interpreter will execute this
- .venv/lib/python3.12/site-packages/torch/fx/interpreter.py:206: calling convention, where you pass a list of arguments, which will be cleared
- .venv/lib/python3.12/site-packages/torch/fx/interpreter.py:252: arguments passed to ``run`` and this method returns
- .venv/lib/python3.12/site-packages/torch/fx/interpreter.py:278: f"Expected positional argument for parameter {target}, but one was not passed in!"
- .venv/lib/python3.12/site-packages/torch/fx/graph_module.py:107: # avoid mutating the passed in dict
- .venv/lib/python3.12/site-packages/torch/fx/graph_module.py:193: # passing base class as an argument - https://github.com/python/mypy/issues/5865.
- .venv/lib/python3.12/site-packages/torch/fx/graph_module.py:457: pass
- .venv/lib/python3.12/site-packages/torch/fx/graph_module.py:533: raise RuntimeError("Unsupported type " + str(root) + " passed for root!")
- .venv/lib/python3.12/site-packages/torch/fx/graph_module.py:799: pass
- .venv/lib/python3.12/site-packages/torch/fx/graph_module.py:841: # bypass patching of torch.nn.Module.__call__ done while symbolic tracing.
- .venv/lib/python3.12/site-packages/torch/fx/config.py:1: # Whether to disable showing progress on compilation passes
- .venv/lib/python3.12/site-packages/torch/fx/config.py:5: # If True this also shows the node names in each pass, for small models this is great but larger models it's quite noisy
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:432: # TODO: binary search
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:471: a submodule named ``bar``, passing ``bar`` into this function will return
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:645: # This covers the very specific case where we are passing in flat
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:647: # In this case, just take the concrete_args and pass them through.
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:685: # TODO: type annotations for *args and **kwargs
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:724: Note that after this call, ``self.root`` may be different from the ``root`` passed
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:725: in here. For example, when a free function is passed to ``trace()``, we will
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:741: A ``Graph`` representing the semantics of the passed-in ``root``.
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:1030: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:1033: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:1261: raise NotImplementedError("wrap must be called at the top level of a module")
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:1297: Note that although you can still pass in different values of `b`, they will be ignored.
- .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:1301: overspecializing, pass in `fx.PH` for values that shouldn't be
- .venv/lib/python3.12/site-packages/torch/fx/subgraph_rewriter.py:15: from .passes.utils.matcher_with_name_node_map_utils import InternalMatch
- .venv/lib/python3.12/site-packages/torch/fx/subgraph_rewriter.py:269: from torch.fx.passes.utils.matcher_utils import InternalMatch, SubgraphMatcher
- .venv/lib/python3.12/site-packages/torch/fx/subgraph_rewriter.py:419: # Update the passed-in GraphModule to reflect the new state of
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unify_refinements.py:7: def infer_symbolic_types_single_pass(traced):
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unify_refinements.py:20: This is useful when one pass is not enough
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:59: from torch.fx.passes.shape_prop import _extract_tensor_metadata
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:167: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:229: # AOTAutograd doesn't pass the "outer sizes" as an actual argument
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:231: # call to tensor unflatten.  Because the outer sizes isn't passed
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:401: # TODO: This doesn't properly track storages.  A more robust
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:672: # intentionally pass on primitives
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:673: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:779: # TODO: we could use types to test this
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:830: # TODO: maybe constant SymInts should also be allowed?  Not sure if
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1007: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1192: # TODO: inductor lowering for with_effects needs to be updated to propagate
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1286: from torch._inductor.fx_passes.dedupe_symint_uses import dedupe_symints
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1327: # TODO: Make downstream users of this work with OperatorBase
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1388: # It's for passing the export verifier which needs to verify the meta['val']
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1389: # TODO(tmanlaibaatar): we should systematically couple it with expoert verifier,
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1580: # TODO: I'm not sure what the point of this class is; you can just
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1606: # TODO handle case where the first character of target is '*'
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1671: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1677: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:2133: # TODO: We need to explicitly import torch._dynamo before calling dispatch_trace,
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:2147: # TODO: it would be nice to line these up with the names
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:2193: # TODO: Would be nice to fix this at the source...
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:2242: # TODO: kind of a bad way to do it, should maybe figure out a better way
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:2327: # TODO: this is a legacy name, there is only ever one proxy mode as it's an
- .venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:2364: # TODO: properly compute types
- .venv/lib/python3.12/site-packages/torch/fx/experimental/_dynamism.py:43: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/_dynamism.py:44: # Skip attributes that raise NotImplementedError since they won't
- .venv/lib/python3.12/site-packages/torch/fx/experimental/_dynamism.py:90: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:242: # TODO. We leave it like this till we add a type to represent tensor sizes
- .venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:705: raise NotImplementedError(f"Method {n.op} not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:946: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:953: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:964: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:972: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:979: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:990: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/meta_tracer.py:145: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/meta_tracer.py:228: # TODO
- .venv/lib/python3.12/site-packages/torch/fx/experimental/_config.py:34: # TODO: Perhaps consider allowing unions for the configs below (so you can hit
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:127: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:273: # TODO: There's a ref-cycle here (wrapped_f -> cumulative_cache_info
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:341: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:383: true if integer is passed in.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:402: true if integer is passed in.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:422: true if integer is passed in.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:485: # TODO: do boolean equality test too, see
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:495: # (TODO: should be a helper for this, maybe sym_eq?  That
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:518: post facto apply any renamings discovered in the PropogateUnbackedSymInts pass.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:578: #   subsequent passes cause torch.tensor to become a constant and
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:583: # constant-ification pass) ensure that the quantity is now truly
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:654: primarily only used in a DCE pass to figure out purity.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:893: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:904: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:907: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:938: # TODO: Apparently, returning an OrderedSet here breaks
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1141: # TODO: Determine if this is correct
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1226: # TODO: DivideByKey needs to test divisibility at runtime!
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1541: TODO: Make Dynamo handle this appropriately if this is seen in Dynamo-ed
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1546: TODO: I didn't support min/max because I didn't have a use case where this
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1576: and isinstance(upper_bound, int)  # TODO: relax
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1602: Applies a constraint that the passed in SymInt must lie between min-max
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1607: that doesn't have a lot of safety guarantees (TODO: provide higher level
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1696: # TODO: check perf implications of this
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1740: # for its associated ShapeEnv are satisfied by the passed arguments.  This
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1772: dynamic_shapes passed to export.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1791: # constraint C, the client must pass inputs that satisfy the constraint,
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1837: # TODO: better printing for -oo and oo
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2057: # TODO: add storage offset and stride symbolic_context
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2101: # In order to preserve the symbolic decisions made during dynamo tensor fakification, we pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2107: # TODO(voz): Shape env validation
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2132: # TODO(voz): consider a weakref to the shape_env here
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2378: # TODO: remove this try catch (esp for unbacked_only)
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2404: # TODO: Deduplicate this with torch/_prims_common/__init__.py
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2664: *args: Arguments passed to the parent classes.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2712: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2952: # TODO(avik): https://github.com/pytorch/pytorch/issues/101093
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3129: except (NotImplementedError, AssertionError) as e:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3242: )  # let pass if analysis min = 2 and specified min = 0/1
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3437: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3561: # These are parameters that we don't wish to pass down the road to new ShapeEnv instances
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3635: # when the constraint/dynamic dims are not explicitly passed to us.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4072: # TODO: Do something nontrivial when upper_bound is expression
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4073: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4104: # TODO: Shouldn't we install a guard if the symbol is backed?  Or is the
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4122: # TODO: this does not install a deferred runtime assert yet
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4124: # TODO: Maybe dedupe this with _maybe_guard_rel?
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4138: # TODO: Actually, we can support this as long as one of them is a symbol.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4485: # actually pass true symbolic sizes to this function
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4533: # TODO: make this configurable from outside symbolic_context; we made a symbolic_context
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4538: # TODO: This should be DYNAMIC, using DUCK for BC
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4669: is, pass it into hint.  Otherwise, pass None and we will make our best
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4933: # TODO: storage_offset handling?
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:5340: # TODO: Make this more efficient by binding all the size/stride/offsets
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:5371: raise NotImplementedError(f"Unknown lang: {lang}")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:5595: # TODO: type this better
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:5807: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:5881: # TODO: With int_oo, I think this condition is a noop
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:5915: raise NotImplementedError(f"Unimplemented for lang: {lang}")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:5980: # Only run translation validation when we are not passing custom guards
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6059: reference symints from the passed in input
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6144: # TODO: maybe it's guaranteed x in is var_to_range?
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6199: # TODO We could further canonicalize Eq ordering the lhs and rhs somehow
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6210: # we do not pass evaluate=False like others on purpose here!
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6271: # TODO try to get rid of CleanDiv since it breaks the invariant thats simplifications of sympy
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6290: # TODO: compute hint might have gotten broken here
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6309: for s in sorted(fs, key=str)  # TODO: speed up sort?
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6380: # TODO it would seem that this pass is not necessary given the
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6385: # for now just do a separate pass to catch common nested case
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6422: # TODO: overload for allow_none literal
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6514: # TODO: in a Dynamo context, having user code, and having the
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6549: # TODO: Help text about how to use our runtime tests to fix this
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6612: # TODO: Rework all of this, the constraint logic is very
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6682: # TODO: Should we propagate size-like-ness?
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6779: # FIRST one most useful (TODO: Maybe we could consider tracking all of
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6880: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6904: # TODO: Maybe trivial solutions for int should also be
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6922: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6923: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6947: d = q / sympy.gcd(q, c)  # TODO: CleanDiv?
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6968: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:6969: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7356: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7387: # TODO: split conjunctions and evaluate them separately
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7429: # TODO: does this even worked with unbacked :think:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7489: # TODO: maybe reconcile this with use of counterfactual hints
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7498: # TODO: dedupe this with _maybe_evaluate_static
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7529: # TODO: better logging
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7531: "oblivious_size %s -> %s (passed counterfactual)",
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7541: # and if they pass we add a runtime assertions and continue.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7608: # TODO: If we successfully eliminate a symbol via equality, it
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7690: # TODO: split conjunctions and evaluate them separately
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7697: # TODO: assert bool(static_expr)
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:7737: # TODO: Do this in a way that is less janky than int(s.name[1:])
- .venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:8046: # This helper function is used in passes that insert runtime assertions in the graph.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/const_fold.py:7: from torch.fx.passes.split_module import split_module
- .venv/lib/python3.12/site-packages/torch/fx/experimental/const_fold.py:227: # split_module currently does not use get_attrs for attrs. Instead it passes
- .venv/lib/python3.12/site-packages/torch/fx/experimental/const_fold.py:230: # somehow a priori knowing the attrs that should be passed as args. We can
- .venv/lib/python3.12/site-packages/torch/fx/experimental/const_fold.py:298: # This is so that the original caller who may have passed in a graph module will
- .venv/lib/python3.12/site-packages/torch/fx/experimental/partitioner_utils.py:202: # Go through all top nodes and find the largest latency (critical pass latency)
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:17: from torch.fx.passes.shape_prop import ShapeProp
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:175: # TODO: Determine whether this can be removed after type inference.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:230: This generates a heuristic that can be passed into `optimize_for_inference` that
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:276: This is a heuristic that can be passed into `optimize_for_inference` that
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:312: pass_config: Optional[dict[str, Any]] = None,
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:316: Performs a set of optimization passes to optimize a model for the
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:317: purposes of inference. Specifically, the passes that are run are:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:325: Note: As FX does not currently handle aliasing, this pass currently
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:328: default_pass_config = {
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:333: if pass_config is None:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:334: pass_config = {}
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:335: default_pass_config.update(pass_config)
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:337: if default_pass_config["conv_bn_fuse"]:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:339: if default_pass_config["remove_dropout"]:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:341: if default_pass_config["mkldnn_layout_optimize"] is False:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:343: if not isinstance(default_pass_config["mkldnn_layout_optimize"], dict):
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:345: if "heuristic" not in default_pass_config["mkldnn_layout_optimize"]:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:347: use_mkl_heuristic = default_pass_config["mkldnn_layout_optimize"]["heuristic"]
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:372: "this pass is only for torch.float modules"
- .venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:375: "this pass is only for CPU modules"
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:68: # TODO: An incomplete list
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:516: # TODO: use the file/line for some useful diagnostic on why a
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:526: # TODO: use the file/line for some useful diagnostic on why a
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:536: # TODO: use the file/line for some useful diagnostic on why a
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:557: # TODO: file/line here is very important, because the assert has been
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:594: # TODO: use the file/line for some useful diagnostic on why a
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:628: # TODO: this probably needs the sizes-strides eval functions
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:865: and no other optimizations are needed. We pass evaluate=false, with the correct order of args and save the following.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1153: # NB: There is a TODO in C++ to allow omitting the batch dim.  If that
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1220: # TODO: These could also be done with indicators, maybe it is better
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1247: # TODO: let C++ also take advantage of this
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1380: # TODO: consider constant prop here
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1436: # TODO: consider constant prop here
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1539: # same time, there is no way to wrap a plain None into an FX node. Thus, there is no way to pass None here
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1543: # TODO: Remove the args construction below if a different sentinel is used by FX.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1609: # TODO: This is technically hotpath, but in the ideal end state
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1630: # TODO: this is an awful implementation
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1713: # TODO: Remove eq and other relations from this list.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1729: # TODO: remove these
- .venv/lib/python3.12/site-packages/torch/fx/experimental/_backward_state.py:6: BackwardState is used to pass Python hooks from the forwards pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/_backward_state.py:7: into the backwards pass in Dynamo+Compiled Autograd.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/_backward_state.py:10: Dynamo will pass an empty BackwardState to the forwards, then populate
- .venv/lib/python3.12/site-packages/torch/fx/experimental/accelerator_partitioner.py:19: from torch.fx.passes.graph_manipulation import get_size_of_all_nodes
- .venv/lib/python3.12/site-packages/torch/fx/experimental/accelerator_partitioner.py:20: from torch.fx.passes.split_module import split_module
- .venv/lib/python3.12/site-packages/torch/fx/experimental/accelerator_partitioner.py:357: # TODO: add different size support for sparse_nn_partition
- .venv/lib/python3.12/site-packages/torch/fx/experimental/schema_type_annotation.py:58: # TODO: can we emit the union of these? What are the implications on TorchScript
- .venv/lib/python3.12/site-packages/torch/fx/experimental/merge_matmul.py:8: from torch.fx.passes.tools_common import legalize_graph
- .venv/lib/python3.12/site-packages/torch/fx/experimental/merge_matmul.py:115: # TODO: Properly handle aliasing caused by get_attr. For now,
- .venv/lib/python3.12/site-packages/torch/fx/experimental/validator.py:386: # TODO: Probably OK to relax this and allow lower precision
- .venv/lib/python3.12/site-packages/torch/fx/experimental/validator.py:398: raise NotImplementedError(f"to_dtype {dtype} NYI")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/rewriter.py:30: # a disable here. This function is an optimization pass and not really
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/unification_tools.py:62: will be passed to the function as a list, such as func([val1, val2, ...]).
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/utils.py:88: raise Exception("XFailed test passed")  # pragma:nocover  # noqa: TRY002
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/utils.py:90: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/match.py:31: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:13: "MDNotImplementedError",
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:27: class MDNotImplementedError(NotImplementedError):
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:28: """A NotImplementedError for multiple dispatch"""
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:200: NotImplementedError: Could not find signature for add: <int, float>
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:251: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:274: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:281: except MDNotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:287: except MDNotImplementedError:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:288: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:290: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/dispatcher.py:426: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/conflict.py:21: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/unification/multipledispatch/__init__.py:5: MDNotImplementedError,
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint.py:17: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint.py:79: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint.py:94: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/transform_to_z3.py:77: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/transform_to_z3.py:201: raise NotImplementedError("operation not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/transform_to_z3.py:204: raise NotImplementedError("Operation not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/transform_to_z3.py:311: raise NotImplementedError("operation not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:152: raise NotImplementedError("Not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:359: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:440: raise NotImplementedError("Not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:542: # TODO: add the extra check mentioned here:
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:564: # TODO: review this rule; should input = dyn; output = dyn be included here?
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:583: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:586: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:701: # TODO: we should figure out why there is a key-error here.
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:765: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:768: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:805: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:807: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:924: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:966: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:969: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:986: # TODO normalize index
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:995: raise NotImplementedError("Not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:1067: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:1114: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:1117: # TODO generate add constraints for scalar addition
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:1118: raise NotImplementedError("Addition not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:1562: raise NotImplementedError(f"Method {n.op} not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_transformation.py:192: TODO: we have to check if this is the case for all HF models
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_transformation.py:221: pass
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_transformation.py:224: raise NotImplementedError("Method not yet implemented")
- .venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_transformation.py:1028: # pad the shorter input with None so we can pass it to the broadcasting helper function
- .venv/lib/python3.12/site-packages/torch/fx/passes/net_min_base.py:652: 1st pass: search for end_idx by finding the last node in culprit block
- .venv/lib/python3.12/site-packages/torch/fx/passes/net_min_base.py:654: 2nd pass: search for start_idx by finding the first node in culprit block
- .venv/lib/python3.12/site-packages/torch/fx/passes/operator_support.py:44: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:22: __pass_count = 0
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:27: passname: str,
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:37: self.passname = passname
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:62: GraphTransformObserver.__pass_count += 1
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:66: self.passname,
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:72: def get_current_pass_count(cls):
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:73: return cls.__pass_count
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:75: def apply_gm_pass(self, pass_fn: Callable[[GraphModule], T]) -> Optional[T]:
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:77: if not self._check_disable_pass():
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:78: return pass_fn(self.gm)
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:82: def apply_graph_pass(self, pass_fn: Callable[[Graph], T]) -> Optional[T]:
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:84: if not self._check_disable_pass():
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:85: return pass_fn(self.gm.graph)
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:89: def _check_disable_pass(self):
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:93: debug_info = lambda: self.passname  # noqa: E731
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:140: f"pass_{GraphTransformObserver.__pass_count}_{self.passname}_input_graph.dot",
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:146: self.passname,
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:158: f"pass_{GraphTransformObserver.__pass_count}_{self.passname}_output_graph.dot",
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:168: source = NodeSource(None, self.passname, NodeSourceAction.CREATE)
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:197: def created_this_pass(source):
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:198: return source.pass_name == self.passname and source.action == [
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:205: source for source in new_from_node if not created_this_pass(source)
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_transform_observer.py:209: new_node_source = NodeSource(old, self.passname, action)
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:67: pass insert them into the graph as proper tests.
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:69: This pass also deduplicates size-related computation, CSE-ing ops that produce
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:90: and we delete all previous calls, adding bound checks at the end of this pass.
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:96: from torch._export.passes._node_metadata_hook import _set_node_metadata_hook
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:115: # TODO: Request simplification on runtime asserts before emitting them
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:182: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:186: pass
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:223: # and instead add 2 runtime asserts at the end of this pass, if the min/max bounds are non-trivial.
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:254: # TODO: Remove relaxing assert on unbacked_symint https://github.com/pytorch/pytorch/issues/119689
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:265: # TODO: use ra.msg here, but it's pretty
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:428: # equivalent, but the refinement calls we perform in this pass may struggle with associating the two.
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:438: # TODO: some CSE when generating these nodes can probably
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:489: # TODO: need to assert divisibility
- .venv/lib/python3.12/site-packages/torch/fx/passes/runtime_assert.py:590: # TODO(pianpwk): calling sym_constrain_range_for_size or adding bound asserts
- .venv/lib/python3.12/site-packages/torch/fx/passes/splitter_base.py:13: from torch.fx.passes.graph_manipulation import get_size_of_node
- .venv/lib/python3.12/site-packages/torch/fx/passes/splitter_base.py:114: This behavior can be turned off by passing allow_non_tensor=True.
- .venv/lib/python3.12/site-packages/torch/fx/passes/splitter_base.py:205: pass
- .venv/lib/python3.12/site-packages/torch/fx/passes/splitter_base.py:845: This pass finds ACC submodules with less than specified size and merges
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_drawer.py:14: from torch.fx.passes.shape_prop import TensorMetadata
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:14: "loop_pass",
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:15: "this_before_that_pass_constraint",
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:16: "these_before_those_pass_constraint",
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:24: Convenience wrapper for passes which modify an object inplace. This
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:46: This is useful for logging output of passes. Note inplace_wrapper replaces
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:47: the pass output with the modified object. If we want to log the original
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:52: def my_pass(d: Dict) -> bool:
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:60: pm = PassManager(passes=[inplace_wrapper(log_hook(my_pass))])
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:74: logger.log(level, "Ran pass %s\t Return value: %s", fn, val)
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:80: def loop_pass(
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:81: base_pass: Callable,
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:86: Convenience wrapper for passes which need to be applied multiple times.
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:91: base_pass (Callable[Object, Object]): pass to be applied in loop
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:92: n_iter (int, optional): number of times to loop pass
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:100: @wraps(base_pass)
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:101: def new_pass(source):
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:105: output = base_pass(output)
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:108: output = base_pass(output)
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:111: f"loop_pass must be given positive int n_iter (given "
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:116: return new_pass
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:123: def _validate_pass_schedule_constraint(
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:124: constraint: Callable[[Callable, Callable], bool], passes: list[Callable]
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:126: for i, a in enumerate(passes):
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:127: for j, b in enumerate(passes[i + 1 :]):
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:131: f"pass schedule constraint violated. Expected {a} before {b}"
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:132: f" but found {a} at index {i} and {b} at index{j} in pass"
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:137: def this_before_that_pass_constraint(this: Callable, that: Callable):
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:149: def these_before_those_pass_constraint(these: Callable, those: Callable):
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:154: For example, the following pass list and constraint list would be invalid.
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:156: passes = [
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:157: loop_pass(pass_b, 3),
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:158: loop_pass(pass_a, 5),
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:161: constraints = [these_before_those_pass_constraint(pass_a, pass_b)]
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:165: these (Callable): pass which should occur first
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:166: those (Callable): pass which should occur later
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:182: Collects passes and constraints. This defines the pass schedule, manages
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:183: pass constraints and pass execution.
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:186: passes (Optional[List[Callable]]): list of passes. A pass is a
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:189: constraint is a callable which takes two passes (A, B) and returns
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:191: `this_before_that_pass_constraint` for example.
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:194: passes: list[Callable]
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:200: passes=None,
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:203: self.passes = passes or []
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:207: def build_from_passlist(cls, passes):
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:208: pm = PassManager(passes)
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:209: # TODO(alexbeloi): add constraint management/validation
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:212: def add_pass(self, _pass: Callable):
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:213: self.passes.append(_pass)
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:220: def remove_pass(self, _passes: list[str]):
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:221: if _passes is None:
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:223: passes_left = [ps for ps in self.passes if ps.__name__ not in _passes]
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:224: self.passes = passes_left
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:227: def replace_pass(self, _target, _replacement):
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:228: passes_left = []
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:229: for ps in self.passes:
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:231: passes_left.append(_replacement)
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:233: passes_left.append(ps)
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:234: self.passes = passes_left
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:239: Validates that current pass schedule defined by `self.passes` is valid
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:245: _validate_pass_schedule_constraint(constraint, self.passes)
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:251: for _pass in self.passes:
- .venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:252: out = _pass(out)
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:149: # TODO: this should be beefed up to be able to properly re-inplace with:
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:152: # TODO: we should also figure this info out using torchgen.
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:158: # but we do NOT want the reinplacing pass to directly add these into the program.
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:297: This pass currently expects to operate on a **functional, ATen** graph.
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:364: It's only a problem if "a" (or that view) is later passed
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:370: It's only a problem if "a" (or that view) is later passed
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:485: to do this, but we can no longer run FX's DCE pass now that we have mutable
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:533: # Today, the re-inplace pass on directly acts on:
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:579: # TODO: later, add the optimization for handling `copy_()` calls in the graph.
- .venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:660: # Maybe it's fine to wait until the end of the pass to update it.
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:27: # TODO: refactor
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:28: from torch.fx.passes.runtime_assert import _get_sym_val
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:48: # This pass is also responsible for doing CSE on the fly as we do this, since
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:52: # This pass runs on the JOINT graph produced by AOT Autograd, prior to partitioning.
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:53: # The primary goal of this pass is to eliminate floats by replacing TensorScalar
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:59: # Additionally, there is a separate pass that changes which device computations
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:60: # occur on. That pass must be run after this one, but still before partitioning.
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:62: # HISTORY NOTE: Originally, I wanted to formulate this pass as pushing item()
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:77: # TODO: make sure this runs before CPU->CUDA pass for cudagraph friendliness
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:99: Converts Python scalar operations into Tensor operations within the graph. This pass looks for
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:263: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/fx/passes/_tensorify_python_scalars.py:316: # Now do one more pass that specializes all symfloats we didn't manage
- .venv/lib/python3.12/site-packages/torch/fx/passes/fake_tensor_prop.py:82: # TODO: How is it possible that we get a non fake tensor?  We
- .venv/lib/python3.12/site-packages/torch/fx/passes/tools_common.py:97: Finds groups of connected ACC nodes that pass non-tensor data between each other.
- .venv/lib/python3.12/site-packages/torch/fx/passes/split_utils.py:9: from torch.fx.passes.utils import HolderModule, lift_subgraph_as_module
- .venv/lib/python3.12/site-packages/torch/fx/passes/split_module.py:96: from torch.fx.passes.split_module import split_module
- .venv/lib/python3.12/site-packages/torch/fx/passes/split_module.py:300: # having passes.runtime_assert establish some invariants that I can
- .venv/lib/python3.12/site-packages/torch/fx/passes/split_module.py:356: # TODO currently placeholders/parameters aren't put into random partitions,
- .venv/lib/python3.12/site-packages/torch/fx/passes/split_module.py:431: # We don't pass in get_attr nodes as inputs to the partition, but
- .venv/lib/python3.12/site-packages/torch/fx/passes/split_module.py:481: # Fill in the passed-in mapping from new qualname to old qualname
- .venv/lib/python3.12/site-packages/torch/fx/passes/graph_manipulation.py:9: from torch.fx.passes.shape_prop import ShapeProp
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:103: # TODO: assert pattern is a connected graph
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:227: # TODO: use a more efficient way to check if gn is matched before: two-way dict
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:352: from torch.fx.passes.utils.fuser_utils import validate_partition
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/fuser_utils.py:10: from torch.fx.passes.tools_common import legalize_graph, NodeList, NodeSet
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/fuser_utils.py:11: from torch.fx.passes.utils import lift_subgraph_as_module  # type: ignore[attr-defined]
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/fuser_utils.py:130: f"{node} doesn't belong to passed in graph module {gm._get_name()}"
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/fuser_utils.py:154: # TODO: do we really need copy the get_attr node into the graph?
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/fuser_utils.py:156: pass
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/common.py:6: from torch.fx.passes.utils.matcher_utils import SubgraphMatcher
- .venv/lib/python3.12/site-packages/torch/fx/passes/utils/source_matcher_utils.py:80: # TODO: Bypass "torch_fn" when "source_fn_stack" because now "torch_fn" can
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:3: from ..pass_manager import (
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:6: these_before_those_pass_constraint,
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:7: this_before_that_pass_constraint,
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:12: def test_pass_manager_builder(self) -> None:
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:13: passes = [lambda x: 2 * x for _ in range(10)]
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:14: pm = PassManager(passes)
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:17: def test_this_before_that_pass_constraint(self) -> None:
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:18: passes = [lambda x: 2 * x for _ in range(10)]
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:19: pm = PassManager(passes)
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:22: pm.add_constraint(this_before_that_pass_constraint(passes[-1], passes[0]))
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:26: def test_these_before_those_pass_constraint(self) -> None:
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:27: passes = [lambda x: 2 * x for _ in range(10)]
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:28: constraint = these_before_those_pass_constraint(passes[-1], passes[0])
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:29: pm = PassManager([inplace_wrapper(p) for p in passes])
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:36: def test_two_pass_managers(self) -> None:
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:40: passes = [lambda x: 2 * x for _ in range(3)]
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:41: constraint = these_before_those_pass_constraint(passes[0], passes[1])
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:43: for p in passes:
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:44: pm1.add_pass(p)
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:49: passes = [lambda x: 3 * x for _ in range(3)]
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:50: constraint = these_before_those_pass_constraint(passes[0], passes[1])
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:52: for p in passes:
- .venv/lib/python3.12/site-packages/torch/fx/passes/tests/test_pass_manager.py:53: pm2.add_pass(p)
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:11: from torch.fx.passes.infra.pass_base import PassResult
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:17: __all__ = ["pass_result_wrapper", "this_before_that_pass_constraint", "PassManager"]
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:21: def pass_result_wrapper(fn: Callable) -> Callable:
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:23: Wrapper for passes which currently do not return a PassResult.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:52: def _validate_pass_schedule_constraint(
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:53: constraint: Callable[[Callable, Callable], bool], passes: list[Callable]
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:55: for i, a in enumerate(passes):
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:56: for j, b in enumerate(passes[i + 1 :]):
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:60: f"pass schedule constraint violated. Expected {a} before {b}"
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:61: f" but found {a} at index {i} and {b} at index{j} in pass"
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:66: def _topological_sort_passes(
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:67: passes: list[Callable], constraints: list[Callable]
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:71: passes: Passes that we are ordering
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:72: constraints: Constraints applied on these passes
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:79: return passes
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:82: graph: dict[Callable, list[Callable]] = {p: [] for p in passes}
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:83: indegree_map: dict[Callable, int] = dict.fromkeys(passes, 0)
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:85: for a in passes:
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:86: for b in passes:
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:98: visited: dict[Callable, bool] = dict.fromkeys(passes, False)
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:99: sorted_passes: list[Callable] = []
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:103: sorted_passes.append(p)
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:113: cycle_passes = list(filter(lambda p: indegree_map[p] != 0, indegree_map.keys()))
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:114: if len(cycle_passes) != 0:
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:116: f"Circular dependency detected within the following passes: {cycle_passes}"
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:120: return sorted_passes
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:124: def this_before_that_pass_constraint(this: Callable, that: Callable) -> Callable:
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:129: For example, the following pass list and constraint list would be invalid.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:131: passes = [pass_b, pass_a]
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:133: constraints = [this_before_that_pass_constraint(pass_a, pass_b)]
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:137: this (Callable): pass which should occur first
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:138: that (Callable): pass which should occur later
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:155: Collects passes and constraints. This defines the pass schedule, manages
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:156: pass constraints and pass execution.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:159: passes (Optional[List[Callable]]): List of passes. A pass is a
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:162: constraint is a callable which takes two passes (A, B) and returns
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:164: `this_before_that_pass_constraint` for example.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:165: steps (int): Max number of times we run the passes (default = 1).
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:166: run_checks_after_each_pass (bool): Whether to run checks and linting
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:167: after each pass
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:172: passes: list[Callable[[nn.Module], PassResult]]
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:179: passes=None,
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:182: run_checks_after_each_pass: bool = False,
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:185: self.passes = passes or []
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:190: self.run_checks_after_each_pass = run_checks_after_each_pass
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:193: def add_pass(self, _pass: Callable):
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:195: Adds a pass into the current list of passes.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:197: self.passes.append(_pass)
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:209: Validates that current pass schedule defined by `self.passes` is valid
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:215: _validate_pass_schedule_constraint(constraint, self.passes)
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:221: the passes based on this order.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:225: will re-run the passes, allowing for circular dependencies.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:227: self.passes = _topological_sort_passes(self.passes, self.constraints)
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:233: This function is run before and after each pass if the
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:234: `run_checks_after_each_pass` flag is enabled.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:246: pass
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:250: Runs a list of passes in the order based on `self.passes` on the given
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:251: graph module. Each time a pass is run, checks and linting will be run on
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:252: the graph module if `run_checks_after_each_pass` is set.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:254: If the module is a graph module, we will run the list of passes until
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:257: # Order the passes based on the constraints
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:264: # Run the set of passes `steps` number of times or until the graph stops
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:270: # Run the set of passes on the graph module
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:271: for i, fn in enumerate(self.passes):
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:273: logger.debug("Running pass '%s'", fn_name)
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:282: f"The result of the pass {fn_name} should be type PassResult."
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:283: + "Please wrap it with pass_result_wrapper()"
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:289: logger.debug("Graph after pass '%s': %s", fn_name, module.graph)
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:293: if self.run_checks_after_each_pass:
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:297: prev_pass_names = [
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:299: for p in self.passes[:i]
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:301: msg = f"An error occurred when running the '{fn_name}' pass after the following passes: {prev_pass_names}"
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_manager.py:304: # If the graph no longer changes, then we can stop running these passes
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/__init__.py:1: from . import pass_manager
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/partitioner.py:11: from torch.fx.passes.operator_support import OperatorSupportBase
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/partitioner.py:12: from torch.fx.passes.utils.fuser_utils import fuse_by_partitions
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:16: Result of a pass:
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:18: modified: A flag for if the pass has modified the graph module
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:30: Base interface for implementing passes.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:33: pass instances of the Pass directly to the PassManager and call them as a
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:36: We can directly pass an instance of a class implementing this interface into
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:37: the PassManager's `passes` attribute.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:42: Runs the precondition check, the pass itself, and the postcondition check.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:53: The pass that is run through the given graph module. To implement a
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:54: pass, it is required to implement this function.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:57: graph_module: The graph module we will run a pass on
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:62: This function will be called before the pass is run and will check that
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:64: pass. It is not required to implement this function.
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:72: This function will be called after the pass is run and will check that
- .venv/lib/python3.12/site-packages/torch/fx/passes/infra/pass_base.py:74: pass. It is not required to implement this function.
- .venv/lib/python3.12/site-packages/torch/fx/passes/dialect/common/cse_pass.py:6: from torch.fx.passes.infra.pass_base import PassBase, PassResult
- .venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:5: from torch.fx.passes.fake_tensor_prop import FakeTensorProp
- .venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:6: from torch.fx.passes.infra.partitioner import CapabilityBasedPartitioner
- .venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:7: from torch.fx.passes.operator_support import OperatorSupport
- .venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:8: from torch.fx.passes.tools_common import CALLABLE_NODE_OPS
- .venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:13: # TODO: why is submodules passed here
- .venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:54: # TODO: single node partition may be wrong due to the pessimization
- .venv/lib/python3.12/site-packages/torch/sparse/_semi_structured_ops.py:90: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/_semi_structured_ops.py:116: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/_semi_structured_ops.py:137: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/_semi_structured_ops.py:141: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/_semi_structured_ops.py:145: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/__init__.py:666: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:205: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:272: # TODO in the future we can add in padding to support sparse dimensions that aren't perfect multiples
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:306: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:315: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:449: Since we cannot transpose the compressed representations, we store both for the fw/bw pass respectively.
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:452: This can be used in the backward pass to mask the gradients.
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:508: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:512: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:624: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:628: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:634: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:641: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:647: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/sparse/_triton_ops_meta.py:83: that can be passed to the corresponding operation, e.g.
- .venv/lib/python3.12/site-packages/torch/sparse/_triton_ops_meta.py:181: raise NotImplementedError(f"names for {op=}")
- .venv/lib/python3.12/site-packages/torch/sparse/_triton_ops_meta.py:845: raise NotImplementedError(op)
- .venv/lib/python3.12/site-packages/torch/sparse/_triton_ops_meta.py:901: raise NotImplementedError(op)
- .venv/lib/python3.12/site-packages/torch/sparse/_triton_ops.py:100: # TODO: investigate if contiguity along other axes than the
- .venv/lib/python3.12/site-packages/torch/sparse/_triton_ops.py:497: raise NotImplementedError(indices_format)
- .venv/lib/python3.12/site-packages/torch/sparse/_triton_ops.py:894: raise NotImplementedError(obj.layout)
- .venv/lib/python3.12/site-packages/torch/sparse/_triton_ops.py:1111: raise NotImplementedError(indices_format)
- .venv/lib/python3.12/site-packages/torch/utils/mobile_optimizer.py:25: optimization_blocklist: A set with type of MobileOptimizerType. When set is not passed,
- .venv/lib/python3.12/site-packages/torch/utils/mobile_optimizer.py:26: optimization method will run all the optimizer pass; otherwise, optimizer
- .venv/lib/python3.12/site-packages/torch/utils/mobile_optimizer.py:27: method will run the optimization pass that is not included inside optimization_blocklist.
- .venv/lib/python3.12/site-packages/torch/utils/mobile_optimizer.py:28: preserved_methods: A list of methods that needed to be preserved when freeze_module pass is invoked
- .venv/lib/python3.12/site-packages/torch/utils/mobile_optimizer.py:43: # Convert potential byte arrays into strings (if there is any) to pass type checking
- .venv/lib/python3.12/site-packages/torch/utils/mobile_optimizer.py:59: optimized_cpp_module = torch._C._jit_pass_optimize_for_mobile(
- .venv/lib/python3.12/site-packages/torch/utils/mobile_optimizer.py:64: optimized_cpp_module = torch._C._jit_pass_vulkan_optimize_for_mobile(
- .venv/lib/python3.12/site-packages/torch/utils/mobile_optimizer.py:69: optimized_cpp_module = torch._C._jit_pass_metal_optimize_for_mobile(script_module._c, preserved_methods_str)
- .venv/lib/python3.12/site-packages/torch/utils/backend_registration.py:11: # TODO: Should use `torch._C._get_privateuse1_backend_name()` to get
- .venv/lib/python3.12/site-packages/torch/utils/backend_registration.py:104: # if isinstance(device, str), this means that the parameter passed in is in the string format "foo:0"
- .venv/lib/python3.12/site-packages/torch/utils/backend_registration.py:127: # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
- .venv/lib/python3.12/site-packages/torch/utils/hooks.py:131: # the Module's input without " passing through the Module's
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:48: when set, this context manager overrides the value of ``debug`` passed to
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:49: checkpoint. To defer to the local setting, pass ``None`` to this context.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:270: " with .grad() or passing an `inputs` parameter to .backward()."
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:272: " or call .backward() without passing the `inputs` argument."
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:358: backward pass. Activation checkpointing can be applied to any part of a
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:368: If the :attr:`function` invocation during the backward pass differs
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:369: from the forward pass, e.g., due to a global variable, the checkpointed
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:375: The ``use_reentrant`` parameter should be passed explicitly. In version
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:376: 2.4 we will raise an exception if ``use_reentrant`` is not passed.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:390: entirety during the backward pass.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:393: forward pass, as it runs with the forward pass under
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:399: :func:`torch.autograd.backward` API for the backward pass without its
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:401: of performing the backward pass.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:416: with :func:`torch.no_grad`, the backward pass will raise an error.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:423: function: describes what to run in the forward pass of the model or
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:425: passed as the tuple. For example, in LSTM, if user passes
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:434: requires reentrant autograd. This parameter should be passed
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:436: ``use_reentrant`` is not passed. If ``use_reentrant=False``,
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:466: "passed explicitly. In version 2.5 we will raise an exception "
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:467: "if use_reentrant is not passed. use_reentrant=False is "
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:469: "behavior, you can pass use_reentrant=True. Refer to docs for more "
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:510: be saved for re-running the segment in the backward pass.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:513: The ``use_reentrant`` parameter should be passed explicitly. In version
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:514: 2.4 we will raise an exception if ``use_reentrant`` is not passed.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:534: requires reentrant autograd. This parameter should be passed
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:536: ``use_reentrant`` is not passed. If ``use_reentrant=False``,
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:554: "parameter should be passed explicitly. "
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:556: "is not passed. use_reentrant=False is "
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:558: "behavior, you can pass use_reentrant=True. Refer to docs for more "
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:769: pass
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:842: # TODO: we can probably make this check stricter by checking that
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:905: "have different metadata than during the forward pass.\n"
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:912: Tip: To see a more detailed error message, either pass `debug=True` to
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:921: because you passed `debug=True` to `torch.utils.checkpoint.checkpoint()`.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:955: You are seeing this error because you passed `debug=True` to checkpoint and
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:980: pass
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1057: pass
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1081: "recomputation than during the original forward pass.\n"
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1148: pass
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1209: # version counter. TODO: Use reentrant_dispatch instead of
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1219: Context passed to policy function during selective checkpointing.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1221: This class is used to pass relevant metadata to the policy function during
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1250: pass and will not be recomputed during the backward pass
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1252: forward pass and will be recomputed during the backward pass
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1313: # TODO HOPs don't mutate -> this is always true today but will not be true forever
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1362: operations are recomputed during the backward pass.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1457: fn: describes what to run in the forward pass of the model or
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1459: passed as the tuple. For example, in LSTM, if user passes
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1478: *args: Arguments to pass in to the given ``function``.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1479: **kwargs: Keyword arguments to pass into the given ``function``.
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1506: "In torch.compile mode, `context_fn` arg passed to `torch.utils.checkpoint` " + \
- .venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1567: "PyTorch's device state was initialized in the forward pass "
- .venv/lib/python3.12/site-packages/torch/utils/_content_store.py:102: # TODO: make storage support buffer protocol so this isn't
- .venv/lib/python3.12/site-packages/torch/utils/_content_store.py:111: # TODO: factor this into a random utility
- .venv/lib/python3.12/site-packages/torch/utils/_content_store.py:154: # TODO: offer some sort of non-blocking API to speed things up
- .venv/lib/python3.12/site-packages/torch/utils/_content_store.py:159: # TODO: consider not using torch.save for this; we don't actually
- .venv/lib/python3.12/site-packages/torch/utils/_content_store.py:185: # TODO: Support more advanced snapshotting of requires_grad/grad/etc
- .venv/lib/python3.12/site-packages/torch/utils/weak.py:143: pass
- .venv/lib/python3.12/site-packages/torch/utils/weak.py:169: pass
- .venv/lib/python3.12/site-packages/torch/utils/weak.py:336: # TODO, add _fix_weakref type binding
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:141: passed to the ``unflatten_fn``.
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:166: raise NotImplementedError("KeyPaths are not yet supported in cxx_pytree.")
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:218: passed to the ``unflatten_fn``.
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:256: # TODO(XuehaiPan): remove this condition when we make Python pytree out-of-box support
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:586: # These specializations help with type inference on the lambda passed to this
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:955: # a user can pass in vmap(fn, in_dims)(*inputs). `in_dims` should be
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:1039: raise NotImplementedError("KeyPaths are not yet supported in cxx_pytree.")
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:1060: raise NotImplementedError("KeyPaths are not yet supported in cxx_pytree.")
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:1092: raise NotImplementedError("KeyPaths are not yet supported in cxx_pytree.")
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:1097: raise NotImplementedError("KeyPaths are not yet supported in cxx_pytree.")
- .venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:1102: raise NotImplementedError("KeyPaths are not yet supported in cxx_pytree.")
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:572: This :class:`setuptools.build_ext` subclass takes care of passing the
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:655: # not get passed. Necessary when only one of 'cxx', 'nvcc' or 'sycl' is
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:656: # passed to extra_compile_args in CUDAExtension or SyclExtension, i.e.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:671: # compile any extension that has passed in py_limited_api to the
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:706: # NVCC does not allow multiple -std to be passed, so we avoid
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:707: # overriding the option if the user explicitly passed it.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:719: # NVCC does not allow multiple -ccbin/--compiler-bindir to be passed, so we avoid
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:720: # overriding the option if the user explicitly passed it.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:844: # escaping quoted arguments to pass them thru SYCL compiler
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:849: # strings passed to SYCL compiler.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:982: # Replace space with \ when using hipcc (hipcc passes includes to clang without ""s so clang sees space in include paths
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1160: with the flag ``py_limited_api=True``.  When this flag is passed, it is
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1232: with the flag ``py_limited_api=True``.  When this flag is passed, it is
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1421: with the flag ``py_limited_api=True``.  When this flag is passed, it is
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1509: # but gcc doesn't like having /usr/include passed explicitly
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1605: which can be overridden by setting the ``CXX`` environment variable. To pass
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1608: with optimizations, pass ``extra_cflags=['-O3']``. You can also use
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1609: ``extra_cflags`` to pass further include directories.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1611: CUDA support with mixed compilation is provided. Simply pass CUDA source
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1614: passing the CUDA lib64 directory as a library directory, and linking
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1615: ``cudart``. You can pass additional flags to nvcc via
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1621: SYCL support with mixed compilation is provided. Simply pass SYCL source
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1624: than the C++ compiler. You can pass additional flags to SYCL compiler
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1707: # For PyTorch extensions we want to relax those restrictions and pass compiler, stdlib and abi properties
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1905: precisely, strings passed to ``cpp_sources`` are first concatenated into a
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2582: # Warning: don't pass stdout=None to subprocess.run to get output.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2592: # To work around this, we pass in the fileno directly and hope that
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2663: # TODO generalize with_cuda as specific device type.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2727: # escaping quoted arguments to pass them thru SYCL compiler
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2798: `cflags`: list of flags to pass to $cxx. Can be None.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2800: `cuda_cflags`: list of flags to pass to $nvcc. Can be None.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2803: `sycl_cflags`: list of flags to pass to SYCL compiler. Can be None.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2809: `ldflags`: list of flags to pass to linker. Can be None.
- .venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2902: # so we pass '-x c++' explicitly notifying compiler of file format
- .venv/lib/python3.12/site-packages/torch/utils/collect_env.py:291: #      Spec store bypass:     Mitigation; Speculative Store Bypass disabled via prctl and seccomp
- .venv/lib/python3.12/site-packages/torch/utils/_freeze.py:209: # instead of passing in the real build time path to 'compile', we
- .venv/lib/python3.12/site-packages/torch/utils/_freeze.py:210: # pass in a marker instead. This prevents the build time path being
- .venv/lib/python3.12/site-packages/torch/utils/file_baton.py:44: passed to the constructor.
- .venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:14: # TODO: Remove this once ScriptModule supports registering None buffer
- .venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:55: # TODO: Remove this once ScriptModule supports registering None buffer
- .venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:55: If inputs is passed in as a list then the inputs will be bundled for 'forward'.
- .venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:56: If inputs is instead passed in as a map then all the methods specified in the map
- .venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:63: Returns a list of tuples suitable for passing to the model like
- .venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:76: Returns a list of tuples suitable for passing to the model like
- .venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:144: Returns a list of tuples suitable for passing to the model like
- .venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:198: Returns a list of tuples suitable for passing to the model like
- .venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:211: Returns a list of tuples suitable for passing to the model like
- .venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:394: # TODO: Should we do this even for non-contiguous tensors?
- .venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:404: # TODO: Provide more useful diagnostics.
- .venv/lib/python3.12/site-packages/torch/utils/_triton.py:41: pass
- .venv/lib/python3.12/site-packages/torch/utils/_triton.py:57: pass
- .venv/lib/python3.12/site-packages/torch/utils/_triton.py:86: pass
- .venv/lib/python3.12/site-packages/torch/utils/_triton.py:94: pass
- .venv/lib/python3.12/site-packages/torch/utils/_triton.py:114: pass
- .venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:91: "intended to pass a context manager factory, rewrite your call as "
- .venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:92: "context_decorator(lambda: ctx()); if you intended to pass a context "
- .venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:145: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:148: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:293: dataclass; in particular, it must be constructed by passing the fields
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:394: In a :func:`torch.compile` region, if instances of these types get passed to
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:413: Otherwise if you want to pass instance of a class to a
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:607: # TODO: change this warning to an error after OSS/internal stabilize
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:719: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:818: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:828: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:838: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1432: # These specializations help with type inference on the lambda passed to this
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1747: # a user can pass in vmap(fn, in_dims)(*inputs). `in_dims` should be
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1812: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1821: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1864: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1940: # TODO(angelayi): remove this function after OSS/internal stabilize
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1949: # TODO(angelayi): remove this function after OSS/internal stabilize
- .venv/lib/python3.12/site-packages/torch/utils/_pytree.py:2041: "Please pass a flatten_with_keys_fn argument to register_pytree_node."
- .venv/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:22: # TODO: Limitations and things about enable_torch_dispatch_mode we should fix before exposing it:
- .venv/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:87: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:426: passing them into ``callback`` to get a transformed tensor,
- .venv/lib/python3.12/site-packages/torch/utils/throughput_benchmark.py:71: from the need to hold GIL every time we execute Python code or pass around
- .venv/lib/python3.12/site-packages/torch/utils/_traceback.py:86: # TODO: This creates a temporary file for every frame, but we
- .venv/lib/python3.12/site-packages/torch/utils/_traceback.py:178: # TODO: Maybe indicate that the traceback was elided?
- .venv/lib/python3.12/site-packages/torch/utils/_traceback.py:222: pass it CapturedTraceback with C++ traces,  it is better not to use this
- .venv/lib/python3.12/site-packages/torch/utils/_config_module.py:174: _bypass_keys = set({"_is_dirty", "_hash_digest", "__annotations__"})
- .venv/lib/python3.12/site-packages/torch/utils/_config_module.py:347: _bypass_keys: set[str]
- .venv/lib/python3.12/site-packages/torch/utils/_config_module.py:353: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_config_module.py:358: if name in self._bypass_keys:
- .venv/lib/python3.12/site-packages/torch/utils/_config_module.py:733: raise NotImplementedError("NYI")
- .venv/lib/python3.12/site-packages/torch/utils/_config_module.py:736: raise NotImplementedError("NYI")
- .venv/lib/python3.12/site-packages/torch/utils/_config_module.py:774: # `super().__setattr__` to bypass custom `__setattr__`
- .venv/lib/python3.12/site-packages/torch/utils/flop_counter.py:621: It also supports hierarchical output by passing a module (or list of
- .venv/lib/python3.12/site-packages/torch/utils/flop_counter.py:649: warnings.warn("mods argument is not needed anymore, you can stop passing it", stacklevel=2)
- .venv/lib/python3.12/site-packages/torch/utils/show_pickle.py:92: obj = str(str_bytes, "utf-8", "surrogatepass")
- .venv/lib/python3.12/site-packages/torch/utils/module_tracker.py:48: # Access anything during the forward pass
- .venv/lib/python3.12/site-packages/torch/utils/module_tracker.py:85: A boolean marking if this is currently running during the backward pass or not
- .venv/lib/python3.12/site-packages/torch/utils/dlpack.py:53: # TODO: add a typing.Protocol to be able to tell Mypy that only objects with
- .venv/lib/python3.12/site-packages/torch/utils/dlpack.py:108: # device is either CUDA or ROCm, we need to pass the current
- .venv/lib/python3.12/site-packages/torch/utils/dlpack.py:114: # The array API specify that the default legacy stream must be passed
- .venv/lib/python3.12/site-packages/torch/utils/dlpack.py:118: # Since pytorch is not using PTDS by default, lets directly pass
- .venv/lib/python3.12/site-packages/torch/utils/hipify/hipify_python.py:502: TODO:
- .venv/lib/python3.12/site-packages/torch/utils/hipify/cuda_to_hip_mappings.py:8614: # TODO: Undo this special-case; see the header for motivation behind this
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/timer.py:51: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/timer.py:54: "code is CPU only, pass `timer=timeit.default_timer` to the "
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/timer.py:191: stmt: str = "pass",
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/timer.py:192: setup: str = "pass",
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/timer.py:224: setup = ("" if setup == "pass" else setup)
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/timer.py:287: raise NotImplementedError("See `Timer.blocked_autorange.`")
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/timer.py:290: raise NotImplementedError("See `Timer.blocked_autorange.`")
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/common.py:57: "" if (self.setup == "pass" or not self.setup)
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/fuzzer.py:59: If a dict is passed, the keys are taken to be choices
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/fuzzer.py:62: If a dict is passed, `minval` and `maxval` must not be set.
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/fuzzer.py:123: # If we directly pass the keys to `choice`, numpy will convert
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/fuzzer.py:175: case the negative value will pass the size check and OOM when attempting to
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/fuzzer.py:204: generation process, while ints are simply passed as literals.
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/fuzzer.py:240: concrete shape of the Tensor to be created will be passed, and
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/fuzzer.py:241: concrete values of all parameters will be passed as kwargs. Note
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/compile.py:133: If you'd like to leverage this utility for training make sure to pass in a torch.optim.Optimizer
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/sparse_fuzzer.py:30: generation process, while ints are simply passed as literals.
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/cpp_jit.py:31: # first pass through the loop.
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:34: # TODO(#105471): Rename the count field
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:353: Key takeaway: Any globals passed must be wrapped in `CopyIfCallgrind` to
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:390: boundaries, what can be passed through `globals` is severely restricted
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:392: achievable (albeit perhaps less ergonomically) by passing a `setup`
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:461: # TODO: Figure out if we can use torch.serialization.add_safe_globals here
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:474: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:791: pass_baseline = (
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:793: f"{block_stmt('pass')}\n"
- .venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:888: baseline=(pass_baseline if collect_baseline else ""),
- .venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:49: - Fix various TODO comments in this file and the JS.
- .venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:174: # TODO: Undo at least that second hack.  We should support string states.
- .venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:190: or passed to burn_in_info.
- .venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:288: # TODO: Handle this case better.  TorchScript ranges are in bytes,
- .venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:321: # TODO: handle errors here and just ignore the file?
- .venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:353: It can load model_info.json over HTTP, or be passed to burn_in_info.
- .venv/lib/python3.12/site-packages/torch/utils/jit/log_extract.py:56: raise NotImplementedError(f"A default value is not implemented for type {inp.type()}")
- .venv/lib/python3.12/site-packages/torch/utils/jit/log_extract.py:59: torch._C._jit_pass_erase_shape_information(func.graph)
- .venv/lib/python3.12/site-packages/torch/utils/viz/_cycles.py:122: pass
- .venv/lib/python3.12/site-packages/torch/utils/bottleneck/__main__.py:169: help='Command-line arguments to be passed to the script.')
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:175: # TODO: In Triton, // rounds to zero, but in Python, it is floor division.
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:290: pass  # https://github.com/pytorch/pytorch/issues/108276
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:333: pass  # https://github.com/pytorch/pytorch/issues/108276
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:347: # TODO if https://github.com/triton-lang/triton/issues/619 is fixed
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:1017: # TODO: microoptimization is to avoid overflowing into arbitrary precision
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:1136: # TODO: As an indicator, this != 0 implies == 1 (and vice versa).
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:1172: # TODO: Inability to access size-obliviousness sucks: if we have a
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:58: pass
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:130: # Although the type signature here suggests you can pass any
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:161: # TODO: when the bounds have free variables, this may be
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:940: # TODO: We should tighten value ranges
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:959: # TODO: We should tighten value ranges
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:114: raise NotImplementedError(f"to_dtype {dtype} NYI")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:142: raise NotImplementedError("TODO: truncdiv")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:211: # sharing (TODO: considering splitting out a BaseReferenceAnalysis).
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:255: raise NotImplementedError(f"to_dtype {dtype} NYI")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:421: # TODO: maybe composite implicit autograd doesn't work here?
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:450: # TODO: https://github.com/pytorch/pytorch/pull/133654
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:451: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:469: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:473: # TODO: This is wrong, CPython has a custom implementation of true
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:486: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:577: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:81: raise NotImplementedError(f"_print_ToFloat not implemented for {type(self)}")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:84: raise NotImplementedError(f"_print_Infinity not implemented for {type(self)}")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:87: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:92: raise NotImplementedError(f"_print_FloorDiv not implemented for {type(self)}")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:95: raise NotImplementedError(f"_print_PythonMod not implemented for {type(self)}")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:98: raise NotImplementedError(f"_print_IntTrueDiv not implemented for {type(self)}")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:101: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:106: raise NotImplementedError(f"_print_FloatPow not implemented for {type(self)}")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:109: raise NotImplementedError(f"_print_TruncToInt not implemented for {type(self)}")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:112: raise NotImplementedError(f"_print_RoundToInt not implemented for {type(self)}")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:115: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:125: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:191: # TODO: Not sure this works with Triton, even when base/exp are integral
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:352: # TODO: This is only accurate up to 2**53
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:355: # TODO: PowByNatural: we need to implement our own int-int pow.  Do NOT
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:362: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:394: # TODO: float vs double
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/printers.py:481: # TODO: dispatch to llrint depending on index type
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:51: # TODO: Dedupe this with SYMPY_INTERP
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:56: # TODO add CeilDiv (it doesn't appear in the index_expr)
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:58: # TODO default to some decompositions if the interpreter doesn't have them
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:74: CleanDiv: "floordiv",  # TODO: hmm?
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:83: # TODO: There is a hazard here, if we have float * float it will
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:89: PythonMod: "mod",  # TODO: this is wrong
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:90: # TODO: Inductor can generate these, but it's ill-specified which
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:107: # TODO: do the rest of the opaque unary functions...
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:112: # TODO: This is kind of pointless, we shouldn't be generating sympy.sin
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:173: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/singleton_int.py:59: raise NotImplementedError("NYI")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/singleton_int.py:62: raise NotImplementedError("NYI")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/singleton_int.py:65: raise NotImplementedError("NYI")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/singleton_int.py:68: raise NotImplementedError("NYI")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/singleton_int.py:71: raise NotImplementedError("NYI")
- .venv/lib/python3.12/site-packages/torch/utils/_sympy/symbol.py:85: # TODO: maybe put the assumptions here directly
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_convert_np.py:24: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py:207: # TODO: expose other parameters in the future.
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py:573: # Do not assume that user passes in values in [0, 255], use data type to detect
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py:644: # If user passes in uint8, then we don't need to rescale by 255
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_utils.py:76: assert isinstance(I, np.ndarray), "plugin error, should pass numpy array here"
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:71: # Sometimes PosixPath is passed in and we need to coerce it to
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:73: # TODO: See if we can remove this in the future if we are
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:74: # actually the ones passing in a PosixPath
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:197: between runs easily. e.g. pass in 'runs/exp1', 'runs/exp2', etc.
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:596: corresponding ``dataformats`` argument is passed, e.g. ``CHW``, ``HWC``, ``HW``.
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:834: use_strict_trace (bool): Whether to pass keyword argument `strict` to
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:46: # TODO; Specify a __slots__ for this class or potentially
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:115: # TODO: See if we can remove this in the future
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:125: GraphDef generation operates in two passes:
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:127: In the first pass, all nodes are read and saved to two lists.
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:130: operator nodes (nodes_op). The first pass also saves all scope name
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:133: In the second pass, scope names are fully applied to all nodes.
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:217: # TODO: compute correct memory usage and CPU time once
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:320: use_strict_trace (bool): Whether to pass keyword argument `strict` to
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:328: torch._C._jit_pass_inline(graph)
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:340: # TODO: See if we can extract GPU vs CPU information from the PyTorch model
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:341: # and pass it correctly to TensorBoard.
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:370: pass
- .venv/lib/python3.12/site-packages/torch/utils/tensorboard/_onnx_graph.py:56: # two pass token replacement, appends opname to object id
- .venv/lib/python3.12/site-packages/torch/utils/data/sampler.py:74: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/utils/data/sampler.py:88: #   + `raise NotImplementedError`:
- .venv/lib/python3.12/site-packages/torch/utils/data/sampler.py:92: #     raising a `NotImplementedError` will propagate and make the call fail
- .venv/lib/python3.12/site-packages/torch/utils/data/graph.py:22: # TODO(VitalyFedyunin): Make sure it works without dill module installed
- .venv/lib/python3.12/site-packages/torch/utils/data/graph.py:57: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/utils/data/backward_compatibility.py:11: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:57: # type parameter set to a default value if the user doesn't pass in a custom 'collate_fn'.
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:567: #        other than `torch.set_num_threads` to 1 in the worker process, if the passing
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:610: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:727: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732: # TODO(https://github.com/pytorch/pytorch/issues/76750)
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:758: # TODO: add limited pickling support for sharing an iterator
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:763: raise NotImplementedError("{} cannot be pickled", self.__class__.__name__)
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1167: #     start a process and pass the arguments over via a pipe.
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1328: # On Linux when DataLoader is used with multiprocessing we pass the data between
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1331: # passing around their file descriptors through AF_UNIX sockets. (See
- .venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1377: #               pass
- .venv/lib/python3.12/site-packages/torch/utils/data/distributed.py:22: process can pass a :class:`~torch.utils.data.DistributedSampler` instance as a
- .venv/lib/python3.12/site-packages/torch/utils/data/dataset.py:59: raise NotImplementedError("Subclasses of Dataset should implement __getitem__.")
- .venv/lib/python3.12/site-packages/torch/utils/data/dataset.py:252: raise ValueError("At least one dataset should be passed")
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:166: # TODO: Add try-except to in-place reduce traceback from the Exception
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:220: # TODO: Simplify the traceback message to skip over `response = gen.send(None)`
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:16: # TODO: Use TypeAlias when Python 3.6 is deprecated
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:35: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:39: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:43: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:229: # TODO: When PyTorch drops the support for Python 3.6, it can be converted
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:285: # TODO: the statements below are not reachable by design as there is a bug and typing is low priority for now.
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:304: # TODO: Fix isinstance bug
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:361: # TODO: Fix isinstance bug
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:372: # TODO: Fix isinstance bug
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:418: # TODO:
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/datapipe.py:196: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/datapipe.py:197: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/datapipe.py:335: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/datapipe.py:336: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/gen_pyi.py:304: TODO: The current implementation of this script only generates interfaces for built-in methods. To generate
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:67: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:76: # TODO: Lambda for picking
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:182: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:192: # TODO:
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/common.py:378: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/snapshot.py:7: # TODO: Caveats
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/snapshot.py:8: #   1. Caller (either the ReadingService or DataLoader) must pass in the initial RNG
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/snapshot.py:34: should be in its `initial` state as it was first passed into ``DataLoader`` or ``ReadingService``.
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/decoder.py:368: # TODO: xinyu, figure out why Nvidia do this?
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:139: # TODO(VitalyFedyunin): Verify that item is any sort of batch
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:141: # TODO(VitalyFedyunin): Compact all batch dataframes into one
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:160: # TODO(VitalyFedyunin): Add default collation into df_wrapper
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:174: # TODO(VitalyFedyunin): We can dynamically extract types from the tuple_values here
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:175: # TODO(VitalyFedyunin): Instead of ignoring mypy error, make sure tuple_names is not empty
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:232: # TODO(VitalyFedyunin): Replace `Callable[..., Any]` with `Callable[[IColumn], Any]`
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:233: # TODO(VitalyFedyunin): Replace with `Dict[Union[str, IColumn], Union[Callable, Enum]]`
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:240: # TODO(VitalyFedyunin): Validate passed dictionary
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/sharding.py:28: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:111: # TODO: Performance optimization
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/fileopener.py:58: # TODO: enforce typing for each instance based on mode, otherwise
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/combining.py:298: The instance of this class will pass its instance_id to get the next value from its main DataPipe.
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:9: # TODO(VitalyFedyunin): Add error when two different traces get combined
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:54: #  TODO(VitalyFedyunin): Extract this list from the DFIterDataPipe registred functions
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:73: # TODO: All operations are shared across entire InitialCapture, need to figure out what if we join two captures
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:90: # TODO(VitalyFedyunin): Currently can't pickle (why?)
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:144: # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:155: # TODO(VitalyFedyunin): Add tests
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:156: # TODO(VitalyFedyunin): Need to join context if one of them are empty because we used capture
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:159: # TODO: Check if args or kwargs have more than one different context
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:161: # TODO: Allow CaptureA to take context from mock
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:204: # TODO(VitalyFedyunin): Do not use provate function here, copy own implementation instead.
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:234: # TODO: VitalyFedyunin execute kwargs and maybe nested structures
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:256: # TODO(VitalyFedyunin): This should be atomic and thread safe
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:275: # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:386: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:445: # TODO(VitalyFedyunin): Must implement all special functions of datapipes
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:448: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:38: # TODO(VitalyFedyunin): Replacing with TorchArrow only API, as we are dropping pandas as followup
- .venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:125: ):  # TODO(VitalyFedyunin): Replace with better iterable exception
- .venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py:120: When used in a :attr:`worker_init_fn` passed over to
- .venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py:175: # TODO: Implement `SeedSequence` like object for `torch.random`
- .venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py:371: pass
- .venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:16: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/package/_mock.py:96: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/package/_mock.py:103: # (e.g. `x = MockedObject("foo")`), so pass it through normally.
- .venv/lib/python3.12/site-packages/torch/package/_mock.py:115: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/package/package_importer.py:268: # TODO: Once we decide to break serialization FC, we can
- .venv/lib/python3.12/site-packages/torch/package/package_importer.py:305: # TODO from zdevito:
- .venv/lib/python3.12/site-packages/torch/package/package_importer.py:614: If a name, the module is imported.  If the passed or imported module
- .venv/lib/python3.12/site-packages/torch/package/package_importer.py:693: pass
- .venv/lib/python3.12/site-packages/torch/package/package_importer.py:710: pass
- .venv/lib/python3.12/site-packages/torch/package/_stdlib.py:97: "getpass",
- .venv/lib/python3.12/site-packages/torch/package/importer.py:78: # TODO: I guess we should do copyreg too?
- .venv/lib/python3.12/site-packages/torch/package/importer.py:86: pass
- .venv/lib/python3.12/site-packages/torch/package/importer.py:162: pass
- .venv/lib/python3.12/site-packages/torch/package/package_exporter.py:215: importer: If a single Importer is passed, use that to search for modules.
- .venv/lib/python3.12/site-packages/torch/package/package_exporter.py:216: If a sequence of importers are passed, an ``OrderedImporter`` will be constructed out of them.
- .venv/lib/python3.12/site-packages/torch/package/package_exporter.py:445: pass
- .venv/lib/python3.12/site-packages/torch/package/package_exporter.py:522: "save_module() expects a string input, did you perhaps mean to pass `__name__`?"
- .venv/lib/python3.12/site-packages/torch/package/package_exporter.py:678: # If not module was passed on in the entries preceding this one, continue.
- .venv/lib/python3.12/site-packages/torch/package/package_exporter.py:908: # TODO: Once we decide to break serialization FC, we can
- .venv/lib/python3.12/site-packages/torch/package/_mangling.py:33: PackageMangler. It will pass through names created by a different
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:143: ``default_identifier``. Can be passed as callable in which case it will be called with
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:179: ``default_identifier``. Can be passed as callable in which case it will be called with
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:239: identifier (Optional[Union[str, Callable[[str], str]]]): Optional description for the scalars. Can be passed
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:274: identifier (Optional[Union[str, Callable[[str], str]]]): Optional description for the tensors. Can be passed
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:312: # TODO: Instead of always upcasting to int64, it would be sufficient to cast to the next higher dtype to avoid
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:386: If you use this before the ``super().__init__(...)`` call in the constructor, you have to pass the ``id``
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:820: # TODO: Remove this conversion as soon as all operations are supported natively by the MPS backend
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:1132: **options (Any): Options passed to each pair during construction.
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:1268: **options (Any): Options passed to each pair during construction.
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:1393: the comparison. Can also passed as callable in which case it will be called with the generated message and
- .venv/lib/python3.12/site-packages/torch/testing/_comparison.py:1586: # TODO: compose all metas into one AssertionError
- .venv/lib/python3.12/site-packages/torch/testing/_creation.py:107: ValueError: If ``requires_grad=True`` is passed for integral `dtype`
- .venv/lib/python3.12/site-packages/torch/testing/_creation.py:110: ValueError: If both :attr:`noncontiguous` and :attr:`memory_format` are passed.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:115: # TODO: Expand this class to handle arbitrary settings in addition to boolean flags?
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:336: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:465: param_kwargs (dict): Param kwargs to pass to the test (e.g. {'op': 'add', 'dtype': torch.int64})
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:468: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:719: raise ValueError(f'{test}: An empty arg_values was passed to @parametrize. '
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:1015: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:1467: # TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:1605: def xpassIfTorchDynamo_np(func):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2755: # TODO: Revisit the relaxed pairs and check how much work it is to fix the tests that would fail without the relaxation.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2803: ``check_dtype=True`` is passed.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2951: # if the exception is NotImplementedError, and if so just skip the test instead
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2958: class AssertRaisesContextIgnoreNotImplementedError(unittest.case._AssertRaisesContext):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2960: if exc_type is not None and issubclass(exc_type, NotImplementedError):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3032: # When True, if a test case raises a NotImplementedError, instead of failing
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3058: self.wrap_with_policy(method_name, lambda: skip_exception_type(NotImplementedError))
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3167: # TODO: sure looks like we unconditionally initialize the context here
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3186: #       passes or not. For the same reason, we can't wrap the `method`
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3242: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3263: # TODO: Remove this; this is grandfathered in because we suppressed errors
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3323: self.skipTest(f"This test passed, maybe we can remove `{file_name}`")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4008: #   arguments then wrap the function in a lambda or pass a partial function.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4009: # TODO: add args/kwargs for passing to assertEqual (e.g. rtol, atol)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4070: # TODO: default this to True
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4143: # TODO: compose all metas into one AssertionError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4145: # This emulates unittest.TestCase's behavior if a custom message passed and
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4172: context: Optional[AssertRaisesContextIgnoreNotImplementedError] = \
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4173: AssertRaisesContextIgnoreNotImplementedError(expected_exception, self)  # type: ignore[call-arg]
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4198: context = AssertRaisesContextIgnoreNotImplementedError(  # type: ignore[call-arg]
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4227: # TODO: Support context manager interface
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4411: should_alert (bool, optional): If True, then the check will only pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4413: expected message. If False, then the check will only pass if
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4495: checkpoint fails to load. If None, the test will pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4520: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4649: # TODO: consider more complicated noncontiguity schemes
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4670: # TODO: remove this (prefer make_symmetric_matrices below)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4720: # TODO: remove this (prefer make_symmetric_pd_matrices below)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4975: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:5002: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:5142: def skip_but_pass_in_sandcastle(reason):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:5145: "passes" the test instead to avoid creating tasks complaining about tests
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:5165: in addition to passing args to a mock object.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:5249: def skip_but_pass_in_sandcastle_if(condition, reason):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:5252: "passes" the test instead to avoid creating tasks complaining about tests
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:5391: #   and tensors passed as kwargs. The following creates a function that accepts just
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:5570: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:5700: # TODO(xmfan): even using TemporaryDirectoryName will result in permission error
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_cuda.py:216: # tf32 and fp32 are different only when all the three checks pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/hop_db.py:89: 'flat_apply',  # is WIP, doesn't pass any of the tests yet
- .venv/lib/python3.12/site-packages/torch/testing/_internal/hop_db.py:103: "dynamo_bypassing_wrapper",  # TODO(soulitzer)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/logging_utils.py:74: # 3. passes a ref to the gathered records to each test case for checking
- .venv/lib/python3.12/site-packages/torch/testing/_internal/custom_op_db.py:227: raise NotImplementedError("Operator is data-dependent and cannot be vmapped.")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/custom_op_db.py:426: raise NotImplementedError("Operator is data-dependent and cannot be vmapped.")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/dist_utils.py:34: Note: pass the string representation of MessageTypes that should be used
- .venv/lib/python3.12/site-packages/torch/testing/_internal/dist_utils.py:91: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_jit.py:297: torch._C._jit_pass_constant_propagation(traced_graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_jit.py:298: torch._C._jit_pass_propagate_shapes_on_graph(traced_graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:52: """Contains args / kwargs to be passed to an optimizer constructor."""
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:135: # the optim supports passing in sparse gradients as well as dense grads
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:137: # the optimizer constructor supports passing in capturable as a kwarg
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:147: # whether the optimizer.step() function requires a closure to be passed
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:202: # We default to torch.float32, but dtypes should be specified through passed in
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:219: # Construct parameter kwargs to pass to the test.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:484: ),  # TODO: Move out to testing in param_group?
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:510: # TODO: consider tensor LR! See multi_tensor_optimizer_configs in test_optim.py --> tensor LR should work
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:1181: ),  # TODO: Move out to testing in param_group?
- .venv/lib/python3.12/site-packages/torch/testing/_internal/dynamo_test_failures.py:106: # TODO: due to case sensitivity problems, for now list these files by hand
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:305: # test blow pass on macOS 12 as it falls back to cpu
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:335: # before macOS 13.2 it falls back to cpu and pass the forward pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:347: # test blow pass on macOS 12 as it falls back to cpu
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:684: # TODO: remove these once downstream function 'aten::_linalg_svd.U' have been implemented
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:889: # Unsupported Border padding mode, forward pass success as fallback to cpu
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:892: # Forward pass is passing since `msort` doesn't return the indices, just the values, which match the CPU.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:893: # On the backward pass for `sort` both are used (values and indices), thus resulting in a issmatch between CPU and MPS.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:894: # Running `msort` with stable `sort` passes.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:911: # Forward pass is passing since `msort` doesn't return the indices, just the values, which match the CPU.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:912: # On the backward pass for `sort` both are used (values and indices), thus resulting in a issmatch between CPU and MPS.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:913: # Running `msort` with stable `sort` passes.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_mps.py:919: # TODO: remove these once downstream function 'aten::_linalg_svd.U' have been implemented
- .venv/lib/python3.12/site-packages/torch/testing/_internal/autograd_function_db.py:429: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/autograd_function_db.py:448: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:976: # so if we pass size as a tuple, we have a tuple containing a tuple
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1327: # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1334: # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1422: # TODO: add reduction kwargs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1884: # TODO: no layout
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1892: # TODO: no layout
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1916: # The scalar we are passing to new_full must be the same dtype
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2439: ((1,), (1,), {})  # dim not passed, fallback to default
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2678: # TODO: FIXME
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:3267: # TODO: this can be simplified after https://github.com/pytorch/pytorch/issues/69316 is fixed
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4509: # TODO: @krshrimali, once to_numpy method in SampleInput class is modified to take None inputs,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4932: # Tests that gelu errors out when passed an approximation we don't know.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5018: # test case passing a single output size
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5026: # test case passing a tuple output size
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5034: # test case passing an output ratio
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5065: # test case passing a single output size
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5073: # test case passing a tuple output size
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5081: # test case passing an output ratio
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5215: # TODO: can't switch `to.device` overload to use positional arguments
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:6324: # Tests that hardtanh errors out when passed min_val > max_val.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:6923: # which we pass to `make_tensor`.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:7378: # they pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:7826: # TODO: add reference inputs for where(condition) signature
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:9198: # TODO: remove once the issue is resolved
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:11731: # TODO: Fix test_out_arg_all_dtypes as torch.empty_like(expected_output) where expected_output=op(input)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12189: # trigger addmm being decomposed by a jit pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12407: # TODO: update sample inputs with for_inplace_variant kwarg to support this test
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12419: # TODO: update sample inputs with for_inplace_variant kwarg to support this test
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12642: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12658: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12722: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12910: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":118,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13005: # This fails on CUDA but passes on ROCm
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13589: # NotImplementedError: Tensors of type SparseCsrTensorImpl do not have is_contiguous
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13622: # NotImplementedError: Could not run 'aten::sparse_sampled_addmm' with arguments from the 'SparseCsrMeta' backend.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13639: # NotImplementedError: Tensors of type SparseCsrTensorImpl do not have is_contiguous
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13669: # NotImplementedError: Could not run 'aten::_sparse_mm_reduce_impl' with arguments from the 'SparseCsrMeta' backend
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14053: # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14273: # TODO: some signatures of median do support out
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14281: # TODO: some signatures of nanmedian do support out
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14290: # TODO: some signatures of var_mean do support out
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14306: # TODO: some signatures of var_mean do support out
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14321: # TODO: some signatures of std_mean do support out
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14335: # TODO: some signatures of var_mean do support out
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14369: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14455: # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14467: # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14484: # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14499: # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14551: # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14566: # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14574: # necessary because np.heaviside incorrectly returns float64 when passed args of dtype int64
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14629: # is passed or not. Hence two OpInfo entries, one with dtype and other without.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14669: # is passed or not. Hence two OpInfo entries, one with dtype and other without.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14829: DecorateInfo(unittest.skip('Fails in most cases, passes on LAZY for some reason'), 'TestCommon', 'test_variant_consisten
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14869: # NotImplementedError: Could not run
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14899: # NotImplementedError: Could not run
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14926: # NotImplementedError: Could not run
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15173: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":104, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15213: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":104, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15276: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":104, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15317: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":103, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15357: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":103, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15411: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":103, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15497: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15508: # bool can't be passed to Scalar arguments in JIT tracer because
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15533: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15547: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15561: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15580: # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15610: # false INTERNAL ASSERT FAILED at "...torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15626: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15641: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15660: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15678: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15696: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15712: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15729: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15745: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15785: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15867: # locally for me but passes in CI.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15903: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15926: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15938: # TODO: add shape checks
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16003: # TODO: add shape checks
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16007: # TODO: investigate nondeterminism
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16388: # TODO Need to understand what this is testing and why it doesn't work
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16391: # TODO skip this for now since we can't skip on runtime arch support
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16436: # TODO: Skip because it produces a CUDA illegal memory access for some reason
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16476: # TODO: combine this with the nn.functional.silu OpInfo when
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16481: #   This is why the dtypes list above passes test_dtypes,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16655: # TODO(whc) should not need sample_inputs_func, but without it
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16677: # This test cannot handle a callable passed to `distance_function`. If we would use
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16678: # `distance_function=None`, the test would pass fine.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16711: # NotImplementedError: Cannot copy out of meta tensor; no data!
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16828: # TODO: FIXME
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16832: # FIXME: incorrectly tries to pass a rhs scalar
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16836: # TODO: FIXME, ideally by implemented grad for both inputs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16856: #                     # test does not work with passing lambda for op
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16872: # FIXME: incorrectly tries to pass a rhs scalar
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16876: # TODO: FIXME, ideally by implementing grad for both inputs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16898: #                     # test does not work with passing lambda for op
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17408: # Fails on CUDA but passes on ROCm
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17684: # TODO: FIXME tolerance is too high
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18138: # TODO(@heitorschueroff) update SampleInput to handle such cases
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18151: # test does not work with passing lambda for op
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18212: # test does not work with passing lambda for op
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18254: # test does not work with passing lambda for op
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18279: # TODO(@kshitij12345): Refactor similar to `mvlgamma` entries.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18414: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19272: # TODO: same as this?
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19397: # Computed gradient is incorrect -- would be an exfail but gradgrad somehow passes
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19546: # CUDA histc returns a float tensor but does not correctly warn when passed an integral out tensor
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19799: # JIT has issue when op is passed as lambda
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19858: OpInfo('trapz',  # TODO: in the future, 'trapz' should be made a proper alias of 'trapezoid'
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20160: # NotImplementedError: Could not run 'aten::normal_' with arguments from the 'SparseCPU' backend
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20162: # TODO: FIXME: complex inputs requiring grad error in forward
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20170: # TODO: implement csr.to_sparse(sample_dim) where sampled_dim is 1.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20303: # at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20316: # at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270, please report a bug to PyTorch.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20352: # is passed or not. Hence two OpInfo entries, one with dtype and other without.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20387: # If we pass `condition` first, none of the input which supports
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20608: # TODO Benchmark again with the new implementation
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20616: # Happens to pass on complex64. Also a mystery
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20682: # Happens to pass on complex64. Also a mystery
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20891: # TODO: Investigate why more granular skips in the test don't work in CI
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20933: # TODO skip this for now since we can't skip on runtime arch support (taken from scaled_dot_product_attention)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20993: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21006: # TODO: delete this OpInfo once we add meta support for grid_sampler_3d
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21130: # Adding it with 'generate_args_kwargs' does not work, since these also get passed
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21143: # FIXME: mean does not support passing keepdim without passing dim
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21298: # FIXME: prod does not support passing keepdim without passing dim
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21303: # FIXME: prod does not support passing None to dim
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21333: # FIXME: sum does not support passing keepdim without passing dim
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21462: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21492: # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21621: # Skip due to NotImplementedError for MPS device.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21909: # TODO: RuntimeError: no _refs support for torch.rand_like
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21910: DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21938: # TODO: RuntimeError: no _refs support for torch.rand_like
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21939: DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21970: # TODO: RuntimeError: no _refs support for torch.rand_like
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21971: DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21997: # TODO: RuntimeError: no _refs support for torch.rand_like
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21998: DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22024: # TODO: RuntimeError: no _refs support for torch.rand_like
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22025: DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22053: # TODO: RuntimeError: no _refs support for torch.rand_like
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22054: DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22083: # TODO: RuntimeError: no _refs support for torch.rand_like
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22084: DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22169: # TODO torch.ops.aten.copy is not in _refs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22221: # TODO copy doesn't have prim refs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22398: # This fails on CUDA but passes on ROCm
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22785: # Fails on CUDA but passes on ROCm
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23028: PythonRefInfo(  # TODO: Port this to an UnaryOpInfo
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23291: # NotImplementedError: argument of type: <class 'complex'>
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23764: # TODO: Uses minimum and clamp
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23792: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23800: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23808: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23819: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23849: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23857: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23865: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23873: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23884: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23895: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23906: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23914: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:23922: # TODO: If self already has the correct dtype and device, then self is
- .venv/lib/python3.12/site-packages/torch/testing/_internal/autocast_test_lists.py:55: # be skipped by passing TEST_WITH_ROCM flag to those ops in self.torch_fp16 list.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/inductor_utils.py:17: from torch._inductor.custom_graph_pass import CustomGraphModulePass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/inductor_utils.py:19: get_custom_backend_pass_for_device,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/inductor_utils.py:145: # TODO: Remove HAS_MPS condition  when `HAS_GPU` includes HAS_MPS
- .venv/lib/python3.12/site-packages/torch/testing/_internal/inductor_utils.py:311: custom_pass: CustomGraphModulePass = None
- .venv/lib/python3.12/site-packages/torch/testing/_internal/inductor_utils.py:323: original_custom_pass = get_custom_backend_pass_for_device(device)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/inductor_utils.py:332: custom_pass if custom_pass is not None else original_custom_pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/inductor_utils.py:342: original_custom_pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:494: # flaky test - TODO fix
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:593: torch._C._jit_pass_inline(CU.the_method.graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:594: torch._C._jit_pass_constant_propagation(CU.the_method.graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:686: # TODO: delete this list once we make all nn_tests work
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_subclass.py:9: # TODO: Move LoggingTensor here.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_subclass.py:43: raise NotImplementedError("You need to implement get_wrapper_properties")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:403: # TODO(future PR): consider combining with skipIfNoQNNPACK,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1248: # TODO: make img_data a single example instead of a list
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1430: # FIXME(rec): shouldn't qconfig be passed to quantize?
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1845: # TODO: remove this check and define two fuse_modules function on this module
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:2084: # TODO: self.fc should be self.conv
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:2099: # TODO: self.fc should be self.conv
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:2117: # TODO: self.fc should be self.conv
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:2271: # TODO: remove this check and define two fuse_modules function on this module
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:2853: # TODO: remove this check and define two fuse_model function on this module
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:118: # Construct parameter kwargs to pass to the test.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:151: """ Contains args and kwargs to pass as input to a function. """
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:160: """ Contains args / kwargs for module instantiation + forward pass. """
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:164: self.constructor_input = constructor_input  # Inputs to pass during construction
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:165: self.forward_input = forward_input  # Inputs to pass to forward()
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:176: # Note that module parameters are passed in for convenience.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:375: # TODO: Uncomment when negative weights is supported.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:542: single batch input before passing them to the module.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:588: single batch input before passing them to the module.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:607: single batch input before passing them to the module.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:631: single batch input before passing them to the module.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:654: The module is passed the input and target in batched form with a single item.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:1518: # TODO: add pos_weight to the definition here and corresponding SampleInputs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:2410: # Construct a TransformerEncoderLayer object to pass to TransformerEncoder.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:2474: # Samples below where we pass reference_fn are for validating the fast path,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:3159: # NotImplementedError: the derivative for '_cudnn_rnn_backward' is not implemented.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:3434: # tracking here rather than in the list in test_aotdispatch.py as eval mode passes
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:3454: # tracking here rather than in the list in test_aotdispatch.py as eval mode passes
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:3474: # tracking here rather than in the list in test_aotdispatch.py as eval mode passes
- .venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:20: # 2. Attempt __torch_function__. In LoggingTensor torch function is disabled so we bypass it entirely
- .venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:32: # TODO: TensorBase should work
- .venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:48: # TODO: clone storage aliasing
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:55: #    the Python module constructor arguments. For example, if in the test dict we pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:56: #    `(10, 8)` to `torch.nn.Linear` constructor, then we should pass `torch::nn::LinearOptions(10, 8)`
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:93: #    (Note that for `i`, since we want it to take the Python input value, we pass '_get_input()' string as value
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:145: # TODO: reference function
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:152: # TODO(#50743): Figure out the error. "RuntimeError: Unrecognized tensor type ID: Batched"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:1066: The module is passed the input and target in batched form with a single item.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2522: # TODO(#50743): figure out the error
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2808: # TODO: This code can path can be removed if #61309 is resolved
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3088: The criterion is passed the input and target in batched form with a single item.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3180: # TODO : Fix these discrepancies
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3210: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3214: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3218: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3225: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3323: # TODO: compare structure (ensure analytic jacobian has correct shape)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3402: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3409: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3441: # TODO: do this with in-memory files as soon as torch.save will support it
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3738: # TODO: torch.complex32 when properly supported
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3820: # TODO: check that criterions don't ignore grad_output
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:91: # TODO: FSDP non-recursive wrapping
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:96: # Move model to DEVICE before passing to the FSDP constructor
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:98: # Move model to DEVICE after passing to the FSDP constructor
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:120: """Runs the backward pass (e.g. including ``loss.backward()``)."""
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:853: parameters in the forward pass (in ms).
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:1479: # TODO: Disable checking the parameters for pure FP16 due to floating
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:1480: # point inaccuracy. Note that this means that the backward pass is not
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:1523: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/hypothesis_utils.py:131: # TODO: Maybe embed the enforced zero_point in the `torch.iinfo`.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:40: skip_but_pass_in_sandcastle,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:41: skip_but_pass_in_sandcastle_if,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:142: # TODO (kwen2501): what is the purpose of this decorator?  Tests with this
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:334: return skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:342: return skip_but_pass_in_sandcastle(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:346: return skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:353: return skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:360: return skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:367: return skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:396: return skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:407: return skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:427: return skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:620: # subprocesses. During the spawn, the main process passes the test name to
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:737: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:838: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:943: # TODO: we should pipe the exception of the failed subprocess here.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:978: # is some follow-up needed. Instead just "pass" the test
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1022: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1026: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1075: test_args: Positional arguments to pass to ``test_fn``.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1076: test_kwargs: Keyword arguments to pass to ``test_fn``.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1172: # TODO: get test name from kwargs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1236: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1239: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1291: # TODO: figure out a better way to do this
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1392: # "pass" the test with an appropriate message.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1665: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1725: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantized.py:164: # TODO: Update all quantization tests to use this decorator.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantized.py:264: # TODO document this better
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantized.py:297: # TODO: can the branch floating point comparisons below be done without
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:107: #     pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:157: #   passing "globals()" to instantiate_device_type_tests(), because it
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:168: #   pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:180: # The dtype is passed as a torch.dtype object.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:188: #   pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:217: #   pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:230: # It is important to use the passed device and dtype as appropriate. Use
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:240: #         If there are fewer devices than the value passed to the decorator
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:857: # TODO: remove "allow_xpu" option after Interl GPU support all test case instantiate by this function.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:893: # We want to call the @classmethod defined in the generic base, but pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:899: # We want to call the @classmethod defined in the generic base, but pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:947: # - supported_backward: Every dtype supported by the operator's backward pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:948: # - unsupported_backward: Run tests on dtypes not supported by the operator's backward pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:951: # - none: Useful for tests that are not dtype-specific. No dtype will be passed to the test
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1122: # Construct parameter kwargs to pass to the test.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1180: "An empty op_list was passed to @ops. "
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1294: raise unittest.SkipTest("TODO: Memory availability checks for XLA?")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1297: raise unittest.SkipTest("TODO: Memory availability checks for Intel GPU?")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1378: slf.fail("expected test to fail, but it passed")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1949: # TODO: the "all" in the name isn't true anymore for quite some time as we have also have for example XLA and MPS now.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:353: torch._C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:354: torch._C._jit_pass_dce(graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:355: torch._C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:356: graph = torch._C._jit_pass_canonicalize(graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:357: torch._C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:360: def run_pass(self, name, trace):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:368: torch._C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:369: result = getattr(torch._C, '_jit_pass_' + name)(graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:372: torch._C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:532: # TODO: check gradients for parameters, not just inputs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:688: # TODO(suo) remove
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:752: # TODO: Remove me once https://bugs.python.org/issue42666 is resolved
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:821: # TODO: inplace tests currently fail, fix and add inplace variant
- .venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:825: # TODO: find better way to standardize on op registration itself..
- .venv/lib/python3.12/site-packages/torch/testing/_internal/optests/autograd_registration.py:80: "we are unable to actually perform this test. Please pass inputs "
- .venv/lib/python3.12/site-packages/torch/testing/_internal/optests/autograd_registration.py:88: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/optests/aot_autograd.py:17: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/optests/generate_tests.py:579: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/optests/generate_tests.py:619: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/optests/generate_tests.py:698: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/optests/make_fx.py:29: "Note that if you passed a python function (and not an operator) to "
- .venv/lib/python3.12/site-packages/torch/testing/_internal/optests/make_fx.py:57: #   we use an expanded Tensor as we cannot pass "meta" Tensors to make_fx.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:498: #   passed to an operation and the errors they thrown are reviewed. Tests
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:740: # TODO: Warn if used
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:746: # TODO: After migration, start adding warnings here
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:792: # TODO: rename this to supports_bwgrad_bwgrad to be consistent with below
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:887: # TODO: rename supports_sparse to supports_sparse_coo
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1262: Please pass this to the sample generation function and run the test logic within the
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1387: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1478: raise NotImplementedError("no sample function specified")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1707: # TODO(@heitorschueroff) Once all reduction operators are using
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1711: # TODO(@heitorschueroff) Once all reduction operators are using ReductionOpInfo
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:2709: # TODO: in the future generalize the reference generators to handle n-ary elementwise operations
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/utils.py:57: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/utils.py:84: # only if all samples pass for the given dtype.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/utils.py:102: # and its string representation for the passed `dtypes`.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/utils.py:127: # If user passed dtypes which are lower than the lowest
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/utils.py:156: # Wrapper that passes PyTorch's default scalar
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:21: #   that list in the Sequence they pass to the @ops decorator.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:40: # yet. So, instead the local op_db must be passed in explicitly.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:54: "aliases": None,  # TODO add a check for alias coverage
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:56: "inplace_variant": None,  # TODO: add a check for inplace coverage
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/signal.py:303: # TODO: same as this?
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:40: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:57: # PyTorch on XLA throws an error when passed with dim argument for 0d tensor.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1425: # TODO: backward uses in-place operations that vmap doesn't like
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1535: # tests do not work with passing lambda for op
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:2316: # TODO: is this really needed?
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:337: # TODO: look in kwargs too?
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:346: # be sliced to pass to the reference
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:694: # TODO: Cover this in the set of error inputs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:757: # TODO: Reducing on ragged dim and non-batch dim is not supported;
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:838: # TODO: write this!
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:839: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:848: # TODO: write this!
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:849: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:853: # TODO: write this!
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:854: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:858: # TODO: write this!
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:859: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:897: # TODO: add Tensor case
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:953: # TODO (need factory functions):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:1071: # TODO (need factory functions):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:1380: # TODO: Handle this with error_inputs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:1423: # TODO: Handle these via error_inputs.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:1433: # multiple dim operation (pass no args)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:1446: # TODO: Handle this with error_inputs
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:1492: # (involving NJTs) to pass to the op. Full name consists of the OpInfo's name and variant name
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/nested.py:1584: # TODO: Translate the rest of the OpInfos
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:26: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:150: # TODO: remove this if-block after gh-98495 is fixed.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:215: # TODO: remove this if-block after gh-98495 is fixed.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:247: # TODO: remove this if-block after gh-98495 is fixed.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:379: # NotImplementedError: Could not run 'aten::sum.IntList_out' with arguments from the 'SparseCsrCPU' backend.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:41: # TODO: Consolidate `i0e` with sample_inputs_unary when `make_tensor`,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:69: # TODO: eliminate low after gh-106692 is fixed:
- .venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:241: # TODO: FIXME
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc_utils.py:84: # we call the generate_tests function of this file, passing to it a fixture for
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:86: skip_but_pass_in_sandcastle,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:87: skip_but_pass_in_sandcastle_if,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:185: skipIfNoTorchVision = skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:234: # Error message substring when find_unused_parameters=True has not been passed
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:236: "passing the keyword argument `find_unused_parameters=True`"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:443: return skip_but_pass_in_sandcastle(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:448: return skip_but_pass_in_sandcastle(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:456: return skip_but_pass_in_sandcastle(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:844: Exception, "failed to pass monitoredBarrier"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:854: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:856: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:859: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:868: # Explicitly pass world size to the barrier because we've
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:884: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:893: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:902: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:920: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:954: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:963: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:976: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1002: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1021: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1037: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1051: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1092: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1172: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1216: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1306: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1340: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1375: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Batch Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1415: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Batch Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1438: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Batch Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1466: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Batch Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1499: @skip_but_pass_in_sandcastle_if(BACKEND != "gloo", "GLOO Batch Send Recv CPU")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1522: @skip_but_pass_in_sandcastle_if(BACKEND != "gloo", "GLOO Batch Send Recv CPU")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1545: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Batch Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1559: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Batch Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1569: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Batch Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1588: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1591: # TODO: now that nccl send/recv is supported, there does not seem to
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1637: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1643: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1650: @skip_but_pass_in_sandcastle_if(BACKEND != "nccl", "NCCL Send Recv Only")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1652: @skip_but_pass_in_sandcastle_if(IS_FBCODE, "Kineto in fbcode causes hang")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1653: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1707: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1713: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1720: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1723: @skip_but_pass_in_sandcastle_if(IS_FBCODE, "Kineto in fbcode causes hang")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1724: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1810: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1817: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1825: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1829: @skip_but_pass_in_sandcastle_if(IS_FBCODE, "Kineto in fbcode code causes hang")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1830: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1873: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1879: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1886: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1889: @skip_but_pass_in_sandcastle_if(IS_FBCODE, "Kineto in fbcode code causes hang")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1890: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1944: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1950: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1957: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1960: @skip_but_pass_in_sandcastle_if(IS_FBCODE, "Kineto in fbcode code causes hang")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1961: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1970: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2069: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2076: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2089: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2096: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2103: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2160: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2163: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2179: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2182: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2204: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2207: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2223: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2226: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2236: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2239: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2249: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2252: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2269: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2272: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2289: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2292: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2303: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2306: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2317: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2320: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2336: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2339: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2355: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2358: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2368: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2371: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2423: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2426: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2442: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2445: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2467: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2470: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2540: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2590: # TODO: move this test to use torch.profiler once kineto issues are
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2681: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2696: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2712: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2733: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2755: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2771: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2790: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2812: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2827: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2836: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2846: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2862: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2878: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2888: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2897: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2912: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2927: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2936: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2957: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2963: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3011: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3224: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3227: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3252: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3255: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3262: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3271: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3274: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3281: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3292: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3295: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3303: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3306: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3343: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3346: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3371: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3374: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3381: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3390: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3393: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3401: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3404: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3445: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3452: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3461: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3468: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3480: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3487: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3494: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3559: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3580: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3633: # TODO: Instead we should probably go through _rank_not_in_group
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3669: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3677: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3688: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3696: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3704: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3828: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3835: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3850: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3859: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3870: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3877: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3892: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3901: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3917: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3924: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3933: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3940: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3951: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3959: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3975: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3983: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3999: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4007: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4017: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4024: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4039: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4046: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4061: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4068: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4110: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4113: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4123: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4133: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4141: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4150: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4158: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4374: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4380: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4386: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4397: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4413: @skip_but_pass_in_sandcastle_if(BACKEND == "nccl", "Gloo-only test")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4435: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4473: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4525: # After second forward pass, hook should still be empty string
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4678: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4705: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:4725: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5122: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5130: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5136: # process_group is passed in to both DDP and comm. hook
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5143: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5160: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5335: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5346: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5357: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5366: passed as gradients in reducer.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5385: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5395: whether final result was properly passed as gradients in reducer.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5419: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5443: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5515: # Runs the forward pass with autocasting.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5521: # Backward passes under autocast are not recommended.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5546: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5754: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5766: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5785: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5798: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5812: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5823: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5884: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5929: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5954: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6000: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6047: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6090: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6114: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6205: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6354: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6410: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6437: # it need to recursively pass the `process_group` in the module when the `SyncBatchNorm`
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6486: # TODO: NCCL backend does not work correctly for bitwise reduction ops
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6561: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6725: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6736: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6744: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6768: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6817: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6877: 2. A second profiling pass after running some iterations of DDP, to check robustness of thread local state.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6880: profiler_ctx : Profiler context manager for pass 1
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6881: profiler_ctx2 : Profiler context manager for pass 2.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6926: # for a single pass, and ensure it is recorded. This tests that the
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6957: @skip_but_pass_in_sandcastle("Currently failing in NVIDIA internal CI")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6964: @skip_but_pass_in_sandcastle_if(IS_FBCODE, "Kineto in fbcode code causes hang")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6965: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7052: @skip_but_pass_in_sandcastle_if(IS_FBCODE, "Kineto in fbcode code causes hang")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7053: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7070: # collect ET in second profiler pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7084: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7160: # Determine num iters for this rank via the passed in mapping.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7242: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7301: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7494: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7528: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7672: # Note that the model can have different shape buffers if we pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7977: # if rank is 0, uses nn1 on the first pass and nn2 on the second pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:7978: # else, uses nn3 on the first pass and nn4 on the second pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8342: # if we don't pass a logger then we can only check that an exception was thrown.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8395: # if we pass a logger we can verify that it was logged
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8415: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8423: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8445: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8463: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8584: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8594: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8604: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8610: # TODO: enable this for general training use cases:
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8688: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8697: # Run monitored barrier and ensure it passes
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8710: RuntimeError, f"Rank {failed_rank} failed to pass monitoredBarrier"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8714: # Other ranks should not pass barrier since rank 0 failed.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8740: RuntimeError, f"Rank {failed_rank} failed to pass monitoredBarrier"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8785: # depending on wait_all_ranks flag passed into monitored_barrier.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8790: err_regex = f"Ranks {rank_str} failed to pass monitoredBarrier"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8793: err_regex = f"Rank {expected_first_fail_rank} failed to pass monitoredBarrier"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8833: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8839: # multiple ranks fail to pass the monitored_barrier.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8840: # TODO(#54879): Provide ability to wait and report all failed ranks
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8866: err_regex = f"Ranks {rank_str} failed to pass monitoredBarrier"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8933: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9092: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9135: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9188: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9209: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9297: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9337: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9438: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9446: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9514: # at the end of the backwards pass for maximum overlap.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9521: # is pre-forward pass. This is because the hook does async
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9522: # communication and forward pass modifies the buffer without
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9531: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9539: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9547: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9584: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9610: # Run with error to trigger backward pass that marks fc1 as being marked
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9635: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9801: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9810: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9819: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9869: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9883: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9925: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:9979: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:10005: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:10044: # run a backward pass and check the gradients
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:10215: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:10220: @skip_but_pass_in_sandcastle_if(True, "Skipped due to flakiness")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:10269: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:10299: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/multi_threaded_pg.py:30: TODO:
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/multi_threaded_pg.py:134: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/multi_threaded_pg.py:211: raise NotImplementedError(f"ReduceScatter does not support {op}")
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/multi_threaded_pg.py:482: # the prefix store is already per group so we pass an empty name here
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:507: # TODO: dist tensor need to support quantized and sparse
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:542: # TODO: add multi mesh choices
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:64: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:73: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:78: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:94: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:352: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:505: # Create a remote module on worker1 and then pass it to worker2 over the RPC layer.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:546: # Create a remote module on worker1 and then pass it to worker2 over the RPC layer.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:562: # Create a remote module on worker1 and then pass its `module_rref` to worker2 over the RPC layer.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:632: r"For debugging consider passing AMD_SERIALIZE_KERNEL=3"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:719: # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:725: # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:751: # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:45: skip_but_pass_in_sandcastle_if,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:497: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:565: # TODO: use torch.futures.collect_all
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:1391: # TODO: with TCP init, rank 0 raises Address already in use because
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3008: def test_pass_local_rrefs(self):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3264: # pass in graceful=False to ensure that we don't wait for other workers.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3292: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3365: # pass in graceful=False to ensure that we don't wait for other workers.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3391: Tests that if no timeout is passed into rpc_async and rpc_sync, then the
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3427: # TODO: enable timeouts for rpc.remote/RRef (https://github.com/pytorch/pytorch/issues/33803)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3450: # still overridden if we pass in a different timeout to the APIs.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3482: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3692: # pass in graceful=True to ensure that local UserRRefs are deleted.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4215: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4248: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4301: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4375: # Do _not_ pass backend.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4582: # Do _not_ pass backend.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4650: # creation is slower than timeout passed into _get_type.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:5011: # TODO: Cuda RPC is failing due to:
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_optimizer_test.py:50: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_optimizer_test.py:64: args: positional arguments to pass to the method
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_optimizer_test.py:65: kwargs: keyword arguments to pass to the method
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_optimizer_test.py:84: args: positional arguments to pass to the method
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_optimizer_test.py:85: kwargs: keyword arguments to pass to the method
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:22: skip_but_pass_in_sandcastle_if,
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:211: raise Exception("Simulate error on backward pass")  # noqa: TRY002
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:518: # NB: RRef.to_here() always passes the autograd context to the
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:522: # rpc/remote with udf (_set_rpc_done here) also always passes the
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:630: # The current rank first creates a tensor on the rref_owner, and then passes
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:712: # kick off forward and backward pass on three other workers (trainers)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:723: # check if the trainers have done with their backward pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:934: # For a context passed from previous nested chain calls, this rank
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:962: # For a context passed from previous nested chain calls, this rank
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1292: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1405: # the autograd context ID is still passed to other workers.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1449: # applying those functions in the backwards pass is a subset of the entire backward pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1539: # TODO, need more investigation
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1541: # ref as arg is passed to pybind boundary, and the ref is not garbage
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1629: # backward pass would hang in the "FAST" mode.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1673: RuntimeError, "Error on Node [0-9]+: Simulate error on backward pass"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1679: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1711: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1863: RuntimeError, "Simulate error on backward pass"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1870: @skip_but_pass_in_sandcastle_if(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1995: # Call MyBackwardFunc as the first op of the backward pass to
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1996: # ensure we release the context early in the backward pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2054: backward_passes = int(debug_info["num_current_backward_passes"])
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2059: assert backward_passes >= 1 and backward_passes <= 4
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2079: # Call custom function in middle of backward pass to ensure all
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2110: self.assertEqual(0, int(debug_info["num_current_backward_passes"]))
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2111: # only have `num_current_backward_passes` and `num_autograd contexts`
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2216: RuntimeError, "Simulate error on backward pass"
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2494: # due to slow add, the continuation of this backward pass will be
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2630: def test_device_maps_backward_pass(self):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2634: # The reverse of this device mapping should be used for the backward pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:2676: # The reverse of this device mapping should be used for the backward pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_agent_test_fixture.py:33: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_agent_test_fixture.py:38: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/examples/parameter_server_test.py:3: # If you need to modify this file to make this test pass, please also apply same edits accordingly to
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/examples/reinforcement_learning_rpc_test.py:3: # If you need to modify this file to make this test pass, please also apply same edits accordingly to
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/examples/reinforcement_learning_rpc_test.py:257: # Other ranks are observers that passively wait for instructions from the agent.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:270: # pass rref to another user in rpc call
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:278: # pass rref to another user in remote call
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:307: def test_future_passed_between_python_and_jit(self):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:365: pass
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:641: def test_kwargs_not_passed(self):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:648: def script_rpc_async_call_without_kwargs_passed(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:656: ret = script_rpc_async_call_without_kwargs_passed(dst_worker_name)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:660: def test_args_kwargs_are_neither_passed(self):
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:667: def script_rpc_async_call_without_args_kwargs_passed(
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:674: ret = script_rpc_async_call_without_args_kwargs_passed(dst_worker_name)
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:930: # TODO, need more investigation
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:932: # ref as arg is passed to pybind boundary, and the ref is not garbage
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:946: # pass rref arg to owner
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:954: # pass rref arg to self/user
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:986: # Run forward pass remotely.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:993: # forward pass.
- .venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:1151: # TODO: Can't get a reliable time for this profiling event since
- .venv/lib/python3.12/site-packages/torch/_lazy/computation.py:8: IR for the passed in lazy tensors.
- .venv/lib/python3.12/site-packages/torch/_lazy/computation.py:10: TODO: This API is currently ts backend specific. We are working on
- .venv/lib/python3.12/site-packages/torch/_lazy/computation.py:17: """Return the graph hash for the passed in lazy tensors"""
- .venv/lib/python3.12/site-packages/torch/_lazy/computation.py:24: TODO: This API is currently ts backend specific. We are working on
- .venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:128: # TODO: This solution is no ideal since we may miss some factory methods. In future
- .venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:185: # TODO: this part is TS backend specific for now and will be generalized to
- .venv/lib/python3.12/site-packages/torch/_lazy/closure.py:11: pass
- .venv/lib/python3.12/site-packages/torch/_lazy/closure.py:104: args (tuple): The arguments to be passed to the closure.
- .venv/lib/python3.12/site-packages/torch/_lazy/__init__.py:16: # TODO(whc) expand this to include backend hooks and align with XLA backend needs
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:28: # TODO update desc with new config args
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:95: TODO: Need a clean way of loading the state of the "prepared" module
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:165: self.model = model  # TODO: Need to figure out how to load without this.
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:172: # TODO: Remove the configuration by reference ('module')
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:297: # TODO handle multiple tensor being quantized on a single module, where to store sparse_params?
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:318: raise NotImplementedError("Need to auto generate mapping ")
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:353: pass
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/weight_norm_sparsifier.py:82: raise NotImplementedError(f"L-{norm} is not yet implemented.")
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/utils.py:21: # see if any of the module tensors have a parametriztion attached that matches the one passed in
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/utils.py:32: r"""Swaps the module using from_dense according to the mapping passed in.
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/utils.py:42: # TODO Fix this typing, as Type[Module] has no attribute "from_dense"
- .venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/utils.py:121: Once the mask is passed, the variable should not change the id. The
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:45: calling the reduce_fn(). This is used by default if a custom one is passed in the
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:47: Note that the mask_fn() definition should contain the sparse arguments that is passed in sparse_config
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:58: Default configuration for the mask_fn. This config will be passed
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:126: """Makes sure that some of the functions and attributes are not passed incorrectly"""
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:140: """Returns hook that computes aggregate of activations passing through."""
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:206: - There is no need to pass in the name of the layer as it is automatically computed as per
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:209: - All the functions (fn) passed as argument will be called at a dim, feature level.
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:375: TODO: Might have to treat functions (reduce_fn, mask_fn etc) in a different manner while serializing.
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/pruner/parametrization.py:9: # see if any of the module tensors have a parametriztion attached that matches the one passed in
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/pruner/base_structured_sparsifier.py:110: # TODO LSTM Structured pruning does not support returned state currently.
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/pruner/prune_functions.py:63: raise NotImplementedError(f"Type {type(next_layer)} not supported yet.")
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/pruner/FPGM_pruner.py:47: raise NotImplementedError("Distance function is not yet implemented.")
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_scheduler/base_data_scheduler.py:23: A specific hyperparameter of the passed sparsifier that needs to be scheduled/varied
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_scheduler/base_data_scheduler.py:25: This is specifically is passed when training needs to be resumed from a particular
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_scheduler/base_data_scheduler.py:109: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/base_data_sparsifier.py:34: pass
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/base_data_sparsifier.py:75: raise NotImplementedError("this function is undefined for this class")
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/base_data_sparsifier.py:309: # need name for the mask otherwise can directly pass mask?
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/base_data_sparsifier.py:314: pass
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/quantization_utils.py:49: config that will be passed to the constructor of data sparsifier object.
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/lightning/callbacks/data_sparsity.py:32: Note: Objects should not be passed in here as they are created
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/lightning/callbacks/data_sparsity.py:36: Dictionary of args to be passed to the data sparsifier.
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/lightning/callbacks/data_sparsity.py:79: Note: Objects should not be passed in here as they are created
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/lightning/callbacks/data_sparsity.py:83: Dictionary of args to be passed to the data sparsifier.
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/lightning/callbacks/data_sparsity.py:88: Note: Objects should not be passed in here as they are created
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/lightning/callbacks/data_sparsity.py:92: Dictionary of args to be passed to the data scheduler.
- .venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/data_sparsifier/lightning/callbacks/data_sparsity.py:94: creates and pass sparsifier object into the class**
- .venv/lib/python3.12/site-packages/torch/ao/pruning/scheduler/base_scheduler.py:97: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/qat/modules/conv_fused.py:134: """Approximated method to fuse conv and bn. It requires only one forward pass.
- .venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/qat/modules/conv_fused.py:165: It requires two forward passes but handles the case bn.weight == 0
- .venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/qat/modules/conv_fused.py:268: # TODO(jerryzh): extend
- .venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/qat/modules/conv_fused.py:341: pass
- .venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/dynamic/modules/linear_relu.py:38: # TODO check if we should set reduce_rage = True by default here
- .venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:20: # TODO: factor out the common parts to ConvNd
- .venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:51: # TODO: Add qat support for BNReLU2d
- .venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:100: # TODO: Add qat support for BNReLU3d
- .venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/modules/fused.py:39: pass
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:14: # TODO (zaf): Inherit from `quantized.LinearPackedParams` (T83294430)
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:22: raise NotImplementedError("Linear prepacking only supports QINT8")
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:101: # TODO (zaf): Inherit from `quantized.Linear` (T83294430)
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:122: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:225: TODO(zaf): Need to add the sparse params to the qconfig
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:237: # TODO: Need to add options to qconfig to avoid the calibration.
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:238: # TODO: Add calibration for the sparsity
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/utils.py:42: pass
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:38: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:149: # TODO: Need to add options to qconfig to avoid the calibration.
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:150: # TODO: Add calibration for the sparsity
- .venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:165: # TODO (zaf): Mask might not be part of the qconfig (T83295194)
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/activation.py:272: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/activation.py:360: # TODO: This method has some duplicate lines with the
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/rnn.py:141: # TODO: make this tanh a member of the module so its qparams can be configured
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/rnn.py:595: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:227: raise NotImplementedError("Only zero-padding is supported!")
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:229: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:233: raise NotImplementedError("Only torch.qint8 is supported for weight tensor!")
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:299: raise NotImplementedError("Only zero-padding is supported!")
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:301: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:305: raise NotImplementedError("Only torch.qint8 is supported for weight tensor!")
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:375: raise NotImplementedError("Only zero-padding is supported!")
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:377: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:381: raise NotImplementedError("Only torch.qint8 is supported for weight tensor!")
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:495: raise NotImplementedError("return_indices is not yet implemented!")
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/functional.py:526: raise NotImplementedError("return_indices is not yet implemented!")
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:72: # TODO(jerryzh168): maybe make this arg a required arg
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:96: # TODO: refactor the duplicated code to utils.py
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:157: we need to pass in a `weight_qparams_dict` that maps from weight name,
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:182: # TODO: refactor nn.RNNCell to have a _forward that takes weight_ih and weight_hh as input
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:221: ret = input  # TODO: remove when jit supports exception flow
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:250: we need to pass in a `weight_qparams_dict` that maps from weight name,
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:327: we need to pass in a `weight_qparams_dict` that maps from weight name,
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:428: # TODO(jerryzh168): maybe make this arg a required arg
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:488: We'll store weight_qparams for all the weights in _flat_weights, we need to pass in
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:633: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:697: We'll store weight_qparams for all the weights in _flat_weights, we need to pass in
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:746: # TODO: maybe we can try inheriting from that class and define get_flat_weights
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:792: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:204: # TODO: add an util function for converting qdtype to dtype
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:230: # TODO: torch.quint4x2 is not supported
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:260: # TODO: get the quant_min and quant_max from activation_post_process
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:266: # TODO: add an util function for converting qdtype to dtype
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:290: # TODO: torch.quint4x2 is not supported
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:316: # TODO: dedup with __init__ of RNNBase
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:401: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:554: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:849: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:1082: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:1143: # TODO: these can be simplified to one level? e.g. using weight_ih as key
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:1158: # TODO: these can be simplified to one level? e.g. using weight_ih as key
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:1254: ret = input  # TODO: remove when jit supports exception flow
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/embedding_ops.py:31: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/embedding_ops.py:40: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/embedding_ops.py:49: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/embedding_ops.py:240: # Create quantized Embedding module and pass in the quantized weight
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/embedding_ops.py:384: # Create quantized EmbeddingBag module and pass in the quantized weight
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/activation.py:238: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/activation.py:255: # TODO: This is a potential source of accuracy drop.
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/rnn.py:45: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/utils.py:21: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:55: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:121: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:124: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:127: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:155: # TODO: maybe change to this when https://github.com/pytorch/pytorch/pull/32958 is landed
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:120: from .fx.graph_passes import add_loggers_to_model, create_a_shadows_b
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:219: # TODO(future PR): consider designing this better, as the difference
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:225: # TODO(future PR): consider refactoring this to better reuse the parent
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:252: # TODO(future PR): make the comparison function configurable
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:409: # TODO(future PR): expose these
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:448: # TODO(future PR): do not observe nodes we do not care
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:550: # TODO(future PR): expose these
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:588: # TODO(future PR): better check when scripted
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:632: # TODO(future PR): align on naming
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:726: # TODO(future PR): expose these
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:879: a single pass through the model.
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:881: High level TODOs for future PRs:
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:920: # TODO(future PR): deduplicate repeating entries
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:931: #     2. pass original args, original kwargs, and expected output to module
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:952: # TODO(future PR): we should rethink the names of all the PNP APIs
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:1033: # TODO(future PR): we should rethink the names of all the PNP APIs
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:1051: # passing inputs through the model is necessary to populate
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:1059: # TODO(future PR): consider aligning API signature with other similar quantization
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:1070: # TODO(future PR): consider aligning API signature with other similar quantization
- .venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:1094: # TODO(future PR): consider matching in a safer way than
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/ns_types.py:19: # TODO(future PR): see if we can use typing_extensions's TypedDict instead
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:484: # TODO(future PR): clean this up
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:527: # TODO(future PR): implement shadowing for binary ops and
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:9: from torch.ao.ns.fx.graph_passes import _maybe_get_fqn
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:11: from torch.ao.ns.fx.utils import (  # TODO(future PR): make this work correctly for methods
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:26: # TODO(future PR): reuse existing mapping instead of creating a new one
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:111: # TODO(future PR): try reversed(list(matches.items()))
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:164: # TODO(future PR): make this code less confusing,  see discussion
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:244: # TODO(future PR): reconsider the design to make this more intuitive.
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:286: pass
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:308: # TODO(future): some graphs could have placeholders which are unrelated
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:349: # TODO(future PR): handle non-normalized kwargs
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:375: # ops with two or more arguments which need to be passed from
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:381: # TODO(future PR): this is not handling complicated graphs correctly, need to
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:383: # TODO(future PR): this is ignoring kwargs, will need to support kwargs
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:472: # TODO(future PR): move logger classes to utils to remove circular dependency
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:510: # TODO(future PR): deduplicate equivalent qconfigs that come from
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:555: # TODO(future PR): handle fusion patterns where non-first nodes
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:558: # pass in all node args and kwargs
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:578: # TODO(future PR): clarify why we are adding kwargs to args
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:628: # TODO(future PR): implement this
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:646: # TODO(future PR): add a test case for this once we have an easy
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:661: # TODO(future): consider making this configurable
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:748: # TODO(future PR): move logger classes to utils to remove circular dependency
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:861: # TODO(future PR): make this support all possible args/kwargs
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:876: # cur_node_orig.name,  # TODO(future PR): set name explicitly
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1054: # TODO(future PR): move this to config
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1066: # TODO(future PR, if needed): support kwargs
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1067: # TODO(future PR, if needed): support multiple shadow users
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1071: # TODO(before land): fix string match
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1144: # TODO(future PR): redesign this to make it easier to consume outputs
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1237: # TODO(future PR): redesign this to make it easier to consume outputs
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1317: # TODO(future PR): redesign this to make it easier to consume outputs
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/qconfig_multi_mapping.py:58: Note: Usage of set methods is the same as in QConfigMapping except with a passed in list of QConfigs rather than a
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:70: # TODO(future PR): make more generic, handle everything
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:155: # TODO(future PR): why does packed_weight.unpack() not work?
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:22: # TODO(future PR): allow customizations
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:23: # TODO(future PR): reuse existing quantization mappings
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:24: # TODO(future PR): add the rest of modules and ops here
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:70: # TODO(future PR): allow customizations from default patterns.
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:75: # TODO: this is a temporary hack to flatten the patterns from quantization so
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:95: # TODO(future PR): if needed, implement matching for a node
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:23: # TODO(future PR): consider deleting this enum and using the torch types
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:30: # TODO(future PR): while these functions can support multiple dtypes,
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:35: # TODO(future PRs): dynamic quant, fake quant, etc
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:44: # TODO(future PR): clean this up
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:197: # TODO(future PR): handle more functionals
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:198: # TODO(future PR): handle functional ops which inherit qparams from input
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:315: # TODO(future PR): use relationship map instead of hardcoding
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:168: pass
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:284: # TODO(future PR): determine the actual dtype of node_c,
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:367: # TODO(future PR): add handling for quantize_per_tensor
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:393: # TODO(future PR): look into using copy_node API instead
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:506: pass
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:508: pass
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:517: pass
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:519: pass
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:537: TODO(before land): real docblock
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:560: # TODO(future PR): enable multiple inputs for nodes which are not at start of subgraph
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:984: # TODO: explain this
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:1034: # such an op, pass the second param as well. Note: dtype casting
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:189: # TODO(next): make this code handle matching by what is before the base op
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:217: # TODO(future PR): check for matches start_op_node and base_op_node
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:410: pass
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:414: pass
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:437: are not related. Please ensure that the two models you pass in have the same number
- .venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:463: one of which is empty. Please ensure that the two models you pass in have the same number
- .venv/lib/python3.12/site-packages/torch/ao/quantization/_learnable_fake_quantize.py:51: # also pass quant_min and quant_max to observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:119: "in a future version. Please pass in a PrepareCustomConfig instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:231: "in a future version. Please pass in a FuseCustomConfig instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:272: Tuple of positional args (keyword args can be passed as positional args as well)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:354: # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:493: # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:536: "in a future version. Please pass in a ConvertCustomConfig instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:587: The keys must include the ones in the qconfig_mapping passed to `prepare_fx` or `prepare_qat_fx`,
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:619: # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:670: # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:722: # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:99: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:103: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:195: # TODO: keeping self.quant_min/max for BC; remove after a couple releases
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:285: # i.e., These buffers start out with numel 0 and become numel 1 once they have their first forward pass.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:329: # TODO: rename observer to observer_ctr
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:471: # TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:60: model_c = torch._C._jit_pass_fold_convbn(model_c)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:75: model_c = torch._C._jit_pass_insert_observers(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:97: torch._C._jit_pass_inline(method_graph)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:99: model_c = torch._C._jit_pass_insert_observer_method_for_ondevice_ptq(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:133: model_c = torch._C._jit_pass_insert_quant_dequant(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:144: model_c = torch._C._jit_pass_quant_finalize(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:151: torch._C._jit_pass_constant_propagation(model.graph)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:152: torch._C._jit_pass_dce(model.graph)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:169: model_c = torch._C._jit_pass_insert_quant_dequant_for_ondevice_ptq(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:172: model_c = torch._C._jit_pass_quant_finalize_for_ondevice_ptq(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:243: torch._C._jit_pass_constant_propagation(model.graph)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_jit.py:244: torch._C._jit_pass_dce(model.graph)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:173: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:177: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:325: torch.quint8 datatypes, the user can choose to use dynamic quantization range by passing
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:359: # as far as I can tell is not allowed to passed as a parameter in torchscript functions. This makes refactoring observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:362: # TODO(jakeszwe, jerryzh168)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:410: # TODO: switch to scale.item() after adding JIT support
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:413: # TODO: switch to zero_point.item() after adding JIT support
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:426: raise NotImplementedError("Cannot reset min/max values in the given observer.")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:431: # TODO(after v1.13): delete this
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:515: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:519: # TODO: MinMaxObserver by itself doesn't support dynamic quantization, but
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:548: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:641: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:648: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:726: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:731: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:754: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:932: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:937: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1023: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1028: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1306: # TODO: For some reason, this is required for it to pass torchscript test
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1436: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1457: Observer that doesn't do anything and just passes its configuration to the
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1466: quant_min: minimum value in quantized domain (TODO: align behavior with other observers)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1559: Observer that doesn't do anything and just passes its configuration to the
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:2111: # TODO(future PR): remove these defaults and enforce activation functions
- .venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:2119: # TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
- .venv/lib/python3.12/site-packages/torch/ao/quantization/_equalize.py:220: If you pass multiple modules in the same list, they will all be equalized together.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quant_type.py:26: # TODO: make this private
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:55: # TODO remove this once BC is no longer required to avoid a SEV
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:239: # TODO remove Dropout special after codebase stable
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:274: # TODO: These are the modules that cannot be observed
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:384: # TODO: remove allow_list
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:394: "passed correct configuration through `qconfig_dict` or "
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:408: # TODO: maybe we should change activation_post_process to _activation_post_process
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:432: # TODO: rename to something more general
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:52: # TODO: deprecated, remove
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:112: "QConfig received observer instance, please pass observer class instead. "
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:145: "QConfigDynamic received observer instance, please pass observer class instead. "
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:283: # TODO: make this compatible with xnnpack constraints
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:445: # TODO: make this compatible with xnnpack constraints
- .venv/lib/python3.12/site-packages/torch/ao/quantization/_correct_bias.py:52: of the data passed to the floating point and quantized models
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fuser_method_mappings.py:59: raise NotImplementedError(f"Cannot fuse train modules: {(conv, bn)}")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fuser_method_mappings.py:104: raise NotImplementedError(f"Cannot fuse train modules: {(conv, bn, relu)}")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fuser_method_mappings.py:116: raise NotImplementedError(f"Cannot fuse eval modules: {(conv, bn, relu)}")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:23: # TODO(future PR): improve this.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:30: # TODO: not sure if typing supports recursive data types
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:37: # TODO: maybe rename this to MatchInputNode
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:120: # TODO: not used now, remove
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:122: # TODO: reuse is_fixed_qparam_node after we move this function to _lower_to_native_backend.py
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:435: # TODO(jerryzh): Figure out why custom quant_min/quant_max are still adjusted.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:542: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:556: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:578: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:598: torch.quint8 datatypes, the user can choose to use dynamic quantization range by passing
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:618: # as far as I can tell is not allowed to passed as a parameter in torchscript functions. This makes refactoring observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:620: # (last update over 1 year ago) and when torchscript is fully deprecated we can refactor. TODO(jakeszwe, jerryzh168)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:684: # TODO: switch to scale.item() after adding JIT support
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:687: # TODO: switch to zero_point.item() after adding JIT support
- .venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:705: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:4: from torch._export.passes.constant_folding import constant_fold
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:5: from torch.ao.quantization.pt2e.duplicate_dq_pass import DuplicateDQPass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:6: from torch.ao.quantization.pt2e.port_metadata_pass import PortNodeMetaForQDQ
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:17: from torch.fx.passes.infra.pass_manager import PassManager
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:96: # TODO: check qconfig_mapping to make sure conv and bn are both configured
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:98: # TODO: (maybe) rewrite this with subgraph_rewriter
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:179: # TODO: only fuse if conv and bn are both configured to be quantized
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:242: f"please make sure you intend to pass argument {use_reference_representation} to convert_pt2e"
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fuse_modules.py:61: raise NotImplementedError(f"Cannot fuse modules: {types}")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:179: # TODO: merge with default static mapping
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:342: # TODO: merge with get_static_quant_module_class
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:36: # TODO: replace all usages with these constants
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:43: # TODO: derive this map from the BackendConfig
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:120: # TODO Currently it's required that separate ops in a fused op/module have the same qconfig.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:135: # TODO: add assert for backend choices
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:319: # TODO: remove this
- .venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:346: # TODO: remove this
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:163: # TODO: remove this class, this is still exposed in torch.ao.quantization
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:166: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:170: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:173: # TODO: remove this class
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:175: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:178: # TODO: remove this class
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:180: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:183: # TODO: remove this class
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:185: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:188: # TODO: remove this class
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:190: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:193: # TODO: remove this class
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:195: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:198: # TODO: remove this class
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:203: # TODO: remove this class
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:205: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:208: # TODO: remove
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:210: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:213: # TODO: remove
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:215: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:218: # TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:220: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:223: # TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:225: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:18: # TODO: move all LSTM util functions from fx/utils.py to this file
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:105: # TODO: maybe make this work for layer_bw as well
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:18: # TODO(future PR): the 1st argument is typed as `List[Node]`, but a better type
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:141: # TODO: 1. merge with fuse matcher 2. document the code
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:24: # TODO: replace all usages with these constants
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:183: # TODO: remove this
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:418: # TODO: remove this
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:497: # TODO: remove this
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:26: # Helper to check the passed in quant min and max are valid for the dtype
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:164: # TODO: remove other variants and keep this one
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:275: # TODO: investigate why
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:368: # TODO: remove other variants and keep this one
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:999: # TODO: support fp16
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:1009: # TODO: dtype is ignored for now
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:1030: # TODO: check for dtype, currently we can't express torch.int4 so it's omitted
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:33: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:48: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:109: # TODO: change the signature for fuser_method to take matched module patterns
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:127: # TODO: is this logic right?
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:152: # TODO: probably should cleanup this condition check, it's hard
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:199: # TODO: we can add the information of whether a value needs to
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:211: # TODO: maybe need more complex attr name here
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:307: # TODO: we can add the information of whether a value needs to
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:409: # TODO: probably should cleanup this condition check, it's hard
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:439: # TODO: we can add the information of whether a value needs to
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:443: # TODO: maybe need more complex attr name here
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:463: # TODO: get reduce range from observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:488: # TODO: we can add the information of whether a value needs to
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:505: # TODO: DeQuantStubs are currently inserted only after custom module LSTM, while observers are inserted
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:599: TODO: this logic is hacky, we should think about how to remove it or make it more
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:640: # TODO: it's not used, so actually we can skip quantization
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:691: # TODO: remove is_reference flag
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:724: # TODO: allow convert_custom_config to override backend_config
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:784: # TODO: rename weight_is_statically_quantized to weight_is_int8_quantized
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:799: # TODO: move this to the reference quantized module
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:927: TODO: maybe we want to redesign this part to align with reference model design
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:952: # TODO: This is the first step in enabling the full fx custom module
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1030: "in a future version. Please pass in a ConvertCustomConfig instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1039: "in a future version. Please pass in a QConfigMapping instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1052: "in a future version. Please pass in a BackendConfig instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1085: # TODO refactor this code once we update the prepare logic to have additional information on
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1251: # TODO: maybe move this to quantize_fx.py
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1257: # TODO: this looks hacky, we want to check why we need this and see if we can
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:267: # TODO: correct the namespace for these modules
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:273: # TODO: merge with STATIC_LOWER_MODULE_MAP after we merge
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:302: # TODO: LinearLeakyReLU is registered as global but it is only fused and
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:398: # TODO: add tests for lowering these ops
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:613: # Match dequantize node(s). Both of the following conditions must pass:
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:674: # This pass only support op of "call_module"
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:852: # TODO: maybe define a WeightedDynamicallyQuantizedModule
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:876: # TODO: WeightedQuantizedModule is currently assuming static quant apis
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:879: # TODO: maybe define a WeightedWeightOnlyQuantizedModule
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1195: # TODO: add safety checks that users for the ref_node and dq_node needs to be one
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1200: # TODO: add a warning or error out here? (bc-breaking if error out)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1210: # TODO: add a warning or error out here? (bc-breaking if error out)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1241: # TODO: enable we have patterns that needs to swap the modules
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1280: # pass scale/zer_point arguments from quantize_per_tensor to the default node operator
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_equalize.py:274: "EqualizationQConfig received observer instance, please pass observer class instead. "
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_equalize.py:409: If the node being passed in is the linear1 node, then we want to return eq_obs2,
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:250: # TODO: instead of instantiating the instance, we can use inspect to get the default args
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:276: # TODO: support check for standalone module
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:290: # TODO(future PR): remove the cast to bool below after figuring
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:300: # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:315: # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:336: # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:338: # TODO: we should check is_dynamic here as well, the code from _is_input_arg_dtype_supported_by_backend
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:350: # TODO: this is a hack because we can only specify one activation_obs_or_fq for
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:543: # TODO: refactor the following code in terms of apply a qconfig to a pattern
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:589: TODO(future PR, if needed): explicitly spell out the non-Tensor
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:841: # TODO: move this to a separate function
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:853: # TODO: we are assuming "target_dtype_info" exists here, maybe
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:929: # TODO: this is looking into how the value is used in the future
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:932: # have the same dtype, we can have an extra pass that removes the extra observers
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1204: # TODO: this does not handle dynamic quantization yet
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1273: # TODO: probably need to remove `is_general_tensor_value_op`
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1292: Note: not all dtypes in the graph will be correct after this pass, but a
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1410: # TODO(future PR): delete the orphaned observer modules
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1477: passes which optimize the graph by deduplicating observers, etc.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1520: # TODO: we probably don't need this counter since each graph will only have
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1584: # TODO(future PR): update the output_quantized_idxs API to match
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1589: # TODO(future PR): support more dtypes in model outputs, if necessary
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1623: # TODO: we might want to handle these more uniformly with the default path
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1660: # TODO: reuse placeholder_node_to_input_index and output_node_to_output_index
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1667: # TODO: change this to insert obs/fq by pattern instead of by node
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1673: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1700: # TODO: take a closer look to see if we can remove this check
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1798: # TODO: This currently diverges from how custom modules are handled today,
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:2017: "in a future version. Please pass in a QConfigMapping instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:2026: "be supported in a future version. Please pass in a QConfigMapping instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:2035: "in a future version. Please pass in a PrepareCustomConfig instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:2044: "in a future version. Please pass in a BackendConfig instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:2077: # TODO: support regex as well
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/pattern_utils.py:17: # TODO(future PR): fix the typing on QuantizeHandler (currently a circular dependency)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:41: # TODO: revisit this list. Many helper methods shouldn't be public
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:247: # TODO: delete
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:325: # TODO(future PR): remove this entire function  and
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:333: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:345: # TODO(future PR): remove this entire function  and
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:776: TODO: traverse upwards from the output and handle the case when tuple is not a
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:863: # TODO: log warnings only when the user enabled a debug flag
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:872: # TODO: for now, just use the existing eps value as scale_min. In the future, we should
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:914: # TODO: handle fp16 qconfigs properly
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:26: # TODO: We should make this private in the future
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:44: "in a future version. Please pass in a FuseCustomConfig instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:53: "in a future version. Please pass in a BackendConfig instead.",
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:77: # TODO: change this to inplace changes to graph, since we no longer construct
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:115: # TODO: add validation that root_node is a module and has the same type
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:149: # TODO: dedup with quantization matching function in match_utils.py
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:74: # TODO: currently it only works for modules,
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:76: # TODO: currently it only works for object_type configurations,
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:224: r"""Compare the qconfig_mapping passed in convert to the one from prepare and check the values
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:21: * :attr:`num_batches_tracked` specifies number of batches passed through the observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:23: * :attr:`average_batch_activation_range` defines average across the ranges of each batch passed through
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:25: * :attr:`epoch_activation_min` defines the minimum value passed through the observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:27: * :attr:`epoch_activation_max` defines the maximum value passed through the observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:31: * :attr:`min_val` defines the per channel minimum values passed through
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:33: * :attr:`max_val` defines the per channel maximum values passed through
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:83: # return the passed in the value
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:92: Returns the passed in x_copy
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:123: Returns the passed in x_copy
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py:159: Returns the passed in x_copy
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report.py:70: 1.) Initialize ModelReport object with reports of interest by passing in initialized detector objects and model
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report.py:227: observer_args (Tuple): The arguments we want to pass into the observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report.py:534: ModelReport API. The generated mapping encompasses all the
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report.py:592: ModelReport API. The generated mapping encompasses all the
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report.py:643: ModelReport API for equalization. The generated mapping encompasses all the
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/model_report_visualizer.py:63: 1.) Initialize ModelReport object with reports of interest by passing in initialized detector objects
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/detector.py:200: raise ValueError("passed in target_fqn not found in graph's targets.")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/detector.py:515: key "observer_args" -> The arguments that are meant to be passed into the observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/detector.py:881: # ensure passed in inputs are valid
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/detector.py:967: key "observer_args" -> The arguments that are meant to be passed into the observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/detector.py:1141: # for each module (both passed in dicts should have same keys)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/detector.py:1242: It then uses the passed in weight info inconjunction to compute the desired ratio
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/detector.py:1419: # make sure passed in percentile is valid
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/detector.py:1488: key "observer_args" -> The arguments that are meant to be passed into the observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_model_report/detector.py:1529: total_batches (int): The total number of batches that passed through observer in this epoch
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:31: from torch.fx.passes.utils.matcher_with_name_node_map_utils import InternalMatch
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:83: # TODO: merge this with the `no_conv_bias` case
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:95: Approximated method to fuse conv and bn. It requires only one forward pass.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:99: # TODO: allow setting eps
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:141: # TODO: allow setting eps
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:175: # Dummy args to be passed into q-dq ops
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:209: # TODO: allow setting eps
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:273: # TODO: allow setting eps
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:491: # TODO: this is error prone, use the replace_literals_with_placeholders hack instead
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:668: # TODO: use the public replace_pattern API once it also returns replacement nodes
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:711: #       TODO: do this for literal args for batchnorm as well
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/duplicate_dq_pass.py:11: from torch.fx.passes.infra.pass_base import PassBase, PassResult
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:107: # TODO(Leslie): This function still fails to support custom momentum and eps value.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:179: # TODO: expose these under this namespace?
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/lowering.py:3: from torch._inductor.fx_passes.freezing_patterns import freezing_passes
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/lowering.py:58: freezing_passes(lowered_model, example_inputs)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/port_metadata_pass.py:13: from torch.fx.passes.infra.pass_base import PassBase, PassResult
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/port_metadata_pass.py:205: Doing it via a separate pass, helps readability of the code. Once we are able to refactor PT2E quant
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/port_metadata_pass.py:206: code, this pass should like to be integrated in the refactored variant of "convert" step.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:29: # TODO: make pt2e folder private?
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:144: # TODO: add assertions for types of root qspecs
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:305: # TODO: maybe edge_or_node_to_qspec should be edge_or_node_to_root_qspec, this will simplify
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:557: # TODO: simplify logic for inserting observers
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:164: # TODO: move this to torch/ao/quantization/utils.py
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:333: # TODO: move this information to fx node itself
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:590: # TODO: Handle this in export itself and don't wrap the model in another GraphModule
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:609: raise NotImplementedError(error_message)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:612: raise NotImplementedError(error_message)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/graph_utils.py:11: from torch.fx.passes.utils.source_matcher_utils import (
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/graph_utils.py:54: When customized_equivalent_types passes in,
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:41: TODO: maybe can replace this with call to torch.iinfo
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:62: # TODO: decide on if we want to allow custom quant_min/quant_max here
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:207: operator that pass in min_val and max_val directly instead of deriving these from a single input.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:213: difference: instead of passing in `input` Tensor and use that to calculate min_val/max_val
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:214: and then scale/zero_point, we pass in min_val/max_val directly
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:474: # TODO: validations
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:475: # TODO: validate scale/zero_point dimensions are compatible with block_size
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:583: # TODO: validate scale/zero_point dimensions are compatible with block_size
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:668: # TODO: this seems to be a detail for tinygemm (converting from uint to int, probably need to refactor this)
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py:754: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:95: # TODO: change to mul.Scalar
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:100: # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:163: # TODO: use out_dtype(mul, ...) here when the op is ready
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:313: # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:371: # TODO: change this to mul.Scalar?
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:446: # TODO: use out_dtype op
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:522: # TODO: use out_dtype(mul, ...) here when the op is ready
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:549: # TODO: use out_dtype op
- .venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:551: # TODO: debug the implementation later when torchdynamo time out issue is resolved
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xpu_inductor_quantizer.py:97: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/embedding_quantizer.py:93: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:27: from torch.fx.passes.utils.matcher_with_name_node_map_utils import (
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:30: from torch.fx.passes.utils.source_matcher_utils import get_source_partitions
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:53: # TODO: remove, since we can use observer_or_fake_quant_ctr to express this
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:572: # TODO: annotate the uses of input, weight, and bias separately instead
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:994: # TODO: remove Optional in return type, fix annotated_partitions logic
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:1010: # TODO: change this to AnnotationException
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:1053: # TODO: remove?
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:1097: # TODO: make the list of ops customizable
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/utils.py:74: # TODO This is non standard behavior and should be removed when we migrate off capture_pre_autograd_graph.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:148: # TODO: qat + per channel?
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:270: # TODO: move this to BoltNNQuantizer?
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:376: # TODO: implement the support for None to be canceling out previous annotations
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:393: # TODO: implement the support for None to be canceling out previous annotations
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:446: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/quantizer.py:50: # TODO: add init for quant_min/quant_max
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/quantizer.py:125: # TODO: change the value to QuantizationSpec in a separate PR
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/quantizer.py:156: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/quantizer.py:161: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:40: from torch.fx.passes.utils.source_matcher_utils import (
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:109: # and b) the given nodes list passes the filter function check.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:162: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:180: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:818: # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:883: # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:939: # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:980: # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:1575: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/composable_quantizer.py:83: pass
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/fbgemm.py:27: # TODO: For now, these DTypeConfigs are identical to the ones defined in native.py
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:1: # TODO: rename executorch to qnnpack_executorch since executorch is a general runtime
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:261: # TODO: we can add fusion for torch.relu as well
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:305: # TODO: this is not used right now since we have extra check in prepare
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/native.py:173: # TODO: express this BackendConfig as a union of the FBGEMM and QNNPACK BackendConfigs
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:26: # TODO: need to fix the way we insert observers for this pattern
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:94: # TODO: remove when functionalization is supported in PT2 mode
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:144: # TODO: this is not used right now since we have extra check in prepare
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:158: # TODO: remove when functionalization is supported in pt2_mode
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/qnnpack.py:82: # TODO: add additional restriction on qscheme to ensure it
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:32: # TODO: rename to be more explicit, e.g. qat_conv_relu
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:139: # TODO: this is not used right now since we have extra check in prepare
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:410: # TODO: we can add fusion for torch.relu as well
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/utils.py:185: # TODO(future PR): move backend_config_dict to use dataclass and move this logic to
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/onednn.py:96: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/onednn.py:109: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/onednn.py:161: raise NotImplementedError(f"Cannot fuse train modules: {(conv, bn, add)}")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/onednn.py:244: raise NotImplementedError(f"Cannot fuse train modules: {(conv, bn, add)}")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/onednn.py:345: raise NotImplementedError(f"Cannot fuse train modules: {(conv, bn, add, relu)}")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/onednn.py:438: raise NotImplementedError(f"Cannot fuse train modules: {(conv, bn, add, relu)}")
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:51: # TODO: maybe rename this to something that's not related to observer
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:115: Config object that specifies the supported data types passed as arguments to
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:125: in the DTypeConfig means we pass in `torch.quint8` as the dtype argument
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:127: `torch.quint8` means we pass in `torch.quint8` as the dtype argument to
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:132: tensor passed to the quantized linear op. Though it can still be the
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:290: # TODO: refer to NativeBackendConfig once that is implemented
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:495: (or quantization parameters passed to quantize ops in the reference model) for the
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:514: Add a set of supported data types passed as arguments to quantize ops in the
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:524: Set the supported data types passed as arguments to quantize ops in the
- .venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/tensorrt.py:30: TODO: add a README when it's more stable
- .venv/lib/python3.12/site-packages/torch/distributions/exp_family.py:37: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/exp_family.py:44: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/exp_family.py:52: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/laplace.py:83: # TODO: If we ever implement tensor.nextafter, below is what we want ideally.
- .venv/lib/python3.12/site-packages/torch/distributions/constraints.py:102: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/constraints.py:116: ``.is_discrete`` attribute will raise a NotImplementedError.
- .venv/lib/python3.12/site-packages/torch/distributions/constraints.py:119: ``.event_dim`` attribute will raise a NotImplementedError.
- .venv/lib/python3.12/site-packages/torch/distributions/constraints.py:130: raise NotImplementedError(".is_discrete cannot be determined statically")
- .venv/lib/python3.12/site-packages/torch/distributions/constraints.py:136: raise NotImplementedError(".event_dim cannot be determined statically")
- .venv/lib/python3.12/site-packages/torch/distributions/constraints.py:201: ``.is_discrete`` attribute will raise a NotImplementedError.
- .venv/lib/python3.12/site-packages/torch/distributions/constraints.py:204: ``.event_dim`` attribute will raise a NotImplementedError.
- .venv/lib/python3.12/site-packages/torch/distributions/multivariate_normal.py:122: :attr:`precision_matrix` is passed instead, it is only used to compute
- .venv/lib/python3.12/site-packages/torch/distributions/multinomial.py:72: raise NotImplementedError("inhomogeneous total_count is not supported")
- .venv/lib/python3.12/site-packages/torch/distributions/continuous_bernoulli.py:70: # close to 0 and 1, later on; otherwise the clamped 'probs' would always pass
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:60: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:105: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:129: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:137: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:144: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:151: raise NotImplementedError(f"{self.__class__} does not implement mode")
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:158: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:181: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:202: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:212: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:222: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:246: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:255: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:312: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/distributions/distribution.py:332: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:180: NotImplementedError: If the distribution types have not been registered via
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:189: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:235: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:284: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:498: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:500: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:552: # TODO: Add Beta-Laplace KL Divergence
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:591: # TODO: Add ContinuousBernoulli-Laplace KL Divergence
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:650: # TODO: Add Exponential-Laplace KL Divergence
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:695: # TODO: Add Gamma-Laplace KL Divergence
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:727: # TODO: Add Gumbel-Laplace KL Divergence
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:824: # TODO: Add Pareto-Laplace KL Divergence
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:921: # TODO: Uniform-Laplace KL Divergence
- .venv/lib/python3.12/site-packages/torch/distributions/kl.py:946: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/binomial.py:159: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributions/binomial.py:169: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributions/utils.py:33: the same size and type as the first tensor passed to `values`.  If all the
- .venv/lib/python3.12/site-packages/torch/distributions/uniform.py:36: # TODO allow (loc,scale) parameterization to allow independent constraints.
- .venv/lib/python3.12/site-packages/torch/distributions/von_mises.py:190: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/distributions/wishart.py:54: :attr:`precision_matrix` is passed instead, it is only used to compute
- .venv/lib/python3.12/site-packages/torch/distributions/transforms.py:102: pass  # default behavior
- .venv/lib/python3.12/site-packages/torch/distributions/transforms.py:140: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/transforms.py:147: raise NotImplementedError(f"{type(self)}.with_cache is not implemented")
- .venv/lib/python3.12/site-packages/torch/distributions/transforms.py:186: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/transforms.py:192: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/transforms.py:198: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributions/independent.py:128: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributions/constraint_registry.py:141: `NotImplementedError` if no transform has been registered.
- .venv/lib/python3.12/site-packages/torch/distributions/constraint_registry.py:147: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributions/constraint_registry.py:248: # TODO define a bijection for LowerCholeskyTransform
- .venv/lib/python3.12/site-packages/torch/_logging/scribe.py:16: pass
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:38: # TODO: Maybe we should allow for some sub-hierarchy so you can control which
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:133: # flattens all the qnames together (TODO: consider memoizing?)
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:355: Whether to emit verbose/intermediate FX pass logs for graph code. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:401: Whether to emit the graphs before inductor grad passes. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:404: Whether to emit the graphs generated by after post grad passes. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:407: Whether to emit the graphs before inductor fusion passes. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:410: Whether to emit the graphs after inductor fusion passes. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:513: f"Unrecognized log or artifact name passed to set_logs: {alias}"
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:1184: # TODO: deal with structured logging that occurs outside of specific compile ids
- .venv/lib/python3.12/site-packages/torch/_logging/_internal.py:1258: # TODO: Actually, the rank probably should just be emitted once at
- .venv/lib/python3.12/site-packages/torch/_logging/_registrations.py:82: "Verbose FX pass logs, e.g. from tensorify_python_scalars and runtime_assert.",
- .venv/lib/python3.12/site-packages/torch/_logging/_registrations.py:115: "Prints the FX graph before inductor pre grad passes. Useful to understand what's being given to Inductor before grad pa
- .venv/lib/python3.12/site-packages/torch/_logging/_registrations.py:119: "Prints the FX graph generated by post grad passes. Useful to understand what's being given to Inductor after post grad 
- .venv/lib/python3.12/site-packages/torch/_logging/_registrations.py:123: "Prints the IR before inductor fusion passes.",
- .venv/lib/python3.12/site-packages/torch/_logging/_registrations.py:128: "Prints the IR after inductor fusion passes.",
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:433: properly. So, it is recommended to always pass the signal length :attr:`n`.
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:480: So, it is recommended to always pass the signal length :attr:`n`:
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:578: properly. So, it is recommended to always pass the signal shape :attr:`s`.
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:627: So, it is recommended to always pass the signal shape :attr:`s`.
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:726: properly. So, it is recommended to always pass the signal shape :attr:`s`.
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:775: So, it is recommended to always pass the signal shape :attr:`s`.
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:816: properly. So, it is recommended to always pass the signal length :attr:`n`.
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:992: So, it is recommended to always pass the signal shape :attr:`s`.
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:1099: properly. It is recommended to always pass the signal shape :attr:`s`.
- .venv/lib/python3.12/site-packages/torch/fft/__init__.py:1150: So, it is recommended to always pass the signal shape :attr:`s`.
- .venv/lib/python3.12/site-packages/torch/export/_swap.py:15: from torch.fx.passes.tools_common import legalize_graph, NodeList
- .venv/lib/python3.12/site-packages/torch/export/_swap.py:16: from torch.fx.passes.utils.fuser_utils import erase_nodes, fuse_as_graphmodule
- .venv/lib/python3.12/site-packages/torch/export/_swap.py:161: 2. TODO: Remove module's in_spec + initial unflatten call
- .venv/lib/python3.12/site-packages/torch/export/_swap.py:162: 3. TODO: Remove module's out_spec + final flatten call
- .venv/lib/python3.12/site-packages/torch/export/_swap.py:263: # TODO: Handle the duplicate module case
- .venv/lib/python3.12/site-packages/torch/export/_swap.py:357: more obvious to graph passes.
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:28: from torch.fx.passes.runtime_assert import insert_deferred_runtime_asserts
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:57: placeholder_naming_pass,
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:65: from torch.fx.passes.infra.pass_base import PassResult
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:66: from torch.fx.passes.infra.pass_manager import PassManager
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:206: # TODO (tmanlaibaatar)https://github.com/pytorch/pytorch/issues/129430
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:281: # TODO we are silently allowing non-safe(non-functional) ops through a crack
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:335: from torch._export.passes.lift_constants_pass import _materialize_and_lift_constants
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:379: # TODO T204030333
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:404: # retracing treats them as persistent buffers, so we inform the constants lifting pass
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:423: # TODO (tmanlaibaatar) Ideally run_decomp should just call _non_strict_export
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:519: placeholder_naming_pass(
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:533: gm, new_graph_signature = _remove_unneccessary_copy_op_pass(
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:573: # TODO(zhxhchen17) Return the new graph_signature directly.
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:631: # Run this pass before creating input/output specs, since size-related CSE/DCE might affect output signature.
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:633: from torch._export.passes._node_metadata_hook import (
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:641: 'File "torch/fx/passes/runtime_assert.py", line 24, '
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:772: def _remove_unneccessary_copy_op_pass(
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:797: def _common_getitem_elimination_pass(
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:975: # TODO unfortunately preserving graph-level metadata is not
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1033: _common_getitem_elimination_pass(
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1260: args: List[Any] original args passed to __call__
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1261: kwargs: Dict[str, Any] original kwargs passed to __call
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1408: raise NotImplementedError("Calling train() is not supported yet.")
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1411: raise NotImplementedError("Calling eval() is not supported yet.")
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1498: def _transform_do_not_use(self, *passes: PassType) -> "ExportedProgram":
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1499: pm = PassManager(list(passes))
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1500: # Since we abstractly run the passes, we need to disable backend decomp here
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1512: # TODO(zhxchen17) Remove this.
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1607: # TODO: remove this
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1616: # TODO(zhxchen17) Formalize this.
- .venv/lib/python3.12/site-packages/torch/export/exported_program.py:1686: # so we will bypass this error.
- .venv/lib/python3.12/site-packages/torch/export/decomp_utils.py:33: until we really need to materialize it (which is when we run decomposition pass.)
- .venv/lib/python3.12/site-packages/torch/export/_tree_utils.py:12: pass in foo(a=a, b=b) OR foo(b=b, a=a) and receive the same result.
- .venv/lib/python3.12/site-packages/torch/export/_draft_export.py:1: import getpass
- .venv/lib/python3.12/site-packages/torch/export/_draft_export.py:15: from torch._export.passes.insert_custom_op_guards import (
- .venv/lib/python3.12/site-packages/torch/export/_draft_export.py:78: pass
- .venv/lib/python3.12/site-packages/torch/export/_draft_export.py:204: raise NotImplementedError("Not implemented yet")
- .venv/lib/python3.12/site-packages/torch/export/_draft_export.py:271: sanitized_username = re.sub(r'[\\/:*?"<>|]', "_", getpass.getuser())
- .venv/lib/python3.12/site-packages/torch/export/_remove_auto_functionalized_pass.py:13: from torch._inductor.fx_passes.post_grad import decompose_auto_functionalized
- .venv/lib/python3.12/site-packages/torch/export/_remove_auto_functionalized_pass.py:25: def unsafe_remove_auto_functionalized_pass(
- .venv/lib/python3.12/site-packages/torch/export/_remove_auto_functionalized_pass.py:29: This pass removes an instances of the higher order op 'auto_functionalized',
- .venv/lib/python3.12/site-packages/torch/export/_remove_auto_functionalized_pass.py:31: This pass doesn't perform safety checks to make sure that this inplace mutation is safe.
- .venv/lib/python3.12/site-packages/torch/export/__init__.py:17: from torch.fx.passes.infra.pass_base import PassResult
- .venv/lib/python3.12/site-packages/torch/export/__init__.py:18: from torch.fx.passes.infra.pass_manager import PassManager
- .venv/lib/python3.12/site-packages/torch/export/__init__.py:115: If you are specifying dynamism on keyword args, you will need to pass them in the order that
- .venv/lib/python3.12/site-packages/torch/export/__init__.py:133: is passed here.
- .venv/lib/python3.12/site-packages/torch/export/__init__.py:234: If you are specifying dynamism on keyword args, you will need to pass them in the order that
- .venv/lib/python3.12/site-packages/torch/export/__init__.py:253: is passed here.
- .venv/lib/python3.12/site-packages/torch/export/__init__.py:467: # TODO: For backward compatibility, we support loading a zip file from 2.7. Delete this path in 2.9(?)
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:165: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:177: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:184: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:192: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:229: _Dim = Dim  # TODO(pianpwk): remove after it's no longer internally breaking
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:277: # TODO(avik): use sympy value range analysis instead?
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:297: # TODO(avik): use sympy value range analysis instead?
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:409: # The saved constraints will be used directly for the post-exporting pass
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:412: # TODO: A better way is needed. Currently we use 't_id' to map the constraint,
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:750: # TODO(avik): check that shape is indeed a Shape
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:790: "Maybe such tensors were copied when passing them as args? "
- .venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:896: # TODO(avik): raise an error in the future
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:34: from ._remove_effect_tokens_pass import _remove_effect_tokens
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:162: # arguments (through placeholders). So in order to pass in
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:173: # Assert that the kwargs passed in exactly match the positional
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:334: # graph's forward pass (_sink_params).
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:504: # TODO(zhxchen17) We can register modules ahead of time instead of reorder later.
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:575: # TODO(suo): untangle this.
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:579: # TODO(suo): The FlatArgsAdapter returns a list of flat args,
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:731: Functionalization represents a buffer mutation by passing the buffer as
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:809: # TODO: support skip connection by inlining the child module.
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:1108: # and if preserve_module_call_signature is set, we may not be able to pass sym_size
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:1307: from torch._export.passes._node_metadata_hook import (
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:1413: # TODO Can be optimized by adding submodules ahead of time.
- .venv/lib/python3.12/site-packages/torch/export/unflatten.py:1561: Exported modules are purely functional, so they pass their parameters and
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:34: from torch._export.passes.collect_tracepoints_pass import CollectTracepointsPass
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:35: from torch._export.passes.lift_constants_pass import (
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:45: apply_runtime_assertion_pass,
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:46: placeholder_naming_pass,
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:125: # This isn't really necessary, and isn't much more efficient since the runtime asserts pass does CSE,
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:337: # TODO Figure out why sometimes we have root sometimes we don't.
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:360: except Exception:  # TODO(zhxchen17) Remove this.
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:408: def _preserve_requires_grad_pass(
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:476: When we run an interpreter-based pass over a GraphModule, execution of data-dependent operators
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:483: This pass attempts a simpler way of handling these for export, by throwing away the previously computed bindings, and re
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:531: 1. Applies runtime assertion pass
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:532: 2. Recompute unbacked_bindings pass
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:539: # Run runtime asserts pass before creating input/output specs, since size-related CSE/DCE might affect output signature.
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:542: gm, graph_signature = apply_runtime_assertion_pass(gm, graph_signature)
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:545: # Useful for any pass that's interpreter-based and might call rebind_unbacked(),
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:568: from torch._export.passes.replace_autocast_with_hop_pass import (
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:569: replace_autocast_with_hop_pass,
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:571: from torch._export.passes.replace_set_grad_with_hop_pass import (
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:572: replace_set_grad_with_hop_pass,
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:575: # Note: replace_set_grad_with_hop_pass need to be after lift_constant_pass because
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:576: # a getattr of a constant tensor doesn't have meta["val"] until after lift_constant_pass.
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:577: # If replace_set_grad_with_hop_pass is before lift_constant_pass,
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:578: # and the constant_tensor is passed as input of the set grad hop, the placeholder's
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:580: gm, export_graph_signature = replace_set_grad_with_hop_pass(
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:584: gm, export_graph_signature = replace_autocast_with_hop_pass(
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:600: placeholder_naming_pass(
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:610: _preserve_requires_grad_pass(
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:839: transform=lambda x: x,  # TODO(zhxchen17) Revisit if this is needed later.
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:900: # TODO unfortunately preserving graph-level metadata and output node's meta
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:906: # This means we run the export solver before the runtime asserts pass.
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:1021: TODO(pianpwk): make this a consistent node-level check once nn_module_stack is populated for cond submodules.
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:1296: # This is because we trace based on the kewargs passed in from user
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:1431: # First, we want to pass through the graph to try populating
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:1454: # TODO: Fix recompile() in  _LazyGraphModule. T207713214
- .venv/lib/python3.12/site-packages/torch/export/_trace.py:2125: If you are specifying dynamism on keyword args, you will need to pass them in the order that
- .venv/lib/python3.12/site-packages/torch/export/_unlift.py:21: from ._remove_effect_tokens_pass import _remove_effect_tokens
- .venv/lib/python3.12/site-packages/torch/export/_unlift.py:289: # it is ok because we have a separate pass later in the stack that populates
- .venv/lib/python3.12/site-packages/torch/export/_unlift.py:431: # TODO T206340015
- .venv/lib/python3.12/site-packages/torch/export/pt2_archive/_package.py:182: pass
- .venv/lib/python3.12/site-packages/torch/export/pt2_archive/_package.py:321: # TODO:Consider dedup this with the weights saved in package_aoti_files
- .venv/lib/python3.12/site-packages/torch/export/pt2_archive/_package.py:387: "No value passed in for `exported_programs`, `aoti_files`, and "
- .venv/lib/python3.12/site-packages/torch/export/pt2_archive/_package.py:395: # TODO: turn this into an error
- .venv/lib/python3.12/site-packages/torch/export/pt2_archive/_package.py:570: # TODO: turn this into an error in 2.9
- .venv/lib/python3.12/site-packages/torch/export/experimental/__init__.py:34: def _remove_detach_pass(
- .venv/lib/python3.12/site-packages/torch/export/experimental/__init__.py:71: _remove_detach_pass(gm, new_graph_signature)
- .venv/lib/python3.12/site-packages/torch/export/passes/__init__.py:8: __all__ = ["move_to_device_pass"]
- .venv/lib/python3.12/site-packages/torch/export/passes/__init__.py:11: def move_to_device_pass(
- .venv/lib/python3.12/site-packages/torch/accelerator/__init__.py:211: ...     pass
- .venv/lib/python3.12/site-packages/torch/accelerator/__init__.py:213: >>> # No-op when None is passed
- .venv/lib/python3.12/site-packages/torch/accelerator/__init__.py:216: ...     pass
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:217: raise NotImplementedError("split: indices_or_sections")
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:244: raise NotImplementedError("split: indices_or_sections: list")
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:307: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:323: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:344: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:361: # XXX: this breaks if start is passed as a kwarg:
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:378: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:542: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:600: raise NotImplementedError("mode='same' and even-length weights")
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:1308: raise NotImplementedError("'order' parameter is not supported.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:1385: raise NotImplementedError(f"sorting {tensor.dtype} is not supported")
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:1410: raise NotImplementedError(f"searchsorted with dtype={a.dtype}")
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:1441: msg = "'%s' arg requires %d <= %s < %d, but %d was passed in"
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:1894: raise NotImplementedError("complex weights histogram.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_funcs_impl.py:2049: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_numpy/linalg.py:20: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:57: dtype; real floating-point dtypes (`float*`) get passed through unchanged
- .venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:80: raise NotImplementedError(f"argmax with dtype={a.dtype}.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:100: raise NotImplementedError(f"argmin with dtype={a.dtype}.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:149: raise NotImplementedError(f"amax with dtype={a.dtype}")
- .venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:167: raise NotImplementedError(f"amin with dtype={a.dtype}")
- .venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:387: # raise NotImplementedError("overwrite_input in quantile not implemented.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:391: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/random.py:136: raise NotImplementedError("We do not random.shuffle lists in-place")
- .venv/lib/python3.12/site-packages/torch/_numpy/random.py:162: # TODO: check a.dtype is integer -- cf np.random.choice(3.4) which raises
- .venv/lib/python3.12/site-packages/torch/_numpy/_normalizations.py:32: # So we never pass the out array to implementer functions and handle it in the
- .venv/lib/python3.12/site-packages/torch/_numpy/_normalizations.py:85: raise NotImplementedError(f"'{parm.name}' parameter is not supported.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_normalizations.py:114: # Dynamo can pass torch tensors as out arguments,
- .venv/lib/python3.12/site-packages/torch/_numpy/_normalizations.py:215: # NB: extra unknown arguments: pass through, will raise in func(*args) below
- .venv/lib/python3.12/site-packages/torch/_numpy/_util.py:25: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/_util.py:29: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/_util.py:90: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/_util.py:105: raise NotImplementedError("does not handle tuple axis")
- .venv/lib/python3.12/site-packages/torch/_numpy/_util.py:181: raise NotImplementedError(mesg)  # noqa: B904
- .venv/lib/python3.12/site-packages/torch/_numpy/_unary_ufuncs_impl.py:70: # TODO set __name__ and __qualname__
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:68: raise NotImplementedError(f"{key=}") from e
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:80: raise NotImplementedError("Modifying flags is not implemented")
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:175: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:299: raise NotImplementedError(f"astype(..., order={order} is not implemented.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:301: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:305: raise NotImplementedError(f"astype(..., subok={subok} is not implemented.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:307: raise NotImplementedError(f"astype(..., copy={copy} is not implemented.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:323: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:352: raise NotImplementedError(f"view(..., type={type} is not implemented.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:512: raise NotImplementedError("'subok' parameter is not supported.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:514: raise NotImplementedError("'like' parameter is not supported.")
- .venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:516: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:268: except (TypeError, ValueError, NotImplementedError):
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:269: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:444: except (NotImplementedError, TypeError):
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:445: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:544: except (TypeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:545: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:927: except (TypeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:928: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:1117: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:1466: raise NotImplementedError("_nulp not implemented for complex array")
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:1568: >>> # or passing a func
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:1610: Arguments passed to `func`.
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:1612: Keyword arguments passed to `func`.
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:1752: All arguments are passed as this to the underlying tempfile.mkdtemp
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:1768: parameters are the same as for tempfile.mkstemp and are passed directly
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:1894: warnings will be passed out and be matched by the outer level.
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:1924: pass
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:2095: # There is no filter in place, so pass to the outside handler
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:2096: # unless we should only pass it once
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:2202: Arguments passed to `func`.
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:2204: Keyword arguments passed to `func`.
- .venv/lib/python3.12/site-packages/torch/_numpy/testing/utils.py:2333: pass
- .venv/lib/python3.12/site-packages/torch/_dispatch/python.py:86: # TODO: test the specs match; empirically  sometimes we have a tuple
- .venv/lib/python3.12/site-packages/torch/_dispatch/python.py:136: # TODO: suppress guards
- .venv/lib/python3.12/site-packages/torch/_dispatch/python.py:146: # TODO: This probably does the wrong thing if you're running other
- .venv/lib/python3.12/site-packages/torch/_export/error.py:51: facing APIs, and writing graph passes.
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:14: from torch._export.passes.replace_quantized_ops_with_standard_ops_pass import (
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:86: _C._jit_pass_onnx_function_substitution(graph)
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:103: _C._jit_pass_onnx_function_substitution(graph)
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:111: _C._jit_pass_onnx_lint(graph)
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:120: _C._jit_pass_onnx_function_substitution(graph)
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:144: # Global variables that are not passed in as inputs to the loop sub-blocks
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:269: Perform two passes to get a mapping of blocks to a set of FQNs of its lifted attributes.
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:271: each block to a graph which will be passed into torch.cond. A restriction for torch.cond is that model
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:273: we will run this pass which will:
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:288: # full IR aliasing pass and figure out the FQN of an attribute.
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:817: # TODO: covnert sourceRange() into stack_trace
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:890: # TODO: covnert sourceRange() into stack_trace
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:949: # TODO: covnert sourceRange() into stack_trace
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:1029: # TODO: (1/N) stage.
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:1188: # TODO: support aten::enable_grad in both TorchScript and Converter.
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:1265: # TODO: Revisit this later after HigherOrderOp design changes.
- .venv/lib/python3.12/site-packages/torch/_export/converter.py:1522: # TODO: adjust input orders to match GraphSignature convention
- .venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:23: from torch._export.passes.lift_constants_pass import ConstantAttrMap
- .venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:284: pass
- .venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:339: # TODO(avik): refactor Dynamo to avoid duplication of the following code
- .venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:529: # TODO(avik): Maybe record the constraint violation error instead and replay later?
- .venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:690: pass
- .venv/lib/python3.12/site-packages/torch/_export/__init__.py:107: If you are specifying dynamism on keyword args, you will need to pass them in the order that
- .venv/lib/python3.12/site-packages/torch/_export/__init__.py:134: # We want to export to Torch IR here to utilize the pre_grad passes in
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:21: from torch.fx.passes.runtime_assert import insert_deferred_runtime_asserts
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:25: from torch._export.passes.lift_constants_pass import ConstantAttrMap
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:68: # retracing treats them as persistent buffers, so we inform the constants lifting pass
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:71: from torch._export.passes.lift_constants_pass import ConstantAttrMap
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:97: # TODO some annoying circular dependency issue
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:161: aten IR OR run_decomposition pass.
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:325: from torch._export.passes.add_runtime_assertions_for_constraints_pass import (
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:383: # this means we deferred a guard from export analysis to runtime, let this pass
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:385: pass
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:585: from torch.fx.passes.split_module import split_module
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:623: def _insert_aten_to_metadata_assert_pass(gm: torch.fx.GraphModule) -> None:
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:624: from torch._export.passes._node_metadata_hook import (
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:665: def apply_runtime_assertion_pass(gm: torch.fx.GraphModule, graph_signature):
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:666: from torch._export.passes._node_metadata_hook import (
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:674: 'File "torch/fx/passes/runtime_assert.py", line 24, '
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:690: _insert_aten_to_metadata_assert_pass(gm)
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:812: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:828: # TODO: Directly provide inspect.signature compatible TS-d module.
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:909: def placeholder_naming_pass(
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:919: This pass is run at the end of _export_non_strict() to assign better placeholder node names:
- .venv/lib/python3.12/site-packages/torch/_export/utils.py:1028: # because this is created before the placeholder naming pass
- .venv/lib/python3.12/site-packages/torch/_export/verifier.py:28: pass
- .venv/lib/python3.12/site-packages/torch/_export/verifier.py:36: # TODO(angelayi): remove this in favor of _check_val
- .venv/lib/python3.12/site-packages/torch/_export/verifier.py:54: ):  # TODO(zhxchen17) Remove Tensor.
- .venv/lib/python3.12/site-packages/torch/_export/verifier.py:174: pass
- .venv/lib/python3.12/site-packages/torch/_export/verifier.py:208: # TODO Remove this allowlist.
- .venv/lib/python3.12/site-packages/torch/_export/verifier.py:218: # TODO (tmanlaibaatar)
- .venv/lib/python3.12/site-packages/torch/_export/verifier.py:240: # TODO (tmanlaibaatar) more proper way is needed here
- .venv/lib/python3.12/site-packages/torch/_export/verifier.py:253: # TODO(T140410192): should have fake tensor for all dialects
- .venv/lib/python3.12/site-packages/torch/_export/verifier.py:309: # TODO(zhxchen17)
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:11: from torch._export.pass_infra.node_metadata import NodeMetadata
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:12: from torch._export.pass_infra.proxy_value import ProxyValue
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:23: from torch.fx.passes.infra.pass_base import PassBase, PassResult
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:24: from torch.fx.passes.shape_prop import _extract_tensor_metadata, TensorMetadata
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:49: pass
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:54: Interpreter-based pass class to help users maintain the IR spec while writing
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:121: # TODO (tmanlaibaatar) properly support Quantized FakeTensor
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:126: # TODO we should allocate static shapes
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:135: # TODO: This is just a workaround to get over the
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:165: # TODO (tmanlaibaatar) properly support Quantized FakeTensor
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:173: # TODO: This is just a workaround to get over the
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:318: # TODO(angelayi): Update this with what we decide to do for metadata in
- .venv/lib/python3.12/site-packages/torch/_export/pass_base.py:355: pass
- .venv/lib/python3.12/site-packages/torch/_export/db/examples/cond_predicate.py:8: The conditional statement (aka predicate) passed to cond() must be one of the following:
- .venv/lib/python3.12/site-packages/torch/_export/db/examples/cond_operands.py:12: The operands passed to cond() must be:
- .venv/lib/python3.12/site-packages/torch/_export/db/examples/cond_branch_nonlocal_variables.py:8: The branch functions (`true_fn` and `false_fn`) passed to cond() must follow these rules:
- .venv/lib/python3.12/site-packages/torch/_export/db/examples/cond_branch_nonlocal_variables.py:9: - both branches must take the same args, which must also match the branch args passed to cond.
- .venv/lib/python3.12/site-packages/torch/_export/db/examples/cond_branch_nested_function.py:8: The branch functions (`true_fn` and `false_fn`) passed to cond() must follow these rules:
- .venv/lib/python3.12/site-packages/torch/_export/db/examples/cond_branch_nested_function.py:9: - both branches must take the same args, which must also match the branch args passed to cond.
- .venv/lib/python3.12/site-packages/torch/_export/db/examples/cond_branch_class_method.py:15: The branch functions (`true_fn` and `false_fn`) passed to cond() must follow these rules:
- .venv/lib/python3.12/site-packages/torch/_export/db/examples/cond_branch_class_method.py:16: - both branches must take the same args, which must also match the branch args passed to cond.
- .venv/lib/python3.12/site-packages/torch/_export/serde/schema_check.py:15: pass
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:107: pass
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:301: storage_offset=serialize_sym_int(0),  # TODO needs to be fixed.
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:351: # TODO: this should be fixed by deserialization instead.
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:382: # TODO: Remove this adjustment when Ed gets rid of fractional ranges
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:526: # TODO(zhxchen17) Maybe provide a function name helper in FX.
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:530: else:  # TODO(zhxchen17) Don't catch all here.
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:565: # TODO: create a new tensor_values here, meta might have faketensor info
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:595: # skip passing custom obj into the weight arg as an hack
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:785: pass
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1275: raise AssertionError("TODO")
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1621: # TODO: Directly serialize exported_program.constants once
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1710: ):  # TODO(zhxchen17) Follow up on this.
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1721: else:  # TODO(zhxchen17) Don't catch all here.
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:2219: # TODO(avik): find a better way to keep this collection in sync;
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:2276: # TODO(pianpwk): if we can clean up unused symbols in range_constraints,
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:2629: raise NotImplementedError(f"Unimplemented node output type: {arg}")
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:2818: # TODO(zhxchen17) blocked on thrift schema refactor
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:3389: pass
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:3397: pass
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:3444: pass
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:3452: pass
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:3512: raise NotImplementedError(f"{cls.__class__} namespace() must be implemented")
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:3516: raise NotImplementedError(f"{cls.__class__} op_name() must be implemented")
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:3520: raise NotImplementedError(f"{cls.__class__} op_name() must be implemented")
- .venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:3524: raise NotImplementedError(f"{cls.__class__} op_schema() must be implemented")
- .venv/lib/python3.12/site-packages/torch/_export/serde/schema.py:469: # The structure is used to serialize instances of AOTInductorModel to pass
- .venv/lib/python3.12/site-packages/torch/_export/passes/add_runtime_assertions_for_constraints_pass.py:13: from torch.fx.passes.infra.pass_base import PassBase, PassResult
- .venv/lib/python3.12/site-packages/torch/_export/passes/add_runtime_assertions_for_constraints_pass.py:69: called **during** the interpreter-based pass.
- .venv/lib/python3.12/site-packages/torch/_export/passes/add_runtime_assertions_for_constraints_pass.py:163: # Sometimes this pass would return a wrong graph where we have mismatched
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_with_hop_pass_util.py:49: # Split_module pass intentially doesn't add output node
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_with_hop_pass_util.py:51: # TODO (tmanlaibaatar) Figure out if this is right behaviour
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_with_hop_pass_util.py:70: # for passing verifier and better readability, also propagate metadata
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_with_hop_pass_util.py:99: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_with_hop_pass_util.py:100: f"repalce_with_hop_pass doesnt' support output type {type(output_args)}"
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_with_hop_pass_util.py:103: # TODO (shangdiy): remove this line, since the export graph can be non-functional
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_with_hop_pass_util.py:157: def _replace_with_hop_pass_helper(
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_with_hop_pass_util.py:178: new_subgm, _ = _replace_with_hop_pass_helper(
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_set_grad_with_hop_pass.py:10: from .replace_with_hop_pass_util import (
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_set_grad_with_hop_pass.py:12: _replace_with_hop_pass_helper,
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_set_grad_with_hop_pass.py:86: Helper function for replace_set_grad_with_hop_pass().
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_set_grad_with_hop_pass.py:110: def replace_set_grad_with_hop_pass(
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_set_grad_with_hop_pass.py:117: return _replace_with_hop_pass_helper(
- .venv/lib/python3.12/site-packages/torch/_export/passes/constant_folding.py:134: # TODO - fix errors with this
- .venv/lib/python3.12/site-packages/torch/_export/passes/constant_folding.py:141: # TODO - constant folding triton kernel returns the inputs -- fix this
- .venv/lib/python3.12/site-packages/torch/_export/passes/constant_folding.py:150: # TODO - more complicated strategy
- .venv/lib/python3.12/site-packages/torch/_export/passes/insert_custom_op_guards.py:5: from torch._export.passes._node_metadata_hook import (
- .venv/lib/python3.12/site-packages/torch/_export/passes/collect_tracepoints_pass.py:9: from torch.fx.passes.infra.pass_base import PassBase, PassResult
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_quantized_ops_with_standard_ops_pass.py:645: TODO: SetAttr + quantized ops will result incorrect program. This flag is used to temporarily
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_quantized_ops_with_standard_ops_pass.py:646: bypass test cases.
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_quantized_ops_with_standard_ops_pass.py:648: The deadcode elimination pass is needed to remove legacy quantized ops. Otherwise, retracing
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_quantized_ops_with_standard_ops_pass.py:650: this pass regard them as dead code and remove them. Below is an example of GraphModule before
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_quantized_ops_with_standard_ops_pass.py:651: and after the dead code elimination pass.
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_view_ops_with_view_copy_ops_pass.py:6: from torch._export.pass_base import _ExportPassBaseDeprecatedDoNotUse
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_view_ops_with_view_copy_ops_pass.py:49: program. This pass replaces view ops with view copy ops for backends that
- .venv/lib/python3.12/site-packages/torch/_export/passes/__init__.py:1: from .replace_view_ops_with_view_copy_ops_pass import ReplaceViewOpsWithViewCopyOpsPass
- .venv/lib/python3.12/site-packages/torch/_export/passes/remove_runtime_assertions.py:2: from torch.fx.passes.infra.pass_base import PassBase, PassResult
- .venv/lib/python3.12/site-packages/torch/_export/passes/remove_runtime_assertions.py:35: # program. We will leave it to the pass caller to call DCE.
- .venv/lib/python3.12/site-packages/torch/_export/passes/functionalize_side_effectful_ops_pass.py:5: from torch._export.pass_base import (
- .venv/lib/python3.12/site-packages/torch/_export/passes/functionalize_side_effectful_ops_pass.py:10: from torch._export.pass_infra.node_metadata import NodeMetadata
- .venv/lib/python3.12/site-packages/torch/_export/passes/functionalize_side_effectful_ops_pass.py:11: from torch._export.pass_infra.proxy_value import ProxyValue
- .venv/lib/python3.12/site-packages/torch/_export/passes/_node_metadata_hook.py:15: pass using graph.create_node. An example of how to use it:
- .venv/lib/python3.12/site-packages/torch/_export/passes/_node_metadata_hook.py:21: pass(gm)
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_autocast_with_hop_pass.py:10: from .replace_with_hop_pass_util import (
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_autocast_with_hop_pass.py:12: _replace_with_hop_pass_helper,
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_autocast_with_hop_pass.py:64: # TODO: check if current auto-cast type is the same as the args of
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_autocast_with_hop_pass.py:150: Helper function for replace_autocast_with_hop_pass().
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_autocast_with_hop_pass.py:178: def replace_autocast_with_hop_pass(
- .venv/lib/python3.12/site-packages/torch/_export/passes/replace_autocast_with_hop_pass.py:185: return _replace_with_hop_pass_helper(
- .venv/lib/python3.12/site-packages/torch/_export/passes/lift_constants_pass.py:52: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_export/passes/lift_constants_pass.py:162: def lift_constants_pass(
- .venv/lib/python3.12/site-packages/torch/_export/passes/lift_constants_pass.py:413: constants.update(lift_constants_pass(gm, export_graph_signature, constant_attrs))
- .venv/lib/python3.12/site-packages/torch/special/__init__.py:957: The backward pass with respect to :attr:`input` is not yet supported.
- .venv/lib/python3.12/site-packages/torch/special/__init__.py:1008: The backward pass with respect to :attr:`input` is not yet supported.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:90: # This HOP allows you to bypass dynamo tracing of the wrapper function while
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:96: class DynamoBypassingWrapper(HigherOrderOperator):
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:98: super().__init__("dynamo_bypassing_wrapper")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:126: dynamo_bypassing_wrapper = DynamoBypassingWrapper()
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:132: TorchDynamo to look into saved tensor hooks and directly passes the control
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:143: that duplication/recomputation is done as a compiler pass in the
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:183: ops (by setting fixed seed for each random op, see `replace_random_passes`).
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:253: Detected that context_fn is passed to torch.utils.checkpoint under torch.compile.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:264: # regardless of this flag (by doing RNG functionalization via `replace_random_passes` in Inductor
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:279: # TODO: We want to use the same `checkpoint(Interpreter(gmod).run, *args, **kwargs)` here
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:57: pass
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:60: pass
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:122: # reconstructing TMA descriptors from the underlying tensors (passed as kernel
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:279: "Incorrect number of arguments passed to kernel: "
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:280: f"passed {list(kwargs.keys())}, expected {kernel.arg_names}."
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:600: # the scf block args are ignored by the pass. but, as they
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:657: # During mutation analysis, the analysis pass will identify mutating ops (e.g. tt.store)
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:658: # and then DFS upwards towards the parameters of the function. Specifically, the analysis pass
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:662: # In the case of scf.if/scf.for, we may have multiple return ops, each passed as an arg
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:674: # Therefore, if _any_ of the return values of the scf.if are mutated, then the analysis pass
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:678: # For the purposes of this analysis pass, we create N yield ops - one for each
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:782: If an intermediate/parameter is passed into a function and is written to
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:891: # This is an argument defined in the kernel, not passed in
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1073: # TODO: remove this when the Triton issue above is fixed
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1187: # TODO(oulgen): Preexisting bug, if two kernel inputs are views of each
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1229: # TODO(oulgen): For performance reasons, we want to ensure that these
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1258: # TODO(oulgen): For performance reasons, we want to ensure that these
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1366: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1369: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1372: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1380: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1391: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1403: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1408: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1411: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1465: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1470: raise NotImplementedError("abstract method")
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1537: # Check Config passed to autotuner in configs
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1552: # Only grid needs to be passed
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1734: # be passed from the kernel configs: the behavior of Triton runtime is that
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1738: # the `kwargs` part (if they're absent there) to facilitate passing them as
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:1873: # One option is to correctly pass the symints in so that the symbolic expressions are defined
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/while_loop.py:80: It's also the initial value of states that are carried across iterations. Note that when pass an integer as carry,
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/while_loop.py:165: # We cannot directly pass cond_op to it. So we wrap it in a dummy function.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/out_dtype.py:18: # TODO to figure out a more generic approach
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/flex_attention.py:223: other_buffers: Other buffers that are passed to the score_mod function
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/flex_attention.py:444: # TODO: So far only the input mutations are checked
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/flex_attention.py:497: # TODO: Figure out a better way to handle this for NJT than using sum()
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/flex_attention.py:748: # TODO: Rework DispatchKey.Autograd to py_autograd_impl
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/flex_attention.py:983: """We already have the forward graph and joint graph from the forward pass, so we create a proxy attach both graphs"""
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/invoke_subgraph.py:37: from torch.fx.passes.runtime_assert import insert_deferred_runtime_asserts
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/invoke_subgraph.py:182: # TODO (@anijain2305) - Delete this function when base_hop uses invoke_subgraph infra
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/invoke_subgraph.py:223: # TODO (@anijain2305) - Delete this function when base_hop uses invoke_subgraph infra
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/invoke_subgraph.py:260: # if they're not passed in
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/invoke_subgraph.py:451: pass
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/auto_functionalize.py:68: pass
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/auto_functionalize.py:149: # TODO is there cases can we use slice even if stride or len(sizes) are not equal?
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/auto_functionalize.py:511: # as it means the the optional arg was passed with its default
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/auto_functionalize.py:617: # as it means the the optional arg was passed with its default
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/auto_functionalize.py:690: # We pass in the tree_spec of tree_flatten(SchemaHolder) to make it proxable
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/executorch_call_delegate.py:93: # TODO: support autograd
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/__init__.py:32: dynamo_bypassing_wrapper,
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/__init__.py:68: "dynamo_bypassing_wrapper",
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/torchbind.py:58: # TODO: this is not really sufficient. While passes (hopefully) check
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/utils.py:25: from torch.fx.passes.runtime_assert import insert_deferred_runtime_asserts
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/utils.py:26: from torch.fx.passes.shape_prop import _extract_tensor_metadata, TensorMetadata
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/utils.py:307: # TODO: Investigate here further which node is exactly aliasing
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/utils.py:315: # TODO: Investigate here further which node is exactly mutating the inputs
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/utils.py:517: # This can happen for lifted_arguments. E.g., the shapes of a dynamic tensor are lifted and passed
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/utils.py:555: # TODO: The parameter use_output_and_grad_bw is required because some operations
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/utils.py:768: # TODO: Return a more detailed information as to which node
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/utils.py:965: For AOT Dispatcher metadata collection pass, HOPs go from functionalization
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/associative_scan.py:55: # TODO: find torch alternative for slice_along dim for torch.jit.script to work
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/associative_scan.py:191: # TODO: Support Autograd
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/associative_scan.py:192: # TODO: Unify handling of pytrees for control flow ops, such as cond, while_loop, etc.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/hints_wrap.py:33: hints (dict): A dict of context hints which could be passed to
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:181: # We cannot directly pass cond_op to it. So we wrap it in a dummy function.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:235: # passing the upstream gradients through.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:342: # TODO: we need to materialize the bw graphs because dynamo is unable to
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/scan.py:228: # TODO: Support _inductor lowering
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/scan.py:229: # TODO: Unify handling of pytrees for control flow ops, such as cond, while_loop, etc.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/scan.py:553: otherwise, the value of initial_g_additional_inputs is passed, which is None for non-Tensor values.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/scan.py:763: # TODO: we need to materialize the bw graphs because dynamo is unable to
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/effects.py:60: AOTAutograd is functional so that future optimization passes do not reorder
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/effects.py:234: optimization passes.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/flat_apply.py:109: # TODO: The following can be updated to support non-graphable outputs and pytrees.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/base_hop.py:34: 3) kwargs may be some config options but aren't passed directly to the subgraph.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/base_hop.py:80: pass
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/base_hop.py:112: # TODO: this should probably route through FakeTensorMode to reuse caching
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/base_hop.py:117: # To support input mutation, hop's subgraph must be functionalized because many inductor passes are
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/base_hop.py:120: #   is implemented in the top-level graph when no hop is presented. All passes must have been and will be
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/base_hop.py:128: #          could recursively run passes on them. Also the epilogue graph is inlined at the end.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/base_hop.py:129: #       b. we call auto_functionalized_v2 and pass in an additional schema in order to properly invoke
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/base_hop.py:182: # TODO: turn this into an error.
- .venv/lib/python3.12/site-packages/torch/_higher_order_ops/base_hop.py:224: # TODO: Something special needs to happen with min cut partitioner
- .venv/lib/python3.12/site-packages/torch/optim/adagrad.py:275: # and pass False to use_fused. This is not a mistake--we want to give the fused impl
- .venv/lib/python3.12/site-packages/torch/optim/radam.py:497: # TODO(mlazos): we should try and get a foreach_where op https://github.com/pytorch/pytorch/issues/117884
- .venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:174: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: pass
- .venv/lib/python3.12/site-packages/torch/optim/_functional.py:21: # TODO: use foreach API in optim._functional to do all the computation
- .venv/lib/python3.12/site-packages/torch/optim/optimizer.py:128: # and pass them as the value arg of foreach ops.
- .venv/lib/python3.12/site-packages/torch/optim/optimizer.py:271: To specify fused, pass True for fused. To force running the for-loop
- .venv/lib/python3.12/site-packages/torch/optim/optimizer.py:272: implementation, pass False for either foreach or fused. """
- .venv/lib/python3.12/site-packages/torch/optim/optimizer.py:803: passed in to ``load_state_dict``. The hook may modify the state_dict inplace
- .venv/lib/python3.12/site-packages/torch/optim/optimizer.py:1006: 2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\ s
- .venv/lib/python3.12/site-packages/torch/optim/optimizer.py:1064: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/optim/swa_utils.py:186: statistics in a post-training step by passing data through the model. The
- .venv/lib/python3.12/site-packages/torch/optim/swa_utils.py:243: """Forward pass."""
- .venv/lib/python3.12/site-packages/torch/optim/swa_utils.py:320: It performs one pass over data in `loader` to estimate the activation
- .venv/lib/python3.12/site-packages/torch/optim/swa_utils.py:331: :attr:`device` before being passed into :attr:`model`.
- .venv/lib/python3.12/site-packages/torch/optim/sgd.py:275: # and pass False to use_fused. This is not a mistake--we want to give the fused impl
- .venv/lib/python3.12/site-packages/torch/optim/sgd.py:344: # Nested if is necessary to bypass jitscript rules
- .venv/lib/python3.12/site-packages/torch/optim/sgd.py:368: # Nested if is necessary to bypass jitscript rules
- .venv/lib/python3.12/site-packages/torch/optim/adam.py:107: # TODO(crcrpar): [low prec params & their higher prec copy]
- .venv/lib/python3.12/site-packages/torch/optim/adam.py:378: # TODO: Support nonzero-dim Tensor betas, see #147921
- .venv/lib/python3.12/site-packages/torch/optim/adam.py:413: # Nested if is necessary to bypass jitscript rules
- .venv/lib/python3.12/site-packages/torch/optim/adam.py:449: # Nested if is necessary to bypass jitscript rules
- .venv/lib/python3.12/site-packages/torch/optim/adam.py:469: # Nested if is necessary to bypass jitscript rules
- .venv/lib/python3.12/site-packages/torch/optim/adam.py:478: # Nested if is necessary to bypass jitscript rules
- .venv/lib/python3.12/site-packages/torch/optim/adam.py:609: # TODO: Support nonzero-dim Tensor betas, see #147921
- .venv/lib/python3.12/site-packages/torch/optim/adam.py:914: # and pass False to use_fused. This is not a mistake--we want to give the fused impl
- .venv/lib/python3.12/site-packages/torch/nested/__init__.py:37: If a nested tensor is passed, it will be returned directly unless the device / dtype / layout
- .venv/lib/python3.12/site-packages/torch/nested/__init__.py:41: If a non-nested tensor is passed, it is treated as a batch of constituents of consistent size.
- .venv/lib/python3.12/site-packages/torch/nested/__init__.py:42: A copy will be incurred if the passed device / dtype differ from those of the input OR if
- .venv/lib/python3.12/site-packages/torch/nested/__init__.py:97: # TODO: Just use nt.to(layout=layout) when it exists.
- .venv/lib/python3.12/site-packages/torch/nested/__init__.py:224: tensor_list (List[array_like]): a list of tensors, or anything that can be passed to torch.tensor,
- .venv/lib/python3.12/site-packages/torch/nested/__init__.py:334: # TODO: switch to as_nested_tensor(tensor) when it is available
- .venv/lib/python3.12/site-packages/torch/nested/__init__.py:446: # TODO: Truly support offsets=None at some point?
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:321: raise NotImplementedError("NYI: broadcasting NT with T with larger dim")
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:384: pass
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:420: pass
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:439: raise NotImplementedError(func)
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:534: # TODO: write a kernel for this
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:537: # TODO: We probably want the output to have the same ragged structure / nested int.
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:662: # TODO: eventually do a direct copy when this is possible
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:1196: # TODO: Back these with proper kernels (e.g. grouped GEMM)
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:1478: dim_to_pass = [inp._ragged_idx] if is_dimlist else inp._ragged_idx
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:1480: inp.to_padded_tensor(identity_element), dim=dim_to_pass, **new_kwargs
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:1662: # TODO: Do this for all other views!
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:1797: # TODO: make this more efficient
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:2222: # TODO: Handle inference mode properly.
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:2254: # TODO: Handle the rest of output_size
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:2626: # TODO: Support this if needed; determine if NJT buffers need be unwrapped as dense.
- .venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:2636: # need to pass dense tensor of shape (B, n_heads, sum(seq_len), D)
- .venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:68: # TODO: Figure out whether masks are actually supported for this layout or not
- .venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:352: # TODO: Explore performance impact of copying
- .venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:357: # TODO: Explore performance impact of copying
- .venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:362: # TODO: Explore performance impact when compiling
- .venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:406: # TODO: Next iteration should add test cases and check it works
- .venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:586: # [TODO] K and V have to have the same Nnz, should probably torch_check
- .venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:640: # TODO: coalesce with torch/nn/utils/attention.py
- .venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:642: # TODO: Investigate why math.sqrt() isn't properly handled by Dynamo?
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:169: # TODO: Revisit this when @properties are better supported by PT2. I think the ideal
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:216: # reasons. TODO: Remove these!
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:246: # TODO: Remove this in favor of the default tensor subclass serialization logic.
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:348: raise NotImplementedError(func)
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:364: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:365: pass
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:371: # TODO: Remove ViewBufferFromNested, ViewNestedFromBuffer, and buffer_from_jagged once the
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:372: # internal BC period has passed.
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:428: # Need to make it obvious that users should be passing in offsets
- .venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:491: # TODO: An alternative way to construct offsets is to use F.pad. This avoids creating
- .venv/lib/python3.12/site-packages/torch/xpu/__init__.py:49: raise NotImplementedError("PyTorch was compiled without XPU support")
- .venv/lib/python3.12/site-packages/torch/xpu/__init__.py:52: raise NotImplementedError("PyTorch was compiled without XPU support")
- .venv/lib/python3.12/site-packages/torch/xpu/__init__.py:272: r"""Return the torch.device type object from the passed in device.
- .venv/lib/python3.12/site-packages/torch/xpu/__init__.py:400: data_ptr(int): Integer representation of the `sycl::queue*` value passed externally.
- .venv/lib/python3.12/site-packages/torch/cpu/__init__.py:94: pass
- .venv/lib/python3.12/site-packages/torch/cpu/__init__.py:97: pass
- .venv/lib/python3.12/site-packages/torch/cpu/__init__.py:100: pass
- .venv/lib/python3.12/site-packages/torch/cpu/__init__.py:103: pass
- .venv/lib/python3.12/site-packages/torch/cpu/__init__.py:111: pass
- .venv/lib/python3.12/site-packages/torch/cpu/__init__.py:114: pass
- .venv/lib/python3.12/site-packages/torch/cpu/__init__.py:117: pass
- .venv/lib/python3.12/site-packages/torch/cpu/amp/autocast_mode.py:42: # TODO: discuss a unified TorchScript-friendly API for autocast
- .venv/lib/python3.12/site-packages/torch/contrib/_tensorboard_vis.py:147: # TODO: handle attrs
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:55: # TODO: Type[torch.SymInt], Type[torch.SymFloat]
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:57: # TODO: This needs a lot more type annotations
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:75: torch_function_passthrough = {
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:121: # TODO: We should check that the symbols are consistent
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:148: # TODO: look at using torch.testing.assert_close instead with an option
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:183: # TODO: we should review why this happens and see about fixing it
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:187: pass
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:234: # TODO: Check the symbols are consistent with each other
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:538: # TODO: are these necessary?
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:770: pass
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:775: pass
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:912: # Extracts dimensions that might be passed either as a list/tuple or as varargs.
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:933: foo(*shape). However a user can pass the shape as a sequence of integers,
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:999: "If this was meant to be inferred, please explicitly pass in -1."
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1137: # TODO: type error here is real, replace with sym_complex
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1156: # TODO: sym_complex_float?
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1298: # TODO: maybe unify with can_cast_to?
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1453: # TODO: when NumberType contains the sym types, can simplify this
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1479: # TODO: document type promotion kinds
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1748: # TODO: maybe inform the user of channels_last_3d if rank of the tensor is 5?
- .venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:2045: # TODO: a better way to handle this would be with a new op, "_unsafe_as_strided"
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:32: pass
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:37: pass
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:42: pass
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:47: pass
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:50: # TODO: implement ref.cast with an option to enforce safe casting
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:184: # TODO: handle tuples of tensors
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:236: pass_is_out: bool = False,
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:306: if pass_is_out:
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:438: # TODO: There is a subtle bug here: prims like copy_to
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:455: # TODO: when tracing this will add torch tensors and not TensorMeta objects
- .venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:457: # TODO: this wrapper is currently untested
- .venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:40: # TODO(thiagocrepaldi): handle overload_name?
- .venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:46: # TODO(thiagocrepaldi): handle overload_name?
- .venv/lib/python3.12/site-packages/torch/onnx/_experimental.py:15: # TODO(justinchuby): Deprecate and remove this class.
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset18.py:141: # TODO(justinchuby): Support multiple quantized args in output
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset18.py:153: # TODO(justinchuby): Support multiple quantized args in output
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:516: # Implicit casting will be handled in scalar type analysis pass.
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1308: # TODO: remove this as onnx opset 11 spec allows negative axes
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1357: # TODO(justinchuby): Looks like this op is deprecated in torch
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2213: # TODO: remove this as onnx opset 11 spec allows negative axes
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3032: "parameter passed to the type_as function is correct.",
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3171: # TODO(justinchuby): Support multiple quantized args in output
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3183: # TODO(justinchuby): Support multiple quantized args in output
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3856: # TODO(justinchuby): Support multiple quantized args in output
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3883: # TODO(justinchuby): Support multiple quantized args in output
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4663: # optimization pass to remove this later. It is an error if all
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4938: # TODO: remove this as onnx opset 11 spec allows negative axes
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5348: # TODO: If indexing is supported natively in ONNX in future opsets,
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5745: # TODO: Might need a fix in torch group_norm module
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6277: # TODO: It would be better to export this as a chunk directly, as this is
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6279: # TODO: Once we have proper scoping, stop reimplementing chunk, delete this
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6336: # TODO(justinchuby): Use a public method in the helper module
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6433: torch._C._jit_pass_onnx_block(
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6441: fixed_outputs = torch._C._jit_pass_fixup_onnx_controlflow_node(
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6446: torch._C._jit_pass_onnx_node_shape_type_inference(
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6496: env = torch._C._jit_pass_onnx_block(
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6524: torch._C._jit_pass_onnx_block(
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6532: fixed_outputs = torch._C._jit_pass_fixup_onnx_controlflow_node(
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6537: torch._C._jit_pass_onnx_node_shape_type_inference(
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset13.py:520: # TODO: So far we don"t have a module using this method. We"ll keep
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:48: # TODO(justinchuby): Remove dependency to this global variable from constant_fold.cpp
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:142: pass
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:250: All but the last element of the tuple will be passed as non-keyword arguments,
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:261: interpreted as containing named arguments. In order to pass a dict as the
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:452: If True, `deduplicate_initializers` pass will not be executed. This means
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:594: _C._jit_pass_inline(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:597: _C._jit_pass_inline_fork_wait(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:598: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:600: _C._jit_pass_onnx_autograd_function_process(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:601: _C._jit_pass_lower_all_tuples(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:608: _C._jit_pass_constant_propagation(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:613: _C._jit_pass_dce(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:614: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:618: # Must run before _C._jit_pass_erase_number_types to prevent type substitution
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:619: if _C._jit_pass_cse(graph):
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:620: _C._jit_pass_onnx_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:622: _C._jit_pass_canonicalize_graph_fuser_ops(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:623: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:624: _C._jit_pass_peephole(graph, True)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:625: _C._jit_pass_fuse_addmm(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:626: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:628: _C._jit_pass_peephole(graph, True)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:629: _C._jit_pass_lower_all_tuples(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:630: # in _jit_pass_onnx, symbolic functions are called for each node for conversion.
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:634: # This pass does a preprocess, and prepares the nodes such that enough context can be received
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:636: _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:637: _C._jit_pass_onnx_preprocess(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:640: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:643: _C._jit_pass_prepare_division_for_onnx(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:645: _C._jit_pass_onnx_remove_print(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:646: _C._jit_pass_onnx_preprocess_caffe2(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:650: _C._jit_pass_onnx_unpack_quantized_weights(graph, params_dict)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:652: _C._jit_pass_erase_number_types(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:656: _C._jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:657: _C._jit_pass_onnx_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:659: graph = _C._jit_pass_onnx(graph, operator_export_type)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:660: _C._jit_pass_onnx_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:661: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:663: _C._jit_pass_onnx_scalar_type_analysis(
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:666: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:668: _C._jit_pass_onnx_peephole(
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:671: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:678: _C._jit_pass_dce_allow_deleting_nodes_with_side_effects(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:679: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:680: graph = _C._jit_pass_canonicalize(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:681: _C._jit_pass_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:684: _C._jit_pass_onnx_graph_shape_type_inference(
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:690: pass
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:842: # Special case for common case of passing a single Tensor
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:940: _C._jit_pass_onnx_function_substitution(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:957: _C._jit_pass_onnx_function_substitution(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:965: _C._jit_pass_onnx_lint(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:974: _C._jit_pass_onnx_function_substitution(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1073: # TODO: can we simplify this to always return a tuple of Tensor or None?
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1075: # Special case for common case of passing a single Tensor
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1105: _C._jit_pass_onnx_assign_output_shape(
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1123: # assign_output_shape pass is not compatible with quantized outputs.
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1127: _C._jit_pass_onnx_assign_output_shape(
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1145: params_dict = _C._jit_pass_onnx_eval_peephole(graph, params_dict)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1147: params_dict = _C._jit_pass_onnx_constant_fold(
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1150: _C._jit_pass_dce_allow_deleting_nodes_with_side_effects(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1154: _C._jit_pass_onnx_graph_shape_type_inference(
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1160: pass
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1162: params_dict = _C._jit_pass_onnx_eliminate_unused_items(graph, params_dict)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1165: # In this pass transform constants of other data types to float/double + cast operator.
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1167: _C._jit_pass_onnx_cast_all_constant_to_floating(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1169: params_dict = _C._jit_pass_filter_non_tensor_arguments(params_dict)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1216: # symbolic functions because there is a higher chance that a pass
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1223: _C._jit_pass_inline(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1224: _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1225: _C._jit_pass_erase_number_types(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1226: _C._jit_pass_dce_allow_deleting_nodes_with_side_effects(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1239: # eliminated in the conversion passes. Users may still see errors caused
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1248: # TODO(justinchuby): Create a way to check if an op is fully supported.
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1274: _C._jit_pass_onnx_track_scope_attributes(graph, onnx_attrs)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1316: "passed in the set for argument `export_modules_as_functions`. "
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1332: _C._jit_pass_onnx_clear_scope_records()
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1473: _C._jit_pass_dce_allow_deleting_nodes_with_side_effects(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1476: # NOTE: cannot call DCE after this pass. DCE will remove function definition nodes.
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1477: node_attr_to_name = _C._jit_pass_onnx_function_extraction(
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1484: params_dict = _C._jit_pass_onnx_deduplicate_initializers(  # type: ignore[assignment]
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1489: _C._jit_pass_onnx_assign_scoped_names_for_node_and_value(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/utils.py:1722: # TODO Wrap almost identical attrs assignment or comment the difference.
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset17.py:145: )  # TODO(#145944): add compatibility with align_to_window option.
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset10.py:741: # TODO(justinchuby): Extract all the cast ops into a helper function.
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:53: # TODO: Update deprecation messages to recommend the new classes
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:105: remained_onnx_input_idx: If provided, only the specified inputs will be passed
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:109: the verifier which inputs to pass into the ONNX model.
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:135: # TODO(justinchuby): Add type checking by narrowing down the return type when input is None
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:268: # TODO: Remove `check_shape` option once every shape inconsistent issue is addressed.
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:444: # TODO: remove this and treat mutating model separately. See #77679
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:621: # TODO: refactor utils.py to remove duplicated code of context setup. See #78834
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:689: # TODO: Below is doing aten graph to onnx. It should be abstracted as a
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:701: params_dict = torch._C._jit_pass_onnx_eval_peephole(graph, params_dict)
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:707: params_dict = _C._jit_pass_onnx_constant_fold(graph, params_dict, opset_version)
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:708: _C._jit_pass_dce_allow_deleting_nodes_with_side_effects(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:711: _C._jit_pass_onnx_graph_shape_type_inference(graph, params_dict, opset_version)
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:713: params_dict = _C._jit_pass_onnx_eliminate_unused_items(graph, params_dict)
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:716: # In this pass transform constants of other data types to float/double + cast operator.
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:718: _C._jit_pass_onnx_cast_all_constant_to_floating(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:720: params_dict = _C._jit_pass_filter_non_tensor_arguments(params_dict)
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:723: _C._jit_pass_dce_allow_deleting_nodes_with_side_effects(graph)
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:874: # TODO(#77679): remove this and treat mutating model separately.
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:931: # TODO: Only copy the argument if mutation is detected in Graph.
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:1282: # TODO: A more compact graph printer.
- .venv/lib/python3.12/site-packages/torch/onnx/verification.py:1841: # TODO: Copied from utils.py `export` until `_optimize_graph`.
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:17: TODO: test coverage for mixed types inputs.
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:20: TODO: bfloat16 support.
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:23: TODO: optional start/end attribute.
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:136: # TODO(justinchuby): Replace insinstance with _is_value once we figure out mypy
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:409: # TODO(justinchuby): Only single output is supported for now. We may want to
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:1298: # TODO(justinchuby): Check if dtype is indeed a int.
- .venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:2162: # TODO: remove these once we support Type's in the JIT IR and we can once again
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:18: from torch.fx.passes.fake_tensor_prop import FakeTensorProp
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:19: from torch.fx.passes.operator_support import OperatorSupport
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:20: from torch.fx.passes.tools_common import CALLABLE_NODE_OPS
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:33: import torch.onnx._internal.fx.passes  # noqa: TCH004
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:84: passes,
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:124: # TODO: select a good default based on the capabilities of the host
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:347: # TODO(justinchuby): Refactor this function
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:618: # (i.e., args passed into OrtBackend._ort_acclerated_call).
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:624: # TODO(justinchuby): Simplify
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:765: # TODO(wschin): Make it to inference session level flag.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:774: Symbolic execution is used to capture the forward pass and backward passes as a single graph.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:814: #     (see onnxfunction_dispatcher passed to FxOnnxInterpreter.run below).
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:855: # TODO(wschin): this is a naive implementation of cache without proper guard
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:927: from torch.onnx._internal.fx import fx_onnx_interpreter, passes
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:947: graph_module = passes.MovePlaceholderToFront(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:992: graph_module = passes.InsertTypePromotion(graph_module).run()
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:1030: # TODO(wschin): enable external allocators.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:1119: from torch.fx.passes.infra.partitioner import CapabilityBasedPartitioner
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:1158: # TODO(wschin): use a better way to identify fused submodule
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:1236: "to pass to `torch.compile`. "
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:417: # TODO: Design the passes API
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:419: def pre_export_passes(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:426: """Applies pre-export passes to the FX graph.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:428: Pre-export passes are FX-to-FX graph transformations that make the graph
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:436: def common_pre_export_passes(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:442: # TODO: Import here to prevent circular dependency
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:443: from torch.onnx._internal.fx import passes
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:446: module = passes.Decompose(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:455: module = passes.Functionalize(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:461: # Input mutations are detected and distilled after `Functionalize` pass.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:463: module = passes.RemoveInputMutation(module).run(*fx_module_args)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:467: module = passes.InsertTypePromotion(module).run()
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:470: module = passes.RestoreParameterAndBufferNames(module, original_model).run()
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:128: # TODO: make_fx lose stack info https://github.com/pytorch/pytorch/issues/90276
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:131: # TODO(XuehaiPan): Dynamo does not support `dummy_leaf = object()` as a sentinel value in the frame.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:133: pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:178: pass_if_any_checks: Sequence[Callable[[], bool]] = [
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:187: if not any(check() for check in pass_if_any_checks):
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:442: `model_outputs` that was passed to this method.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:544: `model_outputs` that was passed to this method.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/registration.py:144: # TODO(justinchuby): Add @functools.lru_cache(maxsize=None) if lookup time becomes
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:4: # TODO(justinchuby): Move more of the symbolic helper functions here and expose
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:242: # now they can pass through None attributes, and have them not show up
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:309: _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:340: # TODO: Expose this to user when migrating symbolic helper functions to here.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:17: _pass,
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:269: # TODO: aten::sym_size has overload, but fx graph is using
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:424: onnx_meta: _pass.GraphModuleOnnxMeta | None = fx_graph_module.meta.get(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:430: f"Only submodules produced by `Modularize` pass is supported in ONNX export."
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:457: # TODO: Fix FakeTensorMode limitation asap
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:458: # We want to pass list of ints and floats to TorchScript graph correctly
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:618: # TODO(wechi): Support call_method.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:637: the exporter's `Modularize` pass. Each `call_module` node has an associated fx.GraphModule
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:670: # TODO: We may want to consider other naming styles. The goal is to be stable and
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/dynamo_graph_extractor.py:114: The pytree extension can be customized by passing in a ``_PyTreeExtensionContext``
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/dynamo_graph_extractor.py:221: return self.pre_export_passes(options, model, graph_module, updated_model_args)  # type: ignore[return-value]
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/dynamo_graph_extractor.py:223: def pre_export_passes(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/dynamo_graph_extractor.py:230: return _exporter_legacy.common_pre_export_passes(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:13: # TODO: Remove after https://github.com/huggingface/safetensors/pull/318
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:49: TODO: Should this really be a global patcher? Can we make it a local patcher?
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:39: # TODO: Figure out how to retrieve commit hash.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:60: Unfortunately, there is no way to pass `autojunk` argument to these functions, and
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:134: return f"Running {self.__class__.__name__} pass. "
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:162: This pattern can be useful for many things, including writing code transformations as well as analysis passes.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:180: TODO(bowbao): Add more overridable methods in call hierarchy
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:181: TODO(bowbao): Create an example once more overridable methods are added.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py:217: # TODO(titaiwang): aten::sym_size has overload, but fx graph is using
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py:437: A function should at least pass the first step to be eligible for the
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:117: # TODO: generalize to allow more checkpoints formats (torch or gguf)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/_utils.py:2: """Common utility functions for FX passes.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/_utils.py:4: These functions should NOT be directly invoked outside of `passes` package.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:13: from torch.onnx._internal.fx import _pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:14: from torch.onnx._internal.fx.passes import _utils
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:18: class Functionalize(_pass.Transform):
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:21: This pass utilizes ``functionalization`` utility of ``torch._functorch`` to convert
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:44: # was passed in as `a` is not mutated.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:58: For ONNX inference, it is recommended to run ``RemoveInputMutation`` after this pass.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:104: # TODO: May need revisit for user fake mode export + dynamic shape scenario.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:109: # to create a new fake mode by passing tracing_mode as "real".
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:133: class RemoveInputMutation(_pass.Transform):
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:136: This pass is recommended to be used after ``Functionalization`` pass.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:137: ``Functionalization`` pass adds `aten.copy_.default` nodes to the graph
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/virtualization.py:7: from torch.onnx._internal.fx import _pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/virtualization.py:14: class MovePlaceholderToFront(_pass.Transform):
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/virtualization.py:15: """This pass move all placeholder nodes to the front of the graph node list.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/virtualization.py:39: class ReplaceGetAttrWithPlaceholder(_pass.Transform):
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:12: from torch.onnx._internal.fx import _pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:341: IR nodes are used for Modularize pass only. They add a layer of abstraction on top of
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:345: The main job of the pass is to group `fx.Node`s that belong to the same `nn.Module`
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:354: the pass creates a `_ModuleNode` and groups the sequence of nodes that shares the
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:433: purpose of this pass. Ignoring that, `fx.Interpreter.run` achieves the same effect
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:694: graph_module.meta["onnx"] = _pass.GraphModuleOnnxMeta(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:695: _pass.PackageInfo.from_python_class(module_class)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:733: class Modularize(_pass.Transform):
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:741: This pass generates a new `fx.GraphModule`. It groups the flattened `fx.Node`s that belong
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:762: The generality decreases along this list. Within the scope of this function, the pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:778: pass can be applied to consolidate completely identical functions and reduce duplication.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:784: [NOTE: Modularize pass ordering]
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:785: This pass groups fx nodes into subgraphs that reside within the `call_module` fx node.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:786: Other fx passes (including some outside the exporter) might not recognize `call_module`.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:787: They may assume that all nodes are flattened. Hence it is recommended to invoke this pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:788: as the last pre onnx export fx pass. If not for this consideration, this operation could
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:795: >>> from torch.onnx._internal.fx import passes
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/modularization.py:824: >>> gm = passes.Modularize(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:24: from torch.onnx._internal.fx import _pass, type_utils as fx_type_utils
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1280: During the type promotion pass, there are cases where the types of the args and kwargs may change,
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1430: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1434: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1536: raise NotImplementedError(f"Unknown fx arg type: {type(fx_arg)}")
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1588: class InsertTypePromotion(_pass.Transform):
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1591: Underneath, the main pass is driven by `_TypePromotionInterpreter`, which is a subclass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1641: "InsertTypePromotion pass needs to run with pre-existing fake args, "
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1642: "Otherwise the pass will produce inaccurate dynamic shape. "
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1651: "It does not accept concrete arguments as input because this pass requires "
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1653: "the pass loses the symbolic dynamic shape information."
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/decomp.py:12: from torch.onnx._internal.fx import _pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/decomp.py:13: from torch.onnx._internal.fx.passes import _utils
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/decomp.py:22: class Decompose(_pass.Transform):
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/decomp.py:56: # TODO: May need revisit for user fake mode export + dynamic shape scenario.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/decomp.py:61: # to create a new fake mode by passing tracing_mode as "real".
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/readability.py:8: from torch.onnx._internal.fx import _pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/readability.py:18: class RestoreParameterAndBufferNames(_pass.Transform):
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/readability.py:21: This pass is useful for readability of the exported ONNX graph. It restores the
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/readability.py:24: `_param_constant9` by FX, this pass will rename it back.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/readability.py:26: This pass must be run after `Decompose` pass. Because this pass is expected to be called on
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_fx_passes.py:7: from torch.onnx._internal.fx import passes
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_fx_passes.py:25: """Inplace pass to insert explicit type promotion nodes, recursively through nested modules."""
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_fx_passes.py:28: passes.InsertTypePromotion(module).run()
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_ir_passes.py:23: # TODO: Ensure the names do not have duplicates
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_ir_passes.py:99: # TODO(justinchuby): Remove this hack and improved onnxscript
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:137: # where an attribute marked as float can be passed as an int.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:181: # TODO(justinchuby): Implement type promotion logic here.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:326: # TODO(justinchuby): Cast the ir.Value here if needed
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:497: are not used in this function. The data structure is passed in for
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:608: # TODO(justinchuby): Handle cast
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:648: # TODO(justinchuby): Remove this once IsScalar and Rank are removed
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:660: pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:676: pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:682: pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py:703: # TODO(after torchlib migration): Remove traceable function handling
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_isolated.py:35: args: The positional arguments to pass to the function.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_isolated.py:36: kwargs: The keyword arguments to pass to the function.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_registration.py:97: # TODO(justinchuby): Handle arbitrary custom ops
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_registration.py:168: # TODO(justinchuby): Remove this once torchlib is migrated to PyTorch
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dispatching.py:165: # TODO: Maybe just check dtype? Being more strict here for now
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dispatching.py:293: # TODO: Handle None attributes
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dispatching.py:347: # TODO: Handle when node does not have a target
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_tensors.py:37: # TODO: Implement indexing
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_capture_strategies.py:43: """Patch PyTorch to bypass some functions torch.export.export does not support."""
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_capture_strategies.py:44: # TODO: Remove the patches once dynamo supports these functions.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_capture_strategies.py:137: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_compat.py:113: # TODO(justinchuby): Support complex inputs with annotations
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_schemas.py:111: # TODO: Add other properties too
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_schemas.py:150: # TODO: Upstream this to IR
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_schemas.py:365: # TODO: Double check the separator for overload
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_schemas.py:467: # TODO: Handle variadic
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_schemas.py:479: # TODO: Use ir_convenience instead to handle int as float
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_schemas.py:519: # TODO: Handle variadic
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_schemas.py:532: pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_testing.py:33: args: The positional arguments to pass to the program.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_testing.py:35: kwargs: The keyword arguments to pass to the program.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_testing.py:78: # TODO(justinchuby): Include output names in the error message
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_onnx_program.py:20: from torch.onnx._internal.exporter import _dynamic_shapes, _ir_passes
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_onnx_program.py:143: # TODO(#151064): Use dlpack when ORT properly supports it
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_onnx_program.py:372: # TODO(justinchuby): Allow different inference options
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_onnx_program.py:410: _ir_passes.rename_axis(self.model, rename_mapping)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_reporting.py:31: # Whether ONNX model passes onnx.checker.check_model
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:35: _fx_passes,
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:36: _ir_passes,
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:274: pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:456: pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:527: pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:549: # TODO(justinchuby): Maybe keep it as None?
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:577: # TODO: Log the message here to expose false positives
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:606: # TODO: Get IR function directly when onnxscript is updated
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:610: # Opset imports are added to the model in the final add_opset_imports pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:974: exported_program = _fx_passes.decompose_with_registry(exported_program, registry)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:978: _fx_passes.insert_type_promotion_nodes(graph_module)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:979: graph_module = _fx_passes.remove_assertion_nodes(graph_module)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1038: # Opset imports are added to the model in the final add_opset_imports pass
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1144: # Subsequent passes can decide if they want to add initializers as inputs
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1219: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1231: # TODO: Decide if we should keep mutated buffers as inputs/outputs
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1233: # TODO(justinchuby): Remove the hack
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1234: _ir_passes.add_torchlib_common_imports(model)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1237: _ir_passes.add_opset_imports(model)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1274: args: The arguments to pass to the model.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1275: kwargs: The keyword arguments to pass to the model.
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1465: # Run the ONNX passes
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1467: _ir_passes.rename_inputs(onnx_program.model, input_names)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1469: _ir_passes.rename_outputs(onnx_program.model, output_names)
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1604: # TODO(justinchuby): The threshold is arbitrary right now
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_torchlib/_torchlib_registry.py:64: # TODO(justinchuby): Simplify the logic and remove the private attribute
- .venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_torchlib/ops/hop.py:118: # The iterated element passed to the body subgraph does not have a sequence axis.
- .venv/lib/python3.12/site-packages/torch/onnx/ops/__init__.py:156: # TODO: Parse domain
- .venv/lib/python3.12/site-packages/torch/onnx/ops/__init__.py:369: Computes scaled dot product attention on query, key and value tensors, using an optional attention mask if passed.
- .venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:21: pass
- .venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:114: # we have to pass requires_grad into constructor, rather than set it as an
- .venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:326: # TODO: Handle distinguishing between subclass and non-subclass versions of NT better
- .venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:501: raise NotImplementedError(sparse.layout)
- .venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:642: # TODO: Maybe this should be in tensor_classes? :)
- .venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:92: pass  # SIGINT; Killed by parent, do nothing
- .venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:297: pass
- .venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:316: the process index and ``args`` is the passed through tuple
- .venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:319: args (tuple): Arguments passed to ``fn``.
- .venv/lib/python3.12/site-packages/torch/multiprocessing/__init__.py:118: pass
- .venv/lib/python3.12/site-packages/torch/multiprocessing/pool.py:20: This lets us pass tensors in shared memory across processes instead of
- .venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:276: # TODO: is there a way to split by device and dtype without appending in the inner loop?
- .venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:297: between the backward pass(es) and :meth:`step`.
- .venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:413: # and `found_inf` to the passed optimizer so that the optimizer can utilize those
- .venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:424: "GradScaler is going to stop passing itself as a keyword argument to the passed "
- .venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:426: "`found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.",
- .venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:62: :class:`autocast` should wrap only the forward pass(es) of your network, including the loss
- .venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:63: computation(s).  Backward passes under autocast are not recommended.
- .venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:75: # Enables autocasting for the forward pass (model + loss)
- .venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:130: # Runs the forward pass with autocasting.
- .venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:146: # Runs the forward pass with autocasting.
- .venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:448: # Casts Tensors and containers of Tensors.  Special-cases passthroughs for strings and np.ndarrays, which
- .venv/lib/python3.12/site-packages/torch/jit/_decompositions.py:84: torch._C._jit_pass_inline(scripted_func.graph)
- .venv/lib/python3.12/site-packages/torch/jit/_decompositions.py:87: torch._C._jit_pass_peephole(scripted_func.graph)
- .venv/lib/python3.12/site-packages/torch/jit/_decompositions.py:88: torch._C._jit_pass_constant_propagation(scripted_func.graph)
- .venv/lib/python3.12/site-packages/torch/jit/_decompositions.py:96: # TODO: replace torch.sigmoid -> aten.sigmoid
- .venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:67: TODO: To remove this check once Union support lands.
- .venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:133: # TODO: To remove this check once Union suppport in TorchScript lands.
- .venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:164: pass
- .venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:172: pass
- .venv/lib/python3.12/site-packages/torch/jit/supported_ops.py:109: pass
- .venv/lib/python3.12/site-packages/torch/jit/_serialization.py:176: # TODO: Pretty sure this approach loses ConstSequential status and such
- .venv/lib/python3.12/site-packages/torch/jit/_check.py:50: The above code will pass the ``AttributeTypeIsSupportedChecker``
- .venv/lib/python3.12/site-packages/torch/jit/_check.py:148: # TODO @ansley: add `Union` once landed
- .venv/lib/python3.12/site-packages/torch/jit/_freeze.py:35: optimize_numerics (bool): If ``True``, a set of optimization passes will be run that does not strictly
- .venv/lib/python3.12/site-packages/torch/jit/_freeze.py:143: optimize_numerics (bool): If ``True``, a set of optimization passes will be run that does not strictly
- .venv/lib/python3.12/site-packages/torch/jit/_freeze.py:174: torch._C._jit_pass_optimize_frozen_graph(mod.graph, optimize_numerics)
- .venv/lib/python3.12/site-packages/torch/jit/_freeze.py:180: torch._C._jit_pass_optimize_frozen_graph(
- .venv/lib/python3.12/site-packages/torch/jit/_freeze.py:189: Perform a set of optimization passes to optimize a model for the purposes of inference.
- .venv/lib/python3.12/site-packages/torch/jit/_freeze.py:232: torch._C._jit_pass_optimize_for_inference(mod._c, other_methods)
- .venv/lib/python3.12/site-packages/torch/jit/annotations.py:131: pass
- .venv/lib/python3.12/site-packages/torch/jit/annotations.py:141: # A stricter version of `inspect.isroutine` that does not pass for built-in
- .venv/lib/python3.12/site-packages/torch/jit/annotations.py:443: # TODO: this is hack to recognize NumberType
- .venv/lib/python3.12/site-packages/torch/jit/annotations.py:449: # TODO: Determine if the other cases need to be fixed as well
- .venv/lib/python3.12/site-packages/torch/jit/annotations.py:542: # TODO: Consider not exporting these during wildcard import (reserve
- .venv/lib/python3.12/site-packages/torch/jit/__init__.py:132: This method is a pass-through function that returns `the_value`, used to hint TorchScript
- .venv/lib/python3.12/site-packages/torch/jit/__init__.py:168: the_type: Python type that should be passed to TorchScript compiler as type hint for `the_value`
- .venv/lib/python3.12/site-packages/torch/jit/__init__.py:172: `the_value` is passed back as return value.
- .venv/lib/python3.12/site-packages/torch/jit/__init__.py:263: pass
- .venv/lib/python3.12/site-packages/torch/jit/__init__.py:266: pass
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:82: pass
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:168: pass
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:187: pass
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:242: pass
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:263: # TODO: proper overriding analysis when implementing class inheritance
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:392: # TODO: more robust handling of recognizing ignore context manager
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:526: # TODO: add input, output validator
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:572: ignore_function_str += return_ann + ": pass"
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:782: # TODO: try to recover the location of else:? Python doesn't give us useful
- .venv/lib/python3.12/site-packages/torch/jit/frontend.py:825: r = ctx.make_range(stmt.lineno, stmt.col_offset, stmt.col_offset + len("pass"))
- .venv/lib/python3.12/site-packages/torch/jit/_decomposition_utils.py:8: f"Must pass specific op overload, not overload packet, found {op}"
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:159: # TODO: figure out one liner to .clone() and set requires_grad
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:201: Verify that a JIT compiled model has the same behavior as its uncompiled version along with its backwards pass.
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:209: you passed in.
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:215: args (tuple or Tensor): the positional arguments to pass to the
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:217: be a single positional argument to be passed to the model.
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:221: before calling backwards; if this is inappropriate, you can pass your
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:223: these are passed as separate positional arguments to `loss_fn`.
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:228: # TODO: In principle, we track device information in our trace, so it
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:232: # TODO: Consider adding a utility function to torch.jit to test
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:271: # TODO: I'm not sure if the clone here is necessary but it is safer
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:382: mod_canonicalized = torch._C._jit_pass_canonicalize(traced_func.graph)
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:383: torch._C._jit_pass_inline(mod_canonicalized)
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:384: torch._C._jit_pass_erase_shape_information(mod_canonicalized)
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:387: check_canonicalized = torch._C._jit_pass_canonicalize(check_mod_func.graph)
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:388: torch._C._jit_pass_inline(check_canonicalized)
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:389: torch._C._jit_pass_erase_shape_information(check_canonicalized)
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:506: " pass check_trace=False to torch.jit.trace()"
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:733: # Special case for common case of passing a single Tensor
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:891: tensors. When a module is passed `torch.jit.trace`, only the
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:897: inputs that will be passed to the function while tracing.
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:914: would be specified in ``example_inputs``. For best results, pass in
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:929: arguments of example inputs that will be passed to the function while
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:1137: When a module is passed to :func:`torch.jit.trace <torch.jit.trace>`, only
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:1148: The inputs will be passed to methods whose names correspond to inputs'
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:1161: be specified in ``inputs``. For best results, pass in a
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:1355: pass
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:1488: args (tuple or Tensor): the positional arguments to pass to the
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:1490: be a single positional argument to be passed to the model.
- .venv/lib/python3.12/site-packages/torch/jit/_trace.py:1491: kwargs (dict): the keyword arguments to pass to the function/module
- .venv/lib/python3.12/site-packages/torch/jit/_dataclass_impls.py:52: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/jit/_dataclass_impls.py:86: return compose_fn(cls, "__init__", body or ["pass"], signature=str(signature))
- .venv/lib/python3.12/site-packages/torch/jit/_dataclass_impls.py:116: "raise NotImplementedError('__hash__ is not supported for dataclasses in TorchScript')"
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:31: # TODO: there should be a more principled way of doing this.
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:82: #       pass
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:300: # TODO: We should really error in this case, but its bc-breaking so
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:319: # TODO: We should really error in this case, but its bc-breaking so
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:399: # TODO: could add more detail here. For example, what the user should do
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:675: # TODO: Why skip this? Because @torch.jit._overload_method will
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:681: # TODO: we don't currently do this functions that are recursively
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:822: f"'{torch.typename(type(mod))}' has uninitialized parameters {name}. Did you forget to run a forward pass?"
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:827: f"'{torch.typename(type(mod))}' has uninitialized buffers {name}. Did you forget to run a forward pass?"
- .venv/lib/python3.12/site-packages/torch/jit/_recursive.py:834: (TODO add a link when the rules are published).
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:41: # TODO: only assertion error is bound in C++ compilation right now
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:96: # TODO: only assertion error is bound in C++ compilation right now
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:406: # TODO: return self
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:611: # TODO: handling of slice
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:616: # TODO: handling of slice
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:677: # TODO: look into rewriting with early return and getting loop unrolling to fire
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:697: # TODO: assertions could be expanded with the error messages
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1028: # TODO: return self
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1036: # TODO: use slicing when slice optimization has landed
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1199: torch._C._jit_pass_inline(scripted_func.graph)
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1202: torch._C._jit_pass_peephole(scripted_func.graph)
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1203: torch._C._jit_pass_constant_propagation(scripted_func.graph)
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1454: # TODO: migrate over all of symbolic_shape_registry_util.cpp
- .venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1469: # quantized_conv_prepack TODO
- .venv/lib/python3.12/site-packages/torch/jit/_builtins.py:134: # eventually ops should encompass all of torch/functional.py, (torch.functional.__all__)
- .venv/lib/python3.12/site-packages/torch/jit/_builtins.py:137: # TODO: add support for more ops
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:89: This method is a pass-through function that returns `value`, mostly
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:102: In eager mode, it is simply a pass-through function that returns `value`
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:348: pass
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:650: init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:843: # TODO: we don't have _concrete_type set after load(), and in general we lose constant information.
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:851: # TODO: it's possible that the following is confusing:
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:873: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:1002: # TODO MAKE SURE THAT DISABLING WORKS
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:1004: pass
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:1068: and can be passed between Python and TorchScript with reference semantics and
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:1083: and can be passed between Python and TorchScript with reference semantics and
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:1169: # If this type is a `nn.Module` subclass, they probably meant to pass
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:1173: f"Type '{obj}' cannot be compiled since it inherits from nn.Module, pass an instance instead"
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:1246: subsequently passed by reference between Python and TorchScript with zero copy overhead.
- .venv/lib/python3.12/site-packages/torch/jit/_script.py:1555: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/dtype_propagation.py:164: # TODO - we avoid calling this in codegen, needs work for non codegen use cases
- .venv/lib/python3.12/site-packages/torch/_inductor/dtype_propagation.py:177: # TODO - TODO - rationalize index_expr. The dtype is not always used and we are inconsistent about int32 or int64
- .venv/lib/python3.12/site-packages/torch/_inductor/dtype_propagation.py:291: # TODO - need to handle multiple outputs
- .venv/lib/python3.12/site-packages/torch/_inductor/dtype_propagation.py:347: # TODO - way of registering dtype for op in backend
- .venv/lib/python3.12/site-packages/torch/_inductor/dtype_propagation.py:380: pass  # mypy will error if we got any of the signatures wrong
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:102: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:122: """During autotuning, we need to pass the same inputs to all choices.
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:641: Will add needed args to pass it in if it is dynamic.
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:654: Will add needed args to pass it in if it is dynamic.
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:806: # TODO (from reviewers as well)
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:871: # TODO: we should have intermediary var shapes
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1074: # We pass template_out as the shape to broadcast the indexing to as
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1082: pass  # ignore default codegen
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1305: ) -> Optional[NotImplementedError]:
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1311: kwargs: Additional kwargs to be passed to self.generate() to generate a new ChoiceCaller.
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1317: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1383: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1446: # TODO(nmacchioni): fix sympy division by zero
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1544: prefix_args: Number of input nodes to be passed as arguments
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1545: suffix_args: Number of input nodes to be passed as arguments
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1547: subgraphs: Optional subgraphs to be passed as arguments, these will be inlined
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1550: if you need to return multiple outputs. You can pass them as inputs and mark them as
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1740: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:1837: # TODO(AlnisM): Does tile_shape always exist?
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2052: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2151: # corresponding ir.Buffer. if passed for a given
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2162: # TODO(jgong5): support multi-template on CPU
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2166: # TODO - assert that we have not mutating kernels here
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2319: # re-benchmarking the same choices with profiler is a bit expensive, so pass it in as a thunk.
- .venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:2671: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_inductor/index_propagation.py:342: # TODO Perhaps move this logic to the simplify indexing pass
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:479: # TODO - would be nice if we could just cache accesses on ReadWrites,
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:559: # but TODO this might be a convenient place to signal to the Collective kernels to inplace
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:592: # TODO(voz): Should the pragma be constant somewhere?
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:613: # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:658: Another example is that even though a buffer is passed in, we may
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:764: # TODO: Figure out what's going on
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:857: # TODO(xmfan): find a better heuristic to model FLOPS/latency relationship
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:891: # TODO when we drop support for Python < 3.10, we can use
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1080: # TODO(shunting) if this cause compilation time increase when
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1494: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1497: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1500: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1607: "At least one node passed to ForeachKernelSchedulerNode.can_fuse should be a foreach node"
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1663: "At least one node passed to ForeachKernelSchedulerNode.fuse should be a foreach node"
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1820: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1823: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2079: # Must run first to correctly set dependencies, before all other passes that rely on
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2101: if config._pre_fusion_custom_pass is not None:
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2102: self.nodes = config._pre_fusion_custom_pass(self.nodes)
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2104: if config._post_fusion_custom_pass is not None:
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2105: self.nodes = config._post_fusion_custom_pass(self.nodes)
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2111: # Peak memory pass and overlap pass must run last, otherwise
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2112: # other reordering passes could undo their effects.
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2185: "All nodes passed to scheduling must have an origin"
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2194: raise NotImplementedError(node)
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2829: # TODO support benchmarking epilogue fusion
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:2922: # TODO: Remove this check after all Triton templates support prologue fusion.
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:3476: # TODO Don't do loop reordering for CPU for now.
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:3572: # TODO - make configurable per input, for instance, bias can fuse fp32 -> fp16 profitably
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:3581: # TODO - would be nice to generalize this, however, we would need more explicit
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:3892: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:4227: raise NotImplementedError(f"Unsupported input node type: {type(node)}")
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:4906: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:4914: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:4945: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:4959: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:4967: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:4973: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:4979: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:4992: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:5001: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:5008: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:5026: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:12: Implement this interface for custom Graph passes:
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:14: 1) The __call__() method contains the implementation of the custom pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:17: passes are applied. This method can return any identifier as long as it uniquely
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:20: existing entries. We expect custom passes would typically depend purely on the
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:23: static list of source files, i.e., the source(s) containing the custom pass
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:27: ** IMPORTANT ** If your custom pass's behavior depends on some external state, then
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:34: # my custom graph optimization pass
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:45: Implementation of the custom pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:51: Return an ID to uniquely identify your custom pass implementation. Return None
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:58: Implement this interface for custom Graph passes:
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:60: 1) The __call__() method contains the implementation of the custom pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:63: passes are applied. This method can return any identifier as long as it uniquely
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:66: existing entries. We expect custom passes would typically depend purely on the
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:69: static list of source files, i.e., the source(s) containing the custom pass
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:77: Implementation of the custom pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/custom_graph_pass.py:83: Return an ID to uniquely identify your custom pass implementation. Return None
- .venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:108: # if lifted_constant_names is passed in, no concrete value is available
- .venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:214: # TODO - fix errors with this
- .venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:221: # TODO - constant folding triton kernel returns the inputs -- fix this
- .venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:230: # TODO - more complicated strategy
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:46: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:49: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:52: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:141: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:426: passthrough_args: Optional[list[str]] = None,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:440: # Some args are hard to abstract to OS compatible, passthrough directly.
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:441: self._passthrough_args: list[str] = passthrough_args or []
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:465: self._passthrough_args = _remove_duplication_in_list(self._passthrough_args)
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:492: def get_passthrough_args(self) -> list[str]:
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:493: return self._passthrough_args
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:519: "passthrough_args": self.get_passthrough_args(),
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:660: passthrough_args: list[str] = []
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:670: passthrough_args.append(" ".join(extra_flags))
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:679: passthrough_args,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:720: passthrough_args,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:735: _append_list(self._passthrough_args, passthrough_args)
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:776: passthrough_args: list[str] = []
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:778: return cflags, include_dirs, passthrough_args
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:781: # TODO(T203137008) Can we unify these flags with triton_cc_command?
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:802: passthrough_args.append(" --rtlib=compiler-rt")
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:803: passthrough_args.append(" -fuse-ld=lld")
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:804: passthrough_args.append(f" -Wl,--script={linker_script}")
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:805: passthrough_args.append(" -B" + build_paths.glibc_lib)
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:806: passthrough_args.append(" -L" + build_paths.glibc_lib)
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:808: return cflags, include_dirs, passthrough_args
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:930: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:947: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:972: passthrough_args: list[str] = []
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:974: # Per https://mac.r-project.org/openmp/ right way to pass `openmp` flags to MacOS is via `-Xclang`
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1054: passthrough_args.append(fb_openmp_extra_flags)
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1059: # TODO: fix issue, can't find omp.h
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1068: return cflags, ldflags, include_dir_paths, lib_dir_paths, libs, passthrough_args
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1092: passthrough_args: list[str] = []
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1100: sys_libs_passthrough_args,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1119: omp_passthrough_args,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1122: cxx_abi_passthrough_args = _get_glibcxx_abi_build_flags()
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1123: fb_macro_passthrough_args = _use_fb_internal_macros()
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1131: + fb_macro_passthrough_args
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1144: passthrough_args = (
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1145: sys_libs_passthrough_args
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1147: + cxx_abi_passthrough_args
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1148: + omp_passthrough_args
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1158: passthrough_args,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1210: torch_passthrough_args,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1226: _append_list(self._passthrough_args, torch_passthrough_args)
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1276: passthrough_args: list[str] = []
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1326: passthrough_args = ["-Wl,-Bstatic -lcudart_static -Wl,-Bdynamic"]
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1338: passthrough_args,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1383: device_passthrough_args: list[str] = []
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1392: device_passthrough_args,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1402: _append_list(self._passthrough_args, device_passthrough_args)
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1496: self._passthrough_parameters_args = ""
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1617: for passthrough_arg in BuildOption.get_passthrough_args():
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1618: self._passthrough_parameters_args += f"{passthrough_arg} "
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1630: passthrough_args: str,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1638: f"{sources} {passthrough_args} {output}"
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1646: f"{include_dirs_args} {passthrough_args} {output}"
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1661: passthrough_args=self._passthrough_parameters_args,
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1750: target_compile_options(aoti_model PRIVATE {self._passthrough_parameters_args} -c)
- .venv/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1828: # TODO: make this work beyond CUDA
- .venv/lib/python3.12/site-packages/torch/_inductor/exc.py:27: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/exc.py:73: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/exc.py:113: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compiler_bisector.py:26: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compiler_bisector.py:31: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compiler_bisector.py:57: ],  # TODO - add cse ?
- .venv/lib/python3.12/site-packages/torch/_inductor/compiler_bisector.py:61: BisectSubsystem("joint_graph_passes"),  # passes applied on joint graph
- .venv/lib/python3.12/site-packages/torch/_inductor/compiler_bisector.py:63: "post_grad_passes"
- .venv/lib/python3.12/site-packages/torch/_inductor/compiler_bisector.py:64: ),  # passes applied individually on forward, and backward in inductor
- .venv/lib/python3.12/site-packages/torch/_inductor/compiler_bisector.py:70: ],  # TODO - add more - fusions ?
- .venv/lib/python3.12/site-packages/torch/_inductor/compiler_bisector.py:108: For subsystems which are applied repeatedly, such as the number of post grad passes or number
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:102: # TODO - only need one of these to be solvable to zero
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:303: # TODO: an earlier version for this code tried to iteratively try the maximum number
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:481: # TODO - a few dynamic shapes issues to resolve
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:502: # TODO - not handled well. indirect loads will not be coalesced,
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:510: # TODO - will the names for all the inputs/outputs accurately
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:590: # TODO - deduplicate with candidate_tilings
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:594: # TODO - reason about indirect vars
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:626: # TODO: separate into dataclass that olds mem, dtype, is_write
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:725: # TODO - if a var is in the middle, such as [n0, n1, n2]
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:756: # TODO - for strictly pointwise fusions,
- .venv/lib/python3.12/site-packages/torch/_inductor/tiling_utils.py:759: # TODO - could also prefer index var splits to reduction, better tested
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:194: # TODO - experiment with whether this limit is useful, setting `len(snodes)` disables it
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:219: # TODO - if the wait is for a collective that started before this collective or on another stream,
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:431: TODO: Come up with a better approach
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:477: # TODO: node_summary was written without FusedSchedulerNode in mind, generally needs to be hardened
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:489: # TODO - this function probably doesn't do a very good job estimating the runtime because it doesn't carefully model
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:507: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:532: for p in config.reorder_for_compute_comm_overlap_passes:
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:534: p = globals()[p]  # it is a builtin pass
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:536: f"Invalid reorder_compute_and_comm_for_overlap pass: {p} is not callable"
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:543: f"==== Visualize overlap before reordering pass {p}, {peak_memory=} ===="  # noqa: G004
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:554: f"==== Visualize overlap after reordering pass {p} (ran in {t} sec)===="  # noqa: G004
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:569: This FX graph pass replaces uses of FSDP2 unsharded params with their corresponding
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:572: NOTE: Can only apply this pass to any of the FSDP2 unsharded params that have this pattern
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:617: Skipping `remove_fsdp2_unsharded_param_graph_input_usage` FX graph pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:631: Skipping `remove_fsdp2_unsharded_param_graph_input_usage` FX graph pass for that unsharded param.
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:737: ):  # TODO(yf225): implement replacement in kwargs
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:811: graph_pass = PatternMatcherPass()
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:835: pass_dict=graph_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/comms.py:875: graph_pass.apply(graph)  # type: ignore[arg-type]
- .venv/lib/python3.12/site-packages/torch/_inductor/analyze_preserves_zero_mask.py:101: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/analyze_preserves_zero_mask.py:106: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:55: custom_backend_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:79: from torch._inductor.custom_graph_pass import (
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:99: from torch._utils_internal import log_cache_bypass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:131: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:134: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:137: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:554: # TODO: pickler.fast is technically deprecated. Will this work on new python versions?
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:576: # TODO: These tensors don't currently pickle, so we can't cache a compiled
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:579: raise BypassFxGraphCache("mkldnn tensors unpickleable")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:612: raise to bypass caching.
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:614: raise BypassFxGraphCache("Reduce unsupported")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:645: raise BypassFxGraphCache("Failed to pickle cache key") from e
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:781: class BypassFxGraphCache(Exception):
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:783: Exception to indicate that the FxGraphCache should be bypassed.
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:898: # Custom post grad passes should provide an ID to hash.
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:899: self.post_grad_custom_pre_pass = self._get_custom_pass_detail(
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:900: config.post_grad_custom_pre_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:902: self.post_grad_custom_post_pass = self._get_custom_pass_detail(
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:903: config.post_grad_custom_post_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:905: self._pre_fusion_custom_pass = self._get_custom_pass_detail_unsafe(
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:906: config._pre_fusion_custom_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:908: self._fuse_ddp_communication_passes = self._get_custom_pass_detail_unsafe(
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:909: config._fuse_ddp_communication_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:912: # Register indcutor backends and custom passes and get their UUIDs.
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:914: self.custom_backend_passes = tuple(
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:915: map(self._get_custom_pass_detail, custom_backend_passes.values())
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:920: # - _pre_fusion_custom_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:921: # - _fuse_ddp_communication_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:927: def _get_custom_pass_detail_unsafe(self, custom_pass: Any) -> Optional[Any]:
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:928: if not custom_pass:
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:930: if isinstance(custom_pass, list):
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:931: return [self._get_custom_pass_detail_unsafe(x) for x in custom_pass]
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:932: if isinstance(custom_pass, str):
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:933: return custom_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:934: if isinstance(custom_pass, CustomGraphPass):
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:935: return custom_pass.uuid()
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:936: if callable(custom_pass):
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:937: # Returning None is safe here because we raise an explicit bypass error
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:938: # later if we detect these passes are set to callables
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:940: raise AssertionError(f"unknown config type: {str(type(custom_pass))}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:942: def _get_custom_pass_detail(
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:943: self, custom_pass: Union[CustomGraphPassType, CustomGraphModulePass]
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:945: if not custom_pass:
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:947: assert isinstance(custom_pass, (CustomGraphPass, CustomGraphModulePass))
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:948: return custom_pass.uuid()
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1008: raise NotImplementedError("Implement _get_tmp_dir_for_key on parent class")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1054: Find the first cache entry in iterate_over_candidates that passes `evaluate_guards`.
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1060: evaluate_guards: Function that evaluates whether a guard passes the check,
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1166: # TODO(masnesral): Investigate whether it's beneficial to store compiled graphs
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1399: raise BypassFxGraphCache(
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1405: raise BypassFxGraphCache("Can't cache torchbind objects")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1410: Check some conditions that would preclude caching and raise BypassFxGraphCache
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1411: to bypass in case caching is not possible.
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1413: # Post grad custom passes must implement the CustomGraphPass or we don't
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1415: for p in (config.post_grad_custom_pre_pass, config.post_grad_custom_post_pass):
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1417: raise BypassFxGraphCache("Unsupported post grad custom pass")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1418: # We should find any users of _pre_fusion_custom_pass and _fuse_ddp_communication_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1419: # and ensure they are not passing us raw callables
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1420: if config._pre_fusion_custom_pass is not None:
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1421: if not isinstance(config._pre_fusion_custom_pass, CustomGraphPass):
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1422: raise BypassFxGraphCache("Unsupported _pre_fusion_custom_pass")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1423: for p in config._fuse_ddp_communication_passes:
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1425: raise BypassFxGraphCache("Unsupported _fuse_ddp_communication_pass")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1431: raise BypassFxGraphCache("Skipping graph with frozen constants")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1434: raise BypassFxGraphCache(
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1443: raise BypassFxGraphCache
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1449: raise BypassFxGraphCache("No shape env")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1467: - cache_info will contain debug info in the event of BypassFxGraphCache.
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1477: except BypassFxGraphCache as e:
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1478: counters["inductor"]["fxgraph_cache_bypass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1479: log.info("Bypassing FX Graph Cache because '%s'", e)
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1481: log_cache_bypass("bypass_fx_graph", str(e))
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1483: "cache_state": "bypass",
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1484: "cache_bypass_reason": str(e),
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1585: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1713: # And then pass the command_line to below write function as extra parameter to
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1727: # TODO (benjaminglass1): the CMake packaging path doesn't support linking files
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1985: # TODO: Fix mmap weights with cuda
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:2124: "TODO: add emit_multi_arch_kernel support for cutlass kernels"
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:2209: # TODO: unify to always use mmap_weights
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:2261: # Because tensors will be passed in as AtenTensorHandle, we need to explicitly convert them.
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:2715: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:3326: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:3459: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:3563: raise NotImplementedError(f"Unsupported output file suffix {dst_file_ext}!")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:3603: raise NotImplementedError("Unsupported env, failed to do dlclose!")
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:3882: # TODO: Make the typing hint strong here
- .venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:4003: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:143: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:210: The pass finds nodes that dislike padding. These are nodes that can be reached
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:413: # record multi_kernel choice for cpp_wrapper so the second pass knows
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:415: # since cpp_wrapper flag is OrderedSet to false for the first pass of codegen.
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:425: # This will be used if autotuning is done in one pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:504: # TODO: this should not be needed once #93059 lands
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:506: # TODO: make a dedicated UnknownSource for this?
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:697: # TODO - get different values per hardware
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:820: # need a second pass to add downstream nodes of those channel last nodes to the sets.
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:821: # This pass is especially needed to avoid mix-layout kernel inputs in backward pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:823: # Let's say a conv-batchnorm 's output is passed to relu whose output is in turn returned
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:824: # from the fwd graph. Without this second pass, we will force relu's output to be contiguous.
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:825: # Then in the kernel in backward pass, the contiguous output of relu may be mix with other channels last
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:826: # tensors and passed to a kernel.
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:828: # This pass improve yolov3 training speedup from 1.116x (worse than disabling layout optimization speedup 1.196x) to 1.4
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1070: # TODO fix partitioning issue and re-enable for backward
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1112: # the buffer should be static but us passing in a fake tensor with
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1132: # TODO(jansel): handle input aliasing
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1171: # passthrough lowerings from .pattern_matcher
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1205: # TODO: should really switch to "needs_fixed_stride" constraint on these
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1232: # that this operator was inserted by a custom pass
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1418: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1587: # TODO: this is sus, it probably should be handled in the
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1753: # TODO(jansel): introduce a store vs inline choice
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1889: # same ShapeEnv as before. In particular, on subsequent graph passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1984: # TODO(Eikan): Only support mixing cpu and other device now.
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:2147: # In the backward pass, V.real_inputs is not OrderedSet.
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:2170: # the first pass of the CPP wrapper-based compilation, as
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:2183: # If autotune_at_compile_time is True, we can do the codegen in one-pass
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:2196: # first pass
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:2205: # second pass
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:2253: graph. The parent graph is passed as an argument: the
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:2307: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/graph.py:2312: # TODO. Revisit this once the logging API is more mature
- .venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:58: # TODO - there are dominated uses whose dtype does not depend on whether
- .venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:79: # TODO - not sure if we should be doing int/float casts while tracing,
- .venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:117: # TODO - if dominated node of one to_dtype is not expressible in int32,
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:26: from torch._inductor.custom_graph_pass import CustomGraphPass
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:67: A Dummy pass to be used by ConfigFuzzer
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:125: # ConfigFuzzer compiled and ran the test and function it passed.
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:126: PASSED = "passed"
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:151: # TODO this needs to be indexed to the module, like inductor or dynamo, for name collisions
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:163: "normalization_aten_pass": {},
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:164: "unbind_stack_aten_pass": {},
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:378: Returns a function that will generate values from a type, based on the SamplingMethod passed in.
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:496: "post_grad_custom_pre_pass": DEFAULT,  # Typing
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:497: "post_grad_custom_post_pass": DEFAULT,  # Typing
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:498: "reorder_for_compute_comm_overlap_passes": DEFAULT,  # Typing
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:499: "joint_custom_post_pass": DEFAULT,  # Typing
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:500: "joint_custom_pre_pass": DEFAULT,  # Typing
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:501: "pre_grad_custom_pass": DEFAULT,  # Typing
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:610: raise ValueError("No default passed to ConfigFuzzer.")
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:902: # TODO support more dimensions
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:937: .passed {
- .venv/lib/python3.12/site-packages/torch/_inductor/fuzzer.py:971: status_class = "passed"
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:90: # TODO(jansel): we should implement decomps or lowerings for these
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:113: # TODO(rec): torch._higher_order_ops._foreach_map is not an OpOverload
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:131: # foreach_map for example just passes output buffers here
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:178: raise NotImplementedError(f"inductor does not support {msg}")
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:218: # TODO(jansel): ezyang says we won't need this in the future, try removing it
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:234: # TODO(jansel): add quantized types?
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:426: # TODO maybe we need to use pytrees here
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1075: # TODO: It would be better to realize the input if any of its sizes
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1190: raise NotImplementedError(f"unrealized as_strided({x}, ...)")
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1570: # TODO <leslie> Remove this fallback when we support vectorization
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1635: # TODO: We observed negative performance impact of pointwise_cat optimization on CPU so disabled it.
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1863: # TODO: don't guard on static shape here
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1912: # TODO: delete once triton adds native support
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2167: raise AssertionError("should be handled in fuse_seed_creation_pass()")
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2433: # TODO: combine this with require_contiguous after
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2854: # TODO(jansel): memory format
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3136: # deferred_runtime_asserts, TODO: try this assert out
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3439: raise NotImplementedError("Fallback for bool indices")
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3449: raise NotImplementedError("Fallback when indices is on a different device")
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3579: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3716: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3807: # TODO: use a masked store for this. currently only triton
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3963: # TODO: Need to support more reduction type
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4544: # TODO: Generalize to other max pooling flavors
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4971: # TODO: should we force these to be realized?
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:5377: # TODO(jansel): should we force these to be realized?
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:6114: # dst.copy_(dst) can happen from the reinplacing pass
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:6788: raise NotImplementedError("Helpful for debugging")
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:6816: # dst.copy_(dst) can happen from the reinplacing pass
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7060: Lowering inductor_prims.prepare_softmax_online to compute max/sum in one pass if no split is needed.
- .venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7093: # TODO: does inference need split online_softmax_reduce?
- .venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:171: - 8 gpus per node  # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
- .venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:179: # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_subproc.py:37: # TODO: Do we need to copy across some kind of logging IDs? (ChromiumEventLogger)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_subproc.py:41: # TODO: This is probably the wrong thing to do long-term - but for now
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_subproc.py:54: # TODO: Consider raising this limit if we start using async w/
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_subproc.py:70: # TODO: In subprocess mode we need to clear the inductor caches.
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_subproc.py:79: # TODO: We probably should be using a separate tmpdir in the worker
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_subproc.py:83: # TODO: We could be less aggressive by keeping a clock which gets
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_subproc.py:90: # TODO: turn off config.fx_graph_async_compile
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:109: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:112: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:178: # TODO - remove, prevents cleanup
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:199: TODO: in the future, we would like to do the following once storage weak refs land
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:245: # TODO - when issue #91395 is landed, we can set a weakref on
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:759: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:978: # TODO: register_generator_state should potentially take explicit device
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1360: "Wrong number of stack traces passed in"
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1633: # TODO: - should we make the storage resizable ?
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1758: lambda: "TODO: graph recording observed an input tensor deallocate during graph "
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1883: # TODO: make generation increment configurable, warn on overwrite.
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1940: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1987: # loop hasn't completed.  Occasionally, a backward pass corresponding to a forward pass may
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1988: # not be executed, so we cannot wait for all pending forward pass backward completions, so
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1990: # invocation. Triggering a backward pass typically doesn't lead to another torch.compile
- .venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:2470: # TODO: we could also allow the these weak refs to continue to be allocated,
- .venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:18: 1. Implicit argument passing.  Examples: ``V.current_node``, ``V.aot_compilation``.
- .venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:28: conveniently access them without having to pass them around.
- .venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:40: TODO: Define a parent class / protocol that defines all of the operations
- .venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:147: # TODO: To be honest, I feel we probably should just error in this
- .venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:190: )  # TODO: improve type
- .venv/lib/python3.12/site-packages/torch/_inductor/sizevars.py:55: # lifting and in some cases we should be directly passing through to ShapeEnv,
- .venv/lib/python3.12/site-packages/torch/_inductor/sizevars.py:262: # approximate test passed, try sound version
- .venv/lib/python3.12/site-packages/torch/_inductor/sizevars.py:637: # TODO(jansel): should we use sympy.diff here?
- .venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py:86: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py:155: pass  # register_at_fork does not exists on windows
- .venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py:161: TODO: remove after rollout.
- .venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py:186: `kernel_src` should be the exact string passed to async_compile.triton()'s first argument.
- .venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py:195: TODO: We store a LambdaFuture as that's the callable returned by async_compile.triton,
- .venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py:198: TODO: Source code here is not just the kernel's source code, but also includes the inductor preamble, etc.
- .venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py:224: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py:355: # process pool is running, so pass them to the subprocess to reset.
- .venv/lib/python3.12/site-packages/torch/_inductor/async_compile.py:532: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:75: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:79: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:83: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:87: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:91: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:105: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:111: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:119: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:132: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:146: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:152: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:158: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:164: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:171: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:177: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:199: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:205: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:218: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:220: # TODO: Better explain how the "collective" semantics of these ops;
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:240: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:242: # TODO: in practice, this seems to actually return None, but not returning
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:250: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:261: # TODO: Improve the description with some pseudocode
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:262: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:274: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:287: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:294: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:297: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:300: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:303: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:306: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:309: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:312: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:315: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:318: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:321: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:324: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:327: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:330: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:333: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:336: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:339: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:342: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:345: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:348: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:351: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:354: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:357: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:360: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:363: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:366: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:369: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:372: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:375: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:378: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:381: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:384: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:387: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:390: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:393: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:396: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:399: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:402: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:405: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:408: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:411: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:414: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:417: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:420: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:423: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:426: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:429: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:432: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:435: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:438: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:443: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:447: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:450: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:454: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:458: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:461: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:464: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:467: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:470: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:473: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:476: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:479: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:482: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:485: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:488: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:491: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:495: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:498: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:501: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:504: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:508: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:511: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:519: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:522: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:525: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:528: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:531: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:534: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:537: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:540: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:543: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:546: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:549: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:552: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:555: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:558: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:561: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:564: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:567: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:570: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:573: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:576: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:579: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:582: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:585: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:588: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:591: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:594: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:597: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:600: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:603: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:606: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:609: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:612: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:615: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:618: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:621: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:624: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:627: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:630: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:633: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:636: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:647: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:654: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:659: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:666: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:670: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:674: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:677: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:682: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:686: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:698: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:702: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:706: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:727: args: positional args passed to the op
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:728: kwargs: keyword args passed to the op
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:734: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:1119: """Wraps the underlying handler with a CSE pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:1134: raise NotImplementedError("store not implemented")
- .venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:1137: raise NotImplementedError("store not implemented")
- .venv/lib/python3.12/site-packages/torch/_inductor/aoti_eager.py:55: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/aoti_eager.py:203: raise NotImplementedError(err_msg)
- .venv/lib/python3.12/site-packages/torch/_inductor/aoti_eager.py:211: raise NotImplementedError(err_msg)
- .venv/lib/python3.12/site-packages/torch/_inductor/aoti_eager.py:259: raise NotImplementedError(f"Unsupported input type: {type(input)}")
- .venv/lib/python3.12/site-packages/torch/_inductor/bounds.py:246: # TODO: this is slightly inaccurate because truncdiv operates at integer
- .venv/lib/python3.12/site-packages/torch/_inductor/__init__.py:146: "Please pass in a package path to aot_inductor_compile() instead "
- .venv/lib/python3.12/site-packages/torch/_inductor/__init__.py:291: TODO: make it return a list by default
- .venv/lib/python3.12/site-packages/torch/_inductor/__init__.py:312: modes passed to `torch.compile()` performs.
- .venv/lib/python3.12/site-packages/torch/_inductor/__init__.py:400: shapes in the passed-in graph module.
- .venv/lib/python3.12/site-packages/torch/_inductor/memory.py:82: # TODO: would be nice to remove the try/except block for both places
- .venv/lib/python3.12/site-packages/torch/_inductor/memory.py:92: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:225: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:586: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:590: raise NotImplementedError(f"get_layout() is not implemented by {type(self)}!")
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:595: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:604: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:612: raise NotImplementedError(f"get_size() is not implemented by {type(self)}!")
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:617: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:640: TODO(ezyang): I think, in principle, every IRNode should have an
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:646: raise NotImplementedError(f"realize NYI on {type(self)}")
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:649: raise NotImplementedError(f"codegen_reference NYI on {type(self)}")
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:663: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:666: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:669: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:674: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:678: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:683: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:689: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:696: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:699: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:702: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:705: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:710: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:713: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:716: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:721: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:724: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:733: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:738: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:741: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:744: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:753: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:756: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:759: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:762: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:776: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:797: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:809: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:961: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:966: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:971: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1121: raise NotImplementedError(f"unknown reduction_type={reduction_type}")
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1301: # TODO this will fail for something like ((1, N) * (N, 1)).sum()
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1327: # TODO determine splits when all inputs are broadcast
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1513: # reuse the passed hint if available
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1640: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1805: # TODO(jansel): realize the reduction so we can do dynamic indexing
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2029: # TODO: Unrolled reduction
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2058: # reuse the passed hint if available
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2209: # TODO: Can combine_fn/reindex close over unbacked symbols? If so, we
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2378: # TODO: custom splitting heuristic for scan
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2397: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2557: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2569: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2624: # the ReinterpretView either, so don't pass along those arguments
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2630: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2639: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2669: raise NotImplementedError(f"make_reindexer NYI on {self}")
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2776: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3002: # TODO: a new class for FixedTransferLayout that output layout is constrained by input layout
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3007: # TODO: unbacked should not diverge from backed in determining striding
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3063: # TODO: These symbols may not escape, if they don't assert so and
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3201: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3316: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3383: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3425: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3428: raise NotImplementedError(type(self).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3729: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3912: pass  # ignore setting of stride
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4002: raise NotImplementedError(type(self.layout).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4026: raise NotImplementedError(type(self.layout).__name__)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4078: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4102: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4242: # there way as kernel arguments (and it is precisely passing in one of
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4283: TODO(jansel): A better algorithm here would look at downstream consumers of this
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4708: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4711: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4721: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4724: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4736: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5105: # FIXME: in some cases we sill need to explicitly pass in ordered_kwargs_for_cpp_kernel
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5181: # ordered_kwargs_for_cpp_kernel is explicitly passed in.
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5204: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5237: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5329: # (we can't pass the constant into the kernel directly)
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5389: In order to pass this to an extern kernel we need a
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5442: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5478: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5479: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5481: # TODO(jansel): impose layout preference on realized buffer
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5582: # TODO - Storage to InputBuffer
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5610: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5611: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5617: # TODO: could also be good to have a codegen fix to recognize overlapping elements
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5679: except (AttributeError, NotImplementedError):
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5687: # TODO move this to the more proper places
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5697: # TODO: combine this with require_contiguous after
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5704: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5746: # pass in a list of const arg names for arg_properties lookup.
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5750: "names passed to codegen_const_args does not match self.constant_args"
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5895: # TODO: I can't tell if the symbols here are temporary
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:6031: # abi-compatible mode, where we retrieve outputs by pass each individual
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:6041: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:6334: raise NotImplementedError(f"Unsupported arg type: {type(arg)}: {arg}")
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:6393: # If we are autotuning, not all arguments will be passed
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:6540: assert isinstance(new_size, int), "TODO: dynamic shapes"
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:6803: # TODO: when we start compiling in C++20, annotate with [[unlikely]].
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:6878: # don't pass the can_auto_functionalize check, but their mutation
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:6895: # op to show up here is if a lowering or pass introduced it.
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:6901: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7688: # TODO(anijain2305) - Support sym expr as operands in future.
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:8176: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/ir.py:8309: # TODO(yifu): add a pre-grad pass to validate the correctness of collective
- .venv/lib/python3.12/site-packages/torch/_inductor/template_heuristics.py:345: # TODO: Unify with other gemm patterns, mm_plus_mm currently follows
- .venv/lib/python3.12/site-packages/torch/_inductor/template_heuristics.py:692: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/template_heuristics.py:985: # TODO: _filter_configs can be removed once backend specific configs are added
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:6: import torch._inductor.custom_graph_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:253: # set to True to enable the back-to-back GEMM pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:254: b2b_gemm_pass = False
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:256: # register custom graph optimization pass hook. so far, pre/post passes are
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:257: # only applied before/after pattern_matcher in post_grad_passes.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:260: # to which your custom passes have been applied:
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:261: post_grad_custom_pre_pass: torch._inductor.custom_graph_pass.CustomGraphPassType = None
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:262: post_grad_custom_post_pass: torch._inductor.custom_graph_pass.CustomGraphPassType = None
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:264: # Registers a custom joint graph pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:265: joint_custom_pre_pass: Optional[Callable[[torch.fx.Graph], None]] = None
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:266: joint_custom_post_pass: Optional[Callable[[torch.fx.Graph], None]] = None
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:268: # Registers a custom pregrad pass. Note that the pre-grad IR is 1.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:270: # use post-grad passes.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:271: pre_grad_custom_pass: Optional[Callable[[torch.fx.graph.Graph], None]] = None
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:273: # Registers a custom pass to be run right before fusion in Inductor scheduler.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:275: # hence custom IR passes built on top of it might break in the future.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:276: _pre_fusion_custom_pass: Optional[
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:283: # Registers a custom pass to be run right after fusion in Inductor scheduler.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:285: # hence custom IR passes built on top of it might break in the future.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:286: _post_fusion_custom_pass: Optional[
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:294: split_cat_fx_passes = True
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:297: efficient_conv_bn_eval_fx_passes = False
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:309: # Call `torch._inductor.fx_passes.group_batch_fusion.list_group_batch_fusions()` to see available fusions.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:319: # normalization_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:320: # remove_split_with_size_one_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:321: # merge_getitem_cat_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:323: # merge_splits_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:324: # mutate_cat_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:325: # split_cat_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:329: # Call `torch._inductor.fx_passes.group_batch_fusion.list_group_batch_fusions(False)` to see available fusions.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:332: # enable reordering pass for improving memory locality
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:345: # enable runtime numeric check for pre/post grad fx passes
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:350: fx_passes_numeric_check: dict[str, Any] = {
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:360: # enable reordering pass for increasing overlap between compute and communication
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:363: # passes (in execution order) for increasing overlap between compute and communication
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:364: # for built-in passes, use string name; for user-defined passes, pass in the function handle
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:366: # hence custom IR passes built on top of it might break in the future.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:367: reorder_for_compute_comm_overlap_passes: list[
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:388: # for built-in estimation function, pass in "default"; for user-defined estimation function, pass in the function handle
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:409: # enable slow autotuning passes to select algorithms
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:412: # enable slow autotuning passes to select pointwise/reductions algorithms
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:415: # enable slow autotuning passes to select gemm algorithms
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:695: # options in caffe2/torch/_inductor/fx_passes/pre_grad.py
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:696: add_pre_grad_passes: Optional[str] = None
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:697: remove_pre_grad_passes: Optional[str] = None
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:728: # Flag to control which fusion passes to apply. Functions in the list will
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:729: # be applied in order. There are two different different fusion passes
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:738: # overlapping. At this moment, this pass performs better than
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:739: # reorder_for_compute_comm_overlap_passes but we will add the logic of
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:741: _fuse_ddp_communication_passes: list[Union[Callable[..., None], str]] = [
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:756: TODO: Remove when parallel compiled is fully enabled internally. For rollout, use a
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:804: # TODO: Set directly after internal rollout.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:819: # Raise error if we bypass the launcher
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:925: # TODO: remove later
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:948: # arguments passed to the @triton.autotune in the user's code; this is unsafe, as
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1112: # TODO - need to debug why this prevents cleanup
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1151: # TODO - enable by default
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1186: # Side effect for this option is increased memory footprint during first pass compilation.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1217: # "inductor_node": Maps to the node name in the FX graph passed to Inductor
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1328: # TODO: Move this into metadata
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1332: # TODO: Move this into metadata
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1345: # Dictionary of metadata users might want to save to pass to the runtime.
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1346: # TODO: Move this somewhere else, since it's no longer really a config
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1364: # Dictionary of presets that can be passed in
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1487: # returned from cutlass_utils.gen_ops() or the op argument passed to
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1630: # Controls `no_asserts` flag passed to Halide target (warning: can false positive)
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1633: # Controls `debug` flag passed to Halide target
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1665: # Save TorchInductor IR before fusion pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1668: # Save TorchInductor IR after fusion pass
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1685: # to specify the shape attribute for the dot graph. For example, passing
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1691: # graph of each pass that changed the graph
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1692: # The nodes that are being transformed in each pass will be colored in yellow
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1712: "joint_custom_pre_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1713: "joint_custom_post_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1714: "pre_grad_custom_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1717: "post_grad_custom_pre_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1718: "post_grad_custom_post_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1719: "_fuse_ddp_communication_passes",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1720: "_pre_fusion_custom_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1732: "post_grad_custom_post_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1733: "post_grad_custom_pre_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1734: "_fuse_ddp_communication_passes",
- .venv/lib/python3.12/site-packages/torch/_inductor/config.py:1735: "_pre_fusion_custom_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:43: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:47: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:51: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:55: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:59: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:187: # now let's create new symbols with the passed in prefix
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:243: except NotImplementedError:  # NoneLayout
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:300: raise NotImplementedError("StarDep does not have an index")
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:315: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:348: raise NotImplementedError("WeakDep does not have an index")
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:511: # TODO(jansel): explore this further normalization
- .venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:561: # TODO: check call sites
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:74: # TODO: Remove underscores here
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:86: raise NotImplementedError(type(self))
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:94: raise NotImplementedError(type(self))
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:96: # TODO: Get rid of this
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:98: raise NotImplementedError(type(self))
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:239: # TODO: migrate all disable reasons to stack trace, refactor
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:354: passed in at runtime.
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:359: To support freezing, FXGraphCache gets passed a CompiledFxGraphConstantsWithGm during
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:465: # TODO - ordered set
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:569: # aot autograd needs to know to pass in inputs as a list
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:668: # TODO: This could be better if we're ever able to serialize compiled
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:725: raise NotImplementedError("NYI")
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:733: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:736: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:752: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:758: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:60: "activation_quantization_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:106: from torch.fx.passes.graph_transform_observer import GraphTransformObserver
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:107: from torch.fx.passes.shape_prop import ShapeProp
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:388: # TODO: There is a bug in a call to this function, to repro:
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:413: # TODO: remove when support is added in triton
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:635: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:704: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:759: # TODO(future): maybe refactor torch/fx/graph.py to make it easy to
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:900: When the passed replacement symbol v is a string, it is converted to a symbol with name v that
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1083: Optionally, pass a dict as 'cache_entries' to get a list of filenames and sizes
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1181: # TODO: Investigate why uint64 tensor creation causes overflow error:
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1338: # TODO(rec): or should this be self.__class__(initial_indent=self._indent)?
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1378: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1382: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1451: # TODO we need to properly guard on this global
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1559: # TODO(dberard) remove this when we get AOTI support for new TMA APIs (#155047)
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1630: and not V.graph.aot_mode  # TODO: Support AOTI for decomposeK
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1720: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1845: # TODO(jgong5): support dynamic shapes for n or k
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1873: and is_last_dim_stride1(mat1)  # TODO(jgong5): support transposed input
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1953: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:1957: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2099: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2254: def pass_execution_and_save(
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2328: # TODO: this is a temporary solution to ensure that we can identify torchrec's
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2333: # NOTE: the `hasattr()` check is to bypass errors such as the following:
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2530: return device != "mps" and is_gpu(device)  # TODO: MPS does not expose streams now
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2687: # TODO(voz): It would be nice to enable this assert, but there are lots of tests that
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2688: # pass in real inputs for now.
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2700: # TODO(voz): Should we always have one anyway?
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2862: # TODO: remove when support is added in triton
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:2924: "or_",  # TODO should remove this op
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:3027: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/utils.py:3111: # TODO: implement V3_BACKENDS_TUPLE
- .venv/lib/python3.12/site-packages/torch/_inductor/choices.py:156: """Hook to change the kwargs passed to TritonKernel, used to apply fixed configurations"""
- .venv/lib/python3.12/site-packages/torch/_inductor/choices.py:177: # TODO(jansel): should this default on for dynamic shapes?
- .venv/lib/python3.12/site-packages/torch/_inductor/choices.py:200: pass  # unbacked symint
- .venv/lib/python3.12/site-packages/torch/_inductor/choices.py:278: # TODO the best heuristic currently has XBLOCK (corresponding to numel_hint) 128
- .venv/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py:210: # The graph passed to standalone_compile must be an Inductor-approved graph,
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:27: from torch.fx.passes.shape_prop import _extract_tensor_metadata, TensorMetadata
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:28: from torch.fx.passes.tools_common import legalize_graph
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:473: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:611: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:623: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:627: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:631: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:637: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:641: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/debug.py:645: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/mkldnn_ir.py:117: # TODO <Leslie> cleaned up the fake_tensor trace as Linear implementation
- .venv/lib/python3.12/site-packages/torch/_inductor/mkldnn_ir.py:184: # TODO support channels_last for such zero stride input.
- .venv/lib/python3.12/site-packages/torch/_inductor/mkldnn_ir.py:892: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/mkldnn_ir.py:946: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/mkldnn_ir.py:1231: # C shim call requires all the outputs to be passed in, and thus the last
- .venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:16: from torch._inductor.fx_passes.freezing_patterns import freezing_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:17: from torch._inductor.fx_passes.post_grad import view_to_reshape
- .venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:46: # TODO (tmanlaibaatar) figure out why this is different
- .venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:121: # TODO - further restrict cse ? right now needed to dedup aliasing ops
- .venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:127: freezing_passes(aot_autograd_gm, aot_example_inputs)
- .venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:266: This pass is performed before freezing so the added nodes can be constant
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:8: a pass (such as torch._inductor.fx_passes.joint_graph.patterns).
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:69: from torch.fx.passes.graph_transform_observer import GraphTransformObserver
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:123: new_meta: dict[str, Any], old_node: torch.fx.Node, pass_name: str = ""
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:133: new_from_node.append(NodeSource(old_node, pass_name, NodeSourceAction.REPLACE))
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:177: # The input nodes that must be passed in to the result
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:236: run_functional_passes: bool = True,
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:241: run_functional_passes (bool). If we should run passes that
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:271: fwd_only, run_functional_passes=run_functional_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:328: pass_name="replace_by_example",
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:458: passed in depth first order.
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:467: Match an arg, but don't pass it to handler
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:582: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:812: Matches a call_function node with any arguments which are passed into the pattern
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1067: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1071: pass_dicts: Union[_PassDictsType, Sequence[_PassDictsType]],
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1078: self.register(pass_dicts, fn, prepend=prepend)
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1079: elif isinstance(pass_dicts, (dict, PatternMatcherPass)):
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1082: pass_dicts[(self.pattern.op, target)].insert(0, self)
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1084: pass_dicts[(self.pattern.op, target)].append(self)
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1086: pass_dicts = typing.cast(Sequence[_PassDictsType], pass_dicts)
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1087: for x in pass_dicts:
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1145: pass_name="Interpreter_Replacer",
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1167: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1178: raise NotImplementedError(f"unhandled {node}")
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1338: Returns True if a duplicate is found and `skip_duplicates=True` is passed in. Errors if
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1375: pass_dicts: Union[_PassDictsType, Sequence[_PassDictsType]],
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1392: pass_dict: dict of passes to register to
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1506: pass_name="replacement",
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1526: # TODO: Revisit the functionalize_rng_ops for lowmem dropout
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1543: for pattern_matcher_pass in (
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1544: pass_dicts if isinstance(pass_dicts, Sequence) else [pass_dicts]
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1546: if isinstance(pattern_matcher_pass, PatternMatcherPass):
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1550: pattern_matcher_pass.seen_patterns,
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1560: pattern.register(pass_dicts)
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1608: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1646: SERIALIZED_PATTERN_PATH = Path(__file__).parent / "fx_passes" / "serialized_patterns"
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1668: pass_dicts: Union[_PassDictsType, Sequence[_PassDictsType]],
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1684: f"torch._inductor.fx_passes.serialized_patterns.{pattern_name}"
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1709: pass_dicts,
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1769: pass_dict: _PassDictsType,
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1782: ).register(pass_dict, prepend=prepend)
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1793: pass_dict: _PassDictsType,
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1805: ).register(pass_dict, prepend=prepend)
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1825: # TODO - fix schema
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1887: pass_name: Optional[str] = None,
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1893: self.pass_name = pass_name
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1931: pass_name = self.pass_name if self.pass_name is not None else "pattern_matcher"
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1933: with GraphTransformObserver(gm, pass_name):
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1973: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2085: run_functional_passes: bool = True,
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2089: # TODO - look into using aot autograd, asserting no mutating ops here
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2096: from .fx_passes.post_grad import remove_noop_ops
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2098: if run_functional_passes:
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2130: from .fx_passes.post_grad import remove_noop_ops
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2134: from .fx_passes.joint_graph import pointless_view
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2136: matcher_pass = PatternMatcherPass()
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2143: ).register(matcher_pass.patterns)
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2144: matcher_pass.apply(gm.graph)
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2196: """Wrapper around lazy init functions in fx_passes/"""
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2215: """Function for extra_check to put pass behind a flag"""
- .venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:2237: # TODO: remove in follow up diff, used internally
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_async.py:77: # TODO: If the future ended in an exception do we want to continue
- .venv/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:46: # will not expose the Sleef* AVX512 symbols since gcc-7/g++-7 cannot pass
- .venv/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:205: )  # TODO: use cflags
- .venv/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:260: )  # TODO: use cflags
- .venv/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:358: # TODO add sve256 support
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:18: from torch._inductor.codecache import BypassFxGraphCache, FxGraphCache
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:124: # (or at least detected and raise a bypass when a non-standard lowering is
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:360: # TODO: For memory purposes should we log to a file and then respond with that?
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:372: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:427: # TODO: Do we need to figure out what changed in TracingContext in the
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:444: # _check_for_hop raises BypassFxGraphCache when it detects something
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:447: except BypassFxGraphCache as e:
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:466: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:486: except (AttributeError, BypassFxGraphCache):
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:490: # TODO: scuba record about not being able to do this?
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:504: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:523: # TODO: Should we split the input into multiple sections where each
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx_ext.py:639: # TODO: make this a FxCompileMode value?
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:126: aten.select_scatter,  # need to be in the ATen graph in order for it to work with the re-inplacing pass
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:127: aten.slice_scatter,  # need to be in the ATen graph in order for it to work with the re-inplacing pass
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:155: # TODO: check if XE4 still need this fallback
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:165: # TODO: for now, inductor doesn't handle asserts
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:295: # TODO: Re-enable for mps once our reductions are performant enough
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:354: # TODO: Re-enable for mps once our reductions are performant enough
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:381: # This pass does two things:
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:395: # We'd like to eliminate naughtiness like this for downstream passes
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:402: # But actually, the ONLY way this could have passed is if u0 == 0,
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:587: # TODO: _to_copy tensor to stride permutation
- .venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:873: # TODO(aakhundov): replace this (and the above) Any by more
- .venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:55: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:90: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:146: pass_fds=(subproc_read_fd, subproc_write_fd),
- .venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:435: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:438: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:446: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:664: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:668: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:841: # TODO(jgong5): use CppPythonBindingsCodeCache for better binding perf
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:73: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:77: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:101: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:105: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:137: # convert it for the backend and passes it to the backend.
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:234: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:318: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:322: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:326: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:330: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/remote_cache.py:334: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:91: from torch.fx.passes.fake_tensor_prop import FakeTensorProp
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:105: from .fx_passes.joint_graph import joint_graph_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:106: from .fx_passes.post_grad import post_grad_passes, view_to_reshape
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:107: from .fx_passes.pre_grad import pre_grad_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:145: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:456: def _recursive_pre_grad_passes(
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:461: "_recursive_pre_grad_passes",
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:463: dynamo_compile_column_us="pre_grad_pass_time_us",
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:465: add_passes = config.add_pre_grad_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:466: remove_passes = config.remove_pre_grad_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:469: # as we don't have recursive example inputs, passing empty set here
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:470: new_subgraph = _recursive_pre_grad_passes(subgraph, ())
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:472: return pre_grad_passes(gm, example_inputs, add_passes, remove_passes)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:475: def _recursive_joint_graph_passes(
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:479: "_recursive_joint_graph_passes",
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:481: dynamo_compile_column_us="joint_graph_pass_time_us",
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:483: # invoke_subgraph already runs the _recursive_joint_graph_passes.  In
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:484: # AOTAutograd, `run_joint_graph_passes_on_hops` partitions the
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:487: # `_recursive_joint_graph_passes` for the subgraph. So, skip recursing
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:491: _recursive_joint_graph_passes(subgraph, skip_invoke_subgraph)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:492: joint_graph_passes(gm)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:495: def _recursive_post_grad_passes(gm: GraphModule, is_inference: bool = False) -> None:
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:497: "_recursive_post_grad_passes",
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:499: dynamo_compile_column_us="post_grad_pass_time_us",
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:503: _recursive_post_grad_passes(subgraph, is_inference)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:504: post_grad_passes(gm, is_inference)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:519: If an additional "lifted_constants" argument is passed in, we will assume the gm has
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:522: When a "skip_folding_node_fn" callback is passed, we will skip constant folding on
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:665: # pass config dict back to user
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:840: # TODO: This is a hack purely to get some info to extract_tensor_metadata_for_cache_key,
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:855: # TODO: this time will be slightly inconsistent with the one computed
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:886: if cache_info is None or cache_info["cache_state"] == "bypass":
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:889: "FX cache bypass reason: %s",
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:891: cache_info.get("cache_bypass_reason", "unknown")
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:956: # In the event of a bypass, we also logged to the remote table earlier
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:957: # with log_cache_bypass.
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:964: # fx_graph_cache_bypass
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:972: # TODO: add remote cache get/put timings here too
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:979: cache_bypass_reason=(
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:980: cache_info.get("cache_bypass_reason")
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1093: # TODO: We should probably eventually add some kind of async version of this
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1124: # TODO: _CompileFxKwargs actually has stronger types than in the
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1183: # TODO: Should we actually dump this?  It should be redundant with the aot
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1219: # pattern matcher passes might not preserve striding information
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1236: _recursive_post_grad_passes(gm, is_inference=is_inference)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1286: # TODO: Remove this when 3.9 is no longer supported
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1302: # TODO(T216453900): need to work around for now to support vllm
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1303: # See details in vllm/compilation/pass_manager.py.
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1351: # For the forward pass, we have the real inputs to be used as example_inputs. For the backward pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1398: # TODO: The switching between AOT mode and not here is a bit
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1515: # TODO: Hoist this above V.aot_compilation
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1551: # This is derivable from the other inputs to this function, but we pass it
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1747: # TODO - could make one single op of multiple slices
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1851: _recursive_joint_graph_passes(aot_autograd_model)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1954: "triton.cudagraphs": False,  # TODO: to be removed
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2011: # TODO: This probably shouldn't be a recursive call
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2098: # Pre-grad passes cannot be run if we weren't given a GraphModule.
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2100: # where a user directly passes a plain Module with the intention of
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2102: # TODO: Get rid of this?
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2129: model_ = _recursive_pre_grad_passes(model_, example_inputs_)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2142: # TODO: Move this before recursive pre-grad passes
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2165: # TODO: The modern style is to use CompileId from TracingContext to
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2183: _recursive_joint_graph_passes(gm)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2291: _recursive_joint_graph_passes(gm, skip_invoke_subgraph=True)
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2399: # In inference_compiler (fw_compiler_base), _recursive_joint_graph_passes will call into
- .venv/lib/python3.12/site-packages/torch/_inductor/mkldnn_lowerings.py:1056: ) and binary_attr == "add":  # <TODO> Support inplace sum fusion
- .venv/lib/python3.12/site-packages/torch/_inductor/mkldnn_lowerings.py:1347: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/package/package.py:124: # TODO(angelayi): We shouldn't need to do this -- miniz should
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:43: # We compare the numerical results before and after pre/post grad fx passes
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:47: logger.warning("Mismatch keys found before and after pre/post grad fx passes.")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:48: logger.debug("keys before pre/post grad fx passes %s", dict_base.keys())
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:49: logger.debug("keys after pre/post grad fx passes %s", dict_control.keys())
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:55: "Mismatch parameter name %s does not exist after pre/post grad fx passes",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:69: "Mismatch parameter values found before and after pre/post grad fx passes."
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:71: logger.debug("value before pre/post grad fx passes %s", dict_base[key])
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:72: logger.debug("value after pre/post grad fx passes %s", dict_control[key])
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:98: "forward output before pre/post grad fx passes %s", tuple_base[i]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:101: "forward output after pre/post grad fx passes %s", tuple_control[i]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:159: if config.fx_passes_numeric_check["requires_optimizer"]:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:191: gm_before_fx_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:192: gm_after_fx_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:203: gm_before_fx_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:204: gm_after_fx_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/numeric_utils.py:211: "Runtime numeric check failed in pre grad fx passes with error: %s", e
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/misc_patterns.py:18: from .post_grad import pass_patterns as post_grad_patterns_all
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:17: from torch.fx.passes.graph_transform_observer import GraphTransformObserver
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:18: from torch.fx.passes.shape_prop import ShapeProp
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:29: from ..utils import is_cpu_device, pass_execution_and_save
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:30: from .group_batch_fusion import group_batch_fusion_passes, PRE_GRAD_FUSIONS
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:37: efficient_conv_bn_eval_pass = PatternMatcherPass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:38: pass_name="efficient_conv_bn_eval_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:41: fuse_split_linear_add_pass = PatternMatcherPass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:42: pass_name="fuse_split_linear_add_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:44: fuse_chunk_squeeze_cat_pass = PatternMatcherPass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:45: pass_name="fuse_chunk_squeeze_cat_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:47: remove_reshape_pass = PatternMatcherPass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:48: pass_name="remove_reshape_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:52: normalization_pass_aten = PatternMatcherPass(pass_name="normalization_pass_aten")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:53: merge_splits_pass_aten = PatternMatcherPass(pass_name="merge_splits_pass_aten")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:54: split_cat_pass_aten = PatternMatcherPass(pass_name="split_cat_pass_aten")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:55: unbind_stack_pass_aten = PatternMatcherPass(pass_name="unbind_stack_pass_aten")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:56: merge_getitem_cat_pass_aten = PatternMatcherPass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:57: pass_name="merge_getitem_cat_pass_aten"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:59: merge_stack_tahn_unbind_pass_aten = PatternMatcherPass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:60: pass_name="merge_stack_tahn_unbind_pass_aten"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:62: mutate_cat_pass_aten = PatternMatcherPass(pass_name="mutate_cat_pass_aten")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:63: remove_split_with_size_one_pass_aten = PatternMatcherPass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:64: pass_name="remove_split_with_size_one_pass_aten"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:68: def save_inductor_dict(pass_to_compare=None):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:69: if not pass_to_compare:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:70: pass_to_compare = list(config.pre_grad_fusion_options.keys()) + list(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:73: return {p: dict(counters["inductor"]).get(p, 0) for p in pass_to_compare}
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:77: for pass_name, count in optimus_dict.items():
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:78: if count != dict(inductor_dict).get(pass_name, 0):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:87: def normalize_node_kwargs_pass(graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:91: def fuse_parallel_linear_pass(graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:99: def remove_split_ops_pass(graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:103: def fuse_chunk_reshape_unsqueeze_concat_pass(graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:107: def fuse_chunk_reshape_concat_pass(graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:111: def remove_noop_pass(graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:115: def stack_to_unsqueeze_pass(graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:119: def merge_concats_pass(graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:167: def _get_pass_name_func(p):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:169: pass_name = p.pass_name
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:170: pass_func = p.apply
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:172: pass_name = p.__name__.lstrip("_")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:173: pass_func = p
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:175: pass_name = None
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:176: pass_func = None
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:178: return pass_name, pass_func
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:181: def _run_pre_dispatch_passes(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:184: add_passes: Optional[str] = None,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:185: remove_passes: Optional[str] = None,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:188: default_pass_list = [
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:189: # normalize passes, must be called as the first passes
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:190: normalization_pass_aten,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:191: normalize_node_kwargs_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:192: remove_noop_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:194: fuse_chunk_reshape_concat_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:195: group_batch_fusion_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:196: normalize_node_kwargs_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:197: fuse_chunk_squeeze_cat_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:198: merge_concats_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:199: fuse_split_linear_add_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:200: remove_reshape_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:201: fuse_parallel_linear_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:202: remove_split_ops_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:203: stack_to_unsqueeze_pass,  # run before fuse_chunk_reshape_unsqueeze_concat_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:204: fuse_chunk_reshape_unsqueeze_concat_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:207: full_pass_list = default_pass_list + [
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:217: f"pre_grad_passes: add_passes: {add_passes}, remove_pass: {remove_passes}"  # noqa: G004
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:219: add_passes_list = []
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:220: remove_passes_list = []
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:221: if add_passes:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:222: add_passes_list = add_passes.split(",")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:223: if remove_passes:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:224: remove_passes_list = remove_passes.split(",")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:232: for p in default_pass_list:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:233: pass_name, pass_func = _get_pass_name_func(p)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:235: if pass_name is None or pass_func is None:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:237: if pass_name in remove_passes_list:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:239: pass_execution_and_save(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:240: pass_func,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:243: f"[Pre grad(predispatch IR)] Apply {pass_name} pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:246: for p in full_pass_list:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:247: pass_name, pass_func = _get_pass_name_func(p)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:248: if pass_name is None or pass_func is None:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:250: if pass_name in add_passes_list:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:251: pass_execution_and_save(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:252: pass_func,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:255: f"[Pre grad(predispatch IR)] Apply {pass_name} pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:258: # Remove noops at the end, which may be generated other passes.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:259: pass_execution_and_save(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:260: remove_noop_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:263: "[Pre grad(predispatch IR)]Apply remove_noop pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:268: def pre_grad_passes(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:271: add_passes: Optional[str] = None,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:272: remove_passes: Optional[str] = None,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:275: Apply passes on the input FX graph using Torch IR.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:279: to write passes on this IR.  Passes must be safe with respect to
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:282: Consider adding a new pass to post_grad.py or joint_graph.py which
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:288: config, "fx_passes_numeric_check"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:289: ) and config.fx_passes_numeric_check.get("pre_grad", False):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:290: gm_before_fx_passes = gm.__copy__()
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:291: # explicitly run with predispatch atenIR based passes
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:293: _run_pre_dispatch_passes(gm, example_inputs, add_passes, remove_passes)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:300: # We should always do the normalization_pass first
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:301: if "normalization_pass" in config.pre_grad_fusion_options:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:302: pattern_matcher_pass = PRE_GRAD_PATTERNS["normalization_pass"]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:303: pattern_matcher_pass.apply(gm.graph)  # type: ignore[arg-type]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:304: group_batch_fusion_passes(gm.graph, pre_grad=True)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:305: for pass_name in config.pre_grad_fusion_options:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:307: if pass_name in PRE_GRAD_FUSIONS or pass_name == "normalization_pass":
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:309: pattern_matcher_pass = PRE_GRAD_PATTERNS[pass_name]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:311: [pattern_matcher_pass.pass_name]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:314: counter = config.pre_grad_fusion_options[pass_name].get("counter", 1)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:316: pattern_matcher_pass.apply(gm.graph)  # type: ignore[arg-type]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:321: "name": f"{pattern_matcher_pass.pass_name}_pre_grad",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:328: # TODO: move efficient_conv_bn_eval_pass to the fusions dict too.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:329: efficient_conv_bn_eval_pass.apply(gm.graph)  # type: ignore[arg-type]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:331: if config.pre_grad_custom_pass is not None:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:332: with GraphTransformObserver(gm, "pre_grad_custom_pass"):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:333: config.pre_grad_custom_pass(gm.graph)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:345: and hasattr(config, "fx_passes_numeric_check")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:346: and config.fx_passes_numeric_check.get("pre_grad", False)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:351: gm_after_fx_passes = gm.__copy__()
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:353: gm_before_fx_passes,  # type: ignore[possibly-undefined]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:354: gm_after_fx_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:356: config.fx_passes_numeric_check.get("num_iterations", 1),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:357: config.fx_passes_numeric_check.get("precision", 1e-4),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:512: # TODO: support kwargs.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:49: The quantization.py file primarily incorporates passes related to quantization fusion
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:397: pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:403: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:503: pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:509: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:562: pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:568: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:734: pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:740: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:816: 2,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:830: 2,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:841: 2,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:855: 2,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1116: # TODO: add cuda kernel support instead of calling mul+sum
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1144: # TODO: add cuda kernel support instead of calling mul+sum
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1159: pass_number=4,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1189: # Some other pass is making some changes that entails
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1427: def _register_dequant_promotion_pass(pattern, pass_number, dtype=torch.float32):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1431: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1564: def _register_qconv_weight_prepack_pass(pattern, pass_number, dtype=torch.float32):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1568: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1739: # There is another pattern due to the pass of convert_conv_weights_to_channels_last
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1883: def _register_qlinear_weight_prepack_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1885: pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:1895: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2252: _register_dequant_promotion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2264: pass_number=0,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2266: )  # pass_number=0 to run before weight prepack
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2273: # Register to pass_number 1, so we can do dequant promotion in pass_number 0.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2274: _register_qconv_weight_prepack_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2275: weight_prepack_pattern, pass_number=1, dtype=dtype
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2326: # Register to pass_number 1, so we can do dequant promotion in pass_number 0.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2327: _register_qlinear_weight_prepack_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2329: pass_number=1,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2349: _register_qlinear_weight_prepack_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2351: pass_number=1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2360: def _register_linear_dynamic_fp16_weight_prepack_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2362: pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2373: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2545: _register_linear_dynamic_fp16_weight_prepack_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2547: pass_number=0 if relu_fused else 1,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2663: pattern_to_pass_number = {
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2671: for pattern, pass_number in pattern_to_pass_number.items():
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2676: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2827: def _register_qconv_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2829: pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:2838: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3025: _register_qconv_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3027: 3,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3077: _register_qconv_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3079: 4,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3122: _register_qconv_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3124: 3,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3152: _register_qconv_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3154: 3,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3159: _register_qconv_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3161: 4,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3187: _register_qconv_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3189: 4 if int8_mixed_bf16_with_inplace_add else 5,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3195: def _register_qlinear_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3197: pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3206: pass_number=pass_number,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3362: _register_qlinear_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3364: 3,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3405: _register_qlinear_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3407: 4,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3456: extra input, we don't match that pattern because we cannot match all these patterns in 3 passes.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3508: _register_qlinear_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3510: 3,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3538: _register_qlinear_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3540: 4,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3566: _register_qlinear_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3568: 4,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3595: _register_qlinear_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3597: 5,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3622: _register_qlinear_post_op_fusion_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3624: 5,  # pass_number
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3631: def _register_quantization_weight_pack_pass():
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3677: Concat Linear optimization pass for WOQ int4
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3678: This pass fuses the original pattern:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/quantization.py:3842: # <TODO> Leslie: Here we verify that the quant node has exactly
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:11: from .split_cat import construct_pattern_matcher_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:17: # TODO: need a better strategy for decomposing mm
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:23: if "decompose_mm_pass" in config.post_grad_fusion_options:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:25: "decompose_mm_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:28: "decompose_mm_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:100: pass_dict=construct_pattern_matcher_pass("decompose_mm_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:118: pass_dict=construct_pattern_matcher_pass("decompose_mm_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:141: pass_dict=construct_pattern_matcher_pass("decompose_mm_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:27: from torch.fx.passes.reinplace import _is_view_op
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:366: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:483: # TODO Using _overlap here causes a several issues.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:587: # TODO this logic can be made more precise using _overlap
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:653: # TODO(yifu): this doesn't properly remove copy epilogues for
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:673: # Stash the metadata. There is a pass later on where we decompose
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:693: # Stash the metadata. There is a pass later on where we decompose
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:719: # This pass iterates over them and sees which ones are safe
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/ddp_fusion.py:15: from torch.fx.passes.graph_transform_observer import GraphTransformObserver
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/ddp_fusion.py:16: from torch.fx.passes.shape_prop import _extract_tensor_metadata, TensorMetadata
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/ddp_fusion.py:571: graph: fx.Graph, passes: list[Union[Callable[..., None], str]], bucket_size_mb: int
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/ddp_fusion.py:573: for i, pa in enumerate(passes):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/ddp_fusion.py:575: graph.owning_module, f"fuse_ddp_communication_pass_{i}"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/micro_pipeline_tp.py:443: # TODO: explore unifying the _Matmul and _ScaledMatmul approaches to handling reshapes.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/micro_pipeline_tp.py:1052: def micro_pipeline_tp_pass(graph: torch.fx.Graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:16: from torch._inductor.fx_passes.dedupe_symint_uses import _SymHashingDict
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:39: from .replace_random import replace_random_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:47: pass_patterns = [
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:86: # TODO - decompose/type promote to avoid this
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:109: # TODO handle Tensor-Scalar adds, it's a different schema
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:308: # TODO: cat, more indexing
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:309: # TODO - do on cpu to avoid syncs
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:420: # TODO - not sure about lossy uint->python value->uint conversions
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:553: def canonicalize_aten_ir_passes(gm: torch.fx.GraphModule):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:555: Canonicalization passes that will run immediately after aot autograd
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:556: tracing. Thsis must be run before all other graph passes.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:561: def joint_graph_passes(graph: torch.fx.GraphModule):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:566: torch.fx.passes.graph_transform_observer.GraphTransformObserver,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:567: subsystem="joint_graph_passes",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:573: # must occur before other passes
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:574: canonicalize_aten_ir_passes(graph)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:576: if config.joint_custom_pre_pass is not None:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:577: GraphTransformObserver(graph, "joint_custom_pre_pass").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:578: config.joint_custom_pre_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:584: GraphTransformObserver(graph, "remove_noop_ops").apply_graph_pass(remove_noop_ops)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:587: GraphTransformObserver(graph, "constant_fold_uniform_value").apply_gm_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:591: if config.joint_custom_pre_pass is not None:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:592: GraphTransformObserver(graph, "joint_custom_pre_pass").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:593: config.joint_custom_pre_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:598: for i, patterns in enumerate(pass_patterns):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:600: graph, f"pass_pattern_{i}"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:601: ).apply_graph_pass(patterns.apply)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:607: count += replace_random_passes(graph)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:609: if config.joint_custom_post_pass is not None:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:610: GraphTransformObserver(graph, "joint_custom_post_pass").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:611: config.joint_custom_post_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:632: pass_dict=patterns,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:685: pass_dict=patterns,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:747: pass_dict=patterns,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:764: pass_dict=patterns,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:784: pass_dict=patterns,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:804: pass_dict=patterns,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:914: pass_dict=pass_patterns[1],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:941: pass_dict=pass_patterns[1],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/b2b_gemm.py:38: pass_name="b2b_gemm_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/b2b_gemm.py:465: args: The args that are passed into the subgraph
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/b2b_gemm.py:475: # For call_function we use the default lowerings and pass in the
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/b2b_gemm.py:510: raise ValueError("B2B-GEMM was passed a subgraph with no output node!")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/b2b_gemm.py:576: pass_dict=B2B_GEMM_PASS,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:51: pre_grad_pass_names = [
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:52: "normalization_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:53: "remove_split_with_size_one_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:54: "merge_getitem_cat_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:55: "merge_stack_tahn_unbind_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:56: "merge_splits_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:57: "mutate_cat_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:58: "split_cat_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:59: "unbind_stack_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:60: "split_cat_to_slices_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:61: "unbind_cat_to_view_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:62: "split_stack_to_cats_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:63: "unbind_stack_to_slices_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:64: "move_reshape_out_of_split_stack_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:67: post_grad_pass_names = [
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:68: "normalization_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:69: "decompose_mm_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:70: "unbind_stack_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:72: "pad_aten_mm_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:73: "split_cat_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:74: "select_cat_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:75: "move_view_after_cat_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:78: for pass_name in pre_grad_pass_names:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:79: # exclude all passes from the group batch fusion
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:81: if pass_name in PRE_GRAD_FUSIONS:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:83: PRE_GRAD_PATTERNS[pass_name] = PatternMatcherPass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:84: pass_name=pass_name,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:87: for pass_name in post_grad_pass_names:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:88: # exclude all passes from the group batch fusion
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:90: if pass_name in POST_GRAD_FUSIONS:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:92: POST_GRAD_PATTERNS[pass_name] = PatternMatcherPass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:93: pass_name=pass_name,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:97: def construct_pattern_matcher_pass(pass_name: str):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:99: Return the specific pattern_matcher_pass given the pass name.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:101: if pass_name in PRE_GRAD_PATTERNS:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:102: return PRE_GRAD_PATTERNS[pass_name]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:104: return POST_GRAD_PATTERNS[pass_name]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:186: # TODO dynamic_shapes with assume_static_by_default=False fails while AOT Autograd tracing.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:209: counters["inductor"]["normalization_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:214: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:218: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:226: pass_dict=construct_pattern_matcher_pass("remove_split_with_size_one_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:230: pass_dict=construct_pattern_matcher_pass("remove_split_with_size_one_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:246: # TODO dynamic_shapes with assume_static_by_default=False fails while AOT Autograd tracing.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:261: counters["inductor"]["remove_split_with_size_one_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:266: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:270: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:301: counters["inductor"]["normalization_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:306: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:362: counters["inductor"]["normalization_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:367: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:398: counters["inductor"]["normalization_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:412: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:451: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:476: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:480: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:513: pass_dict=construct_pattern_matcher_pass("normalization_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:581: pass_dict=construct_pattern_matcher_pass("merge_splits_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:588: # Note: dim is implicitly passed by TorchSplit, as it internally uses a pattern with dim
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:659: counters["inductor"]["merge_splits_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:719: counters["inductor"]["unbind_stack_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1265: pass_dict=construct_pattern_matcher_pass("split_cat_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1282: pass_dict=construct_pattern_matcher_pass("split_cat_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1319: counters["inductor"]["split_cat_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1339: pass_dict=construct_pattern_matcher_pass("unbind_stack_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1345: pass_dict=construct_pattern_matcher_pass("unbind_stack_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1351: pass_dict=construct_pattern_matcher_pass("unbind_stack_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1398: pass_dict=construct_pattern_matcher_pass("split_cat_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1407: pass_dict=construct_pattern_matcher_pass("split_cat_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1416: pass_dict=construct_pattern_matcher_pass("split_cat_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1500: pass_dict=construct_pattern_matcher_pass("merge_getitem_cat_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1579: counters["inductor"]["merge_getitem_cat_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1607: pass_dict=construct_pattern_matcher_pass("mutate_cat_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1640: counters["inductor"]["mutate_cat_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1668: counters["inductor"]["mutate_cat_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1684: pass_dict=construct_pattern_matcher_pass("normalization_aten_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1699: # TODO dynamic_shapes with assume_static_by_default=False fails while AOT Autograd tracing.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1722: counters["inductor"]["normalization_aten_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1727: pass_dict=construct_pattern_matcher_pass("normalization_aten_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1740: # TODO dynamic_shapes with assume_static_by_default=False fails while AOT Autograd tracing.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1763: counters["inductor"]["normalization_aten_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1773: pass_dict=construct_pattern_matcher_pass("split_cat_aten_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1779: "split_cat_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1860: counters["inductor"]["split_cat_aten_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1873: pass_dict=construct_pattern_matcher_pass("select_cat_aten_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1920: counters["inductor"]["select_cat_aten_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1925: pass_dict=construct_pattern_matcher_pass("normalization_aten_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1968: counters["inductor"]["normalization_aten_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:1977: pass_dict=construct_pattern_matcher_pass("unbind_stack_aten_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2029: counters["inductor"]["unbind_stack_aten_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2329: pass_dict=construct_pattern_matcher_pass("split_cat_to_slices_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2343: "split_cat_to_slices_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2367: counters["inductor"]["split_cat_to_slices_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2383: counters["inductor"]["split_cat_to_slices_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2412: pass_dict=construct_pattern_matcher_pass("unbind_cat_to_view_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2420: "unbind_cat_to_view_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2444: counters["inductor"]["unbind_cat_to_view_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2464: counters["inductor"]["unbind_cat_to_view_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2585: pass_dict=construct_pattern_matcher_pass("split_stack_to_cats_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2594: "split_stack_to_cats_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2614: counters["inductor"]["split_stack_to_cats_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2627: counters["inductor"]["split_stack_to_cats_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2658: pass_dict=construct_pattern_matcher_pass("unbind_stack_to_slices_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2666: "unbind_stack_to_slices_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2686: counters["inductor"]["unbind_stack_to_slices_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2701: counters["inductor"]["unbind_stack_to_slices_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2758: pass_dict=construct_pattern_matcher_pass("move_reshape_out_of_split_stack_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2767: "move_reshape_out_of_split_stack_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2806: counters["inductor"]["move_reshape_out_of_split_stack_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2868: counters["inductor"]["move_reshape_out_of_split_stack_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2896: pass_dict=construct_pattern_matcher_pass("move_view_after_cat_aten_pass"),
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:2960: counters["inductor"]["move_view_after_cat_aten_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:6: from torch.fx.passes.graph_transform_observer import GraphTransformObserver
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:7: from torch.fx.passes.shape_prop import _extract_tensor_metadata
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:24: def replace_random_passes(gm: torch.fx.GraphModule):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:30: with GraphTransformObserver(gm, "fuse_seed_creation_pass"):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:31: count += fuse_seed_creation_pass(gm.graph)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:36: def fuse_seed_creation_pass(graph: torch.fx.Graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:91: @register_graph_pattern(CallFunctionVarArgs(aten.rand.default), pass_dict=patterns)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:92: @register_graph_pattern(CallFunctionVarArgs(aten.rand.generator), pass_dict=patterns)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:93: @register_graph_pattern(CallFunctionVarArgs(aten.randn.default), pass_dict=patterns)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:94: @register_graph_pattern(CallFunctionVarArgs(aten.randn.generator), pass_dict=patterns)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/replace_random.py:126: @register_graph_pattern(CallFunctionVarArgs(aten.randint.low), pass_dict=patterns)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:12: from torch.fx.passes.graph_transform_observer import GraphTransformObserver
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:104: raise NotImplementedError("match called on base")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:107: raise NotImplementedError("fuse called on base")
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:381: Batch pointwise math operator (e.g., add, mul) in post grad pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:488: Batch linear left-hand side fusion. This pass tries to fuse the following patterns:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:493: We have a separate pass to eliminate contiguous transpose in a generic way.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:613: Batch linear fusion in pre grad pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:738: Batch layer norm fusion in pre grad pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:905: Batch pointwise ops (e.g., sigmoid, relu, tanh) fusion in pre grad pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:984: Batch pointwise ops (e.g., sigmoid, relu, tanh) fusion in post grad pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:1045: Batch simple match related ops such as nan_to_num in pre grad pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:1216: from split-cat elimination in later passes.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:1381: # we skip all patterns from pattern_matcher passes (e.g., split_cat)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/group_batch_fusion.py:1391: def group_batch_fusion_passes(graph: torch.fx.Graph, pre_grad=True):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:243: # TODO - finetune coefficient here. As a reference point, Triton mm model assumes
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:325: # can be planned layout transform is not free. TODO - way to pad and preserve layout ?
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:329: # TODO - see issue https://github.com/pytorch/pytorch/issues/128889
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:362: # TODO: Build a learned model which would be better than this heuristic
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:376: "pad_aten_mm_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:456: "pad_aten_mm_pass" in torch._inductor.config.post_grad_fusion_options
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:27: # First pass_patterns[0] are applied, then [1], then [2]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:28: pass_patterns = [
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:34: binary_folding_pass = PatternMatcherPass()
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:37: def freezing_passes(gm: torch.fx.GraphModule, aot_example_inputs):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:39: Passes that are applied to the graph to freeze pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:51: torch._inductor.fx_passes.binary_folding.mark_mixed_dtype_allowed_computation_ops(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:58: binary_folding_pass.apply(gm.graph)  # type: ignore[arg-type]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:59: # If we don't have binary folding, we don't need to run the pass again.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:60: # TODO: remove the need to run fake_tensor_prop on the whole model.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:65: torch._inductor.fx_passes.binary_folding.recover_original_precision_folded_computation_ops(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:72: for pattern in pass_patterns:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:104: def register_freezing_graph_pattern(pattern, extra_check=_return_true, pass_number=0):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:105: while pass_number > len(pass_patterns) - 1:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:106: pass_patterns.append(PatternMatcherPass())
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:110: pass_dict=pass_patterns[pass_number],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:118: pass_dict=binary_folding_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:215: pass_patterns[0],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:233: pass_patterns[0],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:251: pass_patterns[0],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:273: pass_patterns[0],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:289: pass_dict=pass_patterns[0],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/efficient_conv_bn_eval.py:14: from .pre_grad import efficient_conv_bn_eval_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/efficient_conv_bn_eval.py:147: pass_dict=efficient_conv_bn_eval_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/efficient_conv_bn_eval.py:149: and inductor_config.efficient_conv_bn_eval_fx_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/efficient_conv_bn_eval.py:238: pass_dict=efficient_conv_bn_eval_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/efficient_conv_bn_eval.py:240: and inductor_config.efficient_conv_bn_eval_fx_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/efficient_conv_bn_eval.py:333: pass_dict=efficient_conv_bn_eval_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/efficient_conv_bn_eval.py:335: and inductor_config.efficient_conv_bn_eval_fx_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:722: # tests that erroneously passing in a float
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:798: # we could also generate all these patterns in 3d.. TODO
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:935: # TODO: Enable CUDA after solving Bert accuracy issue of calling efficient attention
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:1053: "pass_dicts": patterns,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:1076: "pass_dicts": patterns,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:33: _register_quantization_weight_pack_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:49: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:59: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:64: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:69: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:188: def grouped_gemm_pass(graph: torch.fx.Graph):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:192: TODO: Use MultiOutputPattern, current limitation is the pattern requires
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:986: # concat_linear (pass_number=0) -> mkldnn_linear_pack (pass_numer=1) -> _recover_linear(pass_number=2)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1006: pass_number=2,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1081: pass_number=2,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1176: # TODO: Support dynamic shape case for MKLDNN conv transpose.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1302: def _register_weight_pack_pass():
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1415: pass_number=1,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1420: pass_number=1,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1507: # TODO: aarch64: enable op fusion for acl once it supports fused operators. Disabling it for now.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1524: _register_weight_pack_pass()
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1526: _register_quantization_weight_pack_pass()
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:25: from ..codegen.common import custom_backend_passes
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:61: from .group_batch_fusion import group_batch_fusion_passes, POST_GRAD_FUSIONS
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:62: from .micro_pipeline_tp import micro_pipeline_tp_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:75: # First pass_patterns[0] are applied, then [1], then [2]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:76: pass_patterns = [
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:83: def post_grad_passes(gm: torch.fx.GraphModule, is_inference: bool):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:91: torch.fx.passes.graph_transform_observer.GraphTransformObserver,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:92: subsystem="post_grad_passes",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:103: GraphTransformObserver(gm, "reorder_for_locality").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:109: if post_grad_custom_pre_pass := config.post_grad_custom_pre_pass:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:110: GraphTransformObserver(gm, "post_grad_custom_pre_pass").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:111: post_grad_custom_pre_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:120: from .mkldnn_fusion import grouped_gemm_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:122: grouped_gemm_pass(gm.graph)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:132: GraphTransformObserver(gm, "post_grad_custom_pre_pass").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:133: functools.partial(group_batch_fusion_passes, pre_grad=False)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:135: GraphTransformObserver(gm, "remove_noop_ops").apply_graph_pass(remove_noop_ops)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:136: GraphTransformObserver(gm, "remove_assert_ops").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:139: for i, patterns in enumerate(pass_patterns):
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:140: GraphTransformObserver(gm, f"pass_pattern_{i}").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:143: for pass_name in config.post_grad_fusion_options:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:145: if pass_name in POST_GRAD_FUSIONS or pass_name in OPTIMUS_EXCLUDE_POST_GRAD:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:147: pattern_matcher_pass = POST_GRAD_PATTERNS[pass_name]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:149: [pattern_matcher_pass.pass_name]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:151: GraphTransformObserver(gm, pass_name).apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:152: pattern_matcher_pass.apply
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:158: "name": f"{pattern_matcher_pass.pass_name}_post_grad",
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:165: if config.b2b_gemm_pass:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:169: micro_pipeline_tp_pass(gm.graph)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:172: GraphTransformObserver(gm, "fuse_ddp_communication").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:175: config._fuse_ddp_communication_passes,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:180: if post_grad_custom_post_pass := config.post_grad_custom_post_pass:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:181: GraphTransformObserver(gm, "post_grad_custom_post_pass").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:182: post_grad_custom_post_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:185: GraphTransformObserver(gm, "stable_sort").apply_graph_pass(stable_topological_sort)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:187: GraphTransformObserver(gm, "move_constructors_to_cuda").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:193: for device, custom_backend_pass in custom_backend_passes.items():
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:194: if custom_backend_pass is not None:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:197: pass_name = "custom_backend_passes_" + device
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:198: GraphTransformObserver(gm, pass_name).apply_gm_pass(custom_backend_pass)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:201: # ./fx_passes/README.md for a discussion of mutation invariants.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:202: GraphTransformObserver(gm, "reinplace_inplaceable_ops").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:207: ).apply_graph_pass(decompose_triton_kernel_wrapper_functional)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:208: GraphTransformObserver(gm, "decompose_auto_functionalized").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:212: GraphTransformObserver(gm, "reinplace_fsdp_all_gather").apply_graph_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:215: GraphTransformObserver(gm, "decompose_scan_to_while_loop").apply_gm_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:218: GraphTransformObserver(gm, "decompose_map_to_while_loop").apply_gm_pass(
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:260: graph_pass = PatternMatcherPass()
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:264: pass_dict=graph_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:268: "kwargs of map are not merged into args before entering decompose_map_to_while_loop_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:350: lower_to_while_loop, lower_to_while_loop_args, run_functional_passes=False
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:353: graph_pass.apply(gm)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:394: This pass decomposes `scan` to  `while_loop` by replacing the scan fx_node with a while_loop hop.
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:422: This pass will rewrite scan into:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:447: graph_pass = PatternMatcherPass()
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:451: pass_dict=graph_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:457: "kwargs of scan are not merged into args before entering decompose_scan_to_while_loop_pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:561: run_functional_passes=False,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:564: graph_pass.apply(gm)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:580: # Put this patterns in post-grad pass rather than joint-graph
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:581: # pass since otherwise there will be perf/peak-memory regression:
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:589: pass_dicts=pass_patterns[1],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:643: pattern, extra_check=_return_true, pass_number=1
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:649: pattern, extra_check, pass_dict=pass_patterns[pass_number]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:699: # TODO: the pattern can be updated to support the case that index tensor
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:735: TODO: Right now the scatter value must be a scalar. But we could support it
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:791: pass_dict=pass_patterns[1],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:881: # The dim of split and cat should match for passthrough
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1058: # See fx_passes/README.md for a discussion of why this is
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1119: We assume that the reinplacing pass runs before this; the reinplacing pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1123: graph_pass = PatternMatcherPass()
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1127: pass_dict=graph_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1143: match.replace_by_example(decomp, flat_args, run_functional_passes=False)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1145: graph_pass.apply(graph)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1158: We assume that the reinplacing pass runs before this; the reinplacing pass
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1162: graph_pass = PatternMatcherPass()
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1166: pass_dict=graph_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1186: match.replace_by_example(decomp, flat_args, run_functional_passes=False)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1190: pass_dict=graph_pass,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1230: match.replace_by_example(decomp, flat_args, run_functional_passes=False)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1232: graph_pass.apply(graph)
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1278: pass_number=2,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1332: pass_number=2,
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1368: pass_dict=pass_patterns[2],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1402: pass_dict=pass_patterns[2],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1411: pass_dict=pass_patterns[2],
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1430: # TODO: to support other reductions like sum, would need to skip
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1440: MultiOutputPattern([partial_reduc, full_reduc]), pass_dict=pass_patterns[2]
- .venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:1777: # cudagraph does not support cpu tensors. In this pass, we update the graph
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/halide_helpers.py:34: # TODO:
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:58: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:66: # Newer triton versions pass an extra global scratch parameter to the compiled cuda kernel.
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:67: # Inductor never uses this field or enables it, but we still have to pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:71: raise NotImplementedError("Global scratch not yet supported")
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:88: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:139: # TODO handle nvTmaDesc/CUtensormap
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:147: value should be passed to the triton kernel as.
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:152: raise NotImplementedError("nvTmaDesc kernels are not yet supported")
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:166: # Triton uses these as the main way to filter out constants passed to their cubin
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:173: # Despite requiring them to be passed in, the triton CUDA launcher
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:174: # completely ignores the constexprs passed into it when generating code.
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:180: # In newer triton versions, constants are passed in to signature with type `constexpr`
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:184: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:212: # TODO: actually, if the args *don't* match, we probably should
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:215: # Get rid of constants before passing to cubin launcher
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/static_cuda_launcher.py:225: # TODO: can handle grid functions here or in C++, so
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:86: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:251: triton_meta,  # passed directly to triton
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:441: # TODO(jansel): we should find a way to move this extra compile into the worker process
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:740: `args` is passed in with only the non-constexpr args (because the constexpr arg values
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:809: autotuning contanminating them. We try to pass cloned args to the kernel.
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1047: # TODO: should we just load the kernels ahead of time if we know we're going to call this?
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1314: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1371: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1380: log.info("Bypassing StaticallyLaunchedCudaKernel due to %s", str(e))
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1429: # In 3.2.0, triton kernels do not require passing any declared constexprs into the kernel
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1430: # In 3.3.0, triton kernels require all declared constexprs be passed into the kernel, where
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1436: # But CachingAutotuner.run will pass us a different number of arguments depending on
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1439: # want only a subset of the arguments passed to triton.
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1529: # TODO(jansel): need to fixup src.fn which is now None
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1609: # TODO(jansel): delete this branch in mid-2025
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:1969: )  # TODO: query warp size once #129663 is merged
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2298: raise NotImplementedError(f"size_hints: {size_hints}")
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2376: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2380: pass  # skip all these cases
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2396: # TODO: this may only be beneficial when each iteration of the reduction
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2522: # TODO(jansel): we should base target on the SM count of the local GPU
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2538: # TODO(jansel): add more configs in max_autotune
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2586: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2587: # TODO(jansel): we should be able to improve these heuristics
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2651: raise NotImplementedError(f"size_hints: {size_hints}")
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2811: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_heuristics.py:2990: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/hints.py:157: # TODO: Fetch the actual value from ioreg
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/hints.py:210: """Command line args to pass to halide generator"""
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/autotune_cache.py:75: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/autotune_cache.py:204: "backend_hash is not passed on the inductor_meta, unable to use autotune remote cache"
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/autotune_cache.py:227: # Save the args passed to create_cache
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/autotune_cache.py:326: # TODO: Do we need to compute time_taken_ms and encode that somehow?
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/autotune_cache.py:343: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/autotune_cache.py:419: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/autotune_cache.py:460: # TODO: The autotune cache includes configs_hash in the key. The problem
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/autotune_cache.py:502: # TODO: check cache_dir() vs filename, then strip dirname
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/coordinate_descent_tuner.py:42: TODO will it be necessary to tune multiple fields simultaneously.
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/coordinate_descent_tuner.py:45: TODO: what if both increasing and decreasing a field can improve perf.
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/benchmarking.py:46: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/benchmarking.py:92: # TODO(nmacchioni): For non-CPU functions we default to using the GPU-specific benchmarking
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/benchmarking.py:134: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/benchmarking.py:144: raise NotImplementedError("requires Triton") from e
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/benchmarking.py:158: - **kwargs: Additional kwargs passed to Triton's `do_bench`.
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/benchmarking.py:234: - **kwargs: Additional kwargs that may be passed to the fallback.
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/cache_dir_utils.py:1: import getpass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/cache_dir_utils.py:23: sanitized_username = re.sub(r'[\\/:*?"<>|]', "_", getpass.getuser())
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py:392: Ref: https://research.nvidia.com/publication/2016-03_single-pass-parallel-prefix-scan-decoupled-look-back
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py:457: Ref: https://research.nvidia.com/publication/2016-03_single-pass-parallel-prefix-scan-decoupled-look-back
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py:511: # TODO(isuruf): use inline_asm_elementwise here
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py:689: # TODO(jansel): is this needed?
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_compat.py:27: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_compat.py:70: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_compat.py:99: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/runtime/triton_compat.py:102: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_worker/__main__.py:34: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_worker/subproc_pool.py:88: Allows a caller to provide a custom pickler for passing data with the
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_worker/subproc_pool.py:157: pass_fds=(subproc_read_fd, subproc_write_fd),
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_worker/subproc_pool.py:299: pass  # parent process already shutdown
- .venv/lib/python3.12/site-packages/torch/_inductor/compile_worker/subproc_pool.py:375: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/bmm.py:210: # TODO: add out_dtype support for Triton Template
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_decoding.py:317: # TODO: workload evening at runtime for splits fully masked out.
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_decoding.py:372: # TODO: Fix flex decoding non-divisible case!
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_decoding.py:422: # TODO: fix autotuning.
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_decoding.py:494: # TODO: This feels sketchy
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_decoding.py:500: # Note, we don't need to pass in the captured buffers explicitly
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_decoding.py:502: # We do need to explicitly pass it in for autotuning though.
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:203: args: The args that are passed into the subgraph. Contains both fixed and lifted inputs.
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:706: qk = tl.dot(q, k, input_precision=FLOAT32_PRECISION) # TODO: use cuda matmul when q_len <= 2.
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:967: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:971: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1133: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1137: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1190: "Q seqlen must be smaller than the block_mask size in the Q dimension, considering pass a larger block_mask."
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1195: "KV seqlen must be smaller than the block_mask size in the KV dimension, considering pass a larger block_mask."
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1311: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1483: # Note, we don't need to pass in the captured buffers explicitly
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1485: # We do need to explicitly pass it in for autotuning though.
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1610: To do this will either require atomic updates to some grad values or to have a two pass kernel design.
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1734: # TODO: This does not work if DQ is not the same layout as Q (for example,
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:1842: # TODO: This does not work if DQ is not the same layout as Q (for example,
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:2325: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/flex_attention.py:2392: # TODO: We probably also need a layout constraint?
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm_plus_mm.py:137: # TODO(jansel): support different K values when this is fixed:
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:538: # TODO: check if it's beneficial to convert Conv1d to Conv2d and then
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:543: # TODO maybe we can convert weights to channels last just once before
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:622: # TODO(jansel): try unroll for bigger kernels once fixed:
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:645: # TODO(jansel): try unroll for bigger kernels once fixed:
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm.py:1207: # TODO (paulzhan): There is no template that exists for bias and TMA
- .venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm.py:1338: # TODO: is there a cleaner way to ensure aten.mm is always included?
- .venv/lib/python3.12/site-packages/torch/_inductor/autoheuristic/autoheuristic_utils.py:101: # TODO(AlnisM): there might be a better way to do this
- .venv/lib/python3.12/site-packages/torch/_inductor/autoheuristic/learnedheuristic_interface.py:17: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/autoheuristic/autoheuristic.py:131: # TODO(AlnisM): We might want to allow this in the future
- .venv/lib/python3.12/site-packages/torch/_inductor/autoheuristic/autoheuristic.py:167: # TODO(AlnisM): just using the device name for now, but the same GPU model can have different names
- .venv/lib/python3.12/site-packages/torch/_inductor/autoheuristic/autoheuristic.py:248: # TODO: Find a nicer way to handle this
- .venv/lib/python3.12/site-packages/torch/_inductor/autoheuristic/artifacts/_PadMMA100.py:14: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpu_device_op_overrides.py:18: return "pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpu_device_op_overrides.py:21: return "pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpu_device_op_overrides.py:24: return "pass"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_mps.py:57: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_mps.py:63: raise NotImplementedError("No threads or group_size provided")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:103: self.run_wrapper_ir_passes(is_inference)
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:133: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:169: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:257: raise NotImplementedError(f"Unable to extract buffer from node: {node}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:310: raise NotImplementedError(f"Unrecognized buffer/view node: {node}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:341: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:343: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:393: raise NotImplementedError("Subgraphs are not yet supported by FX conversion")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:397: raise NotImplementedError("Subgraphs are not yet supported by FX conversion")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:502: raise NotImplementedError("Comm buffer allocation is not yet supported")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:642: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:644: raise NotImplementedError(f"Unrecognized output layout: {kernel.layout}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:674: raise NotImplementedError("FX conversion only supports Triton kernels.")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper_fxir.py:693: # No need for an FX node, as we will pass the arg to kernels via a SymInt.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:96: # TODO - support subgraph codegen by lifting functions. Check the
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:249: # TODO: this could be auto-generated from a passed-in custom op schema
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:347: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1132: # as a global variable passed when calling exec(code, mod.__dict__, mod.__dict__).
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1133: # For cpp wrapper, we need to pass this python value to the inductor_entry_impl function explicitly.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1143: # If we pass at::Tensor, the compilation will be too slow.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1207: """debug_args kwarg allows CppWrapperCpuArrayRef to pass in wrapped arguments in
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1274: # TODO: handle integer output (e.g., as in attention)
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1297: raise NotImplementedError(f"unsupported type of {output=}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1337: # TODO: consider remove "_out" and add missing inplace variants to fallback_ops.py
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1356: # TODO: update aoti_torch_index_put_out in ir.py to use autogen out version
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1423: # TODO: assert divisibility here
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1453: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1456: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1460: # TODO: Add buf name directly into check_inf_and_nan.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1498: # Because the memory planning is done in two passes (see the implementation
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1499: # of self.generate), the writeline behavior is different in the two passes.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1501: # position of the generated code, so the second pass codegen should not
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1502: # reuse int array declarations generated in the first pass.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1503: # This is why writeline needs to explicitly passed in as a parameter.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1740: # in the abi_compatible mode, outputs are retrieved by passing
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1742: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1780: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1819: # TODO (desertfire) - This function is the old way of supporting
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1955: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2023: raise NotImplementedError("NYI support for return type: SymInt")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2027: raise NotImplementedError("NYI support for return type: List[SymInt]")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2031: # TODO: Only support None and tensor(s) returns for now, SymInt is not implemented yet
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2036: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2042: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2204: # TODO: need to support control flow
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2257: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2266: # In some cases, scalar arguments may be passed in place of tensors.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2311: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2564: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2567: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2600: # TODO: not using type_ as the first step of refactoring. Will update this later.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:2710: # need to pass the array length, because we can't use the std::array member
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_gpu.py:256: # TODO - support subgraph codegen by lifting functions. Check the
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_gpu.py:296: # TODO: This is added because FC. Remove this once the newly added shim symbols,
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_gpu.py:389: # these args are passed to initNDTMADescriptor, which is NOT a triton kernel
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_gpu.py:397: # (CUdeviceptr); we dereference `source` and cast to `void*` to pass to
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_gpu.py:414: # these args are passed to initNDTMADescriptor, which is NOT a triton kernel
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_gpu.py:460: Generates any declarations of args to pass into a kernel call, and then returns the arg names.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_gpu.py:469: is_triton_kernel: whether these are passed into a triton kernel or not. In particular,
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_gpu.py:493: # For most args, a single arg passed to the python triton interface
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_gpu.py:523: # to be passed to the compiled Triton kernel by value
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_gemm_template.py:634: TODO(jgong5): allow tuning various blocking options
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_gemm_template.py:760: # TODO: tune the factor here
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_gemm_template.py:791: # TODO: Decouple the choice of micro-kernel from cache blocking
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_gemm_template.py:821: min_Mc_ratio = 2  # TODO(jgong5): something to tune?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_gemm_template.py:885: # TODO(jgong5): perhaps use size hint to decide?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_gemm_template.py:993: # TODO(jgong5): decide proper number of threads per problem size
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_gemm_template.py:1279: # TODO: Move VNNI weight packing for non-constant tensors into the template,
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_gemm_template.py:1373: # TODO(jgong5): for int8 gemm, bias-add is handled outside of gemm template,
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_gemm_template.py:1777: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:437: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:827: Index expressions often need to be passed in as arguments to the triton kernel.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:845: # TODO instead of trying to blindly find complicated exprs, we should hoist the
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:896: raise NotImplementedError("NYI: codegen_nan_check")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:899: raise NotImplementedError("NYI: call_kernel")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:915: # TODO(jansel): do we need a reshape here?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1097: def prepare_softmax_twopass_fallback(self, dtype, value):
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1105: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1108: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1111: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1333: pass  # need to start a new reduction loop
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1347: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1493: # First pass to collect indexing and decide inplace updates
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1510: # Second pass to do codegen
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1517: # TODO - use split ranges ?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1573: # TODO - this doesn't work with libdevice calls, potentially other bugs
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:1602: # TODO: Maybe unify CUDATemplateKernel to also use PartialRender for flexible epilogue fusion.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:2132: # TODO: incorporate exact bitwidth, and read/write
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:2160: # TODO, add tests, reduction splits if config.triton.tile_reductions
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:2161: # TODO: we should ignore tiny increases in score for extra splits
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:2227: # TODO - look into, occurs with dynamic shapes often
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:2298: # # TODO: enable by default
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:2406: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:2442: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:2445: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd.py:2462: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:55: # TODO(jgong5): support constant shapes and lds as template args.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:131: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:450: // TODO(jgong5): loop unroll for M and N
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:882: # TODO add trans_b support for other micro gemms
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:929: # TODO supports tuning of sub_block_m/sub_block_n
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:1055: // TODO(jgong5): loop unroll for M and N
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:1135: // TODO(jgong5): add prefetch hint for A, B, C
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:1211: // TODO(jgong5): move tail k computation to separate loopnest to save tile configuration overhead
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:1374: # TODO: support float/half input
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py:2010: # TODO(jgong5): allow autotuning on choices of configs
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:68: from ..custom_graph_pass import CustomGraphModulePass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:135: raise NotImplementedError(f"WorkspaceZeroMode.combine({a!r}, {b!r})")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:151: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:155: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:314: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:317: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:320: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:323: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:326: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:329: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:332: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:335: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:338: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:341: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:344: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:347: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:350: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:353: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:356: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:359: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:365: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:369: custom_backend_passes: dict[str, Optional[CustomGraphModulePass]] = {}
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:398: device_custom_pass: Optional[CustomGraphModulePass] = None,
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:403: custom_backend_passes[device] = device_custom_pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:462: def get_custom_backend_pass_for_device(device: str) -> Optional[CustomGraphModulePass]:
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:463: return custom_backend_passes[device] if device in custom_backend_passes else None
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:542: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:766: # TODO: why are people passing strings to the printer here :think:
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:922: # TODO: this is wrong
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:923: # TODO: an easy bandaid is to generate runtime asserts that it's
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:943: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:948: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:955: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:960: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:971: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:984: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:995: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1009: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1014: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1027: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1044: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1755: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2032: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2045: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2050: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2059: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2069: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2078: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2081: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2096: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2100: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2135: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2138: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2346: ) -> Optional[NotImplementedError]:
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2352: kwargs: Additional kwargs to be passed to self.generate() to generate a new ChoiceCaller.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2358: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:2372: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_template.py:126: # TODO: add c10::ForcedUnroll test to test_aoti_abi_check
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_template.py:138: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps_device_op_overrides.py:13: return "pass  # MPS set device"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:1514: # TODO: this seems to be dead
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2093: raise NotImplementedError(f"store mode={mode}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2463: assert tiling_factor > 0, "Expect pass in Non-Zero tiling_factor explicitly"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2534: # TODO: avoid hard-code torch.float
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2540: # TODO: should we consider load mask here?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2787: raise NotImplementedError(f"store mode={mode}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3247: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3372: self._load_mask is None  # TODO: support transposition with mask
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3585: # TODO(jgong5): support alternative tiling factors and data types
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4008: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4046: # is just a function. Hence, it cannot pass the lint check for debug mode.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4047: # We bypass the check if the owning_module is None. Eventually, we should call
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4080: # Bypass the legalization as the kernel can run with bf16/fp16 directly
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4147: # <TODO> This should be removed after full support for vectorization is implemented.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4422: # TODO(leslie-fang-intel): only enable parallel within all outer loop levels.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4580: # TODO(jansel): allow fusion pointwise (vars1, ()) suffix?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4599: # TODO: we can extend fusion support with compatible ranges for FusedSchedulerNode
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4607: # TODO: we can fix if it allows us to CSE at least one of the variables
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4746: # TODO(jgong5): support pre-op fusion with template
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:5111: "Template node passed to CppScheduler.codegen_template must be a SchedulerNode that wraps a CppTemplateBuffer"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:5183: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:5200: # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:5270: # TODO: support kernel profile on other platforms
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:5406: # TODO(jansel): look into chunk size and other schedules
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/multi_kernel.py:58: # the second pass of cpp-wrapper.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/multi_kernel.py:147: # for the second pass of cpp-wrapper codegen, we should call
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/multi_kernel.py:200: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/multi_kernel.py:298: # codegen. The first pass use record_choice to keep the choice and
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/multi_kernel.py:299: # the second pass do lookup by calling lookup_choice.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/multi_kernel.py:302: # since during codegen of the second pass, it's very hard to know the
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_utils.py:197: # TODO: why are people passing strings to the printer here :think:
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_utils.py:738: # TODO: Add support of fusion when the read of template buffer and the write of epilogue output
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:444: """List of indices to pass to tl.load(boundary_check=...)"""
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:497: Codegen string to pass to tl.advance(name, ...).
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:600: # TODO: This is wrong, when lhs, rhs > 2**53, Python does a higher
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:958: # TODO - register these ops as having divergent dtype
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:959: # output if doing graph pass to remove consecutive casts
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1062: raise NotImplementedError("ops.index_expr not implemented outside a kernel")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1066: raise NotImplementedError("ops.masked not implemented outside a kernel")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1215: raise NotImplementedError("ops.load_seed not implemented outside a kernel")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1413: # TODO: we are not always consistent in enforcing that the output of the index expr printing
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1650: # A set of autotuning hints to pass as part of triton_meta
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1794: Compute the index and mask to pass to tl.load() or tl.store()
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1807: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1823: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2267: # unwrapped bf16/fp16 0d tensors are passed in as float32 scalars
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2355: raise NotImplementedError(f"store mode={mode}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2409: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2587: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2630: result_var = self.prepare_softmax_twopass_fallback(dtype, value)
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2685: # Note, we pass config.use_fast_math to the JITFunction
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3105: assert not self.cooperative_reduction, "TODO"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3215: assert not self.cooperative_reduction, "TODO"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3790: This code stomps on the passed-in values by writing an constant to the top of the kernel.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3840: # TODO(jansel): if there are constants, we shouldn't bother passing them as args
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3925: # For each z dimension, there are tl.num_programs(1) yblocks which is passed by grad(x,y,z).
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:4183: # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:4299: # TODO - would be better as a hook in triton do_bench that reset
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:4331: # TODO(jansel): scan does not yet work with cooperative reductions
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:109: # TODO benchmark the performance when large pointwise nodes combining with others
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:197: # TODO support combination of kernels with different block dimensions
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:410: This code stomps on the passed-in values by writing an constant to the top of the kernel.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:677: # TODO: we assume all sub_kernels have the same block size
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:733: # TODO: is it correct to use the first sub kernel's heuristics?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:795: code.splice("pass")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu_array_ref.py:57: # TODO - support subgraph codegen by lifting functions. Check the
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu_array_ref.py:355: # TODO: input shape checking for regular tensor interface as well?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu_array_ref.py:495: # TODO: integrate memory planning & stack allocation?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu_array_ref.py:504: # TODO: this seems legit, NullLine has no node
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu_array_ref.py:510: # codegen allocations in two passes
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu_array_ref.py:702: # TODO: consider remove "_out" and add missing inplace variants to fallback_ops.py
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu_array_ref.py:729: # TODO: update aoti_torch_index_put_out in ir.py to use autogen out version
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_split_scan.py:33: https://research.nvidia.com/publication/2016-03_single-pass-parallel-prefix-scan-decoupled-look-back
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_split_scan.py:86: raise NotImplementedError("NYI TritonSplitDimKernel reductions")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:36: # TODO: Remove fp8 special handling when Triton supports PyTorch fp8 dtypes.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:89: raise NotImplementedError(f"unhandled size_dtype {size_dtype}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:104: raise NotImplementedError(f"unhandled {type(arg)}: {arg}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:230: # TODO(voz): These are kinda redundant, if we can solve out statically_known_multiple_of with
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:244: raise NotImplementedError(f"unhandled {type(x)}: {x}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:114: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:118: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:122: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:260: # TODO(jansel): we could try harder here by merging overlapping in space
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:609: Coordination object to run memory planning passes during wrapper
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:618: """Call all the memory planning passes in sequence"""
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:653: # TODO(jansel): we should support reusing buffers created via ExternKernelAlloc
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd_kernel_features.py:70: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/simd_kernel_features.py:224: raise NotImplementedError(f"groups_dict={groups_dict!r}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_template_kernel.py:131: raise NotImplementedError(f"Unsupported dtype: {node.get_dtype()}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_template_kernel.py:368: In this case, the `offsets` could be provided to adjust the indices passed to
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/debug_utils.py:157: # TODO: Find a more reliable way to detect kernel args types to print for extern kernel calls
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps.py:131: # TODO: This is only accurate up to 2**23
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps.py:199: # TODO: Type annotation for other is wrong, it's often float or int
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps.py:298: # TODO: Does it rely on undefined behavior?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps.py:481: # TODO(NS): Figure out the right balance between optype casts
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps.py:712: raise NotImplementedError(reduction_type)
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps.py:928: device=torch.device("cpu"),  # TODO: Fix me, MPS does not expose streams now
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps.py:938: # TODO(malfet): support asserts
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps.py:942: # TODO(malfet): Is upper bound inclusive or exclusive?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/mps.py:970: # TODO: Merge multiple kernels into a single library
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_bmm_template.py:19: # We pass all sizevars present in BY to the GEMM templates so variables are not renamed in the BMM definition
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_bmm_template.py:95: We use an extra sizevar `b_index` to index the batch dimension, which we pass into the GEMM
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_flex_attention_template.py:25: # TODO: reuse cpp codegen to generate below pointwise/reduction kernels
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_flex_attention_template.py:517: // TODO: reduce the number of calls of q_idx and kv_idx initialization
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_flex_attention_template.py:963: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_flex_attention_template.py:1020: # TODO: use inductor IR to rewrite those fusions
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_flex_attention_template.py:1026: # TODO: make them general for common bmm templates
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:180: raise NotImplementedError("log2")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:446: # TODO(jansel): find a better way to do this, builtin % has wrong sign
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:459: raise NotImplementedError("log2")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:485: # TODO(jansel): find a better ways to do this, the select-based trick from triton.py didn't work
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:531: # TODO(jansel): Halide only supports 32-bit indexing, we should error on overflow
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:560: # TODO(jansel): look into removing the where in the same places triton does
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:565: raise NotImplementedError("frexp")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:815: # TODO(jansel): we should just prevent fusion in cases that hit this
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1014: ):  # TODO(jansel): negative offsets
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1078: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1080: raise NotImplementedError(f"unhandled symbol {sym}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1172: raise NotImplementedError(f"store mode={mode}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1223: # TODO(jansel): implement welford_reduce without fallback
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1374: supports.  If there are gaps in the underlying layout the numel we pass to Halide includes the gaps while
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1469: # TODO(jansel): explore other flags, see:
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1487: # TODO(jansel): it is unclear if this does anything, since input sizes are still int32
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1572: pass  # not integer
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1578: pass  # not integer
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1648: return False  # TODO(jansel): support asserts
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/halide.py:1653: pass  # TODO(jansel): support asserts
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:136: # TODO: Move to a well known place
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:221: # TODO(aakhundov): the sorting below is generally not sufficient, so
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:356: raise NotImplementedError("FX codegen not yet supported for type {type(self)}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:568: """First pass to find reuse"""
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:572: """Second pass to output code"""
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:764: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1018: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1023: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1485: self.run_wrapper_ir_passes(is_inference)
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1606: # TODO: this seems legit, NullLine has no node
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1612: # codegen allocations in two passes
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1633: def run_wrapper_ir_passes(self, is_inference: bool):
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1678: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1732: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1890: # TODO: this fallback and those below actually will generate possibly
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2132: # TODO(aakhundov): add None args to constants, too. currently, this
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2155: # compute the grid in the wrapper and pass it in as an arg
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2268: # This is handled in `generate_args_decl` which has a correct comment of: TODO: only works for
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2357: control flow: only one pass through the control flow operators covers
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2473: raise NotImplementedError(f"Unsupported type {type(arg)}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2595: being passed in as an input."""
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2619: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2642: # arg may be passed in a kwarg style, and then we need to extract its value
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2971: # TODO: need to assert divisibility
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:2972: # TODO: this is invalid C++ codegen
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3008: # TODO (desertfire) - This function is the old way of supporting
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3014: # two passes and the kernels are shared from the first pass to the next.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3017: # subgraph as functions. Therefore for cpp_wrapper first pass with
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3229: # are passed in as they're before.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3329: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3332: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3335: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3338: pass
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3398: # TODO: Uncomment in future. This will be needed to support subgraph
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:3407: # TODO: Uncomment in future. This will be needed to support subgraph
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_python_evt.py:67: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_python_evt.py:79: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_python_evt.py:91: raise NotImplementedError("sigmoid is not supported in CUTLASS python evt")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_python_evt.py:99: raise NotImplementedError("tanh is not supported in CUTLASS python evt")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_python_evt.py:129: raise NotImplementedError(name)
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_python_evt.py:276: # TODO mlazos: relax this, cutlass supports reductions and other ops
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_python_evt.py:295: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_cpp_scheduling.py:137: "Template node passed to CUDAScheduler.codegen_template must be a SchedulerNode that wraps a CUDATemplateBuffer"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_cpp_scheduling.py:153: # typically there is a codegen pass which runs after mark_run
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_cpp_scheduling.py:277: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:62: We want to support three ways of passing in CUTLASS:
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:112: # TODO(ipiszy): remove this hack when CUTLASS solves Python scripts packaging structure issues.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:114: # TODO(mlazos): epilogue visitor tree currently lives in python/cutlass,
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:218: raise NotImplementedError(f"Unsupported cuda arch: {arch}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:238: # TODO: these three look dead?
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:292: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:336: raise NotImplementedError(f"Unsupported data type: {torch_dtype=}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:399: raise NotImplementedError(f"Unsupported data types: {input_torch_dtypes=}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:418: raise NotImplementedError(f"unsupported {torch_dtype=} for alignments")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:461: # Can be used to capture the sourcecode passed to CUDACodeCache.compile
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_template.py:211: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_template.py:257: // Used as pass-through functor in EVT just for type casting / rounding
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:461: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:466: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:471: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:475: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:482: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:486: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:493: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:500: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:507: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:515: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:522: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:530: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:545: This function mutates the passed list of choices by appending the choices for Cutlass GEMM configs to it.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:877: # TODO: update epilogue functor according to epilogues.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:1017: passed inputs to the template at construction time. However, they should be layout compatible.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:1028: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:1243: raise NotImplementedError("_render_evt in CUTLASSGemmTemplate not implemented")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:1562: Render the Cutlass CUDA C++ code required for passing arguments to the GEMM operation.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:1851: Render the Cutlass CUDA C++ code required for passing arguments to the GEMM operation.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:262: and the actual input passed into this template could be [Bias, X, W].
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:341: # we replace with the real kernel name passed as an arg to this function.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:461: TODO: Will add needed args to pass it in if it is dynamic.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:488: TODO: Will add needed args to pass it in if it is dynamic.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:533: TODO: Will add needed args to pass it in if it is dynamic.
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_lib_extensions/gemm_operation_extensions.py:153: # Shape passed to epilogue builder
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_lib_extensions/evt_extensions.py:125: # This is modified to enable directly passing the source code of the epilogue vs getting it from a bona-fide python func
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_lib_extensions/evt_extensions.py:240: raise NotImplementedError(f"Unsupported arg type: {arg_ty}")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/rocm/compile_command.py:96: opts += ["-Rpass-analysis=kernel-resource-usage"]
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/rocm/compile_command.py:147: raise NotImplementedError(f"Unsupported output file suffix {dst_file_ext}!")
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/rocm/rocm_cpp_scheduling.py:83: "Template node passed to ROCmScheduler.codegen_template must be a SchedulerNode that wraps a ROCmTemplateBuffer"
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/rocm/rocm_template.py:186: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/rocm/rocm_kernel.py:86: and the actual input passed into this template could be [Bias, X, W].
- .venv/lib/python3.12/site-packages/torch/_inductor/codegen/rocm/rocm_kernel.py:145: # So, we replace with the real kernel name passed as an arg to this function.
- .venv/lib/python3.12/site-packages/torch/masked/_ops.py:462: raise NotImplementedError(f"identity of {op_name} on {dtype} input")
- .venv/lib/python3.12/site-packages/torch/masked/_ops.py:535: assert mask.dense_dim() == input.dense_dim()  # TODO: eliminate this restriction
- .venv/lib/python3.12/site-packages/torch/masked/_ops.py:827: # TODO: implement sparse CSR specific where operator for efficiency
- .venv/lib/python3.12/site-packages/torch/masked/_ops.py:1400: # TODO: compute count analytically
- .venv/lib/python3.12/site-packages/torch/masked/_ops.py:1619: # TODO: compute count analytically
- .venv/lib/python3.12/site-packages/torch/masked/_ops.py:1630: # TODO: replace torch.subtract/divide/square/maximum with
- .venv/lib/python3.12/site-packages/torch/masked/_ops.py:1800: # TODO: eliminate mask_input as unnecessary when using masked divide.
- .venv/lib/python3.12/site-packages/torch/masked/_ops.py:1804: # TODO: replace torch.maximum with masked maximum when available.
- .venv/lib/python3.12/site-packages/torch/masked/_ops.py:1806: # TODO: replace torch.divide with masked divide when available.
- .venv/lib/python3.12/site-packages/torch/masked/maskedtensor/reductions.py:71: # we simply pass in the values for sparse COO/CSR tensors
- .venv/lib/python3.12/site-packages/torch/masked/maskedtensor/reductions.py:129: # TODO: autograd.Function doesn't support kwarg
- .venv/lib/python3.12/site-packages/torch/masked/maskedtensor/passthrough.py:41: def _is_pass_through_fn(fn):
- .venv/lib/python3.12/site-packages/torch/masked/maskedtensor/passthrough.py:45: def _apply_pass_through_fn(fn, *args, **kwargs):
- .venv/lib/python3.12/site-packages/torch/masked/maskedtensor/__init__.py:5: from .passthrough import _apply_pass_through_fn, _is_pass_through_fn
- .venv/lib/python3.12/site-packages/torch/masked/maskedtensor/_ops_refs.py:17: from .passthrough import _apply_pass_through_fn, PASSTHROUGH_FNS
- .venv/lib/python3.12/site-packages/torch/masked/maskedtensor/_ops_refs.py:259: def _general_passthrough(func, *args, **kwargs):
- .venv/lib/python3.12/site-packages/torch/masked/maskedtensor/_ops_refs.py:260: return _apply_pass_through_fn(func, *args, **kwargs)
- .venv/lib/python3.12/site-packages/torch/nn/init.py:162: which is necessary to induce a stable fixed point in the forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/init.py:469: pass in a transposed weight matrix, i.e. ``nn.init.xavier_uniform_(w.T, ...)``.
- .venv/lib/python3.12/site-packages/torch/nn/init.py:509: pass in a transposed weight matrix, i.e. ``nn.init.xavier_normal_(w.T, ...)``.
- .venv/lib/python3.12/site-packages/torch/nn/init.py:536: The method is described in `Delving deep into rectifiers: Surpassing
- .venv/lib/python3.12/site-packages/torch/nn/init.py:552: forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the
- .venv/lib/python3.12/site-packages/torch/nn/init.py:553: backwards pass.
- .venv/lib/python3.12/site-packages/torch/nn/init.py:568: pass in a transposed weight matrix, i.e. ``nn.init.kaiming_uniform_(w.T, ...)``.
- .venv/lib/python3.12/site-packages/torch/nn/init.py:601: The method is described in `Delving deep into rectifiers: Surpassing
- .venv/lib/python3.12/site-packages/torch/nn/init.py:617: forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the
- .venv/lib/python3.12/site-packages/torch/nn/init.py:618: backwards pass.
- .venv/lib/python3.12/site-packages/torch/nn/init.py:633: pass in a transposed weight matrix, i.e. ``nn.init.kaiming_normal_(w.T, ...)``.
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:461: Useful to pass to :func:`~torch.nn.functional.max_unpool2d`.
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:574: Useful to pass to :func:`~torch.nn.functional.max_unpool3d`.
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:1537: # TODO: Properly support no-batch-dim inputs. For now, these are NOT supported; passing
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:2692: # TODO: Remove this once script supports type() calls
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:2743: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:2772: # TODO: make use of reduce like below when JIT is ready with the missing features:
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:3275: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:3277: # If none of the above pass, then the size of var is incorrect.
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:3331: log_target (bool): A flag indicating whether ``target`` is passed in the log space.
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:3332: It is recommended to pass certain distributions (like ``softmax``)
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4379: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4390: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4492: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4505: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4518: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4531: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4580: `scale_factor` must be passed in and `scale_factor` is used to compute the
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4793: raise NotImplementedError("Got 3D input, but bilinear mode needs 4D input")
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4795: raise NotImplementedError("Got 3D input, but trilinear mode needs 5D input")
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4797: raise NotImplementedError("Got 4D input, but linear mode needs 3D input")
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4799: raise NotImplementedError("Got 4D input, but trilinear mode needs 5D input")
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4801: raise NotImplementedError("Got 5D input, but linear mode needs 3D input")
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4803: raise NotImplementedError("Got 5D input, but bilinear mode needs 4D input")
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4805: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4822: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4831: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4872: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4881: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4890: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:4899: pass
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:5000: behaviour in its backward pass that is not easily switched off.
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:5129: A grid generated by :func:`affine_grid` should be passed to :func:`grid_sample`
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:5190: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:5247: behaviour in its backward pass that is not easily switched off.
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:5293: # TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:5475: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:5806: Computes scaled dot product attention on query, key and value tensors, using an optional attention mask if passed,
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:5845: To disable dropout during evaluation, be sure to pass a value of ``0.0`` when the module
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:6374: # TODO finish disentangling control flow so we don't do in-projections when statics are passed
- .venv/lib/python3.12/site-packages/torch/nn/functional.py:6385: # TODO finish disentangling control flow so we don't do in-projections when statics are passed
- .venv/lib/python3.12/site-packages/torch/nn/cpp.py:25: # Magic methods cannot be assigned dynamically and bypass ``getattr``, so we
- .venv/lib/python3.12/site-packages/torch/nn/__init__.py:24: Given kwargs, returns a canonicalized dict of factory kwargs that can be directly passed
- .venv/lib/python3.12/site-packages/torch/nn/__init__.py:34: Why should you use this function instead of just passing `kwargs` along directly?
- .venv/lib/python3.12/site-packages/torch/nn/_reduction.py:22: ret = -1  # TODO: remove once JIT exceptions support control flow
- .venv/lib/python3.12/site-packages/torch/nn/utils/init.py:15: 1. The module must accept a `device` arg in its constructor that is passed to any parameters
- .venv/lib/python3.12/site-packages/torch/nn/utils/init.py:26: args: args to pass to the module's constructor
- .venv/lib/python3.12/site-packages/torch/nn/utils/init.py:27: kwargs: kwargs to pass to the module's constructor
- .venv/lib/python3.12/site-packages/torch/nn/utils/prune.py:87: args: arguments passed on to a subclass of
- .venv/lib/python3.12/site-packages/torch/nn/utils/prune.py:94: kwargs: keyword arguments passed on to a subclass of a
- .venv/lib/python3.12/site-packages/torch/nn/utils/prune.py:300: # if all checks passed, add to _pruning_methods tuple
- .venv/lib/python3.12/site-packages/torch/nn/utils/prune.py:1284: # TODO: consider removing this check and allowing users to specify
- .venv/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:92: f"foreach=True was passed, but can't use the foreach API on {device.type} tensors"
- .venv/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:167: f"foreach=True was passed, but can't use the foreach API on {device.type} tensors"
- .venv/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:284: f"foreach=True was passed, but can't use the foreach API on {device.type} tensors"
- .venv/lib/python3.12/site-packages/torch/nn/utils/spectral_norm.py:88: #    backproping through two forward passes, e.g., the common pattern in
- .venv/lib/python3.12/site-packages/torch/nn/utils/spectral_norm.py:159: "The module passed to `SpectralNorm` can't have uninitialized parameters. "
- .venv/lib/python3.12/site-packages/torch/nn/utils/_per_sample_grad.py:25: batch_size: The batch size of the input. If None is passed, all tensor arguments in args and kwargs must have
- .venv/lib/python3.12/site-packages/torch/nn/utils/_per_sample_grad.py:26: the same batch size, which is the size of the first dimension. Otherwise, it must be passed manually.
- .venv/lib/python3.12/site-packages/torch/nn/utils/_per_sample_grad.py:85: "Unable to find a tensor in the passed args and kwargs. They may not be pytree-able "
- .venv/lib/python3.12/site-packages/torch/nn/utils/_per_sample_grad.py:98: f"Module passed must be nn.Module, got {type(module).__name__}"
- .venv/lib/python3.12/site-packages/torch/nn/utils/_per_sample_grad.py:102: f"Batch size passed must be None or an integer, got {type(batch_size).__name__}"
- .venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:78: # TODO: expand this to `_ConvNd` when channels_last support is extended
- .venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:157: # TODO: expand this to `_ConvNd` when channels_last support is extended
- .venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:48: the batch, not the varying sequence lengths passed to
- .venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:71: (i.e., they only pass in tensors conforming to this constraint).
- .venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:131: arguments like `non_blocking` and `copy` should be passed as kwargs,
- .venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:228: # TODO: Re-enable this check (.type isn't supported in TorchScript)
- .venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:389: the batch was passed to ``pack_padded_sequence`` or ``pack_sequence``.
- .venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:25: # TODO Make return type more specific
- .venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:52: "The module passed to `WeightNorm` can't have uninitialized parameters. "
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py:149: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py:479: #    backproping through two forward passes, e.g., the common pattern in
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrizations.py:522: # we may want to assert here that the passed value already
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:40: This is useful when using a parametrized parameter more than once in the forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:44: The simplest way to activate the cache is by wrapping the forward pass of the neural network
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:166: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:167: pass
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:428: If the original tensor requires a gradient, the backward pass will differentiate
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:575: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:576: pass
- .venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:707: # TODO: Fix this for tensor subclasses that are parameters:
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:28: For example, if the module has two tied weights self.foo and self.tied_foo and the user passes
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:30: user passes {'foo': foo_value, 'tied_foo': tied_foo_value, ...}, it will raise an error. If the
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:31: user passes {'foo': foo_value, 'tied_foo': foo_value, ...}, it will not raise an error.
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:63: # Make sure the user didn't pass multiple values for the same tied tensor.
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:77: # Only raise an error if the user passed multiple values for the same tied tensor.
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:185: .. note:: If the module has active parametrizations, passing a value in the
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:188: If you want to apply the parametrization function to the value passed
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:223: args (Any or tuple): arguments to be passed to the module call. If not a tuple, considered a single argument.
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:224: kwargs (dict): keyword arguments to be passed to the module call
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:226: tied in the reparamaterized version. Therefore, if True and different values are passed for the tied
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:228: buffers unless the values passed for both weights are the same. Default: True.
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:229: strict (bool, optional): If True, then the parameters and buffers passed in must match the parameters and
- .venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:255: # TODO allow kwargs such as unsafe and others for parametrization
- .venv/lib/python3.12/site-packages/torch/nn/utils/_expanded_weights/conv_utils.py:330: raise NotImplementedError(f"dilation={dilation} not supported.")
- .venv/lib/python3.12/site-packages/torch/nn/utils/_expanded_weights/expanded_weights_utils.py:28: the args and kwargs they pass. Functions that don't are linear and convND.
- .venv/lib/python3.12/site-packages/torch/nn/utils/_expanded_weights/expanded_weights_utils.py:39: r"""Compute the forward pass for a function that has expanded weight(s) passed to it.
- .venv/lib/python3.12/site-packages/torch/nn/utils/_expanded_weights/expanded_weights_utils.py:41: It will run the forward pass where all ExpandedWeights are their original
- .venv/lib/python3.12/site-packages/torch/nn/utils/_expanded_weights/expanded_weights_utils.py:51: expanded_args: Arguments to be passed to :attr:`func`. Will include arguments
- .venv/lib/python3.12/site-packages/torch/nn/utils/_expanded_weights/expanded_weights_utils.py:53: expanded_kwargs: Keyword arguments to be passed to :attr:`func`.
- .venv/lib/python3.12/site-packages/torch/nn/utils/_expanded_weights/expanded_weights_utils.py:63: # input must be the first argument passed
- .venv/lib/python3.12/site-packages/torch/nn/utils/_expanded_weights/expanded_weights_utils.py:133: # this only passes the other checks if the arg allows smaller batch sizes
- .venv/lib/python3.12/site-packages/torch/nn/attention/bias.py:246: is_causal=True,  # TODO: Flash accepts causal = True and for this particular op it means lower right
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:248: 1. (kv_num_blocks, kv_indices): Used for the forwards pass of attention, as
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:258: 3. [GENERATED] (q_num_blocks, q_indices): Required for the backwards pass,
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:262: the backwards pass. These are autogenerated from 2.
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:941: arguments, depending on whether a mask_mod or score_mod func is passed.
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:1074: # cross attention case: pass both query and key/value NJTs
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:1127: # TODO: support CPU for training and return lse
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:1142: """TODO: Remove once non cuda/cpu devices support is added
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:1279: kernel_options (Optional[Dict[str, Any]]): Options to pass into the Triton kernels.
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:1304: raise NotImplementedError("NYI: query, key, and value must be 4D tensors")
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:1353: pass
- .venv/lib/python3.12/site-packages/torch/nn/attention/flex_attention.py:1423: # We cannot directly pass hop to it. So we wrap it in a dummy function.
- .venv/lib/python3.12/site-packages/torch/nn/attention/__init__.py:21: # TODO: Consider using this for sdpa regardless of subclasses
- .venv/lib/python3.12/site-packages/torch/nn/parallel/__init__.py:27: pass
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:64: However, outside the forward and backward passes, parameters are in
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:92: # TODO (rohan-varma): keep_low_precision_grads: bool = False
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:93: # TODO (rohan-varma): APIs to allow users to run batchnorm and layernorm
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:150: # TODO: Expand to remote RRefs.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:278: "DDP join hook requires passing in a DistributedDataParallel "
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:288: """Shadow the DDP collective communication operations in the forward and backward passes."""
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:294: # forward pass
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:295: # TODO: make DDP uneven inputs context manager support buffer
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:299: # Check if need to sync in the backward pass
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:311: # pass allreduce
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:312: ddp._match_all_reduce_for_bwd_pass()
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:458: and each layer is checkpointed at most once (make sure you are not passing
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:533: both the input data for the forward pass and the actual module
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:694: # TODO: This is a temporary work around to enable DDP + TP.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:805: "Run a dummy forward pass to correctly initialize the modules",
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:888: # params. TODO (rohan-varma): Make this compose with general
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1093: # TODO: when zero_grad(set_to_none=False) or in grad
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1100: # is saved and .grad field is set to None, bypassing
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1160: (5) passing a handle of DDP to SyncBatchNorm Layer
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1201: # need to pass in index to Reducer's autograd hook via python.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1208: # are used in the forward pass in the order they are defined.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1256: # passing a handle to torch.nn.SyncBatchNorm layer
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1257: self._passing_sync_batchnorm_handle(self.module)
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1365: # Bypass ignored parameters since those are not reduced by DDP
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1419: "init_process_group and have not passed "
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1430: forward-backward pass exiting the context.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1442: The forward pass should be included inside the context manager, or
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1499: # before the first forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1522: self.reducer._set_forward_pass_work_handle(
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1543: # Notify joined ranks whether they should sync in backwards pass or not.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1564: # TODO (rohan-varma) test this codepath.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1591: # this forward pass, to ensure we short circuit reduction for any
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1601: # TODO: DDPSink is currently enabled for unused parameter detection and
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1621: # run through the DDPSink backward pass. When not all outputs are
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1625: passthrough_tensor_list = _DDPSink.apply(
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1631: output_placeholders[i] = passthrough_tensor_list[i]
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1638: # At the end of the forward pass, reset the grad buffer and grad views
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1672: # of whether backwards pass synchronization will run this iteration or not.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1696: # the models have buffers that should be synchronized in the forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1721: # pass.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1722: def _match_all_reduce_for_bwd_pass(self):
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1757: and "shadow" the forward and backward passes by inserting collective
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1779: ``SyncBatchNorm`` in the model's forward pass, then the flag
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1858: DDP join hook enables training on uneven inputs by mirroring communications in forward and backward passes.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1900: The hook takes in an optional state and is passed in a Dict[str, Tensor]
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1906: state (Any): Optional state that is passed to the hook.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1912: hook will run _before_ the forward pass, and
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1914: hook will run _after_ the forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1919: the backward pass. This will ensure all buffers are
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1920: synchronized by the end of the backward pass. If this
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1921: setting is used, it is recommended to pass
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1923: which will trigger the hook after the forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1926: buffers in the forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:2110: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:2205: def _passing_sync_batchnorm_handle(self, module):
- .venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:2360: "You passed find_unused_parameters=true to DistributedDataParallel, "
- .venv/lib/python3.12/site-packages/torch/nn/parallel/comm.py:137: # TODO: When `len(inputs) == 1` and all inputs are on `destination`, just
- .venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:59: pass, the module is replicated on each device, and each replica handles a
- .venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:60: portion of the input. During the backwards pass, gradients from each replica
- .venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:70: Arbitrary positional and keyword inputs are allowed to be passed into
- .venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:74: and can be corrupted if written to in the model's forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:133: # TODO: update notes/cuda.rst when this class handles 8+ GPUs well
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:228: Keyword arguments won't be passed to the hooks and only to the ``forward``.
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:265: Keyword arguments won't be passed to the hooks and only to the ``forward``.
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:394: Although the recipe for forward pass needs to be defined within
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:399: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1360: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1362: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1390: receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1474: receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1630: passed to the hooks and only to the ``forward``. The hook can modify the
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1638: If ``with_kwargs`` is true, the forward pre-hook will be passed the
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1656: with_kwargs (bool): If true, the ``hook`` will be passed the kwargs
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1693: passed to the hooks and only to the ``forward``. The hook can modify the
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1700: If ``with_kwargs`` is ``True``, the forward hook will be passed the
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1717: with_kwargs (bool): If ``True``, the ``hook`` will be passed the
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2042: # argument. Only pass it in if it is accepted otherwise assume
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2163: # The user can pass an optional arbitrary mappable object to `state_dict`, in which case `state_dict` returns
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2164: # back that same object. But if they pass nothing, an `OrderedDict` is created and returned.
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2184: # TODO: Change `*args` to `*` and remove the corresponding warning in docs when BC allows.
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2230: # TODO: Remove `args` and the parsing logic when BC allows.
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2286: with_module (bool, optional): Whether or not to pass the module
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2444: "pass `assign=True` to assign items in the state dictionary to their "
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2654: This is typically passed to an optimizer.
- .venv/lib/python3.12/site-packages/torch/nn/modules/module.py:3029: This Module's `__call__` method is compiled and all arguments are passed as-is
- .venv/lib/python3.12/site-packages/torch/nn/modules/container.py:62: Modules will be added to it in the order they are passed in the
- .venv/lib/python3.12/site-packages/torch/nn/modules/container.py:64: passed in. The ``forward()`` method of ``Sequential`` accepts any
- .venv/lib/python3.12/site-packages/torch/nn/modules/container.py:83: # input will first be passed to `Conv2d(1,20,5)`. The output of
- .venv/lib/python3.12/site-packages/torch/nn/modules/adaptive.py:72: Labels passed as inputs to this module should be sorted according to
- .venv/lib/python3.12/site-packages/torch/nn/modules/adaptive.py:290: parameter passed to ``AdaptiveLogSoftmaxWithLoss`` constructor.
- .venv/lib/python3.12/site-packages/torch/nn/modules/padding.py:12: # TODO: grad_output size asserts in THNN
- .venv/lib/python3.12/site-packages/torch/nn/modules/padding.py:38: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/nn/modules/_functions.py:166: # backward pass for gradient calculation
- .venv/lib/python3.12/site-packages/torch/nn/modules/_functions.py:187: # This process got an empty input tensor in the forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134: # TODO: fail fast on quantization API usage error, then remove this class
- .venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:302: # TODO: PartialLinear - maybe in sparse?
- .venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: why_not_sparsity_fast_path = f"{enc_layer}.self_attn was passed bias=False"
- .venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:707: - at most one of ``src_mask`` and ``src_key_padding_mask`` is passed
- .venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:709: nor ``src_key_padding_mask`` is passed
- .venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:715: passed for ``src`` to represent padding more efficiently than using a padding
- .venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:838: why_not_sparsity_fast_path = "self_attn was passed bias=False"
- .venv/lib/python3.12/site-packages/torch/nn/modules/upsampling.py:43: `scale_factor` must be passed in and `scale_factor` is used to compute the
- .venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:89: # TODO: check in THNN (if inplace == True, then assert value <= threshold)
- .venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:1010: - if a `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_ is passed, neither ``key_padding_mask``
- .venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:1011: nor ``attn_mask`` is passed
- .venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:1015: `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_ can be passed for
- .venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:928: Useful to pass to :meth:`nn.MaxUnpool2d`. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1014: Useful to pass to :meth:`nn.MaxUnpool3d`. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1294: Useful to pass to nn.MaxUnpool1d. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1328: Useful to pass to nn.MaxUnpool2d. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1371: Useful to pass to nn.MaxUnpool3d. Default: ``False``
- .venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1528: Optionally, you can give non-equal weighting on the classes by passing
- .venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:2030: # TODO: L1HingeEmbeddingCriterion
- .venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:2031: # TODO: MSECriterion weight
- .venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:2032: # TODO: ClassSimplexCriterion
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:351: # Returns True if the weight tensors have changed since the last forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:645: pass
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:652: pass
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:674: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:710: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:793: # TODO: remove the overriding implementations for LSTM and GRU when TorchScript
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1032: pass
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1040: pass
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1071: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1119: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1321: pass
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1328: pass
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1349: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1386: # the user believes he/she is passing in.
- .venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1599: ret = input  # TODO: remove when jit supports exception flow
- .venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:231: First dimension is being passed to Embedding as ``num_embeddings``, second as ``embedding_dim``.
- .venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:285: pass. This scales the output of the Embedding before performing a weighted
- .venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:286: reduction as specified by ``mode``. If :attr:`per_sample_weights` is passed, the
- .venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:435: """Forward pass of EmbeddingBag.
- .venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:509: First dimension is being passed to EmbeddingBag as 'num_embeddings', second as 'embedding_dim'.
- .venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:400: Runs forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:414: # TODO: ContrastiveNorm2d
- .venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:415: # TODO: DivisiveNorm2d
- .venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:416: # TODO: SubtractiveNorm2d
- .venv/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:38: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:41: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:117: "You can silence this warning by not passing in num_features, "
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:137: # `_reversed_padding_repeated_twice` is the padding to be passed to
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:327: padding_mode: str = "zeros",  # TODO: refine this type
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:506: padding_mode: str = "zeros",  # TODO: refine this type
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1135: Performs the forward pass.
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1356: # TODO: Deprecate and remove the following alias `_ConvTransposeMixin`.
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1381: # TODO: Conv2dLocal
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1382: # TODO: Conv2dMap
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1383: # TODO: ConvTranspose2dMap
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1448: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1561: padding_mode: str = "zeros",  # TODO: refine this type
- .venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:100: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:171: # TODO: if statement only here to tell the jit to skip emitting this when it is None
- .venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:190: passed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are
- .venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:283: At train time in the forward pass, the variance is calculated via the biased estimator,
- .venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:393: to 1 and the elements of :math:`\beta` are set to 0. At train time in the forward pass, the
- .venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:503: to 1 and the elements of :math:`\beta` are set to 0. At train time in the forward pass, the
- .venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:761: passed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are
- .venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:231: forward pass when doing parameter shape inference.
- .venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:233: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:254: using :class:`torch.nn.parameter.ParameterMode.Infer`, runs a forward pass
- .venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:257: The module is set into evaluation mode before running the forward pass in order
- .venv/lib/python3.12/site-packages/torch/nn/modules/lazy.py:275: "Run a dummy forward pass to correctly initialize the modules"
- .venv/lib/python3.12/site-packages/torch/nn/backends/thnn.py:6: pass
- .venv/lib/python3.12/site-packages/torch/mtia/__init__.py:118: pass
- .venv/lib/python3.12/site-packages/torch/mtia/__init__.py:142: # TODO: Update _accelerator_hooks_device_count to abstract a MTIA device count API
- .venv/lib/python3.12/site-packages/torch/_library/autograd.py:105: # The dispatcher passes any keyword-only-args as kwargs and the
- .venv/lib/python3.12/site-packages/torch/_library/autograd.py:138: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_library/autograd.py:161: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_library/infer_schema.py:63: # TODO: Once our minimum version is py3.10+ pass `eval_str=True` to
- .venv/lib/python3.12/site-packages/torch/_library/triton.py:30: behavior of the triton kernel when passed a tensor subclass or under
- .venv/lib/python3.12/site-packages/torch/_library/triton.py:112: # Optimization: we're passing regular Tensors into the triton kernel, so
- .venv/lib/python3.12/site-packages/torch/_library/triton.py:125: # We require that the user pass us a function that is make_fx traceable,
- .venv/lib/python3.12/site-packages/torch/_library/fake_class_registry.py:54: pass
- .venv/lib/python3.12/site-packages/torch/_library/fake_class_registry.py:100: # TODO: add this check at compile time for __obj_flatten__.
- .venv/lib/python3.12/site-packages/torch/_library/fake_class_registry.py:242: to the class TensorQueue and the flattend result is passed into FakeTensorQueue's
- .venv/lib/python3.12/site-packages/torch/_library/utils.py:65: f"The qualname passed to the torch.library APIs must consist "
- .venv/lib/python3.12/site-packages/torch/_library/utils.py:139: TODO: torchgen/model.py's FunctionSchema.parse is the source of truth for this,
- .venv/lib/python3.12/site-packages/torch/_library/utils.py:284: # TODO: need to double check the semantics of the "types" argument to torch_dispatch.
- .venv/lib/python3.12/site-packages/torch/_library/utils.py:294: # TODO: check that I got these args correct (in C++, we pass in "0000"??)
- .venv/lib/python3.12/site-packages/torch/_library/custom_ops.py:92: We recommend not passing in a ``schema`` arg and instead letting us infer
- .venv/lib/python3.12/site-packages/torch/_library/custom_ops.py:513: 1. You must tell us how to compute gradients during the backward pass
- .venv/lib/python3.12/site-packages/torch/_library/custom_ops.py:518: ``backward_fn`` runs during the backward pass. It accepts ``(ctx, *grads)``:
- .venv/lib/python3.12/site-packages/torch/_library/custom_ops.py:525: ``setup_context(ctx, inputs, output)`` runs during the forward pass.
- .venv/lib/python3.12/site-packages/torch/_library/custom_ops.py:611: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_library/custom_ops.py:707: ``info.randomness`` is the ``randomness`` option that was passed to :func:`torch.vmap`.
- .venv/lib/python3.12/site-packages/torch/_library/custom_ops.py:849: # TODO: Merge this function with torch.amp.autocast_mode._cast, and refactor it
- .venv/lib/python3.12/site-packages/torch/futures/__init__.py:17: pass
- .venv/lib/python3.12/site-packages/torch/futures/__init__.py:88: completed, or inside a callback function passed to :meth:`then`. In
- .venv/lib/python3.12/site-packages/torch/futures/__init__.py:295: Returns a :class:`~torch.futures.Future` object to a list of the passed
- .venv/lib/python3.12/site-packages/torch/quantization/__init__.py:41: # 'fuse_fx', 'quantize_fx',  # TODO: add quantize_dynamic_fx
- .venv/lib/python3.12/site-packages/torch/quantization/fuse_modules.py:10: # TODO: These functions are not used outside the `fuse_modules.py`
- .venv/lib/python3.12/site-packages/torch/_strobelight/compile_time_profiler.py:138: # we have pass different functionProfilerClass for meta-internal fbcode targets.
- .venv/lib/python3.12/site-packages/torch/_strobelight/compile_time_profiler.py:173: # TODO use threadlevel meta data to tags to record phases.
- .venv/lib/python3.12/site-packages/torch/autograd/functional.py:568: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/autograd/functional.py:674: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/autograd/functional.py:716: # passing the standard basis for R^4 as the grad_output.
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:41: All tensors intended to be used in the backward pass should be saved
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:195: pass
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:357: pass
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:367: pass
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:371: pass
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:381: retrieved during the backward pass. Tensors should not be stored
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:388: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:394: r"""There are two ways to define the forward pass of an autograd.Function.
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:407: raise NotImplementedError("setup_context is not implemented.")
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:417: as many outputs as the :func:`forward` returned (None will be passed in
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:423: requiring grads, you can just pass None as a gradient for that input.
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:426: pass. It also has an attribute :attr:`ctx.needs_input_grad` as a tuple
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:432: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:447: as many inputs as the :func:`forward` got (None will be passed in
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:453: differentiable with respect to that output, you can just pass None as a
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:456: You can use the :attr:`ctx` object to pass any value from the forward to this
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:459: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:470: op in the forward pass, call the class method ``apply``. Do not call
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:539: while ``info.randomness`` is the randomness option passed to
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:555: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:838: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/function.py:844: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:61: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:66: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:71: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:76: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:80: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:125: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:161: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:230: Note that if you pass in tensor constructed under torch.inference_mode(),
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:256: content as the original tensor (passed as input to the corresponding
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:323: """Context manager under which tensors saved by the forward pass will be stored on cpu, then retrieved for backward.
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:326: results saved in the graph during the forward pass will be moved to CPU,
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:327: then copied back to the original device when needed for the backward pass.
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:404: ...         pass
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:459: called with those gradients. ``None`` will be passed for tensors that did not
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:616: pass
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:829: return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
- .venv/lib/python3.12/site-packages/torch/autograd/graph.py:831: )  # Calls into the C++ engine to run the backward pass
- .venv/lib/python3.12/site-packages/torch/autograd/anomaly_mode.py:16: - Running the forward pass with detection enabled will allow the backward
- .venv/lib/python3.12/site-packages/torch/autograd/anomaly_mode.py:17: pass to print the traceback of the forward operation that created the failing
- .venv/lib/python3.12/site-packages/torch/autograd/anomaly_mode.py:36: ...         # Error during the backward pass
- .venv/lib/python3.12/site-packages/torch/autograd/anomaly_mode.py:118: pass
- .venv/lib/python3.12/site-packages/torch/autograd/__init__.py:127: # TODO: We can remove this conditional once we uniformly use
- .venv/lib/python3.12/site-packages/torch/autograd/__init__.py:278: :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.
- .venv/lib/python3.12/site-packages/torch/autograd/__init__.py:325: "arguments both passed to `backward()`. Please only "
- .venv/lib/python3.12/site-packages/torch/autograd/__init__.py:387: :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.
- .venv/lib/python3.12/site-packages/torch/autograd/__init__.py:433: "Expected allow_unused to be True or not passed when materialize_grads=True, "
- .venv/lib/python3.12/site-packages/torch/autograd/__init__.py:499: result = _vmap_internals._vmap(vjp, 0, 0, allow_none_pass_through=True)(
- .venv/lib/python3.12/site-packages/torch/autograd/__init__.py:532: # inputs argument is not passed. It is not supported for torch.autograd.grad().
- .venv/lib/python3.12/site-packages/torch/autograd/forward_ad.py:226: pass
- .venv/lib/python3.12/site-packages/torch/autograd/grad_mode.py:323: pass
- .venv/lib/python3.12/site-packages/torch/autograd/grad_mode.py:363: pass
- .venv/lib/python3.12/site-packages/torch/autograd/grad_mode.py:380: for the backwards pass can result in incorrect gradients, and autograd uses the version counter to detect
- .venv/lib/python3.12/site-packages/torch/autograd/grad_mode.py:401: pass
- .venv/lib/python3.12/site-packages/torch/autograd/profiler_legacy.py:31: category=None,  # TODO: change to `FutureWarning`
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:153: raise NotImplementedError(x.layout)
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:237: raise NotImplementedError(f"_iter_tensor for {x_tensor.layout} input")
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:432: # Prepares the inputs to be passed into the function while including the new
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:504: using the passed ones (many torch.nn tests do this).
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:552: # Do the full reduction in one pass
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:693: # TODO: handle the other Ju
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:694: pass
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:935: # TODO: To cover more problematic cases, replace stride = 0 check with
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:946: ".contiguous on the input before passing it to gradcheck."
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1024: operation' in the backward pass. Please see
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1269: # case 2 (Efficient Zero Tensor Tangent since we don't make a dual object and pass a regular tensor)
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1727: # TODO: properly handle case when u is tuple instead of only taking first element
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1736: test might've passed in slow_mode!
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1786: # Slow gradcheck would've passed!
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1909: # TODO: replicate https://github.com/pytorch/pytorch/pull/77743 for fast gradcheck as well
- .venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:2201: # TODO: do we want to test this too?
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:63: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:66: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:230: # TODO Consider changing _function_events into data structure with size cap
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:769: # TODO: TorchScript ignores standard type annotation here
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:789: # TODO: Too slow with __torch_function__ handling enabled
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:810: A future that completes with the value of the passed in future when
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:819: # passed in future completes, so don't run end callbacks on exit.
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:826: # TODO: Too slow with __torch_function__ handling enabled
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:867: Please note that this order may not match the order in which those arguments were passed
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:940: Please note that this order may not match the order in which those arguments were passed
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:955: correlating each backward-pass op with the corresponding forward-pass op can be difficult.
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:959: During the forward pass, each function range is decorated with ``seq=<N>``.  ``seq`` is a running
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:964: During the backward pass, the top-level range wrapping each C++ backward Function's
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:969: Any functions executed during the backward pass are also decorated with ``seq=<N>``.  During
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:973: objects with the earlier forward pass.
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:977: If, on the other hand, a backward pass with ``create_graph=True`` is underway (in other words,
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:980: to be executed later during double-backward, just as the original functions in the forward pass did.
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:985: numbers, which can be compared to `seq` numbers from the backward pass.
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:991: backward Function ``apply()`` ranges with `seq` numbers in forward-pass ranges is
- .venv/lib/python3.12/site-packages/torch/autograd/profiler.py:1092: )  # TODO: find in sqlite database
- .venv/lib/python3.12/site-packages/torch/autograd/_functions/tensor.py:32: # TODO: deprecate this
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:30: # TODO - We have to register many more distributions here, and also higher level
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:171: # TODO: Investigate if there is be a better way to wrap the tuple in a
- .venv/lib/python3.12/site-packages/torch/_decomp/__init__.py:35: # TODO: relax key type here; torch registrations should be possible to; but
- .venv/lib/python3.12/site-packages/torch/_decomp/__init__.py:230: operator overloads and overload packets passed as input.  Overload
- .venv/lib/python3.12/site-packages/torch/_decomp/__init__.py:262: operators associated with a list of operator overloads and overload packets passed
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:30: # TODO: The mechanism we are using to register decompositions doesn't
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:100: # TODO: do these also belong here?
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:77: # TODO: pretty sure this is not quite right
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:372: # TODO: None of these loss castings are quite correct, see
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:766: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1454: # TODO: this doesn't appear to have enough precision in bfloat16
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1634: # TODO: Take a closer look at the type promotion semantics
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1845: # TODO: this decomposition is NOT here to stay. We would much prefer replacing native_batch_norm
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1993: Return a reserve tensor for batch norm, used only by cudnn to pass forward state to the
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1994: backward pass. This is needed for `_batch_norm_with_update` and `_batch_norm_no_update`,
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:2115: assert not layout or layout == torch.strided, "TODO"
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:2116: assert not pin_memory, "TODO"
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:2147: # This is only valid if we're running the graph without autograd, such as if the backward pass has been traced.
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:2473: # TODO make minimum accept scalars
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:3105: pass  # don't update cur_hidden
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:4198: # The bounds are passed as twice their value so that half-integer values
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:4417: @out_wrapper(pass_is_out=True)
- .venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:4478: # TODO: handling of slice
- .venv/lib/python3.12/site-packages/torch/backends/xeon/run_cpu.py:321: pass
- .venv/lib/python3.12/site-packages/torch/backends/xeon/run_cpu.py:359: pass
- .venv/lib/python3.12/site-packages/torch/backends/xeon/run_cpu.py:443: 'please specify the "--ncores-per-instance" if you have pass the --core-list params'
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:14: # TODO: Add type annotations
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:15: # TODO: Check tensor types for ops
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:151: # TODO: Expose these directly to Python to avoid maintaining this list.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:207: # TODO: Make this an enum.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:240: # TODO: Support non-equal-rank broadcast where semantics match.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:271: # TODO: Handle dilation
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:500: # TODO: Improve this error message, possibly after converting
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:781: # generate code to mutate it before passing to NNAPI.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1197: # TODO: Possibly check scale and zero point.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1199: # TODO: Possibly support variable-sized inputs.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1500: # TODO: Support this by adding trailing 1 dims.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1508: pass
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1532: # TODO: Validate ceil_mode semantics.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1791: # TODO: Transform at load time to share weights with CPU model.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1831: # TODO: Support automatic reshape
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1870: # TODO: Transform at load time to share weights with CPU model.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:2093: # TODO: Transform at load time to share weights with CPU model.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:75: # TODO: See if it's possible to use those directly.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:87: # TODO: See if it's possible to use those directly.
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:89: pass
- .venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:142: # TODO: Maybe make these names match the original.
- .venv/lib/python3.12/site-packages/torch/backends/opt_einsum/__init__.py:55: "torch.einsum will bypass path calculation and simply contract from left to right. "
- .venv/lib/python3.12/site-packages/torch/backends/opt_einsum/__init__.py:61: "torch.einsum will bypass path calculation and simply contract from left to right. "
- .venv/lib/python3.12/site-packages/torch/backends/cuda/__init__.py:205: pass
- .venv/lib/python3.12/site-packages/torch/backends/cuda/__init__.py:260: pass
- .venv/lib/python3.12/site-packages/torch/backends/cuda/__init__.py:311: pass
- .venv/lib/python3.12/site-packages/torch/backends/cuda/__init__.py:532: pass
- .venv/lib/python3.12/site-packages/torch/distributed/argparse_util.py:70: .. note:: it is redundant to pass ``default=True`` for arguments
- .venv/lib/python3.12/site-packages/torch/distributed/run.py:44: ``torchrun`` will pass the ``--local-rank=<rank>`` argument to your script.
- .venv/lib/python3.12/site-packages/torch/distributed/run.py:245: passed as ``--rdzv-endpoint`` to ``torchrun``)
- .venv/lib/python3.12/site-packages/torch/distributed/run.py:287: this module, no need for you to pass ``RANK`` manually.  To initialize a process group in your
- .venv/lib/python3.12/site-packages/torch/distributed/run.py:363: pass
- .venv/lib/python3.12/site-packages/torch/distributed/run.py:756: # If ``args`` not passed, defaults to ``sys.argv[:1]``
- .venv/lib/python3.12/site-packages/torch/distributed/run.py:783: # This env variable will be passed down to the subprocesses
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:235: # TODO refactor into enum/strenum
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:478: Process Group, and tag. Instances of this class will be passed to
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:619: TODO don't expose the map, expose fine grained ops
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:629: TODO don't expose the map, expose fine grained ops
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:639: TODO don't expose the map, expose fine grained ops
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:649: TODO don't expose the map, expose fine grained ops
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:659: TODO don't expose group_count, use something else instead
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:745: # TODO moco benchmark on CPU initializes pgnccl backend today, triggered this assert in CI before it was
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:800: # Provide backward compatibility to cases where `group` passed in is
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:870: # Provide backward compatibility to cases where `group` passed in is
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1066: # TODO: remove this once the ecosystem moves away from it.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1105: # TODO(yifu): remove this function once ranks + tag is not a supported
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1405: pass
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1466: "LOCAL_RANK is not in the environment. Consider passing fallback_rank to allow `get_node_local_rank` to work, "
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1610: specifying what additional options need to be passed in during
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1634: for collectives with CUDA tensors. A custom backend can be specified by passing in
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1835: pass
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1933: # Set the default backend when single backend is passed in.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1947: # when multi backend is passed in
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1986: # TODO: remove this check after lazy initialization is supported
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2027: # TODO: once UCC plugin is fully deprecated, remove
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2076: # TODO: This defaults to the old behavior for PythonProcessGroups which overwrites the
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2228: pass
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2318: pass
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2691: # TODO: We need to also support torch inductor for the time estimator.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2696: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2742: passed to ``dist.P2POp``, all ranks of the ``group`` must participate in
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2946: For example, if the rank 0 node passes [torch.rand(4), torch.rand(2)] and the
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2947: rank 1 node passes [torch.rand(2), torch.rand(2), torch.rand(2)], the allreduce
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:2950: function should take extra care to ensure that each node passes in tensors whose
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3098: Similar to :func:`all_gather`, but Python objects can be passed in.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3111: calling rank is not part of the group, the passed in ``object_list`` will
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3199: Similar to :func:`gather`, but Python objects can be passed in. Note that the
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3328: Similar to :func:`send`, but Python objects can be passed in.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3537: Similar to :func:`broadcast`, but Python objects can be passed in.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3667: Similar to :func:`scatter`, but Python objects can be passed in. On
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4057: rank 0 passes:
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4062: rank 1 passes:
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4073: For example, if the rank 0 node passes [torch.rand(4), torch.rand(2)] and the
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4074: rank 1 node passes [torch.rand(2), torch.rand(2), torch.rand(2)], the
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4078: to ensure that each node passes in tensors whose shapes match across nodes.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4830: It is able to report ranks that did not pass this barrier within the provided timeout.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4886: # TODO(whc) apparently some existing test case for monitored_barrier passes in a timeout in float format?
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4953: # TODO: why is group count incremented only in the else path?
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5003: pg_options (ProcessGroupOptions, optional): Additional options need to be passed in during
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5071: # which may just pass their timeout value (or None)
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5223: ``Backend.GLOO``). If ``None`` is passed in, the backend
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5227: specifying what additional options need to be passed in during
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5302: # which may just pass their timeout value (or None)
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5412: If ``group_size`` is passed in, the world size must be divisible by ``group_size``.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5413: If no ``group_size`` is passed in, it believe that you are creating a group based
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5418: pass in ``group_size`` correctly.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5437: ``Backend.GLOO``). If ``None`` is passed in, the backend
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5441: specifying what additional options need to be passed in during
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5470: "please pass in 'group_size' correctly."
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5486: # TODO: Use itertools.batched(get_process_group_ranks(group=group), group_size) instead when Python 3.12 is supported.
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5531: ``Backend.GLOO``). If ``None`` is passed in, the backend
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5535: specifying what additional options need to be passed in during
- .venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:5628: # TODO copy settings and timeout from default PG
- .venv/lib/python3.12/site-packages/torch/distributed/_checkpointable.py:19: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_checkpointable.py:27: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_checkpointable.py:35: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:71: pass
- .venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:95: pg (Optional[dist.ProcessGroup]): process group passed to tensor functions
- .venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:96: device (Optional[torch.device]): device passed to tensor functions
- .venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:109: # TODO: should we use pytree?
- .venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:345: passed in copy_state_dict (but the value references are the same).
- .venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:616: # TODO: currently, we cannot handle strided sharding if the dp dimension is not even. For example,
- .venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:723: # TODO: We should consolidate the code here as some not all modules can depend on
- .venv/lib/python3.12/site-packages/torch/distributed/_composable_state.py:8: pass
- .venv/lib/python3.12/site-packages/torch/distributed/rendezvous.py:180: and port are correctly passed via ``hostname`` and ``port``. All
- .venv/lib/python3.12/site-packages/torch/distributed/__init__.py:157: pass
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:29: pass
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:32: pass
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:113: # TODO: we need to handle reconstructing a non-contiguous flattened dim.
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:196: # TODO: If we decide to restrict flatten initialization once, we should remove
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:244: The device_mesh passed in needs to be sliced out from the root mesh
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:327: # TODO: this doesn't allow non-contiguous slicing with flatten dim yet. next_idx
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:456: # TODO(yeounoh) implement DeviceMesh backend and register XLA backend.
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:477: # TODO: think about how to allow pg options to be passed to world group
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:608: # TODO: Add two tests to cover internal tests scenarios and re-enable reuse subgroup if exists.
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:741: # TODO: compiler + device_mesh slicing.
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:815: number of groups passed. For example, if a single process group is passed in,
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:816: the resulted DeviceMesh is a 1D mesh. If a list of 2 process groups is passed in,
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:819: If more than one group is passed, then the ``mesh`` and ``mesh_dim_names`` arguments
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:820: are required. The order of the process groups passed in determines the topology of
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:822: The `mesh` tensor passed in must have the same number of dimensions as the number of process
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:823: groups passed in, and the order of the dimensions in the `mesh` tensor must match the order
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:824: in the process groups passed in.
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:870: raise ValueError("Expects at least one ProcessGroup to be passed")
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:872: raise ValueError("Must pass mesh if passing multiple ProcessGroups")
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:875: "Must pass mesh_dim_names if passing multiple ProcessGroups"
- .venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:1039: "If you maintained a 'torch.device' object, it's recommended to pass in 'device.type'.",
- .venv/lib/python3.12/site-packages/torch/distributed/collective_utils.py:39: Or if a function is passed, execute it in rank 0 and broadcast result to all other ranks.
- .venv/lib/python3.12/site-packages/torch/distributed/collective_utils.py:67: # if no pg is passed then execute if rank is 0
- .venv/lib/python3.12/site-packages/torch/distributed/collective_utils.py:180: # Note: use Any for typing for now so users can pass in
- .venv/lib/python3.12/site-packages/torch/distributed/collective_utils.py:195: If check does not pass, all ranks will fail with exception.
- .venv/lib/python3.12/site-packages/torch/distributed/collective_utils.py:202: or covariance (considered same) but users can pass in custom checker
- .venv/lib/python3.12/site-packages/torch/distributed/launch.py:106: The launcher will passes the ``--local-rank=<rank>`` argument to your script.
- .venv/lib/python3.12/site-packages/torch/distributed/launch.py:145: 5. Another way to pass ``local_rank`` to the subprocesses via environment variable
- .venv/lib/python3.12/site-packages/torch/distributed/launch.py:149: will not pass ``--local-rank`` when you specify this flag.
- .venv/lib/python3.12/site-packages/torch/distributed/launch.py:175: help="Use environment variable to pass "
- .venv/lib/python3.12/site-packages/torch/distributed/launch.py:177: "If set to True, the script will not pass "
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:172: :: N.B. If you pass a PG or a 1D list to perform a MPMD collective, the compiler won't be able to recover
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:199: :: N.B. If you pass a PG or a 1D list to perform a MPMD collective, the compiler won't be able to recover
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:209: # TODO this should be done inside AsyncCollectiveTensor to delay the wait() call
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:242: # TODO this should be done inside AsyncCollectiveTensor to delay the wait() call
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:271: :: N.B. If you pass a PG or a 1D list to perform a MPMD collective, the compiler won't be able to recover
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:349: :: N.B. If you pass a PG or a 1D list to perform a MPMD collective, the compiler won't be able to recover
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:377: :: N.B. If you pass a PG or a 1D list to perform a MPMD collective, the compiler won't be able to recover
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:409: :: N.B. If you pass a PG or a 1D list to perform a MPMD collective, the compiler won't be able to recover
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:470: :: N.B. If you pass a PG or a 1D list to perform a MPMD collective, the compiler won't be able to recover
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:702: # NotImplementedError: argument of type: <class 'typing._GenericAlias'>
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:731: "Only 1D mesh is supported, pass in (DeviceMesh, int) together if mesh > 1D"
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:733: # TODO: it should run collective in the whole mesh instead of dim 0
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:772: "Only 1D mesh is supported, pass in (DeviceMesh, int) together if mesh > 1D"
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:937: # but then you pass those sizes explicitly, and the all to all itself
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:1020: # TODO(yifu): remove these in functional collective beta release
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:1062: group=None,  # TODO add a type,
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:1080: op: str = "sum",  # TODO type is actually c10d ReduceOp. is this ok?
- .venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:1081: group=None,  # TODO add a type
- .venv/lib/python3.12/site-packages/torch/distributed/_tensor/__init__.py:15: # TODO: _shards_wrapper/_utils here mainly for checkpoint BC, remove them
- .venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:6: TODO: throw warnings when this module imported
- .venv/lib/python3.12/site-packages/torch/distributed/_tensor/placement_types.py:6: TODO: throw warnings when this module imported
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/planner.py:259: This will be aggregated and passed to create_global_plan.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/planner.py:260: Planner specific data can be passed through SavePlan::planner_data.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/planner.py:428: raise NotImplementedError("LoadPlanner.resolve_bytes is not implemented")
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/logger.py:31: # checkpoint ID can be passed in through the serializer or through the checkpoint id directly
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_loader.py:40: # TODO: test returning `load` here instead.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_checkpointer.py:66: """Calls :py:meth: `torch.distributed.state_dict_saver.save`. Utilizing values passed during initialization."""
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_checkpointer.py:81: Calls :py:meth: `torch.distributed.state_dict_saver._async_save`. Utilizing values passed during initialization.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_checkpointer.py:94: """Calls :py:meth: `torch.distributed.state_dict_loader.load`. Utilizing values passed during initialization."""
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_extension.py:205: the registry, and the version is passed to the class's
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_extension.py:208: method raises an exception, that will pass through to the
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:48: # TODO: Update docstrings for optimizer.py
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:198: # TODO: The ReadItems will have a displaced MetadataIndex, fix it.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:199: # TODO: we should change _create_sharded_read_items to have more ergonomic API
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:229: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:281: Verify the model and options passed by the user and generates _StateDictInfo.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:292: "Optimizers are not passed in but optim_only is set to True."
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:513: # TODO: make this faster.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:691: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:926: # TODO: check if value is the same if exists.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1381: # TODO: correct the state_dict function signature.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1382: # TODO: this API is not yet fully tested. Make it private
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1436: # TODO: correct the load_state_dict function signature.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1437: # TODO: this API is not yet fully tested. Make it private
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_async_process_executor.py:103: # Close the parent's copy of child end after we pass it into the child,
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:16: TODO:
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:26: # TODO: Update Docstring for nested_dict.py
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:105: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:109: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:113: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:125: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:307: # TODO replace with headq
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:384: # TODO: Using the OverlappingCpuLoader with multiple threads creates significant
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:467: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:628: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:830: # TODO sort by offset and cache the reading
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:263: fqn (str) : The state_dict FQN to pass to ``ReadItem``.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:404: # We need to pass shape and stride explicitly, since DTensor might be
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:462: # TODO: let state_dict_util._iterate_state_dict() to support in place option
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/storage.py:37: 0) (all ranks) set checkpoint_id if users pass a valid checkpoint_id.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/storage.py:159: is passed to the ``SavePlanner`` during save calls. Returns None by default.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/storage.py:161: TODO: provide an example
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/storage.py:176: 0) (all ranks) set checkpoint_id if users pass a valid checkpoint_id.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:68: # TODO: Update docstrings for default_planner.py
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:377: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/format_utils.py:84: # TODO: read on each host, instead of only the coordinator
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/format_utils.py:152: Extension of DefaultLoadPlanner, which creates a new Metadata object based on the passed in state dict,
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_saver.py:62: # TODO: test returning `save` here instead.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_saver.py:105: group needs to be passed in.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/hf_storage.py:216: # TODO: make this more efficient by doing offset reads instead of a
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_sharded_tensor_utils.py:19: # TODO: We need to refactor this code.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/staging.py:34: forward/backward pass), and it is the respondsibility of the user to call `AsyncStager.synchronize_staging`
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/staging.py:55: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/utils.py:432: # TODO: integrate with distributed logging flag
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_state_dict_stager.py:65: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_dedup_tensors.py:33: # TODO add docstring for dedup_tensors
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_fsspec_filesystem.py:54: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_fsspec_filesystem.py:100: # TODO: add the dcp.async_save mixin
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:25: # TODO: update docstring for traverse.py
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:176: # TODO: add local offset for _local_tensor in print_nested.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:196: be change by passing a different ``print_fun` callable.
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/metadata.py:122: pass
- .venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_storage_utils.py:38: pass
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:25: # TODO(@fegin): this variable is originally create for testing, we
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:99: # user can pass in device_id as a Union[int, torch.device] even for
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:196: # TODO(fegin): using kwargs is not a good idea if we would like to make
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:225: # TODO: This is a temporary work around to enable DDP + TP.
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:230: # replicate is going to pass is NOT the original module.
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/checkpoint_activation.py:74: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/checkpoint_activation.py:119: pass
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/checkpoint_activation.py:126: # clear this even in the case of exception in fwd pass.
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:26: # TODO: we can add additional info to RegistryItem to share across APIs. E.g.,
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:31: pass
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:106: # If the user passes a sequence of modules, then we assume that
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:108: # (i.e. those without a parent) among the passed-in modules.
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:224: # TODO: verify that installed distributed paradigms are compatible with
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:232: {},  # TODO(@yhcharles): this is a temporary fix, need a better way
- .venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/fully_shard.py:1: # TODO: For backward compatibility, we are importing the public objects
- .venv/lib/python3.12/site-packages/torch/distributed/_symmetric_memory/__init__.py:525: # passed to shard_consumer are contiguous.
- .venv/lib/python3.12/site-packages/torch/distributed/_symmetric_memory/__init__.py:1350: When a list of `torch.dtype`s is passed through the dispatcher as
- .venv/lib/python3.12/site-packages/torch/distributed/_symmetric_memory/__init__.py:1595: TODO(yifu): the SM-based copy can be avoided with a list-based reduction
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/api.py:169: Hook a module with output resharding in the forward pass according
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/api.py:192: Hook a module with local shards collection in the forward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/__init__.py:17: as well as the parameter itself. This is typically passed to a
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:55: 2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\ s
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:82: # TODO: implement state_dict
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:83: raise NotImplementedError("ShardedOptimizer state_dict not implemented yet!")
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:92: # TODO: implement load_state_dict
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:93: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:99: # TODO: implement add_param_group
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:100: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/__init__.py:469: passed to ``__torch_function__`` dispatch API
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:451: # TODO make it as a view of out tensor
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:518: it is the user's responsibility to explicitly pass in a new process_group that
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:521: # TODO: make this a __torch_function__ op once ShardedTensor becomes a
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:578: it is the user's responsibility to explicitly pass in a new process_group that
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:742: # It is compatible with the current use case since, conventionally we don't pass None as global size
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:919: # TODO: figure out what the API should behave when some rank have no shard
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:1148: raise NotImplementedError("Only ChunkShardingSpec supported for reshard.")
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:1150: raise NotImplementedError("Only single local shard supported for reshard.")
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:1184: raise NotImplementedError("Only single local shard is supported.")
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/utils.py:251: # pass all validations, extend shards metadata
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/_ops/init.py:62: described in `Delving deep into rectifiers: Surpassing human-level
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/_ops/init.py:75: forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/_ops/init.py:76: backwards pass.
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/_ops/tensor_ops.py:31: # TODO: set grad with a ShardedTensor that consists of all local grads
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/_internals.py:98: # if shard is all zeros, we should consider as pass
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/_internals.py:100: # strictly limited all offsets to be 0 to pass
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/_internals.py:165: # TODO: Can we improve this error message to point out the gaps?
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/api.py:182: # TODO: figure out a generic and efficient way to scatter the shards for EnumerableShardingSpec
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/api.py:183: raise NotImplementedError("EnumerableShardingSpec.shard not implemented yet!")
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec.py:67: # TODO: support named dimension
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec.py:69: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/_common.py:26: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding_bag.py:408: # TODO: Make the result a PartialTensor and move the logic below there.
- .venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding.py:288: # TODO: Make the result a PartialTensor.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:38: # TODO: Add any other composable APIs that are mutually exclusive.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:45: # TODO (awgu): We may be able to remove this function if we retired the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:78: This constructs the "wrap" function to pass to :func:`_post_order_apply`
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:178: passing in the kwargs given to the root.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:253: "The lambda_fn passed to CustomPolicy should return "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:329: A policy that wraps ``module`` if any policy in the passed in iterable of
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:422: Configuration settings that will be passed to all ``wrap``
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:440: The class that this function wraps the passed in ``nn.Module`` with is the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:441: passed in ``wrapper_cls`` argument into ``enable_wrap``. Both
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:444: ``enable_wrap`` and ``wrap``, the argument passed into ``wrap`` will be
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:518: # wrapper_cls is a function as opposed to a class type, just bypass above check.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:519: pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:573: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/wrap.py:579: "Expected to pass in wrapper_cls arg into _ConfigAutoWrap."
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:57: forward or backward pass. The fully sharded module should be passed to the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:64: - The fully sharded module is exactly the module passed to the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:76: # special cases such as for high CPU overhead or for intentionally bypassing
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:103: # TODO: Define this for now to avoid circular imports. See if we can remove.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:394: which case only the tensor data needs to be passed to the constructor.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:472: setting passed to the FSDP constructor.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:474: precision setting passed to the FSDP constructor.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1226: # D2H transfer during the backward pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1295: pass  # no-op
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1480: # tracked by autograd in the backward pass's recomputed forward.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1607: # TODO (awgu): Gradient accumulation outside `no_sync()`
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1648: # TODO (rohan-varma): test for full precision with keep_low_precision_grads
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1657: # TODO (awgu): We should replace these conditional checks to encode
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1825: # TODO: Change `_unpadded_unsharded_size` if we change the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2104: variables to be passable to an optimizer.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2341: # TODO: If we want to handle shared parameters, we need to re-generate
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2352: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2677: # NOTE: These are hacks to bypass `nn.Module.__setattr__` checks.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2682: # This bypasses any overrides in case `module` is an instance of an
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2689: # This bypasses any overrides in case `module` is an instance of an
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2752: # message is passed in)
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_dynamo_utils.py:12: saving the ``use_orig_params`` setting passed to the FSDP constructor.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_dynamo_utils.py:35: this by capturing the module code more 'functionally' and passing parameters in as inputs each time.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_trace_utils.py:20: However, the user may want to pass a different value such as the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_trace_utils.py:60: This represents the execution order information from the forward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_trace_utils.py:187: passed to ``create_proxy``.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_trace_utils.py:189: function/method/module. This is passed to ``create_proxy``.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_trace_utils.py:191: method/module. This is passed to ``create_proxy``.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_trace_utils.py:193: module. This is passed to ``create_proxy``
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_trace_utils.py:195: created in ``create_proxy``. This is passed to
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_trace_utils.py:198: the Python type that the output of the node has. This is passed
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_trace_utils.py:202: is passed to ``create_proxy``.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:201: * FSDP does not support running the forward pass of a submodule
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:204: is not an FSDP instance, so its forward pass will not all-gather
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:234: ``ShardingStrategy.HYBRID_SHARD``, users can pass in a tuple of
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:258: whether the passed-in ``module`` should have FSDP applied if
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:283: communication and computation overlap in the backward pass. See
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:338: then the user may pass ``torch.cuda.current_device`` to this.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:348: the next forward-pass all-gather before the current forward
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:390: process_group. When device_mesh is passed, FSDP will use the underlying process
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:393: ``ShardingStrategy.HYBRID_SHARD``, users can pass in a 2D DeviceMesh instead
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:394: of a tuple of process groups. For 2D FSDP + TP, users are required to pass in
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:833: """Run the forward pass for the wrapped module, inserting FSDP-specific pre- and post-forward sharding logic."""
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:877: .. note:: This can *not* be used within a forward or backward pass. Nor
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:925: supported when passing ``use_orig_params=True`` to the FSDP
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1033: forward-backward pass after exiting the context. This should only be
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1402: were passed into the optimizer ``optim``.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1406: Input passed into the optimizer ``optim`` representing either a
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1410: is no need to pass it in anymore. (Default: ``None``)
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1525: Input passed into the optimizer representing either a
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1529: is no need to pass it in anymore. (Default: ``None``)
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1644: Input passed into the optimizer representing either a
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1648: is no need to pass it in anymore. (Default: ``None``)
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1779: # Because not all model parameters may be passed as the optimizer
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1862: were passed into the optimizer ``optim``.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1953: were passed into the optimizer ``optim``.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:1998: FSDP communication hook should be registered before running an initial forward pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_wrap_utils.py:43: # TODO: We may relax this no-nested-wrapping constraint to support manual
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:142: # TODO: need to check if this is always correct for composable FSDP.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:209: # passed in to unshard context, but nonzero ranks reshard early, causing this flat_param
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:435: # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:445: pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:492: # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:612: continue  # TODO: Improve unittesting for state_dict finetuning
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:787: # If device_mesh is passed in when initializing FSDP, we automatically turn the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:81: # TODO (awgu): We can broadcast the metadata of rank 0's `all_handles`
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:215: # TODO (awgu): Since every module has at most one handle in the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:219: # TODO(voz): Don't graph break on this - dynamo hates the n1 != n2
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:245: # TODO(voz): Don't graph break on this - dynamo hates the i1 != i2
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_debug_utils.py:102: model (torch.nn.Module): Root module (which may or may not be passed to
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:84: # TODO: figure out the case for the composable APIs.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:99: # TODO: figure out the case for the composable APIs.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:134: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:141: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:145: # TODO: Rank 0 can broadcast the `FlatParameter` to allow all ranks to
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:147: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/api.py:62: since the unsharded parameters are not freed after the forward pass, saving the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/api.py:76: enabling communication and computation overlap in the backward pass at the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/api.py:133: ``buffer_dtype`` in the first forward pass and keeps them in that
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/api.py:138: gradients to full precision after the backward pass in preparation
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/api.py:178: .. note:: By default, if the user passes a model with any ``_BatchNorm``
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/api.py:190: ``param_dtype`` at the beginning of the model's forward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/api.py:337: pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:894: # passed to the optimizer
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:905: # This parameter was not passed to the optimizer
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:966: model (nn.Module): Model whose parameters are passed into the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:969: Iterable[nn.Parameter]]]): Input passed into the optimizer
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:978: # Assume the standard case of passing `model.parameters()` to the optimizer
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1433: # TODO: This solution is not general and only apply to PTD TP solution.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1733: # TODO: it is unclear if we need to do the same check with
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1877: all the groups. This API also allows user to pass ``optim_input`` for the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1899: were passed into the optimizer ``optim``.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:2060: # If device_mesh is passed in when initializing FSDP, we automatically turn the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:67: # TODO (awgu): Refactor this later
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:99: "Cannot pass both process_group and device_mesh at the "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:100: "same time. Please just pass only one of them."
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:106: # passed in, there is no way to ensure all wrapped FSDP instances use the same
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:170: # Assuming that user passed in as intra node group and inter node group
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:175: "Expected process_group to be passed in as either None or "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:282: "Cannot pass both ignored_modules and ignored_states at the "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:283: "same time. Please just pass ignored_states."
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:286: passed_as_ignored_states = ignored_states is not None
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:287: if passed_as_ignored_states:
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:310: # TODO: FSDP's contract for buffers is not well-defined. They are
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:319: ignored_states: list[Any], passed_as_ignored_states: bool
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:328: if passed_as_ignored_states:
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:512: # TODO: we need to add additional check once we support FSDP + PiPPy.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:668: ``_ignored_modules`` represents the argument passed by the user to FSDP.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:681: # TODO: We may relax this by taking the FSDP instance's wrapped
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:701: "Trying to ignore the top-level module passed into the FSDP "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:806: "please pass in device_id argument."
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:836: "before FSDP initialization or pass in the explicit device "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:857: # TODO: We need to establish a contract for FSDP and buffers. For now, we
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:1032: "The passed-in `module` is on CPU and will thus have FSDP's sharding "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:1034: "recommend passing in the `device_id` argument for FSDP to move "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:1075: # TODO: See how to deprecate!
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:1129: "or move the module to GPU before passing it to FSDP."
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:1152: pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:116: pass. The laziness is needed to ensure that the parameter device/dtype and
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:260: # Stream for overlapping gradient reduction with the backward pass gradient
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:319: # But maybe we need to? TODO(voz): Look into this
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:384: # their gradients. They must be re-registered every forward pass in case
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:388: # set the grad to None in the backward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:457: output (Any): Forward pass output; pre-backward hooks are registered on
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:593: # TODO: Do not use the side stream for tensor copies for now; investigate
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:797: # TODO: Post-backward prefetching does not support the multiple handles
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:838: # the second backward pass computation precedes ahead of the first backward
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:839: # pass reduction, which is possible since the reduction is issued in a
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:974: # TODO: Investigate why `NO_SHARD` breaks correctness when using
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:976: # TODO (rohan-varma): When CPU offload and optimizer overlap,
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1007: # TODO (rohan-varma): For CPU offload, this unfortunately
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1086: This runs at the end of the entire backward pass and should only be called
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1097: # TODO (rohan-varma): this also waits for the overlapped optimizer step to finish
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1132: forward pass, meaning that its pre-backward hook runs (unsharding the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1134: not jused in the loss computation corresponding to this backward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1140: # TODO: This already-resharded check is brittle:
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1374: forward pass outputs ``outputs``, which were computed using the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1382: Forward pass outputs with pre-backward hooks registered to tensors that
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1519: backward pass. This should be called from the root FSDP instance at the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:101: pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:109: # TODO: Move all the attributes to this class to enable typing for
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:190: # TODO: This is a temporary hack for differentiate between code paths.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:233: # TODO: Explicitly replacing the checkpoint wrapper prefix is not ideal as
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:332: # TODO: Remove this hack once DMP + FSDP is not supported.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:415: # TODO: Remove this hack once DMP + FSDP is not supported.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:444: # Print the error on rank 0 in case this is called in the backward pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:489: # TODO: We need to run this mixed precision ignored module in fp32,
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:542: # TODO(voz): Extend a dynamo util to answer the above, unify the codepaths here.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param_group.py:528: target_fsdp_param_group: "FSDPParamGroup", pass_type: str
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param_group.py:530: if pass_type == "backward":
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param_group.py:532: elif pass_type == "forward":
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param_group.py:535: raise ValueError(f"Unknown pass type: {pass_type}")
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param_group.py:538: record_function(f"FSDP::{pass_type}_prefetch for {target_fqn}"),
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param_group.py:747: # TODO: Find a way to print the offending FSDP2 module.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_collectives.py:228: # Intentionally try to run a fast-path that bypasses abstractions for the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_collectives.py:243: # 1st pass: for foreach-copy parameters, get inputs and metadata for the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_collectives.py:258: # 2nd pass: use foreach copy to compute the remaining all-gather inputs
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fully_shard.py:151: is typically required immediately when the backward pass begins.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fully_shard.py:334: passed-in module.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fully_shard.py:376: passed-in module.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fully_shard.py:408: passed-in module.
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fully_shard.py:599: # TODO: Remove this padding logic once DTensor pads the local tensor:
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:34: - Original parameter: parameter passed to :class:`FSDPParam`, i.e. the one
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:38: - All-gather inputs: the ``torch.Tensor`` or ``Tensor`` s passed to all-gather,
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:109: A: Yes it would. As an optimization, we have an Inductor post-grad FX pass to remove those resize_ and copy_ ops
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:112: TODO:
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:124: (1) Better safety, we don't need to worry about the graph passes in inductor/partitioning handling input mutations
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:183: # User-defined metadata passed from pre to post-all-gather
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:250: # TODO: Remove this padding logic once DTensor pads the local tensor:
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:270: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:281: # TODO: Replace the sharded DTensor parameter construction logic with
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:283: # TODO: Simplify the following sharded parameter padding logic after
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:304: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:358: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:520: # resize_ and copy_ ops in a compiler graph pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:546: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:620: # TODO: Prefer this DTensor to be read-only and generalize the
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:630: # Access `_unsharded_param` to bypass the sharded state check since we
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:662: the resize_ and copy_ ops in a compiler graph pass to recover performance.)
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:692: # Old signature only passes mesh; keep for BC for now
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:749: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py:878: # NOTE: These bypass `nn.Module.__setattr__` checks, which incur non-trivial
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_init.py:39: "If passing reshard_after_forward as an int, it should be a "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_common.py:21: pass
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_state.py:324: f"modules passed to fully_shard did not run forward before backward, "
- .venv/lib/python3.12/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_state.py:326: "will not run for these modules. We recommend passing only modules "
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/fsdp2_mem_tracker.py:41: TEMP (str): Memory usage of temporary tensors during the backward pass including gradients of activations.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/fsdp2_mem_tracker.py:68: Enumerates the states of FSDP modules during the forward and backward passes.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/fsdp2_mem_tracker.py:227: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/fsdp2_mem_tracker.py:364: # TODO(@sanketpurandare): This will need to be modified after this PR (https://github.com/pytorch/pytorch/pull/127786)
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/memory_tracker.py:230: """Prefix operator name with current module and 'forward', and insert 'fw_start' marker at forward pass start."""
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/memory_tracker.py:243: """Insert the marker 'fw_bw_boundary' at the boundary of forward and backward pass."""
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/sac_ilp.py:156: # [Constraint] Express total activation memory in the backward pass
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/fake_collectives.py:283: # TODO(@sanketpurandare) - Confirm size computation
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/fake_collectives.py:288: # TODO(@sanketpurandare) - Confirm size computation
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/fake_collectives.py:297: # TODO(@sanketpurandare) - Confirm size computation
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:162: args (Tuple): The arguments to pass to the function.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:163: kwargs (Dict[str, Any]): The keyword arguments to pass to the function.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:218: # TODO: also check metadata change on inputs
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:250: args: The arguments to pass to the function.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:251: kwargs: The keyword arguments to pass to the function.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:268: NotImplementedError,
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:271: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:284: args: The arguments to pass to the function.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:285: kwargs: The keyword arguments to pass to the function.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:449: # TODO: @sanketpurandare: Flatten tensors by desugaring the tensor subclasses
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:450: # TODO: @sanketpurandare: Add logic for incorporating communication time
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:475: NotImplementedError: If the estimate mode type is not supported.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/runtime_estimator.py:482: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/sac_estimator.py:609: # TODO: Write a better explanation why this needs to be done
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/sac_estimator.py:931: NotImplementedError: If the estimate mode type is not supported.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/sac_estimator.py:938: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mod_tracker.py:41: # Access anything during the forward pass
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mod_tracker.py:88: A boolean marking if this is currently running during the backward pass or not
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mod_tracker.py:106: Registers user-specified hooks to be called before/after the forward/backward pass for each
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mod_tracker.py:109: pre_fw_hook (Callable, optional): A hook to be called before the forward pass for the
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mod_tracker.py:112: post_fw_hook (Callable, optional): A hook to be called after the forward pass for the
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mod_tracker.py:124: If the module is not alive during the backward pass, the pre_bw_hook and post_bw_hook will
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:56: - ACT: Tensors produced during the forward pass and recomputation in activation checkpointing.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:57: - TMP: Temporary memory used during the backward pass, including gradients of activations.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:75: - PRE_FW: The module is about to run the forward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:76: - POST_FW: The module has finished running the forward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:77: - PEAK_FW: The module has reached the peak memory usage during the forward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:78: - PRE_BW: The module is about to run the backward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:79: - PRE_FW_AC: The module is about to run the forward pass with activation checkpointing.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:80: - POST_FW_AC: The module has finished running the forward pass with activation checkpointing.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:81: - POST_BW: The module has finished running the backward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:82: - PEAK_BW: The module has reached the peak memory usage during the backward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:364: - The ``MemTracker`` does not track memory for tensors that bypass the ``TorchDispatchMode`` ex. under ``no_dispatch``.
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:369: - During AC in the backward pass there might be misattribution between activation and temp memory, but the peak memory
- .venv/lib/python3.12/site-packages/torch/distributed/_tools/mem_tracker.py:670: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_rprop.py:18: # we explicitly allow the distributed optimizer pass gradients to
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_rprop.py:67: "the gradients passed in does not equal to the size of the parameters!"
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_sgd.py:18: # we explicitly allow the distributed optimizer pass gradients to
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_sgd.py:63: # TODO: Once step_param interface is robust, refactor step to call
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_sgd.py:121: "the gradients passed in does not equal to the size of the parameters!"
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adadelta.py:18: # we explicitly allow the distributed optimizer pass gradients to
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adadelta.py:70: "the gradients passed in does not equal to the size of the parameters!"
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:27: # in ScriptModule or pass it to a ScriptFunction
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:31: # TODO (wanchaol): remove this once we added TorchScript
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:36: pass
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:62: # TODO (wanchaol): remove/merge this with ScriptLocalOptimizer once
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:114: # TODO: improve error propagation
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:143: to the latest forward pass executed on a given worker. Also, there is no
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:158: args: arguments to pass to the optimizer constructor on each worker.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:159: kwargs: arguments to pass to the optimizer constructor on each worker.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:169: >>>   # Forward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:174: >>>   # Backward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:39: Non-tensor values are passed as-is in the result.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:120: "ZeRO join hook requires passing in a ZeroRedundancyOptimizer "
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:149: giving the index of the first element in the passed-in
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:207: this should be set to the value passed into the hook constructor.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:328: If ``False``, :meth:`step` runs disjointly after the backward pass
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:352: passed-in parameters are the same dense type.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:355: If you pass ``overlap_with_ddp=True``, be wary of the following: Given
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:363: second forward pass if ``static_graph=False`` or until the third
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:364: forward pass if ``static_graph=True``. To adjust for this, one option
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:593: to the world size and that it does not contain any parameters not passed into the
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:597: passed into the constructor is valid since some parameters may be
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:603: passed into the :class:`ZeroRedundancyOptimizer` constructor.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:615: "was not passed into the ZeroRedundancyOptimizer "
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:706: # Apply the passed-in partition of the parameter group
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:861: Return ``values.index(min(values))``, except only uses one pass.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1104: .. note:: Any extra parameters are passed to the base optimizer as-is.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1398: The persistent form of ``params`` to be passed into the parent
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1434: "Each parameter group passed-in via `params` must "
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1490: # require passing in the parameters as a list
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1496: # Try to pass `_allow_empty_param_list=True` to avoid erroring
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1535: # bypasses the empty parameter list check
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1540: # TODO: Manually add `self.param_groups` if using a functional
- .venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1641: # Translate the passed-in optimizer class to its functional
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adam.py:18: # we explicitly allow the distributed optimizer pass gradients to
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adam.py:143: "the gradients passed in does not equal to the size of the parameters!"
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adagrad.py:18: # we explicitly let the user pass gradients to the `step` function
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adagrad.py:65: # TODO: no union or any types in TorchScript, make step a scalar tensor instead
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adagrad.py:82: "the gradients passed in does not equal to the size of the parameters!"
- .venv/lib/python3.12/site-packages/torch/distributed/optim/apply_optimizer_in_backward.py:35: optimizer_kwargs: (Dict[str, Any]): kwargs to pass to optimizer constructor
- .venv/lib/python3.12/site-packages/torch/distributed/optim/apply_optimizer_in_backward.py:74: # TODO: Remove these attributes once we have a better way of accessing
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adamw.py:18: # we explicitly allow the distributed optimizer pass gradients to
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adamw.py:143: "the gradients passed in does not equal to the size of the parameters!"
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_rmsprop.py:18: # we explicitly allow the distributed optimizer pass gradients to
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_rmsprop.py:76: "the gradients passed in does not equal to the size of the parameters!"
- .venv/lib/python3.12/site-packages/torch/distributed/optim/utils.py:15: # dict to map a user passed in optimizer_class to a functional
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adamax.py:18: # we explicitly allow the distributed optimizer pass gradients to
- .venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adamax.py:77: "the gradients passed in does not equal to the size of the parameters!"
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:26: pass in the FQN of each parameters.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:34: `param_groups` to pass to optimizer if specified.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:39: args: arguments to pass to the optimizer constructor.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:40: kwargs: arguments to pass to the optimizer constructor.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:50: >>> # Forward pass + backward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:58: TODO: Add tutorial for _NamedOptimizer.
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:59: TODO: Add documentation in the docstring for the public attributes
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:89: "Since we pass in param_groups, we will use param_groups to "
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:309: # TODO(chienchin): This API should be FSDP agnostic and should support
- .venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:318: # TODO(chienchin): This API should be FSDP agnostic and should support
- .venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py:54: run_id: The unique run id of the job (if not passed a unique one will be
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_utils.py:50: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_utils.py:186: # TODO: change this function to correctly address this.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_utils.py:187: # TODO: this logic can be applied to contiguous sharding as well
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_utils.py:274: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_utils.py:307: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_shards_wrapper.py:117: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_shards_wrapper.py:168: raise NotImplementedError("No support for view on tensors ndim > 2")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_shards_wrapper.py:209: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_collective_utils.py:68: # TODO: enable async op for shard_dim_alltoall
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_collective_utils.py:101: to preserve the single-device semantic. If passing ``None`` explicitly,
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_collective_utils.py:107: # TODO: Ideally we should use the meta tensor way
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_collective_utils.py:161: to preserve the single-device semantic. If passing ``None`` explicitly,
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_collective_utils.py:167: # TODO: Ideally we should use the meta tensor way
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_collective_utils.py:273: # TODO: see if we need to tweak this or offer a way for user
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_collective_utils.py:334: # TODO: see if we want to support this once there's cross mesh communication
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_tp_conv.py:15: # TODO: whether there requires data exchange is currently determined by padding
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_dispatch.py:242: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_sharding_prop.py:275: # scalar. TODO: figure out a better way to handle this
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_sharding_prop.py:450: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_sharding_prop.py:486: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:145: "Please pass both shape and stride at the same time.",
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:153: # TODO: support uneven sharding when global shape/stride not passed, by
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:157: # TODO: See if we need to make this run_check logic
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:205: # TODO: return the redistributed local tensor directly without
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:209: # TODO: backward is also differentiable now, add a test
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:294: # TODO: consider all_gather the local tensors for better debugging
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:398: local tensor passed in is correct across ranks (i.e. the tensor is sharded for
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:687: the single-device semantic. If passing ``None`` explicitly, :meth:`distribute_tensor` simply uses
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:756: # TODO(xilun): address sharding order
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_api.py:781: # detach the local tensor passed to DTensor since after the construction
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_random.py:43: # TODO: Logs way too much
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_random.py:65: ensure on their own that the value passed in is the desired ``seed`` for ranks
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_random.py:150: pass
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_random.py:153: pass
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_op_schema.py:223: TODO: make this a frozen dataclass
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_op_schema.py:257: # TODO: see if we should merge this with args_spec
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/placement_types.py:421: TODO: we should remove _StridedShard placement once we can unify it with Shard
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/placement_types.py:430: # TODO: this is to avoid extra all-gather in dtensor op dispatch
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/placement_types.py:704: # TODO: if the reduce_op is min/max, etc. the _partition_value should be a
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_redistribute.py:171: # TODO: alltoall/permute reshuffling to change device_mesh if they are not the same
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_redistribute.py:172: raise NotImplementedError("Cross device mesh comm not supported yet!")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_redistribute.py:249: # skip the replicate to partial transformation when we are in backward pass
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:208: raise NotImplementedError("return_debug_mask is not supported yet")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:237: raise NotImplementedError("attn_bias is not supported yet")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:273: raise NotImplementedError("attn_bias is not supported yet")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:376: raise NotImplementedError(f"Unkonwn method {method}")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:465: additional args are passed to the op
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:467: additional kwargs are passed to the op
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:477: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:494: # TODO(fegin): figure out why this is a requirement since SDPA does not have
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:575: # TODO: remove the context parallel strategy from the default propagation
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:602: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:647: raise NotImplementedError(f"{op_call=}")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:1087: # TODO(d4l3k); this should be Shard(2), need to fix Linear layer rules
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:1232: raise NotImplementedError("torch dispatch mode is not supported yet.")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:1445: is passed in, the function will raise an error.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_attention.py:1455: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_register_sharding.py:97: # TODO: handle out variant ops
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_func_map.py:36: :meth:`local_map` is an experimental API that allows users to pass :class:`DTensor` s
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_func_map.py:53: Note that the only exception is when no :class:`DTensor` argument is passed
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_func_map.py:64: the required sharding placements before passing its local tensor to ``func``.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_func_map.py:67: will be skipped and the argument will be directly passed to ``func``.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_func_map.py:96: argument passed in.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_func_map.py:153: # TODO: the current code doesn't consider the uneven sharding case
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_tp_transform.py:25: from torch.fx.passes.infra.pass_base import PassBase, PassResult
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_tp_transform.py:26: from torch.fx.passes.shape_prop import _extract_tensor_metadata
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/experimental/_tp_transform.py:71: This pass is responsible for transforming a single-device graph into a tensor parallel
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_pointwise_ops.py:552: # TODO: add all for_each ops
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_matrix_ops.py:163: # TODO: add support for these later
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_matrix_ops.py:252: # TODO: sdpa might be a good candidate for us to explore decomposed sharding propagation
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_matrix_ops.py:447: # TODO(d4l3k); implement a more correct strategy for constant_pad_nd
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_conv_ops.py:108: # TODO: actually the output_mask is not respected here, we should
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_random_ops.py:32: # TODO: figure out how inplace random op should behave when it's partial
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_einsum_strategy.py:162: # TODO: filter out invalid strategies, at this point we generate
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:77: # Use `object.__setattr__` to bypass frozen checks
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:85: raise NotImplementedError(f"Unsupported norm type: {self.norm_type}")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:103: raise NotImplementedError(f"Unsupported norm type:: {self.norm_type}")
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:108: raise NotImplementedError(self.reduce_op)
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:440: # TODO: The diagonal ops can have an improved sharding strategy for
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:454: # TODO: support the full F.interpolate set of options.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:848: # TODO: we can avoid forcing the redistribution once we figure out
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:865: # TODO: we can avoid forcing the redistribution once we figure out
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:882: # TODO: we can avoid forcing the redistribution once we figure out
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:954: # TODO: change the strategy to the following rule.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:960: # TODO: now grad_out spec follows input spec. we may need
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:997: # no need to redistribute since they should be replicated in forward pass
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:1006: # TODO: now d_weight spec follows input spec w/ a reduction.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_math_ops.py:1088: # TODO: topk on sharded dim requries non-trival reduction, address it later
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_view_ops.py:217: # other dims are passed through
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_view_ops.py:518: # TODO(whc) this helper is pretty hard to understand, at least it should be better documented if not refactored
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_view_ops.py:553: # TODO(whc) dim0 can be sharded or not sharded, can't it?
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_view_ops.py:654: # TODO: optimize this. we shouldn't simply blindly replicate
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/utils.py:147: # TODO: maybe we should determine is_shardable based on
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_tensor_ops.py:435: #   TODO: Ideally we'd like to make sure the output is re-sharded afterwards to keep input sharding.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_tensor_ops.py:497: # TODO: see if we can support input sharding pattern
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_tensor_ops.py:738: TODO: exception: when the dtype of second input is "bool", then a torch.nonzero needs to be triggered first.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_tensor_ops.py:877: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_common_rules.py:93: # TODO: further merge the sharding properly (i.e. reshard one input to replicate)
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_common_rules.py:159: # TODO: consider a more advanced heuristic to pick the best sharding
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_common_rules.py:207: # to pass in the shape here. We should remove this once sharding decomp works
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/_utils.py:26: and only 1D :class:`DeviceMesh` is passed in.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/_utils.py:28: # TODO: Will follow up with dynamo POC to make warnings.warn working with dynamo.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/_utils.py:55: 'If you have a 2-D or N-D device_mesh, consider passing in device_mesh["tp"]'
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:42: # TODO: To add perf optimizations to this iterations
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:102: # TODO: To add test cases and ensure that it works for nested modules
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/api.py:33: slice the DeviceMesh to a 1-D sub DeviceMesh first then pass to this API(i.e. ``device_mesh[\"tp\"]``)
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/api.py:51: semantic. If passing ``None`` explicitly, :meth:`parallelize_module` simply uses its local data instead
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/api.py:68: different ParallelStyles together (i.e. ``ColwiseParallel`` and ``RowwiseParallel``) and pass
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:102: # TODO: figure out dynamo support for instance method and switch this to instance method
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:154: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:299: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:333: If the input passed in to this ``nn.Module`` is a :class:`torch.Tensor`, it assumes that the input is already sharded
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:335: passed in to this ``nn.Module`` is already a :class:`DTensor` but is not sharded on the sequence dimension, it would
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:389: # if the passed in input DTensor is not sharded on the sequence dim, we need to redistribute it
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:396: # assume the input passed in already sharded on the sequence dim and create the DTensor
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:519: # TODO: re-enable the check once we fix the compile path
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:669: # TODO: re-enable the check once we fix the compile path
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/fsdp.py:349: # TODO: this is a short term fix and we should make the get_unflat_views
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/debug/_comm_mode.py:110: This function is called before the forward pass of a module. It
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/debug/_comm_mode.py:159: # used to store module's parents to ensure correctness in backward pass/checkpointing
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/debug/_comm_mode.py:177: This function is called when the forward pass of a module is called.
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/debug/_comm_mode.py:185: This function is called when the backward pass of a module is called. It
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/debug/_comm_mode.py:186: updates the current module for backward passes
- .venv/lib/python3.12/site-packages/torch/distributed/tensor/debug/_comm_mode.py:658: # tracks if the operation is part of the backward pass
- .venv/lib/python3.12/site-packages/torch/distributed/nn/functional.py:56: Receivers must pass ``None`.
- .venv/lib/python3.12/site-packages/torch/distributed/nn/jit/templates/remote_module_template.py:61: # TODO: Merge these two templates together in the future once TorchScript syntax is improved.
- .venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:135: It takes care of autograd recording to ensure the backward pass propagates
- .venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:182: args (Sequence, optional): args to be passed to ``module_cls``.
- .venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:183: kwargs (Dict, optional): kwargs to be passed to ``module_cls``.
- .venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:254: # TODO: We need to change this to rpc.remote, and make it async (see the else branch below).
- .venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:512: Moreover, this also provides a workaround for passing script RemoteModule over RPC,
- .venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:604: It takes care of autograd recording to ensure the backward pass propagates
- .venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:633: args (Sequence, optional): args to be passed to ``module_cls``.
- .venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:634: kwargs (Dict, optional): kwargs to be passed to ``module_cls``.
- .venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:743: "send the `module_rref` to the receiver, and create a new instance on the receiver end by passing this `module_rref`."
- .venv/lib/python3.12/site-packages/torch/distributed/autograd/__init__.py:31: Context object to wrap forward and backward passes when using
- .venv/lib/python3.12/site-packages/torch/distributed/autograd/__init__.py:33: statement  is required to uniquely identify a distributed backward pass
- .venv/lib/python3.12/site-packages/torch/distributed/autograd/__init__.py:36: autograd pass.
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/functions.py:20: .. note:: To enable asynchronous execution, applications must pass the
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/__init__.py:116: passed to the RpcAgent constructor. It must be an agent-specific
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/__init__.py:163: "warning pass `backend=%(backend)s` explicitly.",
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/api.py:425: Use this :class:`~torch.distributed.rpc.WorkerInfo` to avoid passing an
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/api.py:482: pass
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/api.py:488: pass
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/api.py:495: pass
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/api.py:500: pass
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:179: # passed all checked, construct reverse mapping and get list of devices handled by this agent
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:300: # TODO: make async?
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:377: # TODO: add try-except and destroy _agent in all processes if any fails.
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/rref_proxy.py:25: # Bypass ScriptModules when checking for async function attribute.
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/rref_proxy.py:26: bypass_type = issubclass(rref_type, torch.jit.ScriptModule) or issubclass(
- .venv/lib/python3.12/site-packages/torch/distributed/rpc/rref_proxy.py:29: if not bypass_type:
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/control_plane.py:41: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/utils/store.py:185: Optionally, passing rank will enable tracing of missing ranks on timeouts.
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/utils/distributed.py:100: # TODO properly map the exceptions in pybind (c10d/init.cpp)
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/utils/distributed.py:157: socket on it. Close the socket before passing the port to the entity
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/utils/data/elastic_distributed_sampler.py:30: process can pass a DistributedSampler instance as a DataLoader sampler,
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/__init__.py:25: pass  # train
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/__init__.py:118: to pass down to the entrypoint mapped by the replica index (local rank).
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/__init__.py:132: To redirect/tee only certain local ranks, pass ``redirects`` as a map with the key as
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:240: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:455: # TODO log_line_prefixes can be expanded too
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:496: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:507: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:553: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:561: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:779: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:799: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:916: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py:341: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:72: The worker function and argument passed to the worker function must be
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:73: python multiprocessing compatible. To pass multiprocessing data structures
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:75: context as the specified ``start_method`` and pass it as a function argument.
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:97: Log prefixes can be customized by passing a `template string
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:60: args: arguments to pass to ``entrypoint``
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:70: local rank by passing a map
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:72: selectively tee for a particular local rank by passing a map,
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:82: # TODO @kiuk - make entrypoint a required field
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:421: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:432: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:459: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:469: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:477: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:486: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:504: # TODO: BC - specific to static rdzv and can be simplified further
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:679: # TODO after stopping workers, wait at least monitor_interval*2 for
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:497: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:502: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:507: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:734: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:938: # check whether we have passed the rendezvous deadline. If yes,
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1430: "You passed 'keep_alive_interval=None' as a rendezvous configuration option"
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1435: "You passed 'keep_alive_max_attempt=None' as a rendezvous configuration option"
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:60: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:66: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:99: use and to pass implementation specific configurations to the rendezvous
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:124: Below are a full list of the parameters that can be passed to etcd
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:167: # TODO: look into using weakref here instead.
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:201: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:216: # TODO: we should probably handle a few additional errors,
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:271: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:274: # TODO: look into using weakref here instead.
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:311: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:743: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:863: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:883: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:924: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:950: # TODO: implement timeout
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:971: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py:89: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_server.py:24: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/api.py:87: # TODO swap to collectives comms API
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_store.py:109: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_store.py:196: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/metrics/__init__.py:77: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/metrics/__init__.py:83: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/metrics/__init__.py:162: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/metrics/__init__.py:168: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py:49: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py:61: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py:124: pass
- .venv/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py:129: pass
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/join.py:29: Training iteration i.e., in one forward pass, backward pass, and optimizer step.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/join.py:36: It is passed an additional ``bool`` argument ``is_last_joiner``, which indicates if the rank is one of the last to join.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/join.py:305: be called at the beginning of the forward pass in
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/join.py:308: Only the first :class:`Joinable` object passed into the context
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/join.py:319: first one passed into the context manager; ``None`` otherwise.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py:47: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py:54: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py:76: # TODO: register_fsdp once FSDP supports communication hook.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py:79: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py:92: pass
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_quantization/quantization.py:93: Quantize the input tensors, choose the precision types, and pass other necessary arguments and then dequantizes the outp
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_comm_hooks/default_hooks.py:26: raise ValueError(f"Expected to pass in an explicit ProcessGroup to {self}.")
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/mixed_precision_hooks.py:58: # forward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/mixed_precision_hooks.py:78: # reset for next backward pass
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:103: be passed to the model.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:600: # TODO: The above procedure does two matmul+allreduce steps per iteration --
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:824: # TODO: The above procedure does two matmul+allreduce steps per iteration --
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:56: optimizer with backward pass, DDP will run the below hook to run optimizer
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:78: # not average. TODO: (rohan-varma) the div factor may be different
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:83: # TODO (rohan-varma): upcast as needed for DDP mixed precision,
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:110: # reset for the next backwards pass
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:14: # Functional optimizers require passing a list of gradients to their `step()`
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:143: hook before the backward pass and optimizer step can actually be
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:166: # This corresponds to the first bucket of the backward pass
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:183: Modify ``hook`` to overlap :class:`ZeroRedundancyOptimizer` optimizer step with :class:`DistributedDataParallel` backwar
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:225: second forward pass if ``static_graph=False`` or until the third
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:226: forward pass if ``static_graph=True``.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:329: # next forward pass
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:345: Modify ``hook`` to overlap :class:`ZeroRedundancyOptimizer` optimizer step with :class:`DistributedDataParallel` backwar
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:387: second forward pass if ``static_graph=False`` or until the third
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:388: forward pass if ``static_graph=True``.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/ddp_zero_hook.py:452: # next forward pass
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/model_averaging/averagers.py:34: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/model_averaging/averagers.py:103: "by DistributedDataParallel in the backward pass. Therefore, only "
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/model_averaging/utils.py:79: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/model_averaging/hierarchical_model_averager.py:116: "by DistributedDataParallel in the backward pass. Therefore, only "
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:218: be passed into the ``torch.utils.checkpoint.checkpoint``
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:222: supported if ``checkpoint_impl`` is passed as ``CheckpointImpl.REENTRANT`.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:227: **checkpoint_fn_kwargs: (Dict[str, Any]): Keyword arguments to pass into `checkpoint_fn`.
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:283: A lambda function which will be passed each child submodule of ``model`` and returns
- .venv/lib/python3.12/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:289: # TODO: Importing inside function to avoid circular import issue between FSDP and
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_schedule_visualizer.py:36: The schedule can be specified as a string which is passed into get_schedule_class() or a _PipelineSchedule instance.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/microbatch.py:47: pass
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/microbatch.py:115: pass
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/microbatch.py:167: # TODO: check type of v. If it's a tensor, use chunk (or debug mask).
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/microbatch.py:299: # TODO: _debug_mask_minibatches
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:23: from torch.fx.passes.split_module import split_module
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:33: # TODO:
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:118: # Collect metadata about tuple output values. TODO: move this to split_module or FX IR
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:122: # In the forward pass, only emit placeholder, module calls, and
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:126: "Found non-getitem call in forward pass. Please report a bug to PiPPy"
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:246: training procedure to take two arguments (x and targets), pass x into the module
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:247: to get the output of the feedforward computation, pass the model output and the
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:265: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:293: #    to how activations propagated in the forward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:532: # TODO: is there a way not to hard wire init?
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:660: # TODO: investigate
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:730: # TODO: what does split do with module invocations? does it move the modules
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:753: # TODO: backport this into split_module
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:810: f" It might happen if module '{param_fqn}' was passed to some 'leaf function'"
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:831: persistent=True,  # TODO: handle non-persistent buffer
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:910: pass
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:973: logger.debug("Pipeline is in training mode, backward pass generated")
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:979: logger.debug("Pipeline is in inference mode, backward pass not generated")
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:1059: # TODO? Not sure yet.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_IR.py:1174: # TODO: make this implementation out-of-place?
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:42: # TODO(whc) rename to _ActType?
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:161: If `error_step_number` is passed in, an additional label will be added to signify which step
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:172: # TODO make a real 'None action' that prints as empty string and make mypy happy
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:276: # Return losses if there is a container passed in
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:306: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:320: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:553: Will go through all the microbatches and perform only the forward pass
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:684: # Return losses if there is a container passed in
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:707: # 2. Forward passes for all microbatches
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:711: # 3. Wait period before backward passes can begin
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:715: # 4. Backward passes for all microbatches
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:867: # Return losses if there is a container passed in
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:885: # 2. Initial forward passes before 1F1B phase
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:912: # 5. Cooldown phase: remaining backward passes
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:920: # Decrement the wait counter only if we still have backward passes to do
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1134: # TODO we can avoid send/recv if the 2 stages are on the same rank.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1282: "Simply stop passing it, and everything should still work fine."
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1385: TODO: Does not use sorted_batch_isend_irecv(). As a result, this schedule does
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1404: # TODO: assumption that stages only communicate from distances of +1/-1 (no skip connections)
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1498: # TODO: We are assuming that stage will always receive from stage-1
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1508: pass
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1528: pass
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1532: # TODO: We are assuming that stage will always receive from stage+1
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1559: # Return losses if there is a container passed in
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1590: # TODO what level of validation should we offer for compute+comms schedule?
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1604: raise NotImplementedError(f"{format=} is not implemented")
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1609: format must be either "compute_only" or "compute_comms".  If compute_only, the lowering passes
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1625: raise NotImplementedError(f"{format=} is not implemented")
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1629: # TODO should there be an option to dump the compute_only schedule from PipelineScheduleRuntime? It's possible
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1656: TODO: Does not use sorted_batch_isend_irecv(). As a result, this schedule does
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1721: # TODO(whc) it's not actually safe to use _batch_p2p here in the uncommon case the model has skip-connections,
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1869: # TODO(whc) what is the best practice for printing a multiline log?
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:1885: # Return losses if there is a container passed in
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2046: # TODO: we don't need to always append, after all 1f1b are finished we can stop appending None
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2163: # fwd_bwd_ops should encompass the remaining forwards
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2165: # cooldown_ops should encompass the remaining backwards
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2167: # total ops encompass both forward and backward ops
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2227: # TODO: we don't support Zero Bubble with torch.compile so we
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2288: # fwd_bwd_ops should encompass the remaining forwards
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2290: # cooldown_ops should encompass the remaining backwards
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2292: # total ops encompass both forward and backward ops
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2613: as a metric for unit tests involving IR optimization passes as reordering and merging of IR can reduce the number
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/schedules.py:2711: # hacky, but do a second pass to replace any 'none' at this timestep with a real action, if it got unblocked
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:34: The output of the model passed to pipelining can be any type, controlled by the user.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:37: (1) the outputs of intermediate stages are passed via Send/Recv ops to subsequent stages. The implicit assumption
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:40: (2) the outputs of the last layer of the model are returned to the user, or, passed to the loss function.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:50: TODO: should we be stricter about asserting that stage modules (intermediate and output) all return only Tensor
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:141: skipped during the module's actual backward pass. The builder must be invoked by stage after stage runs
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:185: # function is passed to pipeline schedule
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:207: Returns true if this stage has a backward pass.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:290: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:293: # TODO: this is needed for backward_maybe_with_nosync
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:307: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:343: use communication ops.  Instead, they should pass tensor data directly via function call.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:368: # We don't need to do a data copy here, since we can directly pass the activation tensor reference from
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:371: # TODO: confirm, do we use this activation as the root of the backward call for the previous stage? does
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:514: # tensors by default. For gradients to pass back to previous stages, we
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:574: Should only be called once per pipeline schedule step, after all backwards passes have completed.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:683: Perform forward pass on the stage with one microbatch.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:688: - `kwargs` can be passed to all stages via respective `step` calls.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:752: Perform backward pass on the module.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:755: If full_backward is True (the default), the full backward pass including weight and input gradients will be run,
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:796: # TODO: We may want to change our semantics so we are allowed to ignore
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:826: # TODO: we dont need to save this, add to dw_runner?
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:875: # TODO: figure out a better way to do this:
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:893: # TODO why is there a separate recv_info for each pipeline chunk?
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:894: # kwen2501: to avoid passing a `fwd_chunk_id` to this function, we
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:903: # TODO- need a mapping of kwarg to position in self.args_recv_info
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:908: # TODO- need a mapping of kwarg to position in self.args_recv_info
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:910: # (a) the user passed an extra arg or missed an arg
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:911: # (b) the user did not pass a kwarg, which has a default value baked into expected_args
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1011: # TODO(whc)
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1069: # In case there is backward pass, set requires_grad for receive buffers
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1192: # TODO: otherwise needs grad accumulation
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1246: stage1 and so forth, in linear order.  To bypass shape inference, pass the `input_args` and `output_args` to each
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1288: "Deprecation warning: passing input_args and performing init-time shape inference is deprecated. "
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1291: "or additionally pass `output_args` to `PipelineStage` to fully override shape inference. "
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1304: "If passing input_args, also pass output_args to override shape inference"
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1337: # and can pass its output shapes in as args instead of using send/recv.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1344: "Shape inference: stage %s skipping recv, because shape info passed in via `args`",
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1401: # 1. Usually: use send/recv communication to pass the output
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1403: #    pass their shape info via return value and function args rather than send/recv.
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1409: # Case (2) above: pass shape info via return value and caller passes it as args to next stage's
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1442: # TODO move self.device to an argument from step API (from its input tensors)?
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1443: assert num_microbatches is not None, "TODO fix num_microbatches"
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1451: # TODO: create args_recv_info lazily? (same needed for PipelineStage)
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/stage.py:1465: # In case there is backward pass, set requires_grad for receive buffers
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_backward.py:238: # TODO: Handle case where intermediate can have multiple outputs
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_backward.py:252: # [NEW!] Able to pass a GradientEdge to autograd.grad as output
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_backward.py:339: pass
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_backward.py:348: # fix -> explicitly pass in the ref to the fn, so there is no gc cycle anymore
- .venv/lib/python3.12/site-packages/torch/distributed/pipelining/_backward.py:392: # TODO: handling requires_grad=False dynamically. Can we analyze this during initial
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:119: "round",  # TODO: model kwargs
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:209: "copy_to",  # TODO: add OpInfo (or implement .to)
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:400: # TODO: make common validations available as utils
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:465: # TODO: add type promotion support
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:774: # TODO: if this is special maybe it should be defined there and imported here?
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1011: # TODO: register this as a real ref/decomposition once TorchInductor supports complex!
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1656: # TODO: skip unnecessary conversion of long to float
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1737: # TODO: consider refactoring this with add impl
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1949: # TODO: implement alternate where
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1964: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2036: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2117: # "device" option could be passed a str instead torch.device
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2144: # TODO: is_pinned is not currently supported in refs or fake_tensor
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2168: # TODO: non_blocking should be handled by `copy_to`
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2200: # TODO - this is true for eager mode currently, but it's wrong behavior for complex norms
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2318: # reduces over all dimensions if dim=() is passed
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2370: # reduces over all dimensions if dim=() is passed
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2392: # reduces over all dimensions if dim=() is passed
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2416: # reduces over all dimensions if dim=() is passed
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2454: # reduces over all dimensions if dim=() is passed
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2503: # reduces over all dimensions if dim=() is passed
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2661: # of incompatible type passed to unsqueeze
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2784: # We'll implement this in a few passes.  First, we will try to infer the
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2822: # passing an unbacked SymInt which we will defer a runtime
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2846: # TODO: fix this to work with meta tensors
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2982: # TODO: make logic consistent with aten contiguous
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3082: # TODO: we could look at directing collapse_view to skip its meta function here (unsafe_collapse_view)
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3335: # TODO: Adding this as a meta function causes functorch tests to fail when compiled with debug mode.
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4587: # TODO: Add sparse support
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4715: # TODO: Turn this into a decomposition (currently fails on reshape meta tests)
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5233: lambda: f"linspace(): inferred dtype {default_complex_dtype} can't be safely cast to passed dtype {dtype}",
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5335: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5351: pass
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5356: pass
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5528: requires_grad: bool = False,  # TODO: unused
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5555: # TODO: Use requires_grad.  All refs taking the requires_grad kwarg must
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5765: # cast value to correct type before passing to `where`
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6171: # TODO: fix inductor rand_like for integer, bool dtypes
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6205: # TODO: add support for functionalization aten.normal_functional
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6242: lambda: "Cannot pass layout, or pin_memory without size",
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6486: # TODO: This must return a sparse tensor if the input is sparse, but refs have
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6508: # TODO: this is inaccurate, we actually test PySequence_Check
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6551: # TODO: this is inaccurate, we actually test PySequence_Check
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6561: # TODO: test this
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6634: # TODO
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6638: # TODO: test for numpy input with PyArray_Check
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6666: # TODO (or not): support names kwarg
- .venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6678: {"device": "cpu"},  # TODO: use torch.get_default_tensor_type
- .venv/lib/python3.12/site-packages/torch/_refs/special/__init__.py:231: # TODO: add docstring
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:104: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:150: lambda: "Cannot set inplace=True and pass out= at the same time",
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:178: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:199: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:239: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:272: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:383: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:405: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:421: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:481: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:590: # TODO: Raise exception instead of converting value.  This is only for
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:615: # TODO: Raise exception instead of converting value.  This is only for
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:678: # TODO: Raise exception instead of converting value.  This is only for
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:726: # TODO: Enable data-dependent checks with debug mode
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:727: # TODO: This check does not work with FakeTensor inputs; See Issue #85834
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:806: # TODO: raise exception instead of converting value
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:862: # TODO: This ref supports int reduction and out kwarg to be compatible with ATen:
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:864: # TODO: Could be rewritten to support complex:
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:928: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:948: # TODO: Raise exception instead of converting value.  This is only for
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:1032: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:1101: # TODO: Raise exception instead of converting value.  This is only for
- .venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:1170: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/compiler/_cache.py:49: pass
- .venv/lib/python3.12/site-packages/torch/compiler/__init__.py:104: with :func:`allow_in_graph` to bypass Dynamo.
- .venv/lib/python3.12/site-packages/torch/compiler/__init__.py:113: - all Tensors used inside of ``fn`` must be passed directly as inputs to ``fn``
- .venv/lib/python3.12/site-packages/torch/compiler/__init__.py:208: Return valid strings that can be passed to `torch.compile(..., backend="name")`.
- .venv/lib/python3.12/site-packages/torch/compiler/__init__.py:437: >>>        pass # ...logic that is not needed in a compiled/traced graph...
- .venv/lib/python3.12/site-packages/torch/compiler/__init__.py:458: >>>        pass # ...logic that is not needed in a TorchDynamo-traced graph...
- .venv/lib/python3.12/site-packages/torch/compiler/__init__.py:476: >>>        pass # ...logic that is not needed in export...
- .venv/lib/python3.12/site-packages/torch/profiler/_utils.py:145: # TODO: find a better way to identify cudaLaunchKernel
- .venv/lib/python3.12/site-packages/torch/profiler/_utils.py:149: # TODO: find a better way to identify CUDA Kernel
- .venv/lib/python3.12/site-packages/torch/profiler/_utils.py:379: # TODO(dberard) - deprecate / remove workaround for CUDA >= 12, when
- .venv/lib/python3.12/site-packages/torch/profiler/_utils.py:385: pass
- .venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:95: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:181: # TODO: We should also check tensor identities
- .venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:216: # TODO: Check if tensor is reused
- .venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:371: "Please enable multi tensor implementation by passing 'foreach=True' into optimizer."
- .venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:418: # TODO: fixme! Due to lifetime issues of the function name, this field might
- .venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:437: # TODO: We should also check if the loader is bottleneck.
- .venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:483: # TODO: We should also check if the optimizer's numerical behavior will change.
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:158: # TODO(robieta): Move away from load bearing names
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:296: # TODO(robieta):
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:570: the leaves of the first pass through the op tree. (As well as any
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:591: pass
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:825: generally on the forward pass of the first step. We know from
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:831: filter the activations in the forward pass of the first step."""
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:852: # Don't include Tensors created in the backward pass, as these are
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:883: First, they are directly used in the forward pass. (At this point we
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:885: pass but we can deduce enough to suffice.) Some mutable state such as
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:886: batch norm moving averages also contribute to the forward pass, but
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:894: # Determine which Tensors might be parameters based on forward pass
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:896: # we know are part of the backward pass but that doesn't guarantee that
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:897: # they are part of the forward pass.
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:906: # Don't check nodes in the backward pass.
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:950: # Stop filling when we reach the backward pass.
- .venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:1055: # TODO: Write a faster serialize (orjson not available in CI)
- .venv/lib/python3.12/site-packages/torch/profiler/itt.py:71: they are passed as arguments to msg.format().
- .venv/lib/python3.12/site-packages/torch/profiler/profiler.py:69: In case when CUDA is enabled but CUPTI is not available, passing
- .venv/lib/python3.12/site-packages/torch/profiler/profiler.py:84: pass
- .venv/lib/python3.12/site-packages/torch/profiler/profiler.py:88: pass
- .venv/lib/python3.12/site-packages/torch/profiler/profiler.py:92: pass
- .venv/lib/python3.12/site-packages/torch/profiler/profiler.py:685: Note: One can also pass any object satisfying the _ITraceObserver interface.
- .venv/lib/python3.12/site-packages/torch/cuda/_utils.py:59: nvcc_options (list, None): Additional options to pass to NVRTC
- .venv/lib/python3.12/site-packages/torch/cuda/_utils.py:117: # TODO: Should we refactor flags into a common place?
- .venv/lib/python3.12/site-packages/torch/cuda/_utils.py:217: args (list): List of arguments to pass to the kernel.
- .venv/lib/python3.12/site-packages/torch/cuda/_utils.py:248: # TODO: Python floats are actually doubles
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:126: This id can optionally be passed to another graph's ``capture_begin``,
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:173: For effective memory sharing, if you pass a ``pool`` used by a previous capture and the previous capture
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:174: used an explicit ``stream`` argument, you should pass the same ``stream`` argument to this capture.
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:232: Each graphed callable's forward pass runs its source callable's
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:235: The graphed callable's forward pass also appends
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:244: If you pass a tuple of several callables, their captures will use the same memory pool.
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:249: See :ref:`Graph memory management<graph-memory-management>` for when passing a tuple of callables
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:250: is appropriate.  If you pass a tuple of callables, their order in the tuple must be the same order
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:253: If a single callable was passed, ``sample_args`` must be a single tuple of argument Tensors.
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:254: If a tuple of callables was passed, ``sample_args`` must be tuple of tuples of argument Tensors.
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:276: In any :class:`~torch.nn.Module` passed to :func:`~make_graphed_callables`, only parameters
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:280: After you pass a :class:`torch.nn.Module` through :func:`~make_graphed_callables`,
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:284: :class:`torch.nn.Module`\s passed to :func:`~torch.cuda.make_graphed_callables` must not have module hooks
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:285: registered on them at the time they are passed. However, registering hooks on modules *after* passing them
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:289: When running a graphed callable, you must pass its arguments in the same order and format
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:317: "Modules must not have hooks registered at the time they are passed. However, registering hooks "
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:318: + "on modules after passing them through make_graphed_callables is allowed."
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:321: "In any :class:`~torch.nn.Module` passed to "
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:333: # passes to forward (ie, its sample_args) AND the module's parameter attributes.
- .venv/lib/python3.12/site-packages/torch/cuda/graphs.py:379: # the safest approach is to capture all passes in the same order they'll run:
- .venv/lib/python3.12/site-packages/torch/cuda/tunable.py:636: pass  # case is supported
- .venv/lib/python3.12/site-packages/torch/cuda/tunable.py:638: pass  # case is supported
- .venv/lib/python3.12/site-packages/torch/cuda/nvtx.py:45: for this range to pass to the corresponding call to rangeEnd().
- .venv/lib/python3.12/site-packages/torch/cuda/nvtx.py:51: Returns: A range handle (uint64_t) that can be passed to range_end().
- .venv/lib/python3.12/site-packages/torch/cuda/nvtx.py:73: to pass to the corresponding call to device_range_end().
- .venv/lib/python3.12/site-packages/torch/cuda/nvtx.py:80: Returns: An opaque heap-allocated handle that should be passed to _device_range_end().
- .venv/lib/python3.12/site-packages/torch/cuda/nvtx.py:116: they are passed as arguments to msg.format().
- .venv/lib/python3.12/site-packages/torch/cuda/_memory_viz.py:108: pass
- .venv/lib/python3.12/site-packages/torch/cuda/__init__.py:100: pass
- .venv/lib/python3.12/site-packages/torch/cuda/__init__.py:114: pass
- .venv/lib/python3.12/site-packages/torch/cuda/__init__.py:343: # TODO(torch_deploy): this accesses linecache, which attempts to read the
- .venv/lib/python3.12/site-packages/torch/cuda/__init__.py:361: pass
- .venv/lib/python3.12/site-packages/torch/cuda/__init__.py:1034: # bypass _device_count_nvml() if rocm (not supported)
- .venv/lib/python3.12/site-packages/torch/cuda/__init__.py:1427: r"""Return the torch.device type object from the passed in device.
- .venv/lib/python3.12/site-packages/torch/cuda/__init__.py:1759: nvcc_options (list, optional): Additional options to pass to NVRTC
- .venv/lib/python3.12/site-packages/torch/cuda/gds.py:81: flags (int): Flags to pass to ``os.open`` when opening the file. ``os.O_DIRECT`` will
- .venv/lib/python3.12/site-packages/torch/cuda/amp/autocast_mode.py:43: # TODO: discuss a unified TorchScript-friendly API for autocast
- .venv/lib/python3.12/site-packages/torch/_custom_op/autograd.py:49: # TODO(#101191): Use the actual C++ autograd not implemented fallback,
- .venv/lib/python3.12/site-packages/torch/_custom_op/impl.py:83: f"is passed to `custom_op`"
- .venv/lib/python3.12/site-packages/torch/_custom_op/impl.py:212: # Bypass torch.ops.* and directly do OperatorHandle::callBoxed.
- .venv/lib/python3.12/site-packages/torch/_custom_op/impl.py:570: f"custom_op(..., manual_schema)(func): When passing in a manual "
- .venv/lib/python3.12/site-packages/torch/_custom_op/impl.py:588: f"custom_op(..., manual_schema)(func): When passing in a manual "
- .venv/lib/python3.12/site-packages/torch/_custom_op/impl.py:617: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_custom_op/impl.py:619: f"(e.g. you passed an empty list of Tensors). If your operator is a "
- .venv/lib/python3.12/site-packages/torch/_custom_op/impl.py:625: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_custom_op/impl.py:632: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_custom_op/impl.py:637: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_subclasses/schema_check_mode.py:82: # TODO: This is only OK if can't have NaN quantized; idk if
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:123: # TODO: no real reason to restrict multiple outputs
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:180: # TODO: file issue
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:221: # TODO: I think this does the wrong thing if r is inp
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:265: # TODO: remove me
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:407: # TODO: consider a memo
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:429: raise NotImplementedError(f"local_scalar_dense/item NYI for {arg.dtype}")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:658: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:795: # TODO: We can make this a little more faithful with best effort
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:959: # TODO: Minor optimization: track if the shapes
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:1001: # TODO: we don't need the compute type
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:1023: # TODO: is_non-overlapping_and_dense (not bound from Python
- .venv/lib/python3.12/site-packages/torch/_subclasses/_fake_tensor_utils.py:53: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_subclasses/_fake_tensor_utils.py:56: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_subclasses/_fake_tensor_utils.py:204: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_subclasses/_fake_tensor_utils.py:207: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_utils.py:249: # TODO: enable_python_dispatcher() here
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_utils.py:259: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:149: # TODO: move "assert_eq(m1.layout, m2.layout)" out of sparse
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:169: # TODO: test if is resizable (no direct query for this atm)
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:170: # TODO: audit AutogradMeta to see if it matches
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:171: # TODO: test forward AD
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:231: of the tensors/storages passed to us, so we can consistently give
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:305: # TODO: TBH, functorch wrapped tensors probably should have
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:353: # TODO: It's pretty suspicious that functional tensors don't have
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:361: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:379: # TODO: Is it important to enable torch.inference_mode before querying
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:425: # TODO: I actually think recursing here is correct, but we have at
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:846: # TODO: how to check _TensorT?
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:886: # TODO: make a dedicated UnknownSource for this?
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:943: # TODO: deduplicate this
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1006: # outer symbolic context (passed in to this function). Inner size / stride
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1155: #     as_strided() call on the fake-ified base, passing symbolic metadata.
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1164: #     with an as_strided() call on the fake base passing symbolic metadata.
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1192: # TODO: Change this logic to use view replay for consistency?
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1261: # These arguments are never passed, we just use them to close
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1343: assert safe_is_leaf(r), "the callback you passed in doesn't detach"
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1396: assert safe_is_leaf(r), "the callback you passed in doesn't detach"
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1402: # TODO: Handle this better in Dynamo?
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1417: # TODO: This doesn't seem right, where's the MKLDNN'ness
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1434: assert safe_is_leaf(r), "the callback you passed in doesn't detach"
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1450: # TODO: why aren't the recursive calls going to
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1501: # TODO: Actually this all probably doesn't
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1509: # TODO: is_leaf/requires_grad?
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1593: # assert to pass, we have to setup the autograd view
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1604: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1714: assert safe_is_leaf(r), "the callback you passed in doesn't detach"
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1804: # TODO: Use a valid grad-specific symbolic context instead of recycling
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1860: # TODO: zero tensors?  We appear to have eliminated them by
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1864: # TODO: This can probably be simplified quite a bit
- .venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:1933: # TODO: return the description for later
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:122: # TODO: right now, _make_wrapper_subclass's dynamic shape interaction is not great.
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:289: # TODO(sparse-team): fixes #133174 but can we do without the relay?
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:580: # TODO: pull these from aot autograd
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:613: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:619: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:623: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:627: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:631: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:635: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:639: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:643: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:674: # is now stateful, it is better to explicitly pass in correct mode
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:67: # TODO: Hack to unblock https://github.com/pytorch/pytorch/pull/108186
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:344: # You're allowed to pass a meta tensor to be turned into a fake
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:399: # TODO: callback might be used in recursive contexts, in
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:648: # TODO: Generalize this as needed, e.g., into a trie of memos, if
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:680: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:706: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:735: # indicates some sort of confusion (e.g., you accidentally passed
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:736: # in a meta tensor when you should have passed in the real tensor).
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:801: def __torch_dispatch__(  # type: ignore[override] # TODO
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1096: pass
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1136: class _DispatchCacheBypassEntry:
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1145: _DispatchCacheEntry = Union[_DispatchCacheValidEntry, _DispatchCacheBypassEntry]
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1150: class _BypassDispatchCache(Exception):
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1167: bypasses: dict[str, int]
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1184: cache_bypasses: dict[str, int] = defaultdict(int)
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1211: # TODO: This is a temporary measure, see
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1410: dict(FakeTensorMode.cache_bypasses),
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1421: cls.cache_bypasses.clear()
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1440: except _BypassDispatchCache as e:
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1451: FakeTensorMode.cache_bypasses[e.reason] += 1
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1470: if isinstance(entry, _DispatchCacheBypassEntry):
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1473: FakeTensorMode.cache_bypasses[entry.reason] += 1
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1491: except _BypassDispatchCache as e:
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1504: FakeTensorMode.cache_bypasses[e.reason] += 1
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1505: set_cache_key(cache, key, _DispatchCacheBypassEntry(e.reason))
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1510: except _BypassDispatchCache as e:
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1513: FakeTensorMode.cache_bypasses[e.reason] += 1
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1514: set_cache_key(cache, key, _DispatchCacheBypassEntry(e.reason))
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1529: Create a cache key given the dispatch args. Raises _BypassDispatchCache
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1592: raise _BypassDispatchCache("data dependent output")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1607: raise _BypassDispatchCache("dynamic output shape")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1610: raise _BypassDispatchCache("dynamic output shape")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1613: raise _BypassDispatchCache("inplace view")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1616: raise _BypassDispatchCache("unsafe view")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1619: raise _BypassDispatchCache("lift")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1622: raise _BypassDispatchCache("inductor::resize_storage_bytes_")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1625: raise _BypassDispatchCache("non-builtin")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1633: raise _BypassDispatchCache("CompositeImplicitAutograd")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1645: convert FakeTensors into metadata. Raises _BypassDispatchCache to signal
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1646: unsupported cases that should bypass caching.
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1658: raise _BypassDispatchCache("not our fake")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1660: raise _BypassDispatchCache("constant attribute")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1662: raise _BypassDispatchCache(f"{arg.layout} tensor")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1666: raise _BypassDispatchCache("non-fake tensor")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1670: raise _BypassDispatchCache("symbolic shape")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1674: raise _BypassDispatchCache("function argument")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1682: # Special case for AOT Dispatcher first pass, where the fake
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1714: raise _BypassDispatchCache("unrepresented symbol in output")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1719: raise _BypassDispatchCache("non-FakeTensor output")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1724: raise _BypassDispatchCache("constant attribute")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1726: # TODO: support caching sparse outputs?
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1728: raise _BypassDispatchCache("sparse output")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1731: raise _BypassDispatchCache("sparse compressed output")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1737: raise _BypassDispatchCache("kwarg aliases output")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1783: # N.B.: Some checks for bypassing the cache would be performed on the
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1802: raise _BypassDispatchCache("data dependent symnode") from None
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1809: raise _BypassDispatchCache("dispatch_key_set mismatch")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1824: _BypassDispatchCache if the output tensor has characteristics that
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1846: raise _BypassDispatchCache(f"unbacked symbol in HOP {func} output")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2263: # Throwing the exception will pass the control to the next __torch_dispatch__.
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2572: # TODO: Is this really needed?
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2593: # TODO: Remove these exclusions, so that we can remove
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2614: # TODO - we should be use the prim aten impl
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2615: # TODO - fix prims complex ops
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2707: # amount of time to catch the NotImplementedError, so we check it here.
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2714: # It's possible that the kernel will return NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2718: except NotImplementedError as not_implemented_error:
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:3015: # TODO: also check metadata change on inputs
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:3174: bypasses = FakeTensorMode.cache_bypasses
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:3175: if bypasses:
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:3176: log.info("  cache_bypasses:")
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:3177: width = max(len(k) for k in bypasses)
- .venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:3178: for k, v in sorted(bypasses.items(), key=lambda i: -i[1]):
- .venv/lib/python3.12/site-packages/torch/_awaits/__init__.py:12: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_analysis.py:28: # TODO(jansel): double check exception handling
- .venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_analysis.py:174: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_analysis.py:176: raise NotImplementedError(f"unhandled {inst.opname}")
- .venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:71: this variable in the FX graph we are assembling to pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:145: # TODO: Maybe complain if this isn't a int/bool/float variable
- .venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:146: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:164: # TODO: API for adding a custom guard
- .venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:204: passed to the user compiler after compilation.
- .venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:218: Print the partially constructed FX graph that would be passed
- .venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:303: # TODO: improve print format, current guard format is extremely
- .venv/lib/python3.12/site-packages/torch/_dynamo/graph_region_tracker.py:9: 4. Supporting deduplication and other graph transformation passes
- .venv/lib/python3.12/site-packages/torch/_dynamo/graph_region_tracker.py:71: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/cache_size.py:77: TODO(janimesh) - Consider adding a map from tuple_of_match_ids to count -
- .venv/lib/python3.12/site-packages/torch/_dynamo/cache_size.py:108: pass  # cannot weakref bool object
- .venv/lib/python3.12/site-packages/torch/_dynamo/test_minifier_common.py:162: # TODO: return a more appropriate data structure here
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:66: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:70: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:82: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:86: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:90: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:94: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:98: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:102: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:175: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:179: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:248: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:252: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:256: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:260: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:264: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:267: # TODO: I'm a little uncertain about what error classification we should have
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:271: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:275: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:280: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:299: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:304: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:309: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:313: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:318: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:323: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:326: class ObservedNotImplementedError(ObservedException):
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:327: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:332: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:343: NotImplementedError: ObservedNotImplementedError,
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:379: #     pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:497: # TODO replace old unimplemented later
- .venv/lib/python3.12/site-packages/torch/_dynamo/types.py:128: # TODO(whc) how do I annotate a _RecordFunction here?
- .venv/lib/python3.12/site-packages/torch/_dynamo/precompile_context.py:111: # TODO: although this covers completely same artifacts, it's possible
- .venv/lib/python3.12/site-packages/torch/_dynamo/precompile_context.py:146: raise NotImplementedError("TODO")
- .venv/lib/python3.12/site-packages/torch/_dynamo/_trace_wrapped_higher_order_op.py:22: tensors as it takes place in AOTAutograd, as the backward pass is guaranteed not to depend on concrete
- .venv/lib/python3.12/site-packages/torch/_dynamo/_trace_wrapped_higher_order_op.py:61: """Custom Op so that we can register a custom lowering for the new_output + scatter in the backwards pass"""
- .venv/lib/python3.12/site-packages/torch/_dynamo/_trace_wrapped_higher_order_op.py:158: # TODO(jansel): need to ensure this does not get DCEed
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:68: from torch.fx.passes.runtime_assert import insert_deferred_runtime_asserts
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:277: # TODO: replace `same` function with the one in testing
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:396: # TODO: maybe should just pass the entire f_code in here?  Not
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:436: # TODO (tmanlaibaatar) Remove this once we always lift params and buffers
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:534: # Use to pass values to backward hooks when using compiled autograd
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:653: # If user did not provide cache hash - then we always bypass cache.
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:734: # TODO(rzou): can delete after we refactor speculate_subgraph to use nested GraphTracer.
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:910: # TODO `nn_modules` has been historically overloaded to store a lot more
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1393: pass1 = PyCodegen(
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1399: self.codegen_suffix(tx, stack_values_flat, pass1)
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1401: # Use `pass1.uses` to selectively cache multi-user variables into a
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1406: for val, count in pass1.uses.items():
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1410: pass2 = PyCodegen(
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1417: self.codegen_suffix(tx, stack_values_flat, pass2)
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1420: if count_calls(self.graph) != 0 or len(pass2.graph_outputs) != 0:
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1422: self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1425: if len(pass2.graph_outputs) != 0:
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1426: output.append(pass2.create_store(graph_output_var))
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1434: self.add_output_instructions(output + pass2.get_instructions())
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1440: # TODO this local restoration should be removed when fully implementing nested graph breaks
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1619: sub_gms = self.dedup_pass()
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1686: # TODO(voz): The way export uses gm, and fake tensors, is not supported with us resetting
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1690: # TODO(voz): Ostensibily, this should be scoped and
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1828: # TODO: Why isn't this stored in meta :think:
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1888: def dedup_pass(self):
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1925: # Miniature DCE pass, but only for obviously trivial operations
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1941: # TODO: We can also technically remove all cases when the input
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1962: # TODO: I don't think it's possible to have a bare int/float here?
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1965: # TODO: This will bail here if you ever end up with a more complicated
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2065: # we support dynamic float arguments is by doing a joint fx pass and
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2072: # away in the joint pass. In principle we shouldn't choke on unused inputs
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2285: # See note [Export inputs must be explicitly passed in]
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2494: # TODO can remove once inline_inbuilt_nn_modules is always True
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2528: # TODO can remove once inline_inbuilt_nn_modules is always True
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2627: # Note [Export inputs must be explicitly passed in]
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2633: # object which only depends on the inputs you explicitly passed to it.
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2665: # For placeholder nodes, `name` is passed as a str to the target,
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2692: # Also see NOTE: [Export inputs must be explicitly passed in]
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:2959: pass_arg_as_tensor=False,
- .venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:3121: # the function passed to it (call this the "body function"), capture it into a
- .venv/lib/python3.12/site-packages/torch/_dynamo/mutation_guard.py:70: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:48: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:52: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:58: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:72: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:76: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:80: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:84: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:88: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:92: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:96: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:100: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:104: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:108: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:112: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:116: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:120: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:124: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:128: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:136: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:140: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:150: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:421: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/device_interface.py:493: raise NotImplementedError(f"No interface for device {device}")
- .venv/lib/python3.12/site-packages/torch/_dynamo/metrics_context.py:59: contextmanager, call the provided 'on_exit' function and pass a dictionary of
- .venv/lib/python3.12/site-packages/torch/_dynamo/graph_deduplication.py:39: This is the main entry point for applying the graph deduplication pass. \
- .venv/lib/python3.12/site-packages/torch/_dynamo/graph_deduplication.py:54: in which order these nodes are passed as inputs. For the outputs, getitem nodes are created \
- .venv/lib/python3.12/site-packages/torch/_dynamo/graph_deduplication.py:179: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/source.py:105: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/source.py:106: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/source.py:218: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/source.py:318: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/source.py:341: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/source.py:410: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/source.py:425: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/source.py:849: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/source.py:1003: # TODO: can probably write a generic "test this on everything in the chain"
- .venv/lib/python3.12/site-packages/torch/_dynamo/pgo.py:56: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/pgo.py:86: # aliases everything by passing a shared job_id for all your invocations.
- .venv/lib/python3.12/site-packages/torch/_dynamo/pgo.py:495: # TODO: I'm not sure if we should just bong the entire pgo
- .venv/lib/python3.12/site-packages/torch/_dynamo/pgo.py:523: # TODO: info versions of these logs that log only once
- .venv/lib/python3.12/site-packages/torch/_dynamo/pgo.py:736: # TODO: I don't really understand why there's a JSON container format
- .venv/lib/python3.12/site-packages/torch/_dynamo/pgo.py:804: # TODO: use a safe tempfile create to eliminate lock
- .venv/lib/python3.12/site-packages/torch/_dynamo/pgo.py:867: # TODO: don't log this multiple times
- .venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py:114: # TODO: https://github.com/pytorch/pytorch/issues/139200
- .venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py:147: # TODO: https://github.com/pytorch/pytorch/issues/139200
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:463: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:474: the innermost function to pass on the optimize, run, disable etc.
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:541: # TODO: a bit awkward to time, this isn't inside of the dynamo compile region
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:690: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1094: # Note: The hooks object could be global instead of passed around, *however* that would make
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1144: # TODO(voz): Consider making "explain" output alongside a run / part of a run
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1148: # TODO(voz): Do we want a decorator for this?
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1184: # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1191: # TODO(voz): Do we want a decorator for this?
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1248: # TODO(zhxchen17) Also preserve all the user constraints here.
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1370: # TODO: option to print ALL of the stack traces at once
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1632: If you are specifying dynamism on keyword args, you will need to pass them in the order that
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1716: # NB: do NOT pass inner_example_inputs here, we are detecting the
- .venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1834: # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
- .venv/lib/python3.12/site-packages/torch/_dynamo/testing.py:130: def requires_bwd_pass(out: Any) -> bool:
- .venv/lib/python3.12/site-packages/torch/_dynamo/testing.py:134: return any(requires_bwd_pass(x) for x in out)
- .venv/lib/python3.12/site-packages/torch/_dynamo/testing.py:139: raise NotImplementedError("Don't know how to reduce", type(out))
- .venv/lib/python3.12/site-packages/torch/_dynamo/testing.py:171: raise NotImplementedError("Don't know how to reduce", type(out))
- .venv/lib/python3.12/site-packages/torch/_dynamo/testing.py:211: # TODO: shouldn't this be f_locals/f_globals from frame?
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:588: # TODO - source debug string is probably wrong here.
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:706: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:736: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1336: # code_parts in a function object which is then passed on to the leaf
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1502: # TODO(anijain2305) - Delete this when DictGuardManager uses tags
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1571: # TODO(anijain2305) - This is currently restricted to nn.Module objects
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1610: # TODO(anijain2305) - Consider this moving this guard to C++
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1628: # TODO(anijain2305) - Consider this moving this guard to C++
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1914: # TODO(voz): Deduplicate w/ AOTAutograd dupe input guards
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2000: pass  # we always guard on this via GlobalStateGuard()
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2003: pass  # we always guard on this via GlobalStateGuard()
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2006: pass  # we always guard on this via GlobalStateGuard()
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2009: pass  # we always guard on this via GlobalStateGuard()
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2238: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2252: # TODO(anijain2305,williamwen42) - Consider moving this to C++.
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2307: # TODO(voz): Either populate a dispatch_key check into the guards, or error on users passing in an unsupported
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2311: # TODO(voz): We are missing storage offset in all our tensor guards?
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2334: # parameters, but later on you pass on same tensor as two
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2480: # There are 2 steps to this pass:
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2488: # NB: the use of 'ast.unparse' while visiting the nodes makes this pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2491: # NB: this pass creates a new variable for each AST node that is repeated
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2500: # Ad-Hoc: AST nodes this pass focuses on.
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2856: # TODO(anijain2305) - Currently this information is stored as an attr on
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2868: # TODO(anijain2305, ydwu4) - Skipping export because of following test
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:2980: # TODO: don't do the string rep, do something more structured here
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3049: # TODO: we could make use of 'DefaultsSource' and offer a .guard.is_defaults() API
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3151: # TODO(anijain2305) - There is a duplicate logic in Dynamo to find
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3188: # TODO: the "guard" here is actually just the top level SHAPE_ENV
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3189: # which is useless.  Get ShapeEnv to pass in more provenance.
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3264: pass  # cannot weakref bool object
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3277: csepass = PyExprCSEPass()
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3279: csepass.count(code_parts)
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3282: return csepass.replace(expr)
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3398: # passed to the leaf guard at construction time. If its a list, we
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3401: # installed as a lambda guard and can encompass a long list of code_parts.
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3527: # On the first pass, go through the cache entries and accumulate the diff
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3537: # On the second pass, set the diff_guard_sources for each cache line to the
- .venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:3609: # TODO(voz): Combine local and global guard builders.
- .venv/lib/python3.12/site-packages/torch/_dynamo/create_parameter_op.py:44: """Create a placeholder to be passed to the above functions"""
- .venv/lib/python3.12/site-packages/torch/_dynamo/create_parameter_op.py:48: # TODO(jansel): alloc followed by free is inefficient, need a way to allocate an unbacked tensor.
- .venv/lib/python3.12/site-packages/torch/_dynamo/config.py:14: import getpass
- .venv/lib/python3.12/site-packages/torch/_dynamo/config.py:44: # turn on/off DCE pass (deprecated: always true)
- .venv/lib/python3.12/site-packages/torch/_dynamo/config.py:146: # TODO(janimesh, voz): Remove both of these flags (or at least guard_nn_modules)
- .venv/lib/python3.12/site-packages/torch/_dynamo/config.py:151: # buffers are passed as params_flat in tracing context by AOT autograd.
- .venv/lib/python3.12/site-packages/torch/_dynamo/config.py:222: # TODO: Detect this situation automatically so the user doesn't need
- .venv/lib/python3.12/site-packages/torch/_dynamo/config.py:344: # and then later pass on the same parameter as two inputs, dynamo will not
- .venv/lib/python3.12/site-packages/torch/_dynamo/config.py:460: tempfile.gettempdir(), getpass.getuser(), "torch_compile_debug"
- .venv/lib/python3.12/site-packages/torch/_dynamo/config.py:614: # Takes the function/module decorated with torch.compile and passes it through a
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:143: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:404: " is not logged to pt2_compile_events. Make sure the event is active and you passed "
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:424: # TODO: should we assert that the keys of metadata are in CompilationMetrics?
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:545: <event_name> should be the name of a timed event span passed to `dynamo_timed`.
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:557: <event_name> should be the name of a timed event span passed to `dynamo_timed`,
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:619: # TODO(masneral): Deprecate this param.
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:732: # TODO: the events that we capture in calculate_time_spent() seem a little
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:932: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1152: # TODO(anijain2305) - Investigate if we can get rid of this function
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1205: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1290: pre_grad_pass_time_us: Optional[int] = None
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1291: post_grad_pass_time_us: Optional[int] = None
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1292: joint_graph_pass_time_us: Optional[int] = None
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1366: # TODO: The following are legacy fields, populated from the fields that replace
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1431: TODO: Get rid of this function and replace it with CompileEventLogger directly instead.
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1696: # TODO: log to init/id tlparse after I add support for it
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1836: # Add the passed in metadata
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2044: # TODO: this is questionable
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2236: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2410: # TODO: Delete this condition when rollout is done.  NB: this
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2926: # But res is 'BETTER' than ref so we count it pass.
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2990: passes_test = res_error <= (multiplier * ref_error + tol / 10.0)
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2992: not passes_test
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3000: passes_test = True
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3001: if not passes_test:
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3013: return passes_test
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3243: # We need to specialize symfloats for now. Eventually we should do a tensorify pass in dynamo.
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3442: except (NotImplementedError, UnsupportedFakeTensorException) as e:
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3447: if isinstance(e, NotImplementedError):
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3453: gb_type="NotImplementedError/UnsupportedFakeTensorException when running FX node",
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3570: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3615: The second element is a TensorStaticReason, useful for passing to tensor_static_reason_to_message if needed.
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3638: from tabulate import tabulate  # TODO: Check that this is installed
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3881: # TODO - This is a temporary situation where we have two versions of
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3901: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:4143: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:4320: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:859: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:1446: # this pass might change offsets, if so we need to try again
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:26: import getpass
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:139: path = f"{tempfile.gettempdir()}/minifier_{getpass.getuser()}"
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:182: # TODO - Assuming that all modules can be safely repr'd. Check if that assumption is correct.
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:239: # TODO - Keep this code for now. But, I don't think we will need this.
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:336: raise NotImplementedError("Could not write to {minified_repro_path}") from e
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:340: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:363: from .testing import collect_results, reduce_to_scalar_loss, requires_bwd_pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:377: if requires_bwd_pass(out):
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:430: passing = same(
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:438: return passing
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:552: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:555: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:558: # TODO: Support bundling the entire repro into a zip file for ease of
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:581: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:585: # TODO: transfer it to the right device?  But failing this
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:647: # TODO: consider ensuring tensor and storage counters line up?
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:681: # TODO: being optional on device is kind of pointless as the default
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:755: # TODO: this doesn't actually symint atm
- .venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:807: lambda: f"{symint} not in symbolic_shapes and default sym shape not passed in",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:75: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:783: "torch._C._jit_pass_autocast",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:784: "torch._C._jit_pass_batch_mm",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:785: "torch._C._jit_pass_canonicalize_graph_fuser_ops",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:786: "torch._C._jit_pass_canonicalize",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:787: "torch._C._jit_pass_complete_shape_analysis",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:788: "torch._C._jit_pass_concat_frozen_linear",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:789: "torch._C._jit_pass_constant_loop_unrolling",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:790: "torch._C._jit_pass_constant_pooling",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:791: "torch._C._jit_pass_constant_propagation_immutable_types",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:792: "torch._C._jit_pass_constant_propagation",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:793: "torch._C._jit_pass_convert_frozen_ops_to_mkldnn",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:794: "torch._C._jit_pass_create_autodiff_subgraphs",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:795: "torch._C._jit_pass_create_functional_graphs",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:796: "torch._C._jit_pass_cse",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:797: "torch._C._jit_pass_custom_pattern_based_rewrite_graph",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:798: "torch._C._jit_pass_custom_pattern_based_rewrite",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:799: "torch._C._jit_pass_dbr_quant_remove_redundant_aliases",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:800: "torch._C._jit_pass_dce_allow_deleting_nodes_with_side_effects",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:801: "torch._C._jit_pass_dce",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:802: "torch._C._jit_pass_decompose_ops",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:803: "torch._C._jit_pass_dedup_module_uses",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:804: "torch._C._jit_pass_erase_number_types",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:805: "torch._C._jit_pass_erase_shape_information",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:806: "torch._C._jit_pass_filter_non_tensor_arguments",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:807: "torch._C._jit_pass_fixup_onnx_controlflow_node",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:808: "torch._C._jit_pass_fold_convbn",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:809: "torch._C._jit_pass_fold_frozen_conv_add_or_sub",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:810: "torch._C._jit_pass_fold_frozen_conv_bn",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:811: "torch._C._jit_pass_fold_frozen_conv_mul_or_div",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:812: "torch._C._jit_pass_fold_frozen_linear_bn",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:813: "torch._C._jit_pass_fold_prepacking_ops",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:814: "torch._C._jit_pass_functional_to_inplace_activation",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:815: "torch._C._jit_pass_fuse_add_relu",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:816: "torch._C._jit_pass_fuse_addmm",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:817: "torch._C._jit_pass_fuse_clamp_w_prepacked_linear_conv",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:818: "torch._C._jit_pass_fuse_frozen_conv_add_relu",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:819: "torch._C._jit_pass_fuse_linear",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:820: "torch._C._jit_pass_fuse_quantized_add_relu",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:821: "torch._C._jit_pass_fuse_tensorexprs",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:822: "torch._C._jit_pass_fuse",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:823: "torch._C._jit_pass_inline_fork_wait",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:824: "torch._C._jit_pass_inline_functional_graphs",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:825: "torch._C._jit_pass_inline",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:826: "torch._C._jit_pass_inplace_to_functional_activation",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:827: "torch._C._jit_pass_insert_observer_method_for_ondevice_ptq",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:828: "torch._C._jit_pass_insert_observers",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:829: "torch._C._jit_pass_insert_prepack_unpack",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:830: "torch._C._jit_pass_insert_prepacked_ops",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:831: "torch._C._jit_pass_insert_quant_dequant_for_ondevice_ptq",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:832: "torch._C._jit_pass_insert_quant_dequant",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:833: "torch._C._jit_pass_integer_value_refinement",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:834: "torch._C._jit_pass_lint",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:835: "torch._C._jit_pass_loop_unrolling",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:836: "torch._C._jit_pass_lower_all_tuples",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:837: "torch._C._jit_pass_lower_graph",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:838: "torch._C._jit_pass_metal_fold_prepacking_ops",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:839: "torch._C._jit_pass_metal_fuse_clamp_w_prepacked_conv",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:840: "torch._C._jit_pass_metal_insert_prepacked_ops",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:841: "torch._C._jit_pass_metal_optimize_for_mobile",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:842: "torch._C._jit_pass_onnx_assign_output_shape",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:843: "torch._C._jit_pass_onnx_assign_scoped_names_for_node_and_value",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:844: "torch._C._jit_pass_onnx_autograd_function_process",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:845: "torch._C._jit_pass_onnx_block",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:846: "torch._C._jit_pass_onnx_cast_all_constant_to_floating",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:847: "torch._C._jit_pass_onnx_clear_scope_records",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:848: "torch._C._jit_pass_onnx_constant_fold",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:849: "torch._C._jit_pass_onnx_deduplicate_initializers",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:850: "torch._C._jit_pass_onnx_eliminate_unused_items",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:851: "torch._C._jit_pass_onnx_eval_peephole",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:852: "torch._C._jit_pass_onnx_function_extraction",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:853: "torch._C._jit_pass_onnx_function_substitution",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:854: "torch._C._jit_pass_onnx_graph_shape_type_inference",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:855: "torch._C._jit_pass_onnx_lint",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:856: "torch._C._jit_pass_onnx_node_shape_type_inference",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:857: "torch._C._jit_pass_onnx_peephole",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:858: "torch._C._jit_pass_onnx_preprocess_caffe2",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:859: "torch._C._jit_pass_onnx_preprocess",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:860: "torch._C._jit_pass_onnx_quantization_insert_permutes",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:861: "torch._C._jit_pass_onnx_remove_inplace_ops_for_onnx",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:862: "torch._C._jit_pass_onnx_remove_print",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:863: "torch._C._jit_pass_onnx_scalar_type_analysis",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:864: "torch._C._jit_pass_onnx_set_dynamic_input_shape",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:865: "torch._C._jit_pass_onnx_track_scope_attributes",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:866: "torch._C._jit_pass_onnx_unpack_quantized_weights",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:867: "torch._C._jit_pass_onnx",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:868: "torch._C._jit_pass_optimize_for_inference",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:869: "torch._C._jit_pass_optimize_for_mobile",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:870: "torch._C._jit_pass_optimize_frozen_graph",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:871: "torch._C._jit_pass_pattern_based_rewrite",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:872: "torch._C._jit_pass_peephole_list_idioms",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:873: "torch._C._jit_pass_peephole",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:874: "torch._C._jit_pass_prepare_division_for_onnx",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:875: "torch._C._jit_pass_propagate_device",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:876: "torch._C._jit_pass_propagate_dtype",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:877: "torch._C._jit_pass_propagate_shapes_on_graph_and_build_compute",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:878: "torch._C._jit_pass_propagate_shapes_on_graph",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:879: "torch._C._jit_pass_quant_finalize_for_ondevice_ptq",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:880: "torch._C._jit_pass_quant_finalize",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:881: "torch._C._jit_pass_quant_fusion",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:882: "torch._C._jit_pass_refine_integer_values",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:883: "torch._C._jit_pass_refine_tuple_types",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:884: "torch._C._jit_pass_remove_dropout",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:885: "torch._C._jit_pass_remove_expands",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:886: "torch._C._jit_pass_remove_inplace_ops",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:887: "torch._C._jit_pass_remove_mutation",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:888: "torch._C._jit_pass_replace_old_ops_with_upgraders",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:889: "torch._C._jit_pass_replicate_dequantize",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:890: "torch._C._jit_pass_run_decompositions",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:891: "torch._C._jit_pass_specialize_autogradzero",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:892: "torch._C._jit_pass_swap_functional_linear",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:893: "torch._C._jit_pass_transform_conv1d_to_conv2d",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:894: "torch._C._jit_pass_transpose_frozen_linear",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:895: "torch._C._jit_pass_vulkan_fold_prepacking_ops",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:896: "torch._C._jit_pass_vulkan_fuse_clamp_w_prepacked_conv",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:897: "torch._C._jit_pass_vulkan_insert_prepacked_ops",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:898: "torch._C._jit_pass_vulkan_optimize_for_mobile",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:1158: "torch._C._rocm_is_backward_pass",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3405: "torch.fx.passes.shape_prop",
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3595: # TODO(yanboliang, anijain2305) - There are a few concerns that we should
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3732: `is_inlined_call` is used to indicate if the current function call is inlined (f2 is inlined call if it passes check)
- .venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3753: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/codegen.py:179: b) If value.source is None, this is not allowed. TODO - assert this.
- .venv/lib/python3.12/site-packages/torch/_dynamo/codegen.py:204: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/codegen.py:261: # introduced. TODO sort out the invariants among side effect,
- .venv/lib/python3.12/site-packages/torch/_dynamo/codegen.py:347: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/codegen.py:630: if arg.pass_arg_as_tensor:
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:6: This module implements compiled autograd, which traces and optimizes backward pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:13: Compiled autograd can significantly improve backward pass performance by removing
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:344: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:397: # TODO(jansel): are all these modes needed?
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:442: # - copy-paste the backward graph into the CA graph so that CA passes and Dynamo can see it
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:560: # we must manually apply the view_to_reshape post grad pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:1016: # TODO(yf225): work around: remove dead codes like `sym_size` and `sym_numel` which are not used downstream. e.g.
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:1110: pass attempts to reorder the graph to mimic eager behavior.
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:1144: them as soon as possible. This pass attempts to reorder the graph to
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:1200: right before their registered node execution. This pass attempts to
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:1235: schedules them as soon as possible. This pass attempts to reorder the
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:1271: soon as possible. This pass attempts to reorder the graph to mimic eager
- .venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:1410: # forward pass, make sure they are wrapped under this context as well.
- .venv/lib/python3.12/site-packages/torch/_dynamo/external_utils.py:18: Functions and classes for handling autograd hooks and backward passes
- .venv/lib/python3.12/site-packages/torch/_dynamo/external_utils.py:171: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/resume_execution.py:259: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/resume_execution.py:462: # TODO(jansel): add dead code elimination here
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:92: - Handles tensor hooks and backward pass state
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:221: # TODO plumb HOP information here
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:425: # TODO(anijain2305) - Is it possible to remove this specialization?
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:438: # TODO(anijain2305) - Consider adding get_example_value method to
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:565: # TODO track from all possible sources.
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:625: # TODO generalize this so we never need to call `make_cell`.
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:650: # Don't codegen from temp source assigned from the 1st pass.
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:654: # cleared it. TODO move this call into `add_cache`
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:734: # For tensors with a source, we bypass direct inclusion of register_hook calls in the graph.
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:750: # - Functions passed to register_hook are lifted globally.
- .venv/lib/python3.12/site-packages/torch/_dynamo/side_effects.py:900: # TODO generalize this for cells created during inlining.
- .venv/lib/python3.12/site-packages/torch/_dynamo/profiler.py:143: pass  # ops recursively called from other ops (ignored)
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:316: # from the tensorify_python_scalars.py joint fx pass to inform us about
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:405: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:409: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:663: # TODO maybe should respect DtoH sync intention of users later??
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1328: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1364: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1774: #   1) raise exception type - raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1952: # TODO(anijain2305) - This is not tested .. unable to create a testcase
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2094: # 1) except NotImplementedError --> BuiltinVariable
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2266: # doesn't need to be passed in as an arg.
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2402: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2579: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2854: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2927: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3840: # TODO: mlazos, add support for enabling multiple artifact logs
- .venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:4037: # module. TODO generalize the check for other non-importable cases.
- .venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:181: class TODO_UNKNOWN:
- .venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:182: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:362: # Check if the passed arguments are of type Tensor
- .venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:544: # TODO - Running exec generated frame seems propagates f_globals to the
- .venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1237: # TODO: replace with CompileEventLogger.compilation_metrics
- .venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1284: # NB: NotImplementedError used to be on this list, but actually
- .venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1364: # TODO mlazos: add support for same args, or record them
- .venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1439: # TODO: the first condition is not covered by any test
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:298: TODO(voz): We now have allow_in_graph, disallow_in_graph, forbid_in_graph - some more robust
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:391: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:534: happily specialize it and continue. If you want to error in these cases, pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:554: # FX tracers don't respect @forbid_in_graph and choke on the following error since it passes in proxies:
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:586: range of shapes, in eager we will pass it through, but export will raise an error.
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:591: 5) If specialize_on is passed in, we will perform a single generic Dynamo trace followed by
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:608: # TODO: Make this configurable via a supported public API
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:621: # TODO(voz): Should we bounds check?
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:625: # FX tracers don't respect @forbid_in_graph and choke on the following error since it passes in proxies:
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:646: # TODO: Make this configurable via a supported public API
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:652: # TODO(voz): Should we bounds check?
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:699: # TODO: Make this configurable via a supported public API
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:714: # TODO(voz): Should we bounds check?
- .venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:835: # TODO: also implement nonrecursive patch_dynamo_config/dont_skip_tracing.
- .venv/lib/python3.12/site-packages/torch/_dynamo/polyfills/itertools.py:85: # TODO: use indices = itertools.count() and merge implementation with the else branch
- .venv/lib/python3.12/site-packages/torch/_dynamo/polyfills/functools.py:20: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/polyfills/__init__.py:53: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/polyfills/__init__.py:288: # correct because one of the __eq__ checks will pass later, just could be
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:117: # TODO: why do we need to deepcopy the original graph?
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:126: # TODO: Failures here are troublesome because no real inputs,
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:183: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:325: # TODO: improve these names with FQN
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:423: # TODO: factor this out
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:589: # TODO: speed this up
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:665: # TODO: The logic for cloning inputs/models here is intentionally
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:757: # TODO: check eager determinism
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:838: # TODO: lazily load the inputs or something, rather than cloning them
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:989: # TODO: make this an option for --analyze too
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:188: # TODO: Figure out why torch.compile'd hash isn't work on this codepath
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:194: # TODO: improve these names with FQN
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:275: # TODO: factor this out
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:304: # TODO: It's inconsistent to pass SymInt inputs but REAL tensors.
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:305: # We should pass ints and look at the GraphModule placeholders
- .venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:461: # TODO: disable clone
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:12: user-defined objects and passing parameters as inputs to the FX graph. This creates one graph per
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:449: # TODO: Use named_children when it supports remove_duplicate=False.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:508: # TODO: do we want to support __call__ for GM's?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:762: # TODO(anijain2305,export-team) - Remove this if condition when inlining of inbuilt nn modules is
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:863: defined objects and will pass parameters into the FX graph as inputs.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:917: raise NotImplementedError from e
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:1058: # TODO(anijain2305) - This might not be needed if we let Dynamo
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/lists.py:169: # TODO this type check logic mirrors the following
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/lists.py:517: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/lists.py:1123: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/lists.py:1144: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:72: AsPythonConstantNotImplementedError,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:302: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:336: # TODO putting this here to avoid duplication, because we could hit this
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:348: # TODO(anijain2305) - Replace directly calling UserFunctionVariable with
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:398: # TODO refactor these 3 branches.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:420: # TODO figure out why source isn't available here, and whether
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:462: except AsPythonConstantNotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:543: # TODO(anijain2305) - Add support for more builtin methods
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:585: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:790: # * If the generator function does not catch the passed-in exception,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:874: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1028: # check bypasses the if condition for non-root tracers and directly
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1180: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1283: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1434: # TODO improve trace_rules reasoning to provide better hints.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:2100: # Only grid needs to be passed
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:2116: # as we can only pass tensors as non-const args in fx graph,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:2141: # Combine args and kwargs and pass as a dict so that if user defined triton
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:126: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:213: # TODO(anijain2305) - Extend this to support objects with default tp_new
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:521: )  # TODO(voz): These can invoke user code!
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:524: )  # TODO(voz): These can invoke user code!
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:747: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:759: # TODO: arguably, this should route to wrap_symint/wrap_symfloat
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:806: # TODO consider emulating `obj.__dict__` as a `ConstDictVariable` to get
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:837: # TODO else try reconstructing the object by, e.g., leveraging side
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:888: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:918: # TODO(anijain2305) - Identity checking should already be a part
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:934: # TODO(jansel): add a guard to check for monkey patching?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:954: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1146: # TODO(anijain2305) - This is a mapping proxy object. Ideally we
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1182: # TODO(anijain2305) - Investigate if we need specialization for more
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1456: # TODO loosen this restriction and fix `as_proxy`.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1457: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1488: # TODO this isn't really safe, because
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1604: # Dummy class to pass to python_type of RemovableHandleVariable
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1606: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1689: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1732: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1759: # TODO this duplicates the logic in `BuiltinVariable(tuple)`
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1785: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:1823: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/optimizer.py:56: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/optimizer.py:60: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/optimizer.py:134: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:81: from .base import AsPythonConstantNotImplementedError, ValueMutationNew, VariableTracker
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:376: # TODO: If we expand this to handle tensor args, we need to manually
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:868: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:938: except AsPythonConstantNotImplementedError as exc:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:960: except AsPythonConstantNotImplementedError as exc:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1109: # TODO - supporting all comparison operators could also work but
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1151: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1322: # TODO handle more cases and merge this with this with `generic_jump`.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1700: # Only `OrderedDict.fromkeys` accepts `value` passed by keyword
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1826: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1930: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:2045: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:2046: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:2100: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:2112: # TODO(mlazos) - Do we need this?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:2130: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:2161: # TODO(voz): Make it work properly
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:2292: except NotImplementedError as error:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:310: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:316: # TODO: storing a SymInt here but not a FakeTensor is a pretty strange
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:321: # a float or int) which we pass to the FX graph as a Tensor.  This
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:323: # torch.as_tensor on the quantity before passing it in.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:325: # Note that we typically do not pass dynamic integers as tensors, because
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:329: # DO pass it as a tensor.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:332: # pass_arg_as_tensor as subtly broken: we just pun the variable as a
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:336: pass_arg_as_tensor: bool
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:344: # Sometimes, the Tensor we pass to example is freshly allocated (smh).
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:379: pass_arg_as_tensor=False,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:470: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:520: # TODO(jansel): something like a REPR_MATCH might be more robust here
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:624: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:627: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:631: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:634: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:639: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:784: # TODO support source for sets and remove the special logics here.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:884: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1016: # TODO: this doing it manually is bad
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1031: # TODO: see if we need to add custom guard instead of a simple ID_MATCH
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1035: # TODO: see if we need to add custom guard instead of a simple ID_MATCH
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1039: # TODO: see if we need to add custom guard instead of a simple ID_MATCH
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1078: # TODO (yidi): we need to figure out a way to propagate the guards
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1213: # TODO(whc): Why do we limit this to methods on NNModules?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1257: # TODO(jansel): combine this case with the one above
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1451: # If the dict_keys object is passed from outside the compile region, it must either be passed along with
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1452: # the corresponding dict object or treated as a set (when only the keys are passed into the compiled region).
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1453: # - If it is passed along with the dict, the dict object itself is already guarded.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1454: # - If only the dict_keys object is passed, we add EQUALS_MATCH and SEQUENCE_LENGTH guards
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1596: pass_arg_as_tensor=False,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1993: # TODO(pearu,sparse-team) - Add the corresponding SPARSE_TENSOR_MATCH guards
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2133: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2173: # pass_arg_as_tensor should be true because we are wrapping a np.ndarray as argument input, and it needs to be
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2178: pass_arg_as_tensor=True,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2185: # TODO - Why do we need to set the source of the np ndarray vt back to
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2232: # TODO: This should be dynamic, as we in general do not
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2258: # TODO: dynamic_dim = DimDynamic.STATIC should work but
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2276: # TODO: Do I actually need guard for constant source?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2302: pass_arg_as_tensor=False,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2313: # SymFloat.  Removal of the item() call is left to a later FX pass,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2314: # mostly because that pass is more easily done after we have lowered
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2364: # TODO: Switch RandomValueSource over to use this, this is more
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2378: # TODO: Maybe the tensor-ification should be built into the source,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2415: # There's something a bit incoherent about pass_arg_as_tensor,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2429: pass_arg_as_tensor=True,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2435: # Directly do item to bypass capture_scalar_outputs
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2487: # TODO: when can this happen?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2502: pass_arg_as_tensor=True,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2594: #      the passed in proxy.)
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2670: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2747: # NOTE we pass a dummy object as the `item` argument to avoid
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2880: # TODO: this is a little sus, because we didn't check what the self is
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2941: # TODO: not sure about this fake mode test
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3160: # TODO: index export_constraints ahead of time so we don't have to
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3222: # TODO: This can be batched
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3223: # TODO: Doing this here is kind of sus, maybe better to set this
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3320: # TODO: When does this show up?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3362: # Parent contexts are passed in when we are recursively creating
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3413: # TODO: for TensorGuards, this eventually may need more
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3418: # TODO: revise this, but for now this stride instead of ()
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3500: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3501: pass  # failthrough to unimplemented branch
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3602: def passthrough(tx: "InstructionTranslator", value):
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:3606: handlers[cls] = passthrough
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:147: # TODO Temporarily remove to figure out what keys are we breaking on
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:190: # TODO: Put this in utils and share it between variables/builtin.py and here
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:220: # .clone() pass these arguments in kwargs but they're recreated a few
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:688: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:691: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:758: # TODO: Implementing this via inheritance rather than composition is a
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:913: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:917: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:1041: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:207: # more information; it inherits `NotImplementedError` for backward
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:209: class AsPythonConstantNotImplementedError(NotImplementedError):
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:302: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:327: NotImplementedError: If the method is not implemented in a subclass.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:331: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:332: raise NotImplementedError(f"{self} has no type") from None
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:337: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:342: raise AsPythonConstantNotImplementedError(self)
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:348: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:360: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:366: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:370: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:376: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:386: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:390: raise NotImplementedError(str(self))
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:400: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:404: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:407: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:422: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:542: "to the compiled region, instead of passing it as an input to the compiled region."
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:546: "passed in from uncompiled to compiled regions (e.g. `torch.compile(fn)(enumerate(...))`). "
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:558: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:618: # 1. one mistakenly passed in a source
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:626: # 1. one forgot to pass in a source
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:43: from torch.fx.passes.shape_prop import _extract_tensor_metadata
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:360: # TODO - write an example with tensor as a graph attribute in
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:362: raise NotImplementedError(f"get_attr with {type(a_attr)}")
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:364: # TODO - call_module is not supported because Dynamo Fx graph does
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:366: raise NotImplementedError(f"Graph equivalence check saw a {a_node.op}")
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:405: # Can be greater if user passes some args as kwargs
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:626: # TODO - supports input_mutation and aliasing should be False by default for strictness
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:645: unimplemented("Use `set_subgraph_inputs=automatic` when passing `sub_kwargs`.")
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:726: # TODO: support pytree output
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:929: elif value.__name__ == "dynamo_bypassing_wrapper":
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:930: return DynamoBypassingWrapperHigherOrderVariable(value, source, **kwargs)
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1004: # TODO(voz): Support fake tensor dispatch for recursive
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1065: # TODO: Support kwargs
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1821: # Check meta data of carries and inits. If we pass this stage, we are sure that the init and carries
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1927: # TODO: Support kwargs
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:2423: # TODO (tmanlaibaatar) support pytree here
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:2498: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:2549: class DynamoBypassingWrapperHigherOrderVariable(WrapHigherOrderVariable):
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:2571: f"DynamoBypassingWrapperHigherOrderVariable: Unsupported function {type(func_var)}"
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:2591: gmod_meta_key = "_dynamo_bypassing_wrapper_fn"
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:2708: except (NotImplementedError, Unsupported) as err:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:2814: # passed in as arguments. In this case, we need to lift them, which is handled by speculate_subgraph.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:3089: # TODO: assert that bwd_graph didn't capture values that were
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:3092: # TODO(oulgen): Ideally, we would not do a linear search for output
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:3100: # are marked as non-differentiable and pass them to ApplyTemplate
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:3277: except (Unsupported, NotImplementedError):
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/constant.py:124: raise NotImplementedError from e
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/constant.py:128: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/constant.py:131: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/constant.py:153: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/constant.py:165: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/constant.py:262: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:285: rank() or world_size(), as well as passed to utility functions in distributed_c10d
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:290: TODO: make it possible to use ProcessGroupVariable as input to simple functions
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:295: TODO: should we make this inherit VT instead of UDOV? Do we want any of the default behaviors
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:325: # TODO should this just raise unimplemented?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:366: trace_wrapped in the backward pass that CompiledAutograd
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch_function.py:498: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch_function.py:507: # Also notice the `cls` is not explicitly passed in the reference
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch_function.py:671: # TODO move this logic into `TensorVariable`, or try to merge it
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch_function.py:676: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:901: # TODO: this probably should be folded somewhere else but I'm not sure where
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:902: # TODO: some of the other symbolic_shapes special tools can also get this treatment too
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:914: # TODO: this probably should be folded somewhere else but I'm not sure where
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:915: # TODO: some of the other symbolic_shapes special tools can also get this treatment too
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:925: # TODO: this probably should be folded somewhere else but I'm not sure where
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:926: # TODO: some of the other symbolic_shapes special tools can also get this treatment too
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1039: # TODO: there maybe other recursive structures you need to
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1050: # NB: OK to pass torch.tensor(tensor), this will trace fine
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1132: from .base import AsPythonConstantNotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1176: except AsPythonConstantNotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1236: # TODO support more output types
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1313: # TODO(voz): Replace w/ dynamic shape rewrite table.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1324: # TODO for each of the following check on `out=` or `requires_grad=`
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1468: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1490: except NotImplementedError as e:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1516: # TODO(jansel/bdhirsh) - There is some issue with
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:1522: # TODO(jansel): if the new param falls out of scope, currently it won't get freed until
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/lazy.py:152: # TODO: Add support for more types
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:206: # TODO: strip off fake tensor from repr here
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:289: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:305: raise NotImplementedError from exc
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:308: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:311: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:314: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:412: # TODO - This is not a good solution but solves an accuracy issue.
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:524: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:694: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:842: # So, we pass it in as a string (which is also supported, see above implementation for .type() with 0 args)
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1173: # Rewrite __contains__ here so that downstream passes can trace through
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1254: # TODO(voz):
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1260: # Discussion point 1 - Should we bypass this if nopython/fullgraph = True?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1288: # TODO(jansel): returning None here is wrong, it should be
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1388: # TODO: Should we allow non SymTypes here?  Today it is allowed
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1525: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1633: # tensor data with a new type. TODO polyfill?
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1656: # TODO builder should be able to handle `torch.Tensor.__init__`,
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:70: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:152: "Check the arguments passed to `super()`.",
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:274: except NotImplementedError as exc:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:278: explanation="Dynamo requires the attribute name passed to "
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:554: raise NotImplementedError("comptime is special form")
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:574: # TODO: support an expression form as well
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1088: raise NotImplementedError(f"{self} is not a constant") from None
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1092: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1095: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1098: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1171: # Bypass any custom setattr as we are updating the `__dict__` itself
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1208: # TODO(dynamo-team) - We can perhaps expand the scope to more names and
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1434: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1462: # TODO Add all the functions that go from constants to constants to can_constant_fold_through
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1676: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/ctx_manager.py:106: raise NotImplementedError("module_name called on base")
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/ctx_manager.py:109: raise NotImplementedError("fn_name called on base")
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/ctx_manager.py:1005: # stream passed from outside the traced function
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/ctx_manager.py:1067: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/variables/ctx_manager.py:1239: "stream value is not equal to the passed device"
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/tvm.py:119: # TODO(shingjan): This could be replaced by tvm.contrib.torch.optimize_torch
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/tvm.py:144: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/debugging.py:8: - eager: Simple pass-through backend that runs models in eager mode
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/debugging.py:291: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/debugging.py:295: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/registry.py:95: imported by default, it might be easier to pass a function directly
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/registry.py:141: Return valid strings that can be passed to:
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/common.py:18: optimization of both forward and backward passes.
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/common.py:74: # - stop TorchDynamo from trying to compile our the generated backwards pass bw_compiler produces
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/common.py:79: reason="do not trace generated backwards pass",
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:9: - CUDA graph creation and management for both forward and backward passes
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:16: 1. cudagraphs: Full CUDA graph support with both forward and backward pass optimization
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:83: # TODO: not correct for args that contain tensors in a struct
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:89: # TODO: error on unrecognized nodes
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:152: # TODO: add split id to CompileId: https://github.com/pytorch/tlparse/pull/83/files#r1880649384
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:192: # TODO(whc)
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:278: # output strides of one compilation is appropriately passed to the subsequent
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:305: # TODO - better way of doing this?
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:471: # passed as input to a subsequent graph
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:492: pass
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:526: # bypass split/fuse logic if there is only one bucket
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:535: split_gm = fx.passes.split_module.split_module(
- .venv/lib/python3.12/site-packages/torch/_dynamo/backends/tensorrt.py:14: #    pass
- .venv/lib/python3.12/site-packages/torch/_prims/rng_prims.py:268: # TODO: you don't need to do this, the dispatch here already disabled
- .venv/lib/python3.12/site-packages/torch/_prims/executor.py:60: # TODO: caching
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:239: # TODO: This looks wrong, a number that is wrapped into a tensor
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:383: # TODO: implement dtype validation here, too, or on the corresponding refs
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:465: # TODO: fix number type promotion (bool, complex->float)
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:517: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:996: # TODO: complex needs a special meta to account for its float -> complex behavior
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1228: pass
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1516: # TODO: this is only here to support the unsqueeze ref
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1576: # TODO: consider renaming split_dim_view
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1782: # TODO: review stride logic
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1933: # TODO: update meta objects so this can be acquired directly
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2009: # TODO: create a new return type for scalars?
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2041: # TODO: create a new return type for scalars?
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2073: # TODO: create a new return type for scalars?
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2094: # TODO: move this as an option on the reference
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2116: # TODO: Remove safe casting and implement on reference instead
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2180: # TODO: review support arbitrary resizes
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2275: raise NotImplementedError("xor_sum only implemented with inductor")
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2338: # TODO: layout, pin_memory, memory_format
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2339: # TODO: model requires_grad on TensorMeta
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2386: # TODO: layout, pin_memory, memory_format
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2387: # TODO: model requires_grad on TensorMeta
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2429: # TODO: add layout, pin_memory
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2484: # TODO: add layout, pin_memory
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2524: # TODO: add layout
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2607: # TODO: add layout and pin_memory support
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2648: # TODO The MAGMA backend returns V, so this is wrong if used with the MAGMA backend
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2775: # TODO: we should more seriously review randomness modeling and prims
- .venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2945: pass
- .venv/lib/python3.12/site-packages/torch/_prims/context.py:20: from torch._prims_common import torch_function_passthrough
- .venv/lib/python3.12/site-packages/torch/_prims/context.py:61: # TODO: Should these methods be mapped some other way?
- .venv/lib/python3.12/site-packages/torch/_prims/context.py:102: this behavior can be customized by passing a function to should_fallback_fn.
- .venv/lib/python3.12/site-packages/torch/_prims/context.py:126: if orig_func in torch_function_passthrough or orig_func in all_prims():
- .venv/lib/python3.12/site-packages/torch/_functorch/functional_call.py:24: .. note:: If the module has active parametrizations, passing a value in the
- .venv/lib/python3.12/site-packages/torch/_functorch/functional_call.py:27: If you want to apply the parametrization function to the value passed
- .venv/lib/python3.12/site-packages/torch/_functorch/functional_call.py:59: An example of passing multiple dictionaries
- .venv/lib/python3.12/site-packages/torch/_functorch/functional_call.py:109: args (Any or tuple): arguments to be passed to the module call. If not a tuple, considered a single argument.
- .venv/lib/python3.12/site-packages/torch/_functorch/functional_call.py:110: kwargs (dict): keyword arguments to be passed to the module call
- .venv/lib/python3.12/site-packages/torch/_functorch/functional_call.py:112: tied in the reparameterized version. Therefore, if True and different values are passed for the tied
- .venv/lib/python3.12/site-packages/torch/_functorch/functional_call.py:114: buffers unless the values passed for both weights are the same. Default: True.
- .venv/lib/python3.12/site-packages/torch/_functorch/functional_call.py:115: strict (bool, optional): If True, then the parameters and buffers passed in must match the parameters and
- .venv/lib/python3.12/site-packages/torch/_functorch/functional_call.py:170: passed directly to an optimizer).
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:78: raise ValueError(f"Thing passed to transform API must be Tensor, got {type(x)}")
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:87: # TODO: Remove the following hack for namedtuples
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:226: ``func`` with respect to all ``primals`` using the cotangents passed
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:240: passing in the cotangents for each of the outputs
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:343: # It is only separated so that inputs passed to jacrev but not differentiated get the correct wrappers.
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:530: Additionally, passing a tuple to ``argnums`` will compute the Jacobian
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:749: # passing the standard basis for R^4 as the grad_output.
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1031: :func:`jvp` can support functions with multiple inputs by passing in the
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1065: # It is only separated so that inputs passed to jacfwd but not differentiated get the correct wrappers.
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1237: Additionally, passing a tuple to ``argnums`` will compute the Jacobian
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1389: # NB: need create_graph so that backward pass isn't run in no_grad mode
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1487: If 'mutations' is passed in then all mutating operators
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1489: If 'mutations_and_views' is passed in, then additionally, all aliasing
- .venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1595: non-local state, functionalization will simply no-op and pass the view/mutation
- .venv/lib/python3.12/site-packages/torch/_functorch/pyfunctorch.py:63: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/pyfunctorch.py:78: raise NotImplementedError
- .venv/lib/python3.12/site-packages/torch/_functorch/pyfunctorch.py:120: # TODO: would be nice to assert that the layers are the same, but
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:39: from torch.fx.passes import graph_drawer
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:226: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:482: "activation_quantization_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:495: "activation_quantization_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:500: "activation_quantization_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:506: "activation_quantization_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:518: "activation_quantization_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:548: "activation_quantization_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:592: counters["inductor"]["activation_quantization_fwd_aten_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:604: "activation_quantization_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:672: counters["inductor"]["activation_quantization_bwd_aten_pass"] += 1
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:683: "activation_quantization_aten_pass", None
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:696: "activation_quantization_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:719: "name": "before_activation_quantization_fwd_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:732: "name": "after_activation_quantization_fwd_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:743: "name": "before_activation_quantization_bwd_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:766: "activation_quantization_aten_pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:790: "name": "after_activation_quantization_bwd_aten_pass",
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:827: # This is to filter out saved values that don't actually end up being used by the backwards pass
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:927: are executed in the original ``.forward()`` callable passed to
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:932: to be stashed for the backward pass. These stashed tensors become the output
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1083: This pass finds the first bwd node in the graph (by looking at users of
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1090: Why is this pass required in the first place?
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1098: the fwd subgraphs are live for way longer duration than necessary. This pass
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1140: # If gradInp does not depend upon gradOut, we may not find any nodes in the "backwards pass"
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1193: Creating RNG state placeholders for both passes
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1205: # Handle forward pass
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1215: # Handle backward pass
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1264: # Step 2 - Modify the fwd pass such that
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1270: # Step 3 - Modify the bwd pass such that
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1368: # Step 2 - Modify the fwd pass such that
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1418: # Step 3 - Modify the bwd pass such that
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1473: checkpointed blocks. The following pass makes the last output node
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1614: # If a node *must* be materialized in the backwards pass, then we
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1617: # backwards pass is "free". However, if a node must be materialized
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1618: # in the backwards pass, then recomputing it is never free.
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1673: # Heuristic to bias towards nodes closer to the backwards pass
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1742: # We only need to ban nodes in the fw pass, as those are the only ones that would be recomputed.
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:1778: # backwards pass instead of only relying on whether it's unfusible in the
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:2346: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:2470: # TODO: maybe use a different process group?
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:2483: # TODO: maybe use a different process group for this
- .venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:2530: #  add the CSE pass
- .venv/lib/python3.12/site-packages/torch/_functorch/benchmark_utils.py:14: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:113: Reload a set of weights so that `mod` can be used again to perform a forward pass.
- .venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:271: # TODO: We don't need to copy the model to create a stateless copy
- .venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:322: # TODO: We don't need to copy the model to create a stateless copy
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:371: # we're guaranteed that the tangent tensors that we pass
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:386: # duplicate inputs: If we passed in the same tensor for primals_1 and
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:398: # To ensure that these side-effects are compatible to future graph passes that
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:411: # We will pass the token as an input to the graph, thread it through
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:420: # is difficult, after generating the forward graph, we will run a pass to
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:450: Represents a fw or bw_compiler passed to AOTAutograd.
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:461: # TODO: bikeshed on this name
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:540: # TODO: Ensure that this codepath is never exercised from
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:593: The joint graph is then passed through attr:`partition_fn` to isolate the
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:611: # TODO: Chillee argues that dynamo itself should pass in fake tensors to
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:729: # changes depending on whether we pass in is_train / keep_input_mutations,
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:731: # TODO: refactor the subclass path of run_functionalized_fw_and_collect_metadata
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:975: args : args to be passed to :func:`aot_function`
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:976: kwargs : kwargs to be passed to :func:`aot_function`
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1059: # TODO(mlazos): Revisit if this is still needed. With Dynamo install ID
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1232: # TODO: There is something deeply wrong here; compiled_fn running with
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1340: # We only want to create a backward graph w.r.t. the loss that the user passed in.
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1537: # TODO: we might have to temporarily patch config.functionalize_rng
- .venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1693: # TODO(avik): Assigning all other types are allowed right now.
- .venv/lib/python3.12/site-packages/torch/_functorch/config.py:110: # long chain of recomputation in the backwards pass.
- .venv/lib/python3.12/site-packages/torch/_functorch/config.py:112: # Bans recomputation of nodes that must be materialized in the backwards pass
- .venv/lib/python3.12/site-packages/torch/_functorch/config.py:241: # kernel mismatch is detected, bypasses by making a fake kernel from the
- .venv/lib/python3.12/site-packages/torch/_functorch/config.py:246: # TODO: turn on by default
- .venv/lib/python3.12/site-packages/torch/_functorch/config.py:250: # Error on BypassAOTAutogradCache instead of just a warning
- .venv/lib/python3.12/site-packages/torch/_functorch/config.py:256: # - We have many passes in the compiler (min-cut partitioning, DCE, etc)
- .venv/lib/python3.12/site-packages/torch/_functorch/config.py:258: # - If any of these passes reorder/delete/duplicate a collective
- .venv/lib/python3.12/site-packages/torch/_functorch/config.py:279: # TODO(ivankobzarev): Remove this config, being able to deduce it compile time.
- .venv/lib/python3.12/site-packages/torch/_functorch/config.py:286: # TODO(ivankobzarev): Remove this config once extra memory usage is investigated.
- .venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:47: # and only traces the forward pass.
- .venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:66: # and whose backward pass calls the original autograd.Function's backward.
- .venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:186: # TODO: update following link from master to stable once that's out
- .venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:282: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:284: f"Please do not pass kwarg-only Tensors to autograd.Function. "
- .venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:290: # TODO: Update link to stable once that's out
- .venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:305: # TODO: Update link to stable once that's out
- .venv/lib/python3.12/site-packages/torch/_functorch/compilers.py:92: torch._C._jit_pass_remove_mutation(f.graph)
- .venv/lib/python3.12/site-packages/torch/_functorch/compilers.py:165: # TODO: There is some sort of problem where we record that an
- .venv/lib/python3.12/site-packages/torch/_functorch/compilers.py:441: result = forward_and_backward_pass(model, example_inputs)
- .venv/lib/python3.12/site-packages/torch/_functorch/apis.py:27: # to be passed everywhere.
- .venv/lib/python3.12/site-packages/torch/_functorch/pytree_hacks.py:9: # TODO: remove this file when the migration of the pytree utility is done
- .venv/lib/python3.12/site-packages/torch/_functorch/compile_utils.py:72: except NotImplementedError:
- .venv/lib/python3.12/site-packages/torch/_functorch/compile_utils.py:102: # This CSE pass currently doesn't handle re-propogation of unbacked
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:384: # metadata pass of the user's forward function.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:385: # Their only use today is to pass them as a best-guess for tangents when tracing the joint.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:387: # pass once, and re-use the output throughout AOTAutograd
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:413: # TODO: we should kill this
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:609: # away to advance the rng state, and is not passed on to the raw
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:622: # TODO: This function is only a best effort: there are other fields that may not be cache safe
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:735: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:16: # TODO: It would be nice to reset the numbering every time aot_id goes
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:48: # TODO: Don't shove the aot_id in here; set it in the context
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:91: Extra metadata that is needed to compute pre or post compile can be passed in via attributes.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:103: Process the inputs to the compiler_fn. You can pass in extra metadata via kwargs.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:107: aot_config: AOTConfig passed in at compile time
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:163: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:424: #     TODO: discuss on the PR and decide if we want to tr to
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:508: # TODO: I would love to get rid of this argument, but it's
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:552: # TODO: this won't be right for the backward when we convert the call_compiled_backward to use the wrapper
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:668: # But the user might have passed us some tensor subclass inputs (or expect some subclass tensor outputs).
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:765: # When tracing functions for future execution, one must be careful not to pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:767: # in graphs that are ONLY valid if you later pass a new tensor in exactly the
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:852: # TODO: Can avoid the zip here too, probably
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:971: # TODO(voz): This structure is 1:1, we could consider an alternate structure like
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1047: # TODO: work out how to setup this assert correctly
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1072: trace_joint: bool  # TODO: refactor trace_joint
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1430: # calling cuDNN kernels, so when these parameters get passed to the optimizer we will
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1521: # Lowering passes are performed on a deepcopy of this bw_module due to compatbility
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1556: # Calling convention: we expect a grad_out passed to the backward:
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1564: # and we filter them out here before passing the remaining grad_outputs into the compiled backward.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1637: # TODO: replace this with FunctionalizedRngRuntimeWrapper
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1690: # TODO: figure out how to refactor the backward properly
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1805: # TODO: replace this with FunctionalizedRngRuntimeWrapper.post_compile
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1811: # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:2058: # we need to save it for when its backward pass happens
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:2410: # TODO: Check aliasing relationships
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:2411: # TODO: Check strides for metadata mutation
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:36: from torch.fx.passes._tensorify_python_scalars import tensorify_python_scalars
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:302: # Why do we need to pass in num_fw_outs_saved_for_bw?
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:306: # TODO: once we use pre_compile this will be flat_fn at the top of this function
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:442: def run_joint_graph_passes_on_hops(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:448: This pass runs the joint graph passes on the HOP graph. In torch.compile, we
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:449: typically have many passes which work on the joint graph and then end with a
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:457: 2) Run joint graph passes on the `joint_hop_gm` to get `new_fw_hop_gm` and `new_bw_hop_gm`
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:468: NB: This pass works for invoke_subgraph today because we took extra care in
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:565: # redundant joint graph passes for same subgraphs.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:588: # TODO: invoke_subgraph should track which of its inputs static indices
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:591: # Step 2) and 3) - Run joint graph passes and partitioner
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:652: # to collect all the information that we need to pass from the forward hop
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:768: # Since the partitioner is run after the graph passes, we have lost
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:982: raise NotImplementedError(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1313: fx_g = run_joint_graph_passes_on_hops(fx_g, joint_inputs, aot_config)
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1315: # TODO(anijain2305) - Add tensorify_python_scalars to the HOP graph passes.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1436: # Autograd has two passes:
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1437: # (1) a first pass that traverses the autograd graph and figures out which nodes need to be executed
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1438: # (2) a second pass that actually goes ahead and executes each node when it becomes ready,
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1449: # depending on the actual grad_outputs that were passed in during the backward.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1468: # TODO: we should apply the below "detach inputs if their gradients are statically known to be None"
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1568: # make sure to pass the unwrapped fake tensors into the compiler!
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1652: # tensor passed in for compiling the backward graph using the
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1722: # Compiled autograd will run the bw_module in the backward pass,
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1723: # so recompilation need happen anyway if the backward pass is ever
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1727: # the lazy recompilation will cause issue in the backward pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:1777: # TODO: technically, AOTAutograd does a *little* bit of post processing work
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:65: # TODO: Refactor the following code so detach() persists item_memo
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:101: # TODO: replace with AOTDispatchSubclassWrapper once we refactor
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:239: # TODO: should factor this into a separate function for export that always only returns just the graph.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:277: # TODO: replace with AOTDispatchSubclassWrapper once we refactor
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:331: # TODO: in AOTAutograd, we create metadata like _indices_of_inps_to_detach to detect
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:144: #   to pass in as tangents into the backward.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:151: # TODO: refactor to kill this flag
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:196: # precondition: The passed in function already handles unflattening inputs + flattening outputs
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:744: passed_indices = set(static_input_indices)
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:748: if (isinstance(arg, torch.nn.Parameter) or i in passed_indices)
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:128: # TODO: Please remove soon
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:215: # The idea is that when we trace the backward, we need to pass in the *original* primals
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:231: # Make sure the primal we pass to autograd.grad()
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:235: # Make sure the primal we pass to autograd.grad()
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:415: # TODO(future): there is likely a less brittle way to do this by walking
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:424: # TODO(future): there is likely a less brittle way to do this, same
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/functional_utils.py:190: # TODO:add sparse tensors support to functionalization
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/functional_utils.py:445: # isn't actually true.  (TODO: Could this cause problems for Inductor?)
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:357: # we have been passed a list of (flattened) dense-tensor fw-outs, and need to reconstruct any subclass fw outs.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:379: f"additional activations saved for the backward pass ({num_fw_outs_saved_for_bw})"
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:100: #   because autograd will require us to pass the pre-mutated inputs into autograd.grad
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:171: # and not primals (the preserved inputs, pre-mutation, that we pass to grad())
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:209: # being carefully not to pass any mutated inputs into autograd.grad()
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:242: # Call the backwards pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:294: # At runtime, we pass on the current seed and offset. This is hidden from
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:422: # We support a limited amount of mutation of graph inputs during the backward pass.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:423: # (This is used e.g. by Float8, which needs to update buffers during the backward pass)
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:430: # - We could in theory have our analysis pass differentiate mutations in the fw from mutations in
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:488: ), "Found an input to the backward that had metadata mutated during the backward pass. This is not supported"
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:669: # TODO (tmanlaibaatar) revisit this if we ever need to turn on non-strict joint graph export
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:740: # Additionally pass in tokens as inputs
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:753: # - the new set of arguments to pass into this function (now that tensor subclasses have been eliminated)
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:778: # TODO: add subclass guards (later PR).
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:784: # directly on the joint, but this would hurt compile time (adding yet another pass through the joint).
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:837: # We pass append_symints=False here because the partitioner will
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:856: # (1) we pass is a single graph containing the joint fw/bw,
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:36: BypassFxGraphCache,
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:54: from torch._utils_internal import log_cache_bypass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:87: class BypassAOTAutogradCache(Exception):
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:88: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:92: class FXGraphCacheMiss(BypassAOTAutogradCache):
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:93: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:209: # By default we BypassAOTAutogradCache for unknown functions,
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:217: raise BypassAOTAutogradCache(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:227: raise BypassAOTAutogradCache(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:234: raise BypassAOTAutogradCache(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:245: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:247: raise BypassAOTAutogradCache(f"Unsupported node op {node.op}")
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:256: raise BypassAOTAutogradCache("Cannot cache a graph with freezing enabled")
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:261: raise BypassAOTAutogradCache("FX graph cache is not enabled")
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:265: raise BypassAOTAutogradCache(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:283: When view replay is turned on, we bypass autograd cache if
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:289: raise BypassAOTAutogradCache(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:337: # and if it raises an exception, also bypass on our end.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:340: except BypassFxGraphCache as e:
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:342: raise BypassAOTAutogradCache(str(e)) from e
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:387: # TODO: add args and parameters
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:404: raise BypassAOTAutogradCache("AOTAutogradCache requires triton 3.2.0")
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:467: raise BypassAOTAutogradCache("Failed to reload cache entry from disk")
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:498: # the same as the ones it passes to inductor, for both the forward and backward passes.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:499: # (This does not mean that the tensor values passed in are the same: only that their symints are).
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:501: # than those passed to it by inductor.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:503: # We pass the post compile function, which sets various fx_config boxed values,
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:601: return torch._dynamo.disable(compiled_bw, reason="do not trace generated backwards pass")  # type: ignore[return-value]
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:606: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:620: return torch._dynamo.disable(compiled_bw, reason="do not trace generated backwards pass")  # type: ignore[return-value]
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:735: # TODO: maybe also log to aot_graphs_log
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:966: # TODO: this isn't exactly right, because cudagraphs needs to be a shared config
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:974: # TODO: this ignores flat_params, which can exist
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1024: pass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1080: # TODO: should we use the same field for remote cache time saved for both
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1095: # Count missing the FXGraphCache as a miss not a bypass
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1101: # Most often this is BypassAOTAutogradCache, but
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1104: # we can always fallback to a cache bypass.
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1112: counters["aot_autograd"]["autograd_cache_bypass"] += 1
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1113: log.info("Bypassing autograd cache due to: %s", e)
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1114: cache_state = "bypass"
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1116: cache_info["cache_bypass_reason"] = str(e)
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1117: cache_info["cache_bypass_exception_type"] = type(e).__name__
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1118: cache_info["cache_bypass_traceback"] = traceback.format_exc().split(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1121: # TODO: this gets logged implicitly by cache_bypass_reason,
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1124: cache_info["cache_bypass_hard_exception"] = not isinstance(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1125: e, BypassAOTAutogradCache
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1128: log_cache_bypass("bypass_aot_autograd", str(e))
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1161: cache_bypass_reason=cache_info.get("cache_bypass_reason"),
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1297: except BypassAOTAutogradCache as e:
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1298: counters["aot_autograd"]["autograd_cache_bypass"] += 1
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1299: log.info("Bypassing autograd cache due to: %s", e)
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1301: log_cache_bypass("bypass_aot_autograd", str(e))
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1306: log_cache_bypass(
- .venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/autograd_cache.py:1307: "bypass_aot_autograd", "Unable to serialize: " + str(e)
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py:16: backward pass to calculate the peak memory usage.
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py:30: peak_memory_after_forward_pass: float,
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py:33: Simulates the backward pass and keeps track of the peak memory usage.
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py:37: Allows you to set the peak memory after the forward pass, but typically this is
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py:51: peak_memory_after_forward_pass (float): The peak memory usage after the forward pass.
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py:54: (peak_memory_after_forward_pass, "Initial Peak/Current Memory")
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py:137: account_for_backward_pass: bool = False,
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py:154: if account_for_backward_pass:
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py:162: peak_memory_after_forward_pass=sum(
- .venv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/knapsack.py:82: # TODO(chilli): I think if needed, this memory can be optimized with sliding
- .venv/lib/python3.12/site-packages/torch/linalg/__init__.py:1063: out (tuple, optional): output tensor. `B` may be passed as `out` and the result is computed in-place on `B`.
- .venv/lib/python3.12/site-packages/torch/linalg/__init__.py:2258: It is possible to compute the solution of the system :math:`XA = B` by passing the inputs
- .venv/lib/python3.12/site-packages/torch/linalg/__init__.py:2375: out (Tensor, optional): output tensor. `B` may be passed as `out` and the result is computed in-place on `B`.
- documentation/safety_README.md:19: - Logs scrub simple secret-looking strings (password, api_key, secret, AKIA).
- documentation/codex_setup_integration.md:14: | 3.1 | Ingestion | Scaffold `Ingestor` | Created | Placeholder NotImplementedError |
- deploy/deploy_codex_pipeline.py:15: pass
- deploy/deploy_codex_pipeline.py:26: pass
- deploy/deploy_codex_pipeline.py:96: pass
- deploy/deploy_codex_pipeline.py:101: pass
- deploy/deploy_codex_pipeline.py:109: pass
- training/checkpoint_manager.py:146: pass
- training/checkpoint_manager.py:165: pass
- training/engine_hf_trainer.py:407: pass
- training/engine_hf_trainer.py:849: pass
- training/engine_hf_trainer.py:861: pass
- training/data_utils.py:146: pass
- training/data_utils.py:192: pass
- training/data_utils.py:217: pass
- training/functional_training.py:225: pass
- training/functional_training.py:254: pass
- training/functional_training.py:414: pass
- .codex/run_db_utils_workflow.py:402: "\n## Pruning\n- No files pruned automatically. Duplicated inference is now routed through helpers via wrapper; manual f
- .codex/run_db_utils_workflow.py:475: pass  # explicit no-op
- .codex/run_repo_scout.py:236: r"\bTODO\b",
- .codex/run_repo_scout.py:248: r"raise\s+NotImplementedError",
- .codex/run_repo_scout.py:249: r"^\s*pass\s*(#.*)?$",
- .codex/run_repo_scout.py:253: r"throw\s+new\s+Error\(['\"]TODO",
- .codex/run_repo_scout.py:258: r"throw\s+new\s+Error\(['\"]TODO",
- .codex/run_repo_scout.py:263: "sql": [r"--\s*TODO", r"/\*\s*TODO"],
- .codex/run_repo_scout.py:264: "html": [r"<!--\s*TODO"],
- .codex/run_workflow.py:316: pass  # keep open when pooled
- .codex/run_workflow.py:350: pass
- .codex/run_workflow.py:488: pass
- .codex/results.md:44: 83 passed, 3 skipped, 8 xfailed, 2 xpassed, 2 warnings in 7.91s
- .codex/results.md:271: 8 passed, 1 skipped in 29.46s
- .codex/results.md:279: 5 passed in 0.06s
- .codex/results.md:316: 3 passed in 0.07s
- .codex/results.md:4556: ====================================================== 4 passed in 0.05s ===============================================
- .codex/codex_repo_scout.py:235: pass
- .codex/codex_repo_scout.py:238: r"\b(TODO|FIXME|WIP|TBD|XXX|NotImplemented)\b", txt, flags=re.IGNORECASE
- .codex/codex_repo_scout.py:266: r"\b(TODO|FIXME|WIP|TBD|XXX|NOT\s*IMPLEMENTED|NotImplemented)\b", re.IGNORECASE
- .codex/codex_repo_scout.py:268: PY_NOTIMPL_PAT = re.compile(r"raise\s+NotImplementedError\b")
- .codex/codex_repo_scout.py:269: PY_PASS_OR_ELLIPSIS = re.compile(r"^\s*(pass|\.{3})\s*$")
- .codex/codex_repo_scout.py:315: if "NotImplementedError" in line:
- .codex/codex_repo_scout.py:335: if "exit 1" in line and ("TODO" in line or "TBD" in line):
- .codex/codex_repo_scout.py:381: pass
- .codex/notes/Codex_Questions.md:21: ## While performing [AGENTS: pytest], encountered failures (`8 failed, 159 passed, ...`).
- .codex/notes/Codex_Questions.md:23: **Resolution:** Skip tests when optional dependencies are missing and standardize text handling to UTF-8. After installi
- .codex/notes/CODEBASE_AUDIT.md:27: - `tools/apply_interfaces.py` – multiple `TODO`/`NotImplementedError` placeholders.
- .codex/notes/CODEBASE_AUDIT.md:28: - `functional_training.py` – several `pass` statements for unimplemented paths.
- .codex/notes/CODEBASE_AUDIT.md:29: - `configs/interfaces.example.yaml` – references TODO module paths.
- .codex/notes/CODEBASE_AUDIT.md:46: | Documentation & Examples | Implemented | `README`, `docs/`, notebooks | Some README badges TODO, examples minimal | Us
- .codex/notes/CODEBASE_AUDIT.md:48: | Extensibility | Partially Implemented | Interface classes (tokenizer, RL agent), modular data loaders | Registry/plug-
- .codex/notes/CODEBASE_AUDIT.md:58: - README badges and interface config placeholders contain TODOs, indicating unfinished onboarding materials.
- .codex/notes/CODEBASE_AUDIT.md:61: - Tools directory contains numerous `TODO` and `NotImplementedError` markers, suggesting incomplete automation.
- .codex/notes/CODEBASE_AUDIT.md:103: *Risk*: adds optional dependency; misuse of config may break forward pass.
- .codex/status/_codex_status_update-2025-09-03.md:7: - `src/codex_ml/pipeline.py` raises `NotImplementedError` for the real training pipeline.
- .codex/status/_codex_status_update-2025-09-03.md:8: - Interfaces under `src/codex_ml/interfaces/` define abstract methods with `NotImplementedError`.
- .codex/status/_codex_status_update-2025-09-03.md:9: - `codex_digest/tokenizer.py` is a stub (`NotImplementedError`).
- .codex/status/_codex_status_update-2025-09-03.md:10: - `configs/interfaces.example.yaml` contains TODO placeholders for tokenizer wiring.
- .codex/status/_codex_status_update-2025-09-03.md:11: - Various tests (`tests/test_offline_repo_auditor.py`, interface tests) include TODO comments and unimplemented assertio
- .codex/status/_codex_status_update-2025-09-03.md:27: | Documentation & Examples | Partially Implemented | `README.md`, `docs/`, `examples/`, notebooks | No quickstart; noteb
- .codex/status/_codex_status_update-2025-09-03.md:39: - Documentation missing quickstart and example notebook remains TODO.
- .codex/status/_codex_status_update-2025-09-04.md:7: - `src/codex_ml/pipeline.py` raises `NotImplementedError` for the real training pipeline.
- .codex/status/_codex_status_update-2025-09-04.md:8: - Interfaces under `src/codex_ml/interfaces/` define abstract methods with `NotImplementedError`.
- .codex/status/_codex_status_update-2025-09-04.md:9: - `codex_digest/tokenizer.py` is a stub (`NotImplementedError`).
- .codex/status/_codex_status_update-2025-09-04.md:10: - `configs/interfaces.example.yaml` contains TODO placeholders for tokenizer wiring.
- .codex/status/_codex_status_update-2025-09-04.md:11: - Various tests (`tests/test_offline_repo_auditor.py`, interface tests) include TODO comments and unimplemented assertio
- .codex/status/_codex_status_update-2025-09-04.md:29: | Documentation & Examples | Partially Implemented | `README.md`, `docs/`, `examples/`, notebooks | No quickstart; noteb
- .codex/status/_codex_status_update-2025-09-04.md:42: - Documentation missing quickstart and example notebook remains TODO.
- .codex/status/_codex_status_update-2025-09-14.md:17: | **src/codex/** | Houses CLI entry points (`cli.py`), chat logging (`chat.py`), session logging (`logging/session_logge
- .codex/status/_codex_status_update-2025-09-14.md:28: * **`_fix_pool()` stub** in `src/codex/cli.py` is marked `# TODO` and never called. It likely intended to configure a th
- .codex/status/_codex_status_update-2025-09-14.md:42: | **ChatGPT Codex modeling** (model init, dtype, device placement, LoRA/PEFT hooks) | **Partially implemented** | Model 
- .codex/status/_codex_status_update-2025-09-14.md:79: **Why:** The CLI defines a `_fix_pool()` function that is never implemented but could provide CPU parallelism or concurr
- .codex/status/_codex_status_update-2025-09-14.md:87: - """TODO: fix tokenization parallelism pool"""
- .codex/status/_codex_status_update-2025-09-14.md:88: - raise NotImplementedError("_fix_pool is not implemented yet")
- .codex/status/_codex_status_update-2025-09-14.md:113: + pass
- .codex/status/_codex_status_update-2025-09-14.md:120: **Rollback:** Remove the body of `_fix_pool` and restore the original `NotImplementedError`. Alternatively, guard the ca
- .codex/status/_codex_status_update-2025-09-14.md:125: **Why:** LoRA parameters exist in configs but are not passed into the training engine. Users cannot enable LoRA from the
- .codex/status/_codex_status_update-2025-09-14.md:344: - Run `pytest` and `nox` sessions to ensure all tests pass locally without network access.
- .codex/status/_codex_status_update-2025-09-05.md:7: - `src/codex_ml/pipeline.py` raises `NotImplementedError` for the real training pipeline.
- .codex/status/_codex_status_update-2025-09-05.md:8: - Interfaces under `src/codex_ml/interfaces/` define abstract methods with `NotImplementedError`.
- .codex/status/_codex_status_update-2025-09-05.md:9: - `codex_digest/tokenizer.py` is a stub (`NotImplementedError`).
- .codex/status/_codex_status_update-2025-09-05.md:10: - `configs/interfaces.example.yaml` contains TODO placeholders for tokenizer wiring.
- .codex/status/_codex_status_update-2025-09-05.md:11: - Various tests (`tests/test_offline_repo_auditor.py`, interface tests) include TODO comments and unimplemented assertio
- .codex/status/_codex_status_update-2025-09-05.md:12: - Scaffolding utilities under `tools/` (for example, `apply_interfaces.py`) contain multiple `NotImplementedError` place
- .codex/status/_codex_status_update-2025-09-05.md:31: | Documentation & Examples | Partially Implemented | `README.md`, `docs/`, `examples/`, notebooks | No quickstart; noteb
- .codex/status/_codex_status_update-2025-09-05.md:47: - Documentation missing quickstart and example notebook remains TODO.
- .codex/status/_codex_status_update-2025-09-05.md:50: - Code-generation tools in `tools/` remain scaffolds with `NotImplementedError` placeholders.
- .codex/status/_codex_status_update-2025-08-28.md:16: - Numerous `pass` / `NotImplementedError` markers across `codex_ml` utilities (e.g., `src/codex_ml/utils/checkpointing.p
- .codex/status/_codex_status_update-2025-08-28.md:26: | ChatGPT Codex Modeling | Partially Implemented | `functional_training.py`, `codex_script.py` load `AutoModelForCausalL
- .codex/status/_codex_status_update-2025-08-28.md:36: | Documentation & Examples | Partially Implemented | `README.md`, `docs/`, `examples/`, notebooks | Many TODO stubs, out
- .codex/status/_codex_status_update-2025-08-28.md:52: 12. README and examples contain numerous TODOs and placeholders.
- .codex/status/_codex_status_update-2025-08-28.md:66: -        raise NotImplementedError
- .codex/status/_codex_status_update-2025-08-28.md:94: -    pass
- .codex/status/_codex_status_update-2025-09-02.md:7: - `training/engine_hf_trainer.py` contains TODO for loading optimizer state.
- .codex/status/_codex_status_update-2025-09-02.md:8: - `src/codex/cli.py` defines command groups with `pass` implementations.
- .codex/status/_codex_status_update-2025-09-02.md:17: | Training Engine | Partially Implemented | `training/engine_hf_trainer.py` | Resume checkpoints TODO, gradient accumula
- .codex/status/_codex_status_update-2025-09-02.md:62: -            # TODO: load model/optimizer state when supported

#### Missing configs
- Present: configs/training/base.yaml
- Present: configs/data/base.yaml
- Present: configs/tokenization/base.yaml

- Created `configs/training/base.yaml` with default hyper-parameters (seed, lr, batch_size, scheduler, warmup, gradient accumulation, logging flags, dataset paths).

- Replaced `train` CLI command with config-driven implementation supporting `--config`, `--resume`, and `--seed` options.
- Implemented `run_functional_training` in `src/codex_ml/training.py` with resume support and deterministic checkpointing via AST transformation.
- Added pytest `tests/test_training_config_yaml.py` to validate default YAML values.
- Added CLI integration test `tests/test_cli_train_command.py` ensuring checkpoints are created.
- Added resume regression test `tests/test_training_resume.py` verifying training resumes from last checkpoint.
- Extended training config with legacy HuggingFace trainer keys for compatibility.
- Updated `README.md` to document the `codex_cli train` command and default YAML config.
- Documented the new CLI integration in `docs/modules/training_engine.md`.
- Deferred multi-GPU and HF Trainer enhancements; existing pathways untouched to avoid regression risk.
- Deferred full evaluation CLI overhaul pending availability of reference datasets.
- Pytest run failed: missing optional dependencies (`torch`, `numpy`, `pydantic`, `transformers`) required by existing suite.

Update steps completed with noted test dependency gaps.
