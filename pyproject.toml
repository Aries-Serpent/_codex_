[tool.ruff]
line-length = 100
target-version = "py312"

[tool.ruff.lint]
select = ["E", "F", "I"]
ignore = ["E501"]

[tool.ruff.lint.isort]
known-first-party = ["codex"]

[tool.black]
line-length = 100
target-version = ["py312"]

[tool.isort]
profile = "black"  # keep isort aligned with Black to avoid formatting churn

[tool.mypy]
python_version = "3.12"
ignore_missing_imports = true

[[tool.mypy.overrides]]
module = "tests._codex_introspect"
ignore_errors = true

[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
description = "Codex utilities and scripts"
name = "codex"
version = "0.1.0"
authors = [{ name = "Aries-Serpent" }]
requires-python = ">=3.10"
readme = "README.md"
# Core runtime deps for all environments.
# IMPORTANT: torch MUST NOT be in base (we install it via optional groups / scripts).
dependencies = [
    # Support both legacy and new Accelerate via runtime shim
    "accelerate>=0.20.1",
    "transformers>=4.41",
    "hydra-core>=1.3",
    "PyYAML>=6",
]

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]
include = ["codex*", "tokenization"]


[project.optional-dependencies]
cli = ["typer>=0.9", "rich>=13"]
tracking = ["mlflow>=2"]
peft = ["peft>=0.10.0"]

# Dev tools live here so Codex can opt-in explicitly (or you use them locally/CI).
dev = [
  "pytest>=8.3",
  "pytest-cov>=6.0",
  "ruff>=0.4",
  "mypy>=1.10",
  "nox>=2024.4.15",
]

test = [
  "datasets>=2.19",
  "duckdb>=1.0",
  "fastapi>=0.111",
  "httpx>=0.27",
  "pandas>=2.1",
  "scikit-learn>=1.3",
  "peft>=0.10.0",
  "sentencepiece>=0.1.99",
  "zstandard>=0.22",
  "h5py>=3.10",
]

# CPU group: safe for Codex. In Codex we still explicitly pin the CPU index in scripts
# (uv pip install --index-url https://download.pytorch.org/whl/cpu torch),
# but keeping this group means `uv sync --extra cpu` works outside Codex too.
cpu = [
  "torch>=2.3 ; python_version>='3.10'"
]

# GPU group: only for environments that *actually* have CUDA (NOT Codex).
# Outside Codex, youâ€™d install with the proper CUDA index URL, e.g.:
#   pip install --index-url https://download.pytorch.org/whl/cu121 torch==2.8.0
gpu = [
  "torch>=2.3"
]

[project.scripts]
codex-import-ndjson = "codex.logging.import_ndjson:main"
codex-ml-cli = "codex_ml.cli.main:main"
codex-train = "codex_script:main"
codex-tokenizer = "tokenization.cli:app"
codex-generate = "codex_ml.cli.generate:main"
codex-infer = "codex_ml.cli.infer:main"
codex-validate-config = "codex_ml.cli.validate:main"

# Coverage configuration
[tool.coverage.run]
branch = true
parallel = true

# BEGIN: CODEX_PYTEST_COVERAGE
[tool.pytest.ini_options]
addopts = "--cov=src --cov-report=term-missing --cov-report=xml:artifacts/coverage.xml --cov-fail-under=80"
# END: CODEX_PYTEST_COVERAGE
# BEGIN: CODEX_IFACE_ENTRYPOINTS
# [project.entry-points."codex_ml.tokenizers"]
# mytokenizer = "yourpkg.tokenizers.hf:HFTokenizer"
# [project.entry-points."codex_ml.reward_models"]
# simple = "yourpkg.rewards.simple:SimpleReward"
# [project.entry-points."codex_ml.rl_agents"]
# ppo = "yourpkg.rl.ppo:PPOAgent"
# END: CODEX_IFACE_ENTRYPOINTS
