# ğŸ“_codex_: Status Update (2025-09-22)

## 1. Repo Map
- **Key directories.** `.codex/` captures generated manifests, status artefacts and gate telemetry, while `src/`, `codex_ml/`, `configs/`, `tools/`, `docs/`, `tests/`, `tokenization/`, `training/`, `analysis/` and `services/` house the runtime stack, automation, documentation and integration assets that underpin the platform.ã€de69c2â€ L1-L17ã€‘
- **Key files.** `pyproject.toml` centralises the pinned runtime plus optional extras for CLI, tracking, PEFT and hardware-specific torch builds; `noxfile.py` enforces offline gate execution with pinned toolchains and coverage artefact logging; and `tools/status/generate_status_update.py` produces deterministic audits for the `.codex/status/` ledger.ã€F:pyproject.tomlâ€ L1-L56ã€‘ã€F:noxfile.pyâ€ L1-L89ã€‘ã€F:tools/status/generate_status_update.pyâ€ L1-L46ã€‘
- **Stubs & placeholders.** The latest automated scan still reports 51 trivial bodies or `NotImplementedError` blocks across connectors, RL interfaces and legacy CLI shims, and highlights that two packages (`src/data`, `src/safety`) remain gitkeep-only placeholders until filled in.ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L5-L79ã€‘
- **Recent additions.** The unreleased changelog documents freshly added offline dependency stubs, refreshed gating manifests, deterministic tokenizer and MiniLM tests, and regenerated status artefacts to keep the audit trail current.ã€F:CHANGELOG.mdâ€ L1-L24ã€‘

## 2. Capability Audit Table
| Capability | Status | Existing Artifacts | Gaps | Risks | Minimal Patch Plan | Rollback Plan |
| --- | --- | --- | --- | --- | --- | --- |
| Tokenization (fast tokenizer, vocab, encode/decode, padding/truncation) | Implemented (optional deps required) | Typer-based CLI commands, SentencePiece training pipeline, and runtime adapters covering Hugging Face, SentencePiece and whitespace tokenisers with BOS/EOS metadata.ã€F:src/tokenization/cli.pyâ€ L1-L159ã€‘ã€F:src/tokenization/train_tokenizer.pyâ€ L1-L155ã€‘ã€F:src/codex_ml/tokenization/__init__.pyâ€ L1-L109ã€‘ | CLI fallback raises at encode time when the `tokenizers` wheel is absent, so offline encode flows depend on installing optional binaries.ã€F:src/tokenization/cli.pyâ€ L91-L149ã€‘ | Audit or smoke runs without `tokenizers` fail to exercise encode/decode, masking regressions until dependencies are restored.ã€F:src/tokenization/cli.pyâ€ L91-L149ã€‘ | Ship a pure-Python encode fallback (e.g., reuse the whitespace adapter) and gate the optional fast path behind a capability flag; add regression tests in `tests/tokenization` for both code paths. | Revert the fallback helper and restore the current optional-only behaviour if compatibility issues surface. |
| ChatGPT Codex Modeling (model init, dtype, device placement, LoRA/PEFT hooks) | Partially implemented | Built-in MiniLM and decoder-only Transformer models wire through the registry and honour LoRA, dtype and device flags when constructing instances.ã€F:src/codex_ml/models/minilm.pyâ€ L1-L83ã€‘ã€F:src/codex_ml/models/decoder_only.pyâ€ L1-L79ã€‘ã€F:src/codex_ml/models/registry.pyâ€ L16-L89ã€‘ | Only two registry entries ship by default, leaving most connector registries empty and pushing users to author plugins before common baselines (e.g., GPT-style checkpoints) are reachable.ã€F:src/codex_ml/models/registry.pyâ€ L16-L60ã€‘ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L126-L137ã€‘ | Limited catalogue makes evaluation/experimentation brittle and increases drift risk when teams improvise local forks. | Promote additional pre-trained decoders (e.g., GPT2/GPTNeoX) into the registry with local-files-only guards and document how to extend configs. | Drop the new registry rows to fall back to the minimal MiniLM footprint if downstream validation fails. |
| Training Engine (HF Trainer or custom loop, precision, gradient accumulation) | Implemented (dependency-sensitive) | The symbolic training CLI, checkpoint manager, and toy train loop provide seed control, gradient accumulation, metric logging, retention policies and resume semantics.ã€F:src/codex/training.pyâ€ L1-L82ã€‘ã€F:src/codex_ml/utils/checkpointing.pyâ€ L420-L599ã€‘ã€F:src/codex_ml/train_loop.pyâ€ L1-L189ã€‘ | The default test run fails without heavyweight extras (torch, hydra, numpy, typer), showing the engine still assumes optional stacks are present even though stubs exist.ã€6e9466â€ L1-L75ã€‘ | Offline QA can miss regressions because collection stops when import errors surface instead of exercising the guarded code paths. | Add lightweight smoke fixtures that skip gracefully when extras are absent and exercise the pure-Python fallbacks; ensure `pytest -q` emits skips instead of hard errors. | Remove the new smoke fixtures if they prove flaky and reinstate the current skip-all strategy. |
| Configuration Management (Hydra/YAML structure, overrides, sweeps) | Partially implemented | Hydra-compatible YAML defaults and a Pydantic schema validate base training settings while the safety policy ships alongside configs.ã€F:configs/base.yamlâ€ L1-L21ã€‘ã€F:src/codex_ml/config_schema.pyâ€ L1-L70ã€‘ã€F:configs/safety/policy.yamlâ€ L1-L82ã€‘ | The local Hydra shim attempts to defer to the real package but exposes no-op APIs when Hydra is missing, which currently breaks config validation tests.ã€F:hydra/__init__.pyâ€ L1-L119ã€‘ã€6e9466â€ L1-L30ã€‘ | Contributors may believe Hydra overrides are supported even though the shim silently omits compose/initialise helpers, leading to runtime surprises. | Vendor a minimal compose/initialize wrapper (using OmegaConf) so basic overrides work offline and update docs to list fully supported patterns. | Restore the current shim by reverting the wrapper module if behavioural differences break existing automation. |
| Evaluation & Metrics (validation loops, metrics API, NDJSON/CSV logging) | Implemented | The evaluation runner emits NDJSON/CSV logs, bootstrapped confidence intervals and leverages the metric registry (accuracy, perplexity, EM, F1, diversity).ã€F:src/codex_ml/eval/eval_runner.pyâ€ L1-L128ã€‘ã€F:src/codex_ml/metrics/registry.pyâ€ L1-L144ã€‘ | Automated scan notes that many metrics/eval modules lack direct test references, leaving the registry additions thinly validated offline.ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L139-L159ã€‘ | Silent metric drift or schema regressions could slip through when datasets evolve without corresponding test coverage. | Add focused tests for each metric/eval path and capture golden NDJSON snapshots to flag schema changes. | Drop the new tests if they cause instability and rely on manual validation while gaps are triaged. |
| Logging & Monitoring (TensorBoard / W&B / MLflow, system metrics via psutil/NVML) | Partially implemented | Unified logger bootstrap toggles TensorBoard, W&B, MLflow and NVML-aware GPU sampling, while system metrics helpers stream psutil telemetry to NDJSON.ã€F:src/codex_ml/monitoring/codex_logging.pyâ€ L1-L103ã€‘ã€F:src/codex_ml/monitoring/system_metrics.pyâ€ L1-L162ã€‘ | GPU/NVML support and psutil sampling are optional; when psutil is absent the background logger raises, and most registries stay empty so plugins must be provided manually.ã€F:src/codex_ml/monitoring/system_metrics.pyâ€ L82-L143ã€‘ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L126-L137ã€‘ | Missing telemetry dependencies degrade monitoring to no-ops, hiding performance regressions during long offline runs. | Ship psutil as part of the default dev extra, guard NVML initialisation with feature flags, and extend docs with fallback guidance. | Remove the psutil dependency bump if environments cannot accommodate it and keep the current best-effort behaviour. |
| Checkpointing & Resume (weights, optimizer state, scheduler, RNG, best-k retention) | Implemented | `CheckpointManager` persists RNG state, metrics metadata, best-k tracking and handles resume-from-latest, verifying checksums before restore.ã€F:src/codex_ml/utils/checkpointing.pyâ€ L420-L620ã€‘ | End-to-end tests still fail without torch and numpy even though the code handles CPU fallbacks, leaving resume paths unverified in minimal environments.ã€6e9466â€ L1-L49ã€‘ | Operators may assume resume works offline while the lack of exercised coverage masks serializer regressions. | Introduce torch-less smoke tests that save dummy payloads via the pickle path and validate checksum manifests. | Revert the smoke tests if they introduce excessive maintenance overhead relative to the risk. |
| Data Handling (dataset splits, deterministic shuffling, caching) | Implemented | Deterministic split helpers emit manifests and checksums, and the Hugging Face loader falls back to local line datasets when `datasets` is unavailable.ã€F:src/codex_ml/data/split.pyâ€ L1-L118ã€‘ã€F:src/codex_ml/data/hf_datasets.pyâ€ L1-L38ã€‘ | Broader dataset registries remain empty, so advanced loaders or caching policies must be wired manually per project.ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L126-L137ã€‘ | Without curated registries teams may reimplement loaders inconsistently, risking data leakage between experiments. | Populate the dataset registry with canonical corpora (and checksum manifests) plus document cache directory conventions. | Remove new registry entries if downstream deployments prefer bespoke loaders. |
| Security & Safety (dependency locking, secrets scanning, prompt safety) | Partially implemented | Safety filters support deny/allow/redaction rules with environment-configured policy files and dedicated logging, and the repo distributes a default policy pack.ã€F:src/codex_ml/safety/filters.pyâ€ L1-L74ã€‘ã€F:configs/safety/policy.yamlâ€ L1-L99ã€‘ | Automated scans still list empty connector/search scaffolding and no automated secrets audit, so coverage depends on manual policy maintenance.ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L21-L36ã€‘ | Missing connectors/tests could let unsafe prompts or secrets bypass enforcement until a human reviews the logs. | Extend the safety suite with detector unit tests plus a lightweight secrets scan in pre-commit, and document policy review cadence. | Disable the new hooks if they create false positives and rely on manual review in the interim. |
| Internal CI/Test (pytest targets, tox/nox local gates, coverage enforcement) | Partially implemented | `noxfile.py` provisions reproducible sessions, locks torch installs, logs coverage hashes and integrates with session logging; `pytest.ini` standardises markers and paths.ã€F:noxfile.pyâ€ L1-L120ã€‘ã€F:pytest.iniâ€ L1-L18ã€‘ | Running `pytest -q` on a bare environment still fails fast because optional dependencies are missing, so the intended skip markers are not exercised.ã€6e9466â€ L1-L75ã€‘ | Offline validation pipelines halt before running tests that would otherwise skip, obscuring regressions until dependencies are installed. | Add a `nox -s smoke` session that installs only core deps, validates skip behaviour and documents the expected warning output. | Remove the smoke session if it proves redundant once dependency pinning is widely adopted. |
| Deployment (packaging, CLI entry points, Docker infra) | Partially implemented | Multi-stage Dockerfile builds the API service image with health checks and pinned base packages while CLI entry points live in `pyproject`.ã€F:Dockerfileâ€ L1-L21ã€‘ã€F:pyproject.tomlâ€ L1-L33ã€‘ | Container only covers the API slice; broader training/eval images or compose manifests are still placeholders, limiting one-command reproducibility. | Deployments that require training/eval contexts must craft bespoke images, increasing divergence from audited artefacts. | Author minimal training/eval Docker targets (CPU-focused) and document usage alongside the existing API image. | Delete the additional Docker targets if they inflate maintenance cost; the API image already has rollback instructions. |
| Documentation & Examples (README, quickstarts, diagrams, notebooks) | Implemented | Quickstart guide walks through offline environment bootstrapping, tokenizer usage, training, evaluation and telemetry inspection with reproducible commands.ã€F:docs/quickstart.mdâ€ L1-L55ã€‘ | Large portions of the docs backlog flagged by earlier audits (architecture diagrams, connector walkthroughs) remain unimplemented, and empty registries have no companion guides.ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L126-L137ã€‘ | Contributors rely on stale or missing docs for unfinished modules, increasing onboarding time and misconfiguration risk. | Expand docs with registry how-tos and link remediation plans to concrete examples; include generated diagrams or links once assets exist. | Revert to the lean quickstart if expanded docs fall out of sync; highlight the authoritative remediation plan instead. |
| Experiment Tracking (MLflow local tracking, W&B offline mode) | Implemented (opt-in) | MLflow helpers respect offline env vars and optional enable flags, and the ops guide explains how to activate MLflow/TensorBoard/W&B in local-only mode.ã€F:src/codex_ml/monitoring/mlflow_utils.pyâ€ L1-L72ã€‘ã€F:docs/ops/experiment_tracking.mdâ€ L1-L63ã€‘ | Optional dependencies remain disabled by default; without psutil/mlflow installs, telemetry devolves to JSON dumps and requires manual activation. | Teams may assume tracking is live when runs actually emit NDJSON only, reducing experiment reproducibility. | Ship a status banner in training/eval CLIs indicating which tracking backends are active and include smoke assertions in examples. | Remove the banner if it causes noise and retain current opt-in semantics. |
| Extensibility (pluggable components, registry patterns) | Partially implemented | Plugin registry infrastructure enforces collision detection and now ships a guarded offline catalogue covering GPT-2/TinyLLaMA assets, the tiny corpus, weighted accuracy, plus functional trainer and heuristic reward-model shims with Hydra/CLI coverage.ã€F:src/codex_ml/plugins/registries.pyâ€ L210-L531ã€‘ã€F:configs/offline/catalogue.yamlâ€ L1-L30ã€‘ã€F:configs/training/offline/functional.yamlâ€ L1-L22ã€‘ã€F:docs/guides/offline_catalogue.mdâ€ L45-L108ã€‘ã€F:tests/test_model_registry.pyâ€ L131-L142ã€‘ã€F:tests/test_data_registry.pyâ€ L50-L60ã€‘ã€F:tests/test_metric_registry.pyâ€ L54-L64ã€‘ã€F:tests/test_trainer_reward_registry.pyâ€ L5-L38ã€‘ | Additional connector and analysis registries remain empty, so bespoke integrations still require custom adapters for now.ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L126-L137ã€‘ | Leaving advanced registries sparse may encourage teams to bypass the shared catalogue, fragmenting extension points. | Continue seeding connector/RL registries with audited fixtures and document third-party entry-point publishing patterns alongside the offline preset. | Remove the composite preset if it proves confusing and fall back to manual overrides while retaining the individual entries. |

## 3. High-Signal Findings
1. Automated scanning still reports 51 stubbed symbols across CLI shims, connectors and interfaces, signalling the need to prioritise filling or decommissioning scaffolding that lingers in the tree.ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L5-L68ã€‘
    - **Implementation status.** Core runtime adapters (e.g., connectors, RL agent, tokenizer abstractions) now ship concrete implementations with coverage, replacing the empty bodies highlighted in earlier audits.ã€F:src/codex_ml/connectors/base.pyâ€ L1-L139ã€‘ã€F:src/codex_ml/interfaces/rl.pyâ€ L1-L148ã€‘ã€F:src/codex_ml/interfaces/tokenizer.pyâ€ L1-L120ã€‘ã€F:tests/connectors/test_local_connector.pyâ€ L1-L26ã€‘
    - **Completion criteria.** Remaining `pass` placeholders in legacy CLI groups (e.g., `codex.cli:cli/logs`) need real command wiring or intentional removal to declare the stub count closed.ã€F:src/codex/cli.pyâ€ L100-L149ã€‘
2. Twelve modules (including monitoring CLIs and dataset loaders) lack direct test references, so gating on `pytest -q` requires either optional dependency installation or additional smoke coverage to avoid silent regressions.ã€F:.codex/status/_codex_status_update-2025-09-18.mdâ€ L139-L168ã€‘ã€6e9466â€ L1-L75ã€‘
    - **Implementation status.** Newly added async connector and RNG checkpoint suites demonstrate the pattern for lightweight smoke coverage without heavy dependencies, showing that the test harness can exercise optional paths incrementally.ã€F:tests/connectors/test_local_connector.pyâ€ L1-L26ã€‘ã€F:tests/utils/test_checkpoint_rng.pyâ€ L1-L25ã€‘
    - **Completion criteria.** Author focused smoke tests for the uncovered modules (e.g., `codex_ml.monitoring.cli`, `codex_ml.plugins.registries`, `codex_ml.data.cli`) that `importorskip` heavy extras yet validate CLI wiring; the monitoring CLI already exposes deterministic transforms suitable for fixture-based assertions.ã€F:src/codex_ml/monitoring/cli.pyâ€ L1-L60ã€‘ã€F:src/codex_ml/plugins/registries.pyâ€ L1-L57ã€‘ã€F:src/codex_ml/data/cli.pyâ€ L1-L120ã€‘
3. The Hydra shim continues to mask missing functionality, and config-related tests fail without the real libraryâ€”updating the shim or providing OmegaConf fallbacks should be treated as a near-term remediation item.ã€F:hydra/__init__.pyâ€ L1-L122ã€‘ã€6e9466â€ L1-L30ã€‘
    - **Implementation status.** The shim now attempts to load the real Hydra package from virtual environments and gracefully falls back to a no-op `main` decorator, eliminating import-time crashes in offline runs.ã€F:hydra/__init__.pyâ€ L1-L94ã€‘
    - **Completion criteria.** Provide minimal `initialize`/`compose` wrappers backed by OmegaConf so configuration overrides work identically offline, and document the supported subset directly in the shim once parity is achieved.ã€F:hydra/__init__.pyâ€ L95-L122ã€‘
4. The checkpoint manager now stores RNG state, metadata and best-k rotation, meaning resume workflows are feature-complete once torch-backed smoke tests are restored.ã€F:src/codex_ml/utils/checkpointing.pyâ€ L420-L567ã€‘
    - **Implementation status.** Regression tests already confirm RNG round-trips and best-k manifests, validating the persistence guarantees without requiring torch on disk.ã€F:tests/utils/test_checkpoint_rng.pyâ€ L1-L25ã€‘
    - **Completion criteria.** Re-enable a torch-backed smoke in CI once optional wheels are available so GPU/optimizer state restoration paths are validated alongside the pickle fallback.ã€F:src/codex_ml/utils/checkpointing.pyâ€ L462-L544ã€‘
5. Training and evaluation loops consistently emit NDJSON/CSV metrics alongside config hashes, providing reproducibility hooks that can be tapped by additional automation or dashboards.ã€F:src/codex_ml/train_loop.pyâ€ L1-L199ã€‘ã€F:src/codex_ml/eval/eval_runner.pyâ€ L1-L109ã€‘
    - **Implementation status.** Both loops already stream metrics and provenance to deterministic JSON artefacts, and evaluation bootstraps metrics with optional confidence intervals for audit trails.ã€F:src/codex_ml/train_loop.pyâ€ L80-L199ã€‘ã€F:src/codex_ml/eval/eval_runner.pyâ€ L49-L109ã€‘
    - **Completion criteria.** Add automation hooks that ingest the NDJSON outputs into the monitoring CLI (or dashboards) so regressions surface automatically instead of relying on manual inspection.ã€F:src/codex_ml/monitoring/cli.pyâ€ L11-L55ã€‘
6. Offline logging continues to improve with unified CLI flags and psutil-backed system metrics, but missing psutil/NVML installations still degrade telemetry to no-opsâ€”pinning psutil in dev environments is recommended.ã€F:src/codex_ml/monitoring/codex_logging.pyâ€ L1-L200ã€‘ã€F:src/codex_ml/monitoring/system_metrics.pyâ€ L1-L167ã€‘
    - **Implementation status.** Telemetry bootstrappers now expose consistent CLI/Hydra flags, and the system metrics logger records host telemetry whenever psutil is available.ã€F:src/codex_ml/monitoring/codex_logging.pyâ€ L77-L200ã€‘ã€F:src/codex_ml/monitoring/system_metrics.pyâ€ L26-L167ã€‘
    - **Completion criteria.** Ship `psutil` inside the `dev` extra so local smoke runs have telemetry by default, and gate NVML setup behind explicit feature flags to avoid runtime failures when CUDA libraries are absent.ã€F:pyproject.tomlâ€ L32-L96ã€‘ã€F:src/codex_ml/monitoring/codex_logging.pyâ€ L98-L117ã€‘
7. Deterministic dataset splitting now writes manifests and checksums, aligning with reproducibility goals and giving future audits concrete artefacts to diff.ã€F:src/codex_ml/data/split.pyâ€ L1-L198ã€‘
    - **Implementation status.** The helper emits schema-tagged manifests plus checksum files, making it trivial to audit dataset drift across runs.ã€F:src/codex_ml/data/split.pyâ€ L18-L198ã€‘
    - **Completion criteria.** Integrate the manifest writer with dataset registry entries so each canonical corpus advertises its checksum set alongside loading helpers.ã€F:src/codex_ml/data/registry.pyâ€ L13-L101ã€‘
8. Experiment tracking remains opt-in; the ops guide outlines MLflow/W&B offline flows, but CLI banners or smoke outputs would help prevent misunderstandings about active backends.ã€F:docs/ops/experiment_tracking.mdâ€ L1-L63ã€‘
    - **Implementation status.** Documentation clearly states offline-first workflows and the CLI flags required to enable MLflow, TensorBoard or W&B locally.ã€F:docs/ops/experiment_tracking.mdâ€ L10-L63ã€‘
    - **Completion criteria.** Update training/eval CLIs to emit a startup summary of enabled trackers (e.g., MLflow URI, TensorBoard logdir) so users immediately see which integrations are active.ã€F:src/codex_ml/train_loop.pyâ€ L180-L199ã€‘
9. Quickstart documentation already demonstrates fully offline bootstrapping (uv sync, tokenizer training, toy training, evaluation), making it a reliable onboarding entry point for new contributors.ã€F:docs/quickstart.mdâ€ L1-L55ã€‘
    - **Implementation status.** Step-by-step commands cover environment setup, tokenizer usage, deterministic training, evaluation and telemetry inspection without network calls.ã€F:docs/quickstart.mdâ€ L7-L55ã€‘
    - **Completion criteria.** Link each quickstart stage to the corresponding automation (status generator, manifest writer, monitoring CLI) so new contributors can trace how artefacts flow into audits automatically.ã€F:tools/status/generate_status_update.pyâ€ L1-L46ã€‘ã€F:src/codex_ml/monitoring/cli.pyâ€ L11-L55ã€‘
10. The changelog confirms recurring offline hardening work (dependency stubs, regenerated status artefacts), showing that audit hygiene is embedded in day-to-day maintenance.ã€F:CHANGELOG.mdâ€ L1-L32ã€‘
    - **Implementation status.** Recent entries log dependency pins, regenerated status artefacts and regression tests that align with the remediation roadmap.ã€F:CHANGELOG.mdâ€ L3-L32ã€‘
    - **Completion criteria.** Continue tying each high-signal remediation (tests, telemetry guards, registry population) to explicit changelog bullets so auditors can trace when gaps closed relative to status updates.ã€F:CHANGELOG.mdâ€ L3-L32ã€‘

## 4. Testing
- `pytest -q` â€“ **failed** because optional dependencies such as `torch`, `hydra`, `numpy` and `typer` are not installed in the current offline environment; collection stops before reaching guarded skips.ã€6e9466â€ L1-L75ã€‘

## 5. Outstanding Codex Automation Questions
<!-- Copied from docs/status_update_outstanding_questions.md -->

> 2025-09-18: Base and optional extras now use strict version pins in `pyproject.toml` and the refreshed lock files. Use `uv sync --frozen` (or `uv pip sync requirements.lock`) and avoid `pip install -U ...` when preparing environments so the gates run against the pinned toolchain.ã€F:docs/status_update_outstanding_questions.mdâ€ L1-L37ã€‘

| Timestamp(s) | Step / Phase | Recorded blocker | Status | Still Valid? | Current disposition |
| --- | --- | --- | --- | --- | --- |
| 2025-08-26T20:36:12Z | Audit bootstrap (STEP_1:REPO_TRAVERSAL) | Repository snapshot unavailable inside the Copilot session. | Documented resolution | No â€“ environment limitation | Run `tools/offline_repo_auditor.py` locally or attach the repo before auditing; the blocker is archived now that the workspace has direct file access.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L18ã€‘ |
| 2025-08-28T03:55:32Z | PH6: Run pre-commit | Hook execution failed because `yamllint`, `mdformat`, and `detect-secrets-hook` were missing. | Retired | No â€“ hooks removed | Active hook set only invokes local tools (ruff, black, mypy, pytest, git-secrets, license checker, etc.), so the missing CLIs no longer block automation.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L18ã€‘ |
| 2025-08-28T03:55:32Z | PH6: Run pytest with coverage | `pytest` rejected legacy `--cov=src/codex_ml` arguments. | Retired | No â€“ command updated | Coverage flags now target `src/codex` via nox helpers; the legacy failure mode is obsolete.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L18ã€‘ |
| 2025-08-28T03:55:32Z | PH6: Run pre-commit | `check-merge-conflicts` and ruff flagged merge markers / unused imports. | Retired | No â€“ tooling simplified | Hook set no longer includes `check-merge-conflicts`; lint remains covered by ruff/black.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L18ã€‘ |
| 2025-09-10T05:02:28Z; 2025-09-13 | `nox -s tests` | Coverage session failed because `pytest-cov` was missing. | Action required | No | Resolved by commit `f0a1d82`, which pins `pytest-cov==7.0.0`, enforces coverage flags in `noxfile.py`, and logs generated JSON artefacts for auditability.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L21ã€‘ |
| 2025-09-10T05:45:43Z; 08:01:19Z; 08:01:50Z; 08:02:00Z | Phase 4: `file_integrity_audit compare` | Compare step reported unexpected file changes. | Resolved | No â€“ gate clean | Allowlist now covers `.github/workflows.disabled/**`, validation manifests, and helper tooling; diff outputs are empty again.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L23ã€‘ |
| 2025-09-10T05:46:35Z; 08:02:12Z; 13:54:41Z; 2025-09-13 | Phase 6: pre-commit | `pre-commit` command missing in validation environment. | Action required | No | Commit `f0a1d82` pins `pre-commit==4.0.1`, verifies `pre-commit --version`, and records availability in `.codex/session_logs.db`.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L23ã€‘ |
| 2025-09-10T05:46:47Z; 08:02:25Z; 13:55:11Z; 2025-09-13 | Phase 6: pytest | Optional dependency gaps and locale issues caused failures. | Documented resolution | No | Tests now guard heavy integrations with `pytest.importorskip`, so suites skip cleanly when extras are absent.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L25ã€‘ |
| 2025-09-10T05:46:52Z; 07:14:07Z; 08:02:32Z | Phase 6 & Validation: MkDocs | Strict mode build failed (warnings/missing pages). | Mitigated / deferred | Deferred | MkDocs now runs with `strict: false`; keep docs healthy before re-enabling strictness.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L25ã€‘ |
| 2025-09-10T07:13:54Z; 11:12:28Z | Validation: pre-commit | `pre-commit` command not found. | Action required | No | Gate now verifies `pre-commit --version`; ledger entry marked complete.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L26ã€‘ |
| 2025-09-10T07:14:03Z; 11:12:36Z | Validation: pytest | Legacy coverage arguments rejected. | Retired | No â€“ command updated | Covered by coverage tooling update; rely on current pytest/nox configuration.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L26ã€‘ |
| 2025-09-10T08:01:17Z | Phase 4: `file_integrity_audit compare` | CLI invocation order incorrect. | Documented resolution | No â€“ documented | Follow `compare pre post --allow-*`; script rejects other orders.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L27ã€‘ |
| 2025-09-10 (`$ts`) | `tests_docs_links_audit` | Script crashed with `NameError: name 'root' is not defined`. | Documented resolution | No â€“ fixed | `analysis/tests_docs_links_audit.py` now initialises the repo root and exposes a CLI; audit passes locally.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L28ã€‘ |
| 2025-09-10T21:10:43Z; 2025-09-13 | Validation: nox | `nox` command not found. | Action required | No | Commit `f0a1d82` pins `nox==2025.5.1`, adds startup detection, and logs availability in `.codex/session_logs.db`.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L28ã€‘ |
| 2025-09-13 | Training CLI (`python -m codex_ml.cli train-model`) | `ModuleNotFoundError: No module named "torch"`. | Documented resolution | No | CLI now checks for torch, logs the issue, and instructs users to install `codex_ml[torch]`.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L29ã€‘ |
| Undated (Codex_Questions.md) | Metrics generation (`analysis_metrics.jsonl`) | `ModuleNotFoundError: No module named 'codex_ml.cli'`. | Documented resolution | No â€“ resolved | Use `codex.cli` and ensure editable installs/`PYTHONPATH` before generating metrics.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L29ã€‘ |
| 2025-09-17 | Training CLI (resume) | Resume workflows lacked discovery/documentation. | Documented resolution | No â€“ feature implemented | `CheckpointManager.load_latest` discovers latest checkpoints and the `--resume-from` flag is now documented across CLIs.ã€F:docs/status_update_outstanding_questions.mdâ€ L11-L30ã€‘ |

_Runtime and tooling dependencies are pinned in lock files; refresh them with `uv pip compile` / `uv lock` alongside `pyproject.toml` updates to prevent drift._ã€F:docs/status_update_outstanding_questions.mdâ€ L31-L37ã€‘
